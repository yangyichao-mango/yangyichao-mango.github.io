<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>antigeneral&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yangyichao-mango.github.io/"/>
  <updated>2021-04-04T12:18:10.181Z</updated>
  <id>https://yangyichao-mango.github.io/</id>
  
  <author>
    <name>yangyichao-mango</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深入浅出 | 全局一致性快照（一）</title>
    <link href="https://yangyichao-mango.github.io/2021/03/12/wechat-blog/apache-flink:state-1/"/>
    <id>https://yangyichao-mango.github.io/2021/03/12/wechat-blog/apache-flink:state-1/</id>
    <published>2021-03-12T06:21:53.000Z</published>
    <updated>2021-04-04T12:18:10.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-目录"><a href="#1-目录" class="headerlink" title="1.目录"></a>1.目录</h1><ol><li><p>什么是状态？<br>发散思维的去思考状态。我们所理解的状态不仅仅只限于 flink 的状态。让大家了解到状态是一个无处不在的东西</p></li><li><p>什么是全局一致性快照？和状态有什么关系？<br>全局一致性快照的一些生活、工作中应用的例子</p></li><li><p>为什么需要一致性快照？全局一致性快照和 flink 的关系？<br>jvm GC，分布式应用做故障恢复（比如 flink），死锁检测等</p></li><li><p>全局一致性快照的分布式应用举例<br>通过一个简单分布式应用介绍一下全局一致性状态是每时每刻都存在的。时间轴上的每一个时刻都存在一个全局一致性快照（类似拍照片）。flink 做 cp，sp，类似于每隔固定的时间从时间轴上的一个点拿出来这个时间点对应的一个全局一致性状态</p></li><li><p>全局一致性快照的标准定义<br>假如说有两个事件，a和b，在绝对时间下，如果a发生在b之前，且b被包含在快照当中，那么则a事件或者其对快照产生的影响也被包含在快照当中</p></li><li><p>怎么实现全局一致性快照？<br>同步去做，包括时钟同步、Stop-the-world，但是这两种方法都不可接受；<br>既然同步无法做，那如果异步能做出相同的全局一致性状态也可以</p></li><li><p>分布式应用的全局一致性快照其 Process 状态和 Channel状态到底需要记录什么？其之间需要满足什么关系的一些思考？<br>不是必须要在同一时刻嘛，为啥还能异步去做？只要异步做出来的状态和同步做出来的状态效果一致也可以。</p></li><li><p>Chandy-Lamport 算法流程、例子<br>介绍 Chandy-Lamport 算法流程并以一个例子介绍其执行过程</p></li><li><p>flink 实现的全局一致性快照介绍</p></li></ol><h1 id="2-什么是状态？（了解状态）"><a href="#2-什么是状态？（了解状态）" class="headerlink" title="2.什么是状态？（了解状态）"></a>2.什么是状态？（了解状态）</h1><p>目标：首先想让大家发散思维的去思考状态？我们所理解的状态不仅仅只限于 flink 的状态。让大家了解到状态是一个普遍存在的东西<br>定义：就是当前计算需要依赖到之前计算的结果，那么之前计算的结果就是状态<br>举例：</p><ol><li><p>比如生活中的例子：为什么我知道这个是电脑，因为眼睛接收到外界的图案，然后我的大脑接收到这个图案后，拿记忆中存储的图案进行对比，匹配得到这是电脑。那么记忆中存储的图案就是状态；日久生情等都存在状态</p></li><li><p>比如 web server 应用中的状态：打开 github 页面，列表展示了我的归属仓库。其中就是 web client 发了查询我的归属仓库请求，web server 接收到请求之后，然后去 mysql 中进行查询匹配返回。那么 mysql 中存储的内容就是状态<br><img src="/blog-img/apache-flink:state-1/1.png" alt="1"></p></li><li><p>比如 flink 应用中的状态：要去重，就要存储所有的 key；要获取当前最大值，那么历史最大值就是状态<br><img src="/blog-img/apache-flink:state-1/2.jpeg" alt="2"></p></li></ol><h1 id="3-什么是全局一致性快照？（了解全局一致性快照）"><a href="#3-什么是全局一致性快照？（了解全局一致性快照）" class="headerlink" title="3.什么是全局一致性快照？（了解全局一致性快照）"></a>3.什么是全局一致性快照？（了解全局一致性快照）</h1><p><strong>全局：代表是一个分布式的</strong><br><strong>一致性快照：代表绝对时间的同一时刻的状态</strong><br><strong>相当于打开上帝视角，去观察同一时刻的应用所有的状态</strong><br><strong>其实这里的快照 = 状态，文章之后我可能会把这两个词混用，大家明白他们的意思一致即可</strong></p><ol><li><p>比如生活中的例子：比如拍了一个照片，那么照片的内容就是当时的一个全局一致性快照；每一个首脑都是一个进程，所有的进程的状态在同一时刻的组合就是一个全局一致性快照<br><img src="/blog-img/apache-flink:state-1/3.png" alt="3"></p></li><li><p>比如分布式应用的例子：首先是一个分布式应用，它有多个进程分布在多个服务器上；其次，它在应用内部有自己的处理逻辑和状态；第三，应用间是可以互相通信的；第四，在这种分布式的应用，有内部状态，硬件可以通信的情况下；某一时刻的全局状态，就叫做全局的快照。</p></li></ol><p><strong>分布式应用某一时刻的全局一致性快照 = 各个 process 的本地状态 + channel 中正在传递的消息</strong><br><img src="/blog-img/apache-flink:state-1/4.png" alt="4"></p><h1 id="4-为什么需要一致性快照？全局一致性快照和-flink-的关系？"><a href="#4-为什么需要一致性快照？全局一致性快照和-flink-的关系？" class="headerlink" title="4.为什么需要一致性快照？全局一致性快照和 flink 的关系？"></a>4.为什么需要一致性快照？全局一致性快照和 flink 的关系？</h1><p><img src="/blog-img/apache-flink:state-1/5.png" alt="5"></p><h2 id="实时案例"><a href="#实时案例" class="headerlink" title="实时案例"></a>实时案例</h2><pre><code>- 做检查点（全局一致性快照）用来故障恢复，重点就在于我们不必要从历史起点开始重跑所有的数据；（1.kafka 不可能存储历史所有数据 2.重跑历史数据的情况下，时效性是达不到要求的）- 可以做任务的死锁检测</code></pre><p><img src="/blog-img/apache-flink:state-1/6.png" alt="6"></p><h1 id="6-全局一致性快照的分布式应用案例？"><a href="#6-全局一致性快照的分布式应用案例？" class="headerlink" title="6.全局一致性快照的分布式应用案例？"></a>6.全局一致性快照的分布式应用案例？</h1><p>通过一个简单分布式应用介绍一下全局一致性状态是每时每刻都存在的。时间轴上的每一个时刻都存在一个全局一致性快照（拍照片）。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>下面分布式应用的一个示例：<br><img src="/blog-img/apache-flink:state-1/7.jpeg" alt="7"><br><img src="/blog-img/apache-flink:state-1/8.jpeg" alt="8"><br><img src="/blog-img/apache-flink:state-1/9.jpeg" alt="9"><br><img src="/blog-img/apache-flink:state-1/10.jpeg" alt="10"></p><h2 id="每时每刻都存在全局一致性快照"><a href="#每时每刻都存在全局一致性快照" class="headerlink" title="每时每刻都存在全局一致性快照"></a>每时每刻都存在全局一致性快照</h2><p>上面这个只是四个时刻的四个快照，其实应用的每一个时刻都存在一个全局一致性快照。<br><img src="/blog-img/apache-flink:state-1/11.png" alt="11"></p><h1 id="7-全局一致性快照的标准定义"><a href="#7-全局一致性快照的标准定义" class="headerlink" title="7.全局一致性快照的标准定义"></a>7.全局一致性快照的标准定义</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>假如说有两个事件，a和b，在绝对时间下，如果a发生在b之前，且b被包含在快照当中，那么则a也被包含在快照当中。满足这个条件的全局快照，就称为全局一致性快照。<br><img src="/blog-img/apache-flink:state-1/12.png" alt="12"><br><img src="/blog-img/apache-flink:state-1/13.png" alt="13"></p><h2 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h2><p>就是如果将做了绝对时刻 T 的一个快照，那么这个绝对时刻 T 之前发生的所有事件以及其影响都会被包含在这个快照中</p><h1 id="8-怎么实现全局一致性快照？"><a href="#8-怎么实现全局一致性快照？" class="headerlink" title="8.怎么实现全局一致性快照？"></a>8.怎么实现全局一致性快照？</h1><h2 id="同步实现方式"><a href="#同步实现方式" class="headerlink" title="同步实现方式"></a>同步实现方式</h2><p><img src="/blog-img/apache-flink:state-1/14.jpeg" alt="14"></p><ul><li>NTP（<a href="https://baike.baidu.com/item/NTP%E6%9C%8D%E5%8A%A1%E5%99%A8/8633994?fr=aladdin）">https://baike.baidu.com/item/NTP%E6%9C%8D%E5%8A%A1%E5%99%A8/8633994?fr=aladdin）</a>: NTP服务器【Network Time Protocol（NTP）】是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源（如石英钟，GPS等等)做同步化，它可以提供高精准度的时间校正（LAN上与标准间差小于1毫秒，WAN上几十毫秒）<br>结论：无法实现</li><li>同步实现方式：Stop-The-World（<a href="https://www.jianshu.com/p/b210f9db19a3）">https://www.jianshu.com/p/b210f9db19a3）</a></li></ul><p>结论：不满足需求，无法采用</p><h2 id="异步实现方式"><a href="#异步实现方式" class="headerlink" title="异步实现方式"></a>异步实现方式</h2><p>如果同步实现方式不满足需求，那么能使用异步做到同步相同的快照也是可以满足需求的</p><ul><li>异步实现方式：chandy-lamport<br>论文：<a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/12/Determining-Global-States-of-a-Distributed-System.pdf?ranMID=24542&amp;ranEAID=J84DHJLQkR4&amp;ranSiteID=J84DHJLQkR4-mVoVymFnAblBx3zwyf98Pw&amp;epi=J84DHJLQkR4-mVoVymFnAblBx3zwyf98Pw&amp;irgwc=1&amp;OCID=AID2000142_aff_7593_1243925&amp;tduid=%28ir__1hs2uuow6wkfq3oxkk0sohzzwm2xpc33lxd0o6g200%29%287593%29%281243925%29%28J84DHJLQkR4-mVoVymFnAblBx3zwyf98Pw%29%28%29&amp;irclickid=_1hs2uuow6wkfq3oxkk0sohzzwm2xpc33lxd0o6g200">https://www.microsoft.com/en-us/research/uploads/prod/2016/12/Determining-Global-States-of-a-Distributed-System.pdf?ranMID=24542&amp;ranEAID=J84DHJLQkR4&amp;ranSiteID=J84DHJLQkR4-mVoVymFnAblBx3zwyf98Pw&amp;epi=J84DHJLQkR4-mVoVymFnAblBx3zwyf98Pw&amp;irgwc=1&amp;OCID=AID2000142_aff_7593_1243925&amp;tduid=%28ir__1hs2uuow6wkfq3oxkk0sohzzwm2xpc33lxd0o6g200%29%287593%29%281243925%29%28J84DHJLQkR4-mVoVymFnAblBx3zwyf98Pw%29%28%29&amp;irclickid=_1hs2uuow6wkfq3oxkk0sohzzwm2xpc33lxd0o6g200</a></li></ul><h1 id="9-分布式应用的全局一致性快照其-Process-状态和-Channel状态记录了什么？怎么记录-Channel-的状态？"><a href="#9-分布式应用的全局一致性快照其-Process-状态和-Channel状态记录了什么？怎么记录-Channel-的状态？" class="headerlink" title="9.分布式应用的全局一致性快照其 Process 状态和 Channel状态记录了什么？怎么记录 Channel 的状态？"></a>9.分布式应用的全局一致性快照其 Process 状态和 Channel状态记录了什么？怎么记录 Channel 的状态？</h1><h2 id="分布式应用要记录的状态"><a href="#分布式应用要记录的状态" class="headerlink" title="分布式应用要记录的状态"></a>分布式应用要记录的状态</h2><p>如下图案例 Single-Token conservation，是一个分布式应用，有 p 和 q 两个进程，p 可以通过 Channel pq（记为 Cpq） 向 q 发消息，q 可以通过 Channel qp（记为 Cqp） 向 p 发消息，其中有一个叫 token 的消息，在这个系统中一直不停的流转<br><img src="/blog-img/apache-flink:state-1/15.png" alt="15"></p><p>如之前所述，分布式应用的全局一致性快照包含 Process 状态和 Channel 状态<br>那么上图 Single-Token conservation 示例中的<br>全局一致性快照 S = S(p) + S(Cpq) + S(q) + S(Cqp)<br>其中：</p><ul><li>S：全局一致性快照</li><li>S(p)：p 进程的状态</li><li>S(Cpq)：p 进程到 q 进程的 Channel 状态</li><li>S(q)：q 进程的状态</li><li>S(Cqp)：q 进程到 p 进程的 Channel 状态</li></ul><p><img src="/blog-img/apache-flink:state-1/15.png" alt="15"></p><p>问题：<br>这里大家可能会提到一个问题：做全局一致性快照时，其中 S(p)，S(q) 好理解，但是 S(Cpq)，S(Cqp) 到底应该记录什么东西？接下来详细讲讲我的理解</p><h2 id="Process-状态应该记录什么内容？"><a href="#Process-状态应该记录什么内容？" class="headerlink" title="Process 状态应该记录什么内容？"></a>Process 状态应该记录什么内容？</h2><p>记录和用户业务需求相关的状态内容，用到了关于状态的地方，进行记录就好了<br>举例：uid 去重就存储历史所有的 uid 就可以了</p><h2 id="Channel-状态应该记录什么内容？"><a href="#Channel-状态应该记录什么内容？" class="headerlink" title="Channel 状态应该记录什么内容？"></a>Channel 状态应该记录什么内容？</h2><h3 id="一个全局一致性状态记录的-token-都在相同的地方"><a href="#一个全局一致性状态记录的-token-都在相同的地方" class="headerlink" title="一个全局一致性状态记录的 token 都在相同的地方"></a>一个全局一致性状态记录的 token 都在相同的地方</h3><h4 id="全局一致性快照"><a href="#全局一致性快照" class="headerlink" title="全局一致性快照"></a>全局一致性快照</h4><p>token 在 p 时，对应第一张图，这时的全局一致性快照为：<br>S(token-in-p) = S(p-token-in-p) + S(Cpq-token-in-p) + S(q-token-in-p) + S(Cqp-token-in-p) ；<br>其中：</p><ul><li>S(token-in-p)：token 在 p 时，做的全局一致性快照</li><li>S(p-token-in-p)：token 在 p 时，p 进程的状态</li><li>S(Cpq-token-in-p)：token 在 p 时，p 进程到 q 进程的 Channel 状态</li><li>S(q-token-in-p)：token 在 p 时，q 进程的状态</li><li>S(Cqp-token-in-p)：token 在 p 时，q 进程到 p 进程的 Channel 状态</li></ul><p>注意，上述这个表达式其实是结论，这个结论是很好理解的，但是你有想过站在实际应用的角度去思考怎样才能做一个实际快照时x下面的问题吗？</p><ul><li>问题1：为什么第一张图的全局一致性状态是 Process 和 Channel 做的快照都有 token-in-p 呢？<br>根据之前的拍照片的类比，当前这个绝对时刻做快照时，token 在 p；那么所有的 process 和 channel 记录状态时，token 都应该在 p。</li></ul><h3 id="S-Cpq-记录了什么内容？"><a href="#S-Cpq-记录了什么内容？" class="headerlink" title="S(Cpq) 记录了什么内容？"></a>S(Cpq) 记录了什么内容？</h3><h4 id="简单的理解"><a href="#简单的理解" class="headerlink" title="简单的理解"></a>简单的理解</h4><p>这里我们简单先理解下，S(Cpq) 其实就是在 S(p) 和 S(q) 自己的状态做成时，还在 Channel pq 之间发送的那些消息。</p><p>那么我们怎么用数学的方式理解 Cpq 记录的这些消息以及 Process 和 Channel 做状态时需要满足的条件呢？让我们往下看</p><h4 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h4><ul><li>n：在 p 的状态记录前，p 记录的 p 发往 Cpq 的 msg 数；</li><li>n′：在 Cpq 的状态记录前，Cpq 记录的 p 发往 Cpq 的 msg 数；</li><li>m：在 q 的状态记录前，q 记录的 q 从 Cpq 中接收到的 msg 数；</li><li>m′：在 Cpq 的状态记录前，Cpq 记录的 q 从 Cpq 中接收到的 msg 数；</li></ul><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>Cpq 记录 S(Cpq) 时，必然会有 n = n’ ≥ m = m’；<br>即一个 Channel 要记录的状态是，它 sender 记录自己状态之前它所接收到的 msg 列表，再减去 receiver 记录自己状态之前它已经收到的 msg 列表，减去的之后的数据列表就是还在通道中的数据列表，这个列表是需要 Channel 作为状态记录下来的。<br>而如果 n′=m′，那么 Channel c 中要记录的 msg 列表就是 empty 列表。如果 n′&gt;m′，那么要记录的列表是 (m′+1),…n′ 号消息对应的 msg 列表。</p><h4 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h4><p>首先是 n = n’，利用反证法：如果 n != n’，则会有两种情况：</p><ul><li>n &gt; n’ 时：<br>  ○ 可能会出现 n = 10（p 记录状态前，p 记录 p 发往 Cpq msg 数为 10（msg 编号 1 - 10））；<br>  ○ n’ = 7（Cpq 记录状态前，Cpq 记录 p 发往 Cpq 的 msg 数为 7（msg 编号 1 - 7））；<br>  ○ 那么假设 token 的编号为 9，就会出现 p 记录的状态为 S(p-token-in-Cpq)，Cpq 记录的状态为 S(p-token-in-p)，实际是不可能出现的；</li><li>n &lt; n’ 时：<br>  ○ 可能会出现 n = 7（p 记录状态前，p 记录 p 发往 Cpq msg 数为 7（编号 1 - 7））；<br>  ○ n’ = 10（Cpq 记录状态前，Cpq 记录 p 发往 Cpq 的 msg 数为 10（编号 1 - 10））；<br>  ○ 那么假设 token 的编号为 9，就会出现 p 记录的状态为 S(p-token-in-p)，Cpq 记录的状态为 S(p-token-in-Cpq)，实际是不可能出现的；</li><li>n = n’ 时：保障了无论什么情况下，只要 p 做出 S(p-token-in-p) 的状态时，因为 n = n’，代表 p 没有把 token 发出去，Cpq 也没有接受到 token，就能让 Cpq 也做出 S(Cpq-token-in-p)；</li></ul><p>然后是 m = m’，同样利用反证法</p><ul><li>m &gt; m’ 时：<br>  ○ 可能会出现 n = n’ = m &gt; m’，q 记录状态前，Cpq 记录 q 从 Cpq 接收到的 msg 数为 10（编号 1 - 10，因为 n = n’ = m 也即 Cpq 记录的 p 发往 Cpq 的那些 msg）；<br>  ○ Cpq记录状态前，Cpq 记录的 q 从 Cpq 接收到的 msg 数为 7（编号 1 - 7）；<br>  ○ 那么假设 token 的编号为 9，就会出现 Cpq 记录的状态为 S(Cpq-token-in-Cpq)，q 记录的状态为 S(q-token-in-p)，实际是不可能出现的；</li></ul><p>最后是 n′≥m′ and n≥m：在任何一种情况下，做全局一致性快照时，都会有 Cpq 下游接收到的 msg 数不可能超过 p 发送给 Channel 的 msg 条数，即：n′≥m′以及 n≥m（也可使用反证法证明）</p><h3 id="来段伪代码描述全局一致快照"><a href="#来段伪代码描述全局一致快照" class="headerlink" title="来段伪代码描述全局一致快照"></a>来段伪代码描述全局一致快照</h3><h4 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// S_all 即全局一致性快照</span></span><br><span class="line">S_all = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设总共有 x 个 process</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= x; i++) &#123;</span><br><span class="line"><span class="comment">// 第 i 个 process 的状态为 S_i，直接按照 += 写，勿喷</span></span><br><span class="line">  S_all += S_i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设总共有 y 个 channel</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= y; i++) &#123;</span><br><span class="line">  <span class="comment">// 1.S_C_out_in_i：第 i 个 channel 的状态，in 代表第 i 个 channel 的输入，out 含义为第 i 个 channel 的输出</span></span><br><span class="line">  <span class="comment">// 2.m_out_in_i 和 n_out_in_i 其实就是上文中的 n 和 m</span></span><br><span class="line">  <span class="comment">// 2.m_out_in_i：第 i 个 channel 做快照前，发往 in process（下游）的消息个数</span></span><br><span class="line">  <span class="comment">// 3.n_out_in_i：第 i 个 channel 做快照前，接受到 out process（上游） 的消息个数</span></span><br><span class="line">  <span class="comment">// 4.需要注意，每一个 channel 的 m_out_in_i 和 n_out_in_i 都可能是不一样的，这里是伪代码所以直接按照下面的方式写了</span></span><br><span class="line">  S_C_out_in_i = Message[m_out_in_i + <span class="number">1</span>] + ... + Message[n_out_in_i];</span><br><span class="line">  </span><br><span class="line">  S_all += S_C_out_in_i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 状态做完啦~</span></span><br></pre></td></tr></table></figure><h2 id="怎样去记录-S-Cpq-？"><a href="#怎样去记录-S-Cpq-？" class="headerlink" title="怎样去记录 S(Cpq)？"></a>怎样去记录 S(Cpq)？</h2><p>通过上面的分析，我们已经讨论得到了 S(Cpq) 都包含了什么内容，并且其之间要满足什么样的数学关系。但是在现实实际生活中，消息在 Channel 上乱飞时，我们是无法记录这些消息作为 Channel 的状态的。但是这些消息终究会到达目的地，我们可以在消息的目的地去记录这些消息作为 Channel 的状态。即我们可以在 q 中记录 Channel pq 的 S(Cpq)，在 p 中记录 Channel pq 的 S(Cqp)。</p><h3 id="伪代码-1"><a href="#伪代码-1" class="headerlink" title="伪代码"></a>伪代码</h3><p>顺便那么上面那段伪代码就可以简化为下面这样：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// S_all 即全局一致性快照</span></span><br><span class="line">S_all = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设总共有 x 个 process</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= x; i++) &#123;</span><br><span class="line">  <span class="comment">// S_i_all：第 i 个 process 要记录的状态</span></span><br><span class="line">  S_i_all = <span class="keyword">null</span>;</span><br><span class="line">  </span><br><span class="line"><span class="comment">// S_i：第 i 个 process 的状态</span></span><br><span class="line">  S_i_all += S_i; <span class="comment">// 【直接按照 += 写，勿喷】</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 第 i 个 process 总共有 y 个 input channel，即有 y 个上游 process，下文中 j 即指代第 j 个 channel，也代指 j channel 的上游 j process</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= y; j++) &#123;</span><br><span class="line">    <span class="comment">// 1.S_C_j_i：第 i 个 channel 的状态</span></span><br><span class="line">    <span class="comment">// 2.m_j_i 和 n_j_i 其实就是上文中的 n 和 m</span></span><br><span class="line">    <span class="comment">// 2.m_j_i：第 j 个 channel 做快照前，发往 i（下游）的消息个数</span></span><br><span class="line">    <span class="comment">// 3.n_j_i：第 j 个 channel 做快照前，接受到 j（上游） 的消息个数</span></span><br><span class="line">    <span class="comment">// 4.需要注意，每一个 channel 的 m_j_i 和 n_j_i 都可能是不一样的，这里是伪代码所以直接按照下面的方式写了</span></span><br><span class="line">    S_C_j_i = Message[m_j_i + <span class="number">1</span>] + ... + Message[n_j_i];</span><br><span class="line"></span><br><span class="line">    S_i_all += S_C_j_i;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  S_all += S_i_all;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 状态做完啦~</span></span><br></pre></td></tr></table></figure><h3 id="记录-S-Cpq-需要满足的条件"><a href="#记录-S-Cpq-需要满足的条件" class="headerlink" title="记录 S(Cpq) 需要满足的条件"></a>记录 S(Cpq) 需要满足的条件</h3><p>重点重点重点！！！<br>分析上面的伪代码后，我们可以发现，要得到 S_all，其中只有一个变量在进程做快照时不知道的，那就是 n_j_i（即第 i 个 channel 做快照前，接受到 j（上游） 的消息个数），别忘了 n = n‘，即也可以定义为 j 做快照前，j 发往 channel 的消息个数。那么实际上这个值 j process 是知道的，就代表 i 进程需要知道 j 告诉他 n_j_i 的值是多少。重点来了，当 i process 做完快照之后，直接发一个 marker 下去，这个 marker 不会对计算有任何影响（即不会对状态产生任何影响），marker 只是一个标识，j process 做完自己的快照之后，直到接收到 marker 之间的消息就是Channel ij 的状态。i 就是通过 marker 来告诉 j process n_j_i 的值是多少的。</p><h3 id="Chandy-Lamport-记录-Channel-状态中内容的方法"><a href="#Chandy-Lamport-记录-Channel-状态中内容的方法" class="headerlink" title="Chandy-Lamport 记录 Channel 状态中内容的方法"></a>Chandy-Lamport 记录 Channel 状态中内容的方法</h3><p>当消息在 Channel 上乱飞时，我们是无法记录这些消息作为 Channel 的状态的，但是这些消息终究会到达目的地，我们可以在消息的目的地去记录这些消息作为 Channel 的状态。<br>那么可以得到一个算子应该记录的状态就是自己的状态和 input Channel 的状态；</p><p>那么具体怎么做的？就是在发送数据中插入一条特殊的数据 —— marker 数据，这条数据不会对计算有任何影响，即不会对应用的状态有任何影响，只是一个标识；<br>q 在没有记录自己的状态时，接收到了 Cpq 传来的 marker，那么 q 就开始记录自己的状态，并且把 Cpq 记录为空；如果 q 已经记录了自己的状态，那么在收到 marker 之前从 Cpq 接收到 msg 列表就是 Cpq 的状态</p><h2 id="分布式应用全局一致性快照方法总结"><a href="#分布式应用全局一致性快照方法总结" class="headerlink" title="分布式应用全局一致性快照方法总结"></a>分布式应用全局一致性快照方法总结</h2><ol><li>有一个 manager process（这个 manager 可以是所有 process 中的任意一个 process，也可以是一个单独的中央管理者）告诉所有的 process 说可以开始做状态了；</li><li>所有 process 就开始记录自己本地的状态（非所有 input channel）了，记录完本地状态，然后发 marker 给下游所有的 channel，然后开始记录上游所有 input channel 的消息（直到接收到上游所有的 marker）；</li><li>每个 process 对于每一个 input channel，都将自己做完状态后直到收到 marker 之间的消息记录下来，作为这个 input channel 的状态；这里注意，其实每接收到一个消息，process 都是可以进行处理的，这和记录 input channel 的状态并不冲突。</li><li>当收到上游所有 marker 之后，这个 process 要记录的状态就全部得到了，然后告诉 manager process 说做完状态了；</li><li>manager process 接收到所有 process 做完的消息之后，就标记所有的状态以及完成了。</li></ol><h1 id="10-Chandy-Lamport-算法流程、示例"><a href="#10-Chandy-Lamport-算法流程、示例" class="headerlink" title="10.Chandy-Lamport 算法流程、示例"></a>10.Chandy-Lamport 算法流程、示例</h1><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p><img src="/blog-img/apache-flink:state-1/16.jpeg" alt="16"></p><h3 id="发起快照"><a href="#发起快照" class="headerlink" title="发起快照"></a>发起快照</h3><p><img src="/blog-img/apache-flink:state-1/17.png" alt="17"><br>解读：本次快照的起始点，先把起始点的快照给做了，然后发出 marker（这个 Marker 消息是干啥用的呢？？？），开始记录 input channel</p><h3 id="执行快照"><a href="#执行快照" class="headerlink" title="执行快照"></a>执行快照</h3><p><img src="/blog-img/apache-flink:state-1/18.jpeg" alt="18"><br><img src="/blog-img/apache-flink:state-1/19.jpeg" alt="19"><br>解读：</p><ul><li>Pi 记录本地快照，标记 Cki 为空：因为从 Cki 接收到了 marker，这时的状态是 Pk 刚刚做完快照，Pk 做完快照发往 Cki 的消息个数 = Pi 做完快照从 Cki 接收到的消息个数。即 n = n’ = m’ = m；即 Cki = [Empty]；</li><li>Pi 开始向所有 output Channle 发 marker，开始记录除 Cki 之外的 input channel 消息，因为本地快照已经做完了；然后上游还有部分进程没有做完快照，为了记录除 Cki 之外的 input Channel 消息，</li></ul><p>解读：结合前一张图说的开始记录 input channel 消息，Pi 停止记录 Cki 的消息，同时将此前记录所有 Cki 收到的消息作为本次快照中的最终状态；n’ &gt; m’，在 Pi 这里记录了 Cki 的状态，即 Cki = [m‘ + 1, m’ + 2…n]</p><h3 id="终止快照"><a href="#终止快照" class="headerlink" title="终止快照"></a>终止快照</h3><p><img src="/blog-img/apache-flink:state-1/20.jpeg" alt="20"></p><h2 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h2><p><img src="/blog-img/apache-flink:state-1/21.png" alt="21"><br><img src="/blog-img/apache-flink:state-1/22.png" alt="22"><br><img src="/blog-img/apache-flink:state-1/23.png" alt="23"><br><img src="/blog-img/apache-flink:state-1/24.png" alt="24"><br><img src="/blog-img/apache-flink:state-1/25.png" alt="25"><br><img src="/blog-img/apache-flink:state-1/26.png" alt="26"><br><img src="/blog-img/apache-flink:state-1/27.png" alt="27"><br><img src="/blog-img/apache-flink:state-1/28.png" alt="28"><br><img src="/blog-img/apache-flink:state-1/29.png" alt="29"></p><h1 id="11-flink-实现的全局一致性快照介绍（flink-容错机制）"><a href="#11-flink-实现的全局一致性快照介绍（flink-容错机制）" class="headerlink" title="11.flink 实现的全局一致性快照介绍（flink 容错机制）"></a>11.flink 实现的全局一致性快照介绍（flink 容错机制）</h1><h2 id="Chandy-Lamport与-Flink之间的关系"><a href="#Chandy-Lamport与-Flink之间的关系" class="headerlink" title="Chandy-Lamport与 Flink之间的关系"></a>Chandy-Lamport与 Flink之间的关系</h2><p>论文：<a href="https://arxiv.org/pdf/1506.08603.pdf">https://arxiv.org/pdf/1506.08603.pdf</a></p><p>Flink 是分布式系统，所以 Flink 会采用全局一致性快照的方式形成检查点，来支持故障恢复。Flink的异步全局一致性快照算法跟Chandy-Lamport算法的区别主要有以下几点：</p><ul><li>第一，Chandy-Lamput支持强连通图，而 Flink支持弱连通图；</li><li>第二，Flink采用的是裁剪的（Tailored）Chandy-Lamput异步快照算法；</li><li>第三，Flink的异步快照算法在DAG场景下不需要存储 Channel state，从而极大减少快照的存储空间。</li></ul><h2 id="flink-的容错机制"><a href="#flink-的容错机制" class="headerlink" title="flink 的容错机制"></a>flink 的容错机制</h2><p><img src="/blog-img/apache-flink:state-1/30.png" alt="30"></p><h2 id="端到端的Exactly-once"><a href="#端到端的Exactly-once" class="headerlink" title="端到端的Exactly once"></a>端到端的Exactly once</h2><p>Exactly once的意思是，作业结果总是正确的，但是很可能产出多次；所以它的要求是需要有可重放的source。<br>端到端的Exactly once，是指作业结果正确且只会被产出一次，它的要求除了有可重放的source外，还要求有事务型的sink和可以接收幂等的产出结果。</p><h2 id="flink-的全局一致性快照"><a href="#flink-的全局一致性快照" class="headerlink" title="flink 的全局一致性快照"></a>flink 的全局一致性快照</h2><p><img src="/blog-img/apache-flink:state-1/31.png" alt="31"><br><img src="/blog-img/apache-flink:state-1/32.png" alt="32"><br><img src="/blog-img/apache-flink:state-1/33.png" alt="33"></p><h2 id="Barrier-对齐"><a href="#Barrier-对齐" class="headerlink" title="Barrier 对齐"></a>Barrier 对齐</h2><p><img src="/blog-img/apache-flink:state-1/34.png" alt="34"><br><img src="/blog-img/apache-flink:state-1/35.png" alt="35"><br><img src="/blog-img/apache-flink:state-1/36.png" alt="36"></p><h2 id="状态后端"><a href="#状态后端" class="headerlink" title="状态后端"></a>状态后端</h2><h3 id="JVM-Heap"><a href="#JVM-Heap" class="headerlink" title="JVM Heap"></a>JVM Heap</h3><p><img src="/blog-img/apache-flink:state-1/37.png" alt="37"><br>第一种，JVM Heap，它里面的数据是以Java对象形式存在的，读写也是以对象形式去完成的，所以速度很快。但是也存在两个弊端：第一个弊端，以对象方式存储所需的空间是磁盘上序列化压缩后的数据大小的很多倍，所以占用的内存空间很大；第二个弊端，虽然读写不用做序列化，但是在形成snapshot时需要做序列化，所以它的异步snapshot过程会比较慢。</p><h3 id="RocksDB"><a href="#RocksDB" class="headerlink" title="RocksDB"></a>RocksDB</h3><p><img src="/blog-img/apache-flink:state-1/38.png" alt="38"><br>第二种，RocksDB，这个类型在读写时就需要做序列化，所以它读写的速度比较慢。但是它有一个好处，基于LSM的数据结构在快照之后会形成sst文件，它的异步checkpoint过程就是文件拷贝的过程，CPU消耗会比较低。</p>]]></content>
    
    <summary type="html">
    
      本系列每篇文章都是从实际生产触发，从 5W 角度帮助大家理解全局一致性快照，抛砖引玉，提高小伙伴的姿♂势水平。阅读时长大概 20 分钟，话不多说，直接进入正文！
    
    </summary>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/categories/Apache-Flink/"/>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/tags/Apache-Flink/"/>
    
  </entry>
  
  <entry>
    <title>实时数据时效监控体系建设</title>
    <link href="https://yangyichao-mango.github.io/2020/12/01/wechat-blog/apache-flink:realtime-time-monitor/"/>
    <id>https://yangyichao-mango.github.io/2020/12/01/wechat-blog/apache-flink:realtime-time-monitor/</id>
    <published>2020-12-01T06:21:53.000Z</published>
    <updated>2021-04-04T11:10:16.919Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列介绍了实时数据时效监控体系的建设。</p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>数据延迟为是实时数据的一个最大问题。<br>其实不管是哪部分产生延迟，最终的结果是都会直接影响到上层指标（数据质量问题 + 数据时效问题）。<br>为了方便我们在开发阶段，运维阶段快速定位、解决延迟导致的问题；<br>以及为后续可能的报警能力提供基础能力，因此需要建设实时数据流时效监控体系。</p><p>以一张图描述整个传输链路与耗时相关的问题。</p><p><img src="/blog-img/apache-flink:realtime-time-monitor/time-cost.png" alt="架构"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>上述图总共分为以下三部分。</p><ul><li><strong>数据延迟监控</strong></li><li><strong>数据乱序监控</strong></li><li><strong>数据加工延迟监控</strong></li></ul>]]></content>
    
    <summary type="html">
    
      本系列介绍了实时数据时效监控体系的建设。
    
    </summary>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/categories/Apache-Flink/"/>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/tags/Apache-Flink/"/>
    
  </entry>
  
  <entry>
    <title>生产实践 | Flink + 直播（三）| 如何建设当前正在直播 xx 数？</title>
    <link href="https://yangyichao-mango.github.io/2020/11/11/wechat-blog/apache-flink:realtime-live-stream-3/"/>
    <id>https://yangyichao-mango.github.io/2020/11/11/wechat-blog/apache-flink:realtime-live-stream-3/</id>
    <published>2020-11-11T06:21:53.000Z</published>
    <updated>2021-04-04T11:10:38.910Z</updated>
    
    <content type="html"><![CDATA[<h1 id="生产实践-Flink-直播（三）-如何建设当前正在直播-xx-数？"><a href="#生产实践-Flink-直播（三）-如何建设当前正在直播-xx-数？" class="headerlink" title="生产实践 | Flink + 直播（三）| 如何建设当前正在直播 xx 数？"></a>生产实践 | Flink + 直播（三）| 如何建设当前正在直播 xx 数？</h1><blockquote><p>本系列每篇文章都是从一些实际的 case 出发，分析一些生产环境中经常会遇到的问题，抛砖引玉，以帮助小伙伴们解决一些实际问题。本篇文章主要介绍直播间生产侧指标的建设过程，如果对小伙伴有帮助的话，欢迎点赞 + 再看~</p></blockquote><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>本文主要介绍<strong>生产侧指标的建设</strong>，比如当前正在直播直播间数，或者主播数等。在介绍生产侧指标的建设过程之前，我们先回顾下上一节的<strong>架构</strong>图。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-3/tec-arc.png" alt="架构"></p><p>而本篇要介绍的<strong>生产侧指标</strong>的数据链路主要对应以下几个模块。</p><ul><li>数据源：读取直播生产，比如开播，关播等 kafka 数据源日志；</li><li>数据处理：使用生产侧数据源 + 实时画像维表 + flink 建设生产侧实时指标；</li><li>数据汇：将处理完成的指标数据写入到 kafka 中。</li></ul><p>我用另一张图进行了标注，图中<strong>标红</strong>模块为生产侧指标的数据链路涉及到的模块。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-3/metric-prod-tec-arc.png" alt="生产侧架构"></p><p>其中直播间实时画像维表的介绍已经在上节进行了介绍，感兴趣的话可以点击以下链接，跳转到上节进行阅读~</p><p>本小节就不针对<strong>生产侧指标的建设</strong>中所有涉及指标的建设过程进行详细介绍了，我们主要以<strong>当前分钟正在开播直播间数</strong>作为<strong>生产侧指标建设</strong>的一个代表性案例，介绍这个指标的整个建设过程。<br>来为大家还原生产侧指标的业务过程以及技术方案。</p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><p>仍然从几个问题入手，介绍<strong>当前分钟正在开播直播间数</strong>的建设过程。</p><ul><li><strong>当前分钟正在开播直播间数</strong>的定义什么？业务过程是怎么样的？举例？</li><li>怎样去建设这个指标？整体的指标计算流程？</li></ul><h2 id="1-聊聊定义？"><a href="#1-聊聊定义？" class="headerlink" title="1.聊聊定义？"></a>1.聊聊定义？</h2><p>当前分钟正在开播直播间数，其定义就是整个平台中，当前分钟正在开播的直播间数 + 单层维度下钻的当前分钟正在开播的直播间数。</p><p>举例：</p><p>现在的时间点是 2020-11-11 12:42，真实直播的直播间数为 3000 个（平台维度下钻：IOS 平台为 1500，安卓平台为 1500）</p><p>到了 12:43 时，有 200 个直播间进行了关播（其中 100 个为 IOS，100 个为安卓），有 100 个直播间开播（全部为 IOS），则当前正在直播的直播间数为 2900（平台维度下钻：IOS 平台为 1500，安卓平台为 1400）。</p><p>其中 2020-11-11 12:42 的 3000 以及 2020-11-11 12:43 的 2900 以及按照平台下钻的数值就为当前时间正在开播的直播间数。</p><p>因此根据上述定义和分析，我们可以直接将数据源和数据汇的 schema 定义下来，主体信息如下。</p><h3 id="数据源-schema"><a href="#数据源-schema" class="headerlink" title="数据源 schema"></a>数据源 schema</h3><table><thead><tr><th>字段</th><th>备注</th></tr></thead><tbody><tr><td>live_stream_id</td><td>直播间 id</td></tr><tr><td>author_id</td><td>主播 id</td></tr><tr><td>start_or_end</td><td>开播还是关播</td></tr><tr><td>timestamp</td><td>时间戳</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><h3 id="数据汇-schema"><a href="#数据汇-schema" class="headerlink" title="数据汇 schema"></a>数据汇 schema</h3><table><thead><tr><th>字段</th><th>备注</th></tr></thead><tbody><tr><td>timestamp</td><td>时间戳，汇总到分钟粒度</td></tr><tr><td>metric_name</td><td>指标名，举例：开播直播间数</td></tr><tr><td>metric_value</td><td>指标值，举例：3000（开播直播间数）</td></tr><tr><td>dim_name</td><td>维度名，举例：平台，版本</td></tr><tr><td>dim_value</td><td>维度值，举例：IOS，8.1</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><blockquote><p>Notes:</p><p><strong>metric_name 和 metric_value</strong>：</p><p>这两个字段是为了之后进行指标扩充时进行的设计。比如后续如果需要加入开播主播数，开播时长等指标，不用修改数据汇 schema，只需要加一种 metric_name，就可以使用原有 schema 进行数据产出。</p><p><strong>dim_name 和 dim_value</strong>：</p><p>目前我们建设的指标只提供了进行单维度下钻的能力，所以设计了 dim_name 和 dim_value 两个字段，可满足用户查看平台为 IOS 的当前开播直播间数或者使用开播软件版本为 8.1 的当前开播直播间数。<br>如果后续业务场景需要多维下钻能力，可以在字段上面进行扩充。或者也可以提供明细数据在 OLAP 中进行多维下钻。</p></blockquote><h2 id="2-怎样建设？"><a href="#2-怎样建设？" class="headerlink" title="2.怎样建设？"></a>2.怎样建设？</h2><p>对于当前分钟正在开播直播间数来说，其计算方式很简单，就是下面这个数学公式：</p><p><strong>当前分钟正在开播直播间数</strong> = <strong>上一分钟正在开播直播间数</strong> + <strong>当前分钟开播直播间数</strong> - <strong>当前分钟关播直播间数</strong></p><p>可以从上面的公式可以看出，对于当前分钟正在开播直播间数的计算来说，是依赖上下文信息的，即<strong>上一分钟正在开播直播间数</strong>，这也就是我们所说的<strong>状态</strong>。</p><h3 id="指标处理逻辑"><a href="#指标处理逻辑" class="headerlink" title="指标处理逻辑"></a>指标处理逻辑</h3><p>从获取到数据源，到产出指标的整体处理逻辑如下图所示。这里就不进行赘述了。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-3/metric-current-live-live-stream-number-life-cycle.png" alt="技术架构"></p><p>其中标为<strong>粉色</strong>的模块为任务中的<strong>状态</strong>，即任务中一直存储的当前分钟正在开播直播间数。</p><h3 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h3><p>上述指标涉及到了，状态，那么我这里讲一下我对<strong>状态</strong>的理解。如有错误，请在文末讨论中进行指出，我会和大家讨论。</p><p>状态其实就是一个记录上下文信息的东西，如果当前的计算过程依赖到上次计算的结果，那么上次计算的结果就是状态。举几个🌰；</p><ul><li><p><strong>流处理</strong>：如本节介绍的<strong>当前分钟正在开播直播间数</strong>的计算，就是依赖上一分钟的正在开播直播间数（状态）进行的计算。<br>可能有小伙伴会说，我不依赖上一分钟，我从头开始计算可以不？答案是可以的，但是从头开始计算，也需要将所有历史数据进行存储，这些历史数据其实也就是状态，只不过我们将其优化为了上一分钟开播直播间数。</p></li><li><p><strong>批处理</strong>：今天的全量表 = 昨天全量表（状态） + 今天的增量表。</p></li><li><p><strong>数据库存储</strong>：最常见的 mysql 主键自增，unique key 等。<br>为什么新插入一条数据主键会自增？因为 mysql 存储了主键的上一个值（状态）。<br>为什么插入相同数据时，由于 unique key 会导致报错，就是因为 mysql 存储了所有 unique key 的字段的数据（状态）。</p></li><li><p><strong>生活</strong>：当前的手机电量 = 上一分钟的手机电量（状态） + （充电/用电量）。<br>为什么你越来越喜欢你的另一半？因为你对她的感觉 = 前一秒你对她的感觉（状态） + 当前这一秒她亲了你一下。</p></li></ul><p>生活中随处可见状态，即使你不是程序员，我相信也都可以理解状态的概念。</p><h3 id="指标计算代码示例"><a href="#指标计算代码示例" class="headerlink" title="指标计算代码示例"></a>指标计算代码示例</h3><p>按照最简单的实现方式举例如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LiveStreamRealtimeMetricProdProcessorJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataStream&lt;SourceModel&gt; source = SourceFactory.getSourceDataStream(...);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;SinkModel&gt; result = source</span><br><span class="line">                .keyBy(<span class="keyword">new</span> KeySelector&lt;SourceModel, Long&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Long <span class="title">getKey</span><span class="params">(SourceModel commonModel)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> commonModel.getLiveStreamId() % <span class="number">1000</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">                .timeWindow(Time.seconds(<span class="number">60</span>))</span><br><span class="line">                .process(<span class="keyword">new</span> ProcessWindowFunction&lt;SourceModel, SinkModel, Long, TimeWindow&gt;() &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">private</span> ValueState&lt;Long&gt; playingLiveStreamNumberValueState;</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">                        <span class="keyword">this</span>.playingLiveStreamNumberValueState = getRuntimeContext().getState(...);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Long bucket, Context context, Iterable&lt;SourceModel&gt; iterable,</span></span></span><br><span class="line"><span class="function"><span class="params">                            Collector&lt;SinkModel&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        Long playingLiveStreamNumber = <span class="keyword">this</span>.playingLiveStreamNumberValueState.value();</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> (<span class="keyword">null</span> == playingLiveStreamNumber) &#123;</span><br><span class="line">                            playingLiveStreamNumber = <span class="number">0L</span>;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        List&lt;SourceModel&gt; sourceModels = (List&lt;SourceModel&gt;) iterable;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span> (SourceModel sourceModel : sourceModels) &#123;</span><br><span class="line">                            <span class="keyword">if</span> (BizType.I == sourceModel.getBizType()) &#123;</span><br><span class="line">                                playingLiveStreamNumber++;</span><br><span class="line">                            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                playingLiveStreamNumber--;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">this</span>.playingLiveStreamNumberValueState.update(playingLiveStreamNumber);</span><br><span class="line"></span><br><span class="line">                        collector.collect(</span><br><span class="line">                                SinkModel.builder().build()</span><br><span class="line">                        );</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">        SinkFactory.setSinkDataStream(...);</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Data</span></span><br><span class="line">    <span class="meta">@Builder</span></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SourceModel</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 直播间id</span></span><br><span class="line">        <span class="keyword">private</span> Long liveStreamId;</span><br><span class="line">        <span class="comment">// 开播时间，关播时间</span></span><br><span class="line">        <span class="keyword">private</span> Long time;</span><br><span class="line">        <span class="comment">// 主播id</span></span><br><span class="line">        <span class="keyword">private</span> Long authorId;</span><br><span class="line">        <span class="comment">// binlog 时间戳</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">long</span> binlogTimestamp;</span><br><span class="line">        <span class="comment">// 开播，关播</span></span><br><span class="line">        <span class="keyword">private</span> BizType bizType;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">BizType</span> </span>&#123;</span><br><span class="line">        I, <span class="comment">// 开播</span></span><br><span class="line">        D, <span class="comment">// 关播</span></span><br><span class="line">        ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Data</span></span><br><span class="line">    <span class="meta">@Builder</span></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SinkModel</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 时间戳，汇总到分钟粒度</span></span><br><span class="line">        <span class="keyword">private</span> Long timestamp;</span><br><span class="line">        <span class="comment">// 指标名</span></span><br><span class="line">        <span class="keyword">private</span> String metricName;</span><br><span class="line">        <span class="comment">// 指标值</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">double</span> metricValue;</span><br><span class="line">        <span class="comment">// 维度名</span></span><br><span class="line">        <span class="keyword">private</span> String dimName;</span><br><span class="line">        <span class="comment">// 维度值</span></span><br><span class="line">        <span class="keyword">private</span> String dimValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文衔接上文，主要介绍直播间<strong>生产侧指标的建设</strong>，以<strong>当前分钟正在开播直播间数</strong>为代表举例。提出定义以及建设过程相关的问题，以这两个个问题出发，引出了以下两小节。</p><p>第一节简单介绍了当前分钟正在开播直播间数的定义。</p><p>第二节主要介绍了当前分钟正在开播直播间数的建设逻辑以及过程，并对<strong>状态</strong>这个概念进行了一个拓展介绍。</p><p>最后一节对本文进行了总结。</p><p>如果你也有相同的指标建设需求，或者存在一些指标建设过程中的问题，欢迎关注博主公众号，或者添加博主微信，互相交流~</p><p>记得点赞 + 再看喔~</p>]]></content>
    
    <summary type="html">
    
      本系列每篇文章都是从一些实际的 case 出发，分析一些生产环境中经常会遇到的问题，抛砖引玉，以帮助小伙伴们解决一些实际问题。本篇文章主要介绍直播间生产侧指标的建设过程，如果对小伙伴有帮助的话，欢迎点赞 + 再看~
    
    </summary>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/categories/Apache-Flink/"/>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/tags/Apache-Flink/"/>
    
  </entry>
  
  <entry>
    <title>生产实践 | Flink + 直播（二）| 如何建设实时公共画像维表？</title>
    <link href="https://yangyichao-mango.github.io/2020/11/02/wechat-blog/apache-flink:realtime-live-stream-2/"/>
    <id>https://yangyichao-mango.github.io/2020/11/02/wechat-blog/apache-flink:realtime-live-stream-2/</id>
    <published>2020-11-02T06:21:53.000Z</published>
    <updated>2021-04-04T11:11:38.241Z</updated>
    
    <content type="html"><![CDATA[<h1 id="生产实践-Flink-直播（二）-如何建设实时公共画像维表？"><a href="#生产实践-Flink-直播（二）-如何建设实时公共画像维表？" class="headerlink" title="生产实践 | Flink + 直播（二）| 如何建设实时公共画像维表？"></a>生产实践 | Flink + 直播（二）| 如何建设实时公共画像维表？</h1><blockquote><p>本系列每篇文章都是从一些实际生产实践需求出发，解决一些生产实践中的问题，抛砖引玉，以帮助小伙伴们解决一些实际生产问题。本篇文章主要介绍直播间画像实时维表建设的整个过程，如果对小伙伴有帮助的话，欢迎点赞 + 再看~</p></blockquote><h2 id="技术架构"><a href="#技术架构" class="headerlink" title="技术架构"></a>技术架构</h2><p>回顾上一节的<strong>技术架构</strong>图。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-2/tec-arc.png" alt="技术架构"></p><p>整个架构相对来说是比较好理解的。从数据源到数据处理以及最后到数据汇部分。</p><p>但是大家的疑惑点可能就集中在三个维表的建设上，包含<strong>主播用户画像维表，观众用户画像维表，直播间画像维表</strong>。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-2/dim-tec-arc.png" alt="技术架构"></p><p>我们依然从以下几个角度的问题出发，通过分析场景，解答这几个问题来给大家介绍以上三个维表的建设过程。</p><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><ul><li><strong>WHAT：直播实时公共画像维表是指什么？离线公共画像维表又指什么？区别？</strong></li><li><strong>WHY：为什么架构图中的三类公共画像维表要按照实时和离线进行划分？为什么需要建设实时公共画像维表，离线公共画像维表不能满足需求？</strong></li><li><strong>HOW：怎样才能建设满足直播实时数据的实时公共画像维表？</strong></li><li><strong>WHO：需要使用什么样的组件建设直播实时公共画像维表？为什么选用这些组件进行建设？</strong></li></ul><h2 id="WHAT：实时-amp-离线公共画像维表？"><a href="#WHAT：实时-amp-离线公共画像维表？" class="headerlink" title="WHAT：实时 &amp; 离线公共画像维表？"></a>WHAT：实时 &amp; 离线公共画像维表？</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>首先简单介绍下，<strong>实时 &amp; 离线公共画像维表</strong>中存储的内容就是实体的固有属性（比如用户的年龄等），我理解这两个词本身是高层抽象的概念，本文中介绍的<strong>主播用户画像维表，观众用户画像维表，直播间画像维表</strong>是其具体实现。</p><p>其他大佬的文章解释中会对<strong>实时公共画像维表</strong> &amp; <strong>离线公共画像维表</strong>有更加深度的理解，这里我只说明我在直播实时数据建设过程中的理解~</p><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p>其实这两个词的区别从名字上就可以区分出来，实时公共画像维表和离线公共画像维表的最大区别就是数据建设和应用场景要求的时效性不同。</p><h3 id="离线公共画像维表"><a href="#离线公共画像维表" class="headerlink" title="离线公共画像维表"></a>离线公共画像维表</h3><p>特点：</p><ul><li><strong>场景</strong>：适合离线场景，<strong>时效性要求比较弱</strong>的场景，为指标提供画像维度填充或者打标服务</li><li><strong>建设</strong>：一般都是以离线 t + 1 的方式进行建设</li><li><strong>应用</strong>：使用的数据为离线 t + 1 的数据</li><li><strong>举例</strong>：数据仓库中的用户画像维表，为应用层数据提供画像服务；比如不但需要统计总 uv，还需要统计分年龄段的 uv。</li></ul><h3 id="实时公共画像维表"><a href="#实时公共画像维表" class="headerlink" title="实时公共画像维表"></a>实时公共画像维表</h3><p>特点：</p><ul><li><strong>场景</strong>：适合实时场景，<strong>时效性要求比较强</strong>的场景，为指标提供画像维度填充或者打标服务</li><li><strong>建设</strong>：实时的进行建设，延迟一般在秒级别</li><li><strong>应用</strong>：使用的数据都是实时建设好的，必须可以实时获取（秒级别延迟后获取到）并使用</li></ul><h2 id="WHY：为什么建设实时公共画像维表？"><a href="#WHY：为什么建设实时公共画像维表？" class="headerlink" title="WHY：为什么建设实时公共画像维表？"></a>WHY：为什么建设实时公共画像维表？</h2><p>为什么架构图中的三类公共画像维表要按照实时和离线进行划分？为什么需要建设实时公共画像维表，离线公共画像维表不能满足需求？</p><p>这几个问题其实围绕着我们的直播实时数据建设以及应用的场景就可以展开解答。</p><p>接上篇技术架构图，其中直播实时数据需要建设的公共维表分为以下三类：</p><ul><li><strong>直播间画像维表</strong>：包含直播对应的直播类别、开播客户端、标题、开播地址等信息</li><li><strong>主播画像维表</strong>：主播对应的主播名、主播类别、性别、年龄段等</li><li><strong>观众画像维表</strong>：观众对应的观众性别、年龄段等</li></ul><h3 id="直播间画像维表"><a href="#直播间画像维表" class="headerlink" title="直播间画像维表"></a>直播间画像维表</h3><p>首先抛出结论：<strong>直播间画像都是直播间的固有属性画像，直播间画像维表的建设过程是实时的</strong>。</p><p>由于大多数直播的时长都在几小时不等，随着直播的开始，主播域观众的互动也随即产生，从而直播生产和消费的指标也开始产出，随着直播的结束，主播和观众的互动也就结束了，对应的直播生产和消费指标也就不存在了，因此直播间画像的所能提供给其他指标作为维表的价值也就快速消失了，所以直播间画像（标题，开播地址）的应用场景特点就是<strong>时效性很强</strong>。<br>因此直播间画像维表对于直播生产消费指标的建设和应用来说，需要满足可实时建设、可实时查询获取的要求。</p><h3 id="主播-amp-观众用户画像维表"><a href="#主播-amp-观众用户画像维表" class="headerlink" title="主播 &amp; 观众用户画像维表"></a>主播 &amp; 观众用户画像维表</h3><p>结论：<strong>这类画像都是用户的固有属性画像，而非直播间固有属性，和直播间是非强相关的。主播 &amp; 观众用户画像维表的建设过程可以是离线的</strong>。</p><p>无论直播间的开播关播，直播过程中的生产消费，主播画像和观众画像基本上不会产生变动。<br>（举例：大多数情况下，当已经判定一个用户的年龄段画像为 18 - 23 时，即使这个用户开了 10 场直播，或者这个用户观看了 10 场直播，其年龄段判定也基本不会有变化）。<br>因此主播用户画像维表 &amp; 观众用户画像维表对于直播生产消费指标的建设和应用来说，可以满足离线 t + 1 建设，提供数据服务进行实时获取的要求。</p><blockquote><p>Notes：</p><p>主播 &amp; 观众用户画像需要根据用户生产消费行为以及其他信息，使用到机器学习进行性别和年龄段等的用户画像信息判定产出。<br>也有非常多的场景将这类画像进行实时建设，用于实时个性化推荐等。只不过本文的直播实时数据建设对于这两类画像的时效性要求较弱，所以采用了离线的方式进行建设。</p></blockquote><h2 id="HOW-WHO：怎样建设？用什么建设？"><a href="#HOW-WHO：怎样建设？用什么建设？" class="headerlink" title="HOW + WHO：怎样建设？用什么建设？"></a>HOW + WHO：怎样建设？用什么建设？</h2><h3 id="直播间生命周期-amp-数据流转"><a href="#直播间生命周期-amp-数据流转" class="headerlink" title="直播间生命周期 &amp; 数据流转"></a>直播间生命周期 &amp; 数据流转</h3><p>直播间整个生命周期如图所示。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-2/live-stream-life-cycle.png" alt="生命周期"></p><ul><li>1.主播创建直播间，直播间进入开播的状态；</li><li>2.观众进入直播间后，在直播间内与主播进行互动；</li><li>3.最后就是主播对直播间进行关播，标识着直播间生命周期的结束状态。</li></ul><h3 id="直播间画像维表-实时"><a href="#直播间画像维表-实时" class="headerlink" title="直播间画像维表-实时"></a>直播间画像维表-实时</h3><p>实时画像维表的建设。上图中<strong>红色</strong>的字体为实时画像维表的建设和应用过程。</p><h4 id="直播间画像实时数据流转"><a href="#直播间画像实时数据流转" class="headerlink" title="直播间画像实时数据流转"></a>直播间画像实时数据流转</h4><ul><li>1.当主播开播，直播间进行直播后，直播间产生了直播间画像信息，这时可以将画像信息实时的建设到直播间画像实时维表中。<br>并且可以同时建设生产侧的实时指标，利用建设好的<strong>直播间画像实时维表 + 主播 &amp; 观众画像离线维表</strong>进行生产侧指标的维度填充；</li><li>2.当观众进入直播间后，与主播进行互动，产生一系列的消费行为，随即可以建设消费侧的实时指标，利用建设的<strong>直播间画像实时维表 + 主播 &amp; 观众画像离线维表</strong>进行消费侧指标的维度填充；</li><li>3.当主播对直播间进行关播的时候，从直播间画像实时维表中就可以对该直播间的画像进行删除。</li></ul><h4 id="组件选型"><a href="#组件选型" class="headerlink" title="组件选型"></a>组件选型</h4><p>通过上文的分析，可以了解到直播间画像实时维表建设的要求如下：</p><ul><li>实时画像：首先需要支持实时建设，实时访问；</li><li>实时画像：建设的数据都为实时指标，即要求低延迟的请求响应时间；</li><li>公共画像：需要支撑多个大流量生产消费实时任务的访问请求，即提供高 QPS 画像数据服务；</li><li>公共画像：高稳定性。</li></ul><p>因此组件选型就自然落在了高速缓存的范畴中，我们最后经过方案对比之后，选择了 redis 作为我们的实时维表的存储引擎。</p><p>使用了 redis 中的 hash 作为维表存储结构，其中直播间画像维度存储设计如下图。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-2/live-stream-dim-redis-hash.png" alt="维度存储"></p><h4 id="flink-实时维表建设代码示例"><a href="#flink-实时维表建设代码示例" class="headerlink" title="flink 实时维表建设代码示例"></a>flink 实时维表建设代码示例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LiveStreamRealtimeDimBuilderJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataStream&lt;<span class="keyword">byte</span>[]&gt; source = SourceFactory.getSourceDataStream();</span><br><span class="line">        source.process(<span class="keyword">new</span> ProcessFunction&lt;<span class="keyword">byte</span>[], String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(<span class="keyword">byte</span>[] bytes, Context context, Collector&lt;String&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                CommonModel c = CommonModel.parseFrom(bytes);</span><br><span class="line">                <span class="comment">// 开播</span></span><br><span class="line">                <span class="keyword">if</span> (c.isStartLiveStream()) &#123;</span><br><span class="line">                    RedisConfig</span><br><span class="line">                            .get()</span><br><span class="line">                            .hmset(c.getLiveStreamId()</span><br><span class="line">                                    , ImmutableMap.&lt;String, String&gt;builder()</span><br><span class="line">                                            .put(<span class="string">&quot;type&quot;</span>, c.getType())</span><br><span class="line">                                            .put(<span class="string">&quot;client&quot;</span>, c.getClient())</span><br><span class="line">                                            .put(<span class="string">&quot;title&quot;</span>, c.getTitle())</span><br><span class="line">                                            .put(<span class="string">&quot;address&quot;</span>, c.getAddress())</span><br><span class="line">                                            .build()</span><br><span class="line">                            );</span><br><span class="line">                    RedisConfig</span><br><span class="line">                            .get()</span><br><span class="line">                            .expire(c.getLiveStreamId(), <span class="number">30</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (c.isEndLiveStream()) &#123;</span><br><span class="line">                <span class="comment">// 关播</span></span><br><span class="line">                    RedisConfig</span><br><span class="line">                            .get()</span><br><span class="line">                            .expire(c.getLiveStreamId(), <span class="number">2</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Data</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CommonModel</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String liveStreamId; <span class="comment">// 直播间 id</span></span><br><span class="line">        <span class="keyword">private</span> String type; <span class="comment">// 直播间类型</span></span><br><span class="line">        <span class="keyword">private</span> String client; <span class="comment">// 开播客户端</span></span><br><span class="line">        <span class="keyword">private</span> String title; <span class="comment">// 直播间标题</span></span><br><span class="line">        <span class="keyword">private</span> String address; <span class="comment">// 直播间开播地址</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CommonModel <span class="title">parseFrom</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 逻辑根据业务逻辑判定</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isStartLiveStream</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 逻辑根据业务逻辑判定</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEndLiveStream</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 逻辑根据业务逻辑判定</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="主播-amp-观众用户画像维表-离线"><a href="#主播-amp-观众用户画像维表-离线" class="headerlink" title="主播 &amp; 观众用户画像维表-离线"></a>主播 &amp; 观众用户画像维表-离线</h3><p>离线画像维表的建设。主要包含主播和观众的用户画像，性别，年龄等信息。如下图<strong>蓝色</strong>的字体为离线画像维表的应用过程。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-2/live-stream-life-cycle.png" alt="生命周期"></p><h4 id="主播-amp-观众画像数据流转"><a href="#主播-amp-观众画像数据流转" class="headerlink" title="主播 &amp; 观众画像数据流转"></a>主播 &amp; 观众画像数据流转</h4><p>在产出直播间生产侧、消费侧实时数据时，使用主播 &amp; 观众画像进行了画像维度填充。</p><h4 id="存储组件"><a href="#存储组件" class="headerlink" title="存储组件"></a>存储组件</h4><p>其中离线画像维表的存储组件选型与实时相同，同为 redis，画像信息存储方式也是使用 redis hash 结构进行存储。</p><p>以 t + 1 的方式进行画像数据建设并进行数据同步，将建设好的全量主播和观众用户画像同步到 redis 高速缓存当中。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文衔接上文，主要介绍直播间实时维表的建设过程。提出几个建设的问题，以这几个问题出发，引出了一下三小节。</p><p>第一节简单介绍了实时 &amp; 离线公共画像维表的概念。</p><p>第二节从数据应用场景的角度出发，介绍了为什么需要建设实时的公共画像维表。</p><p>第三节主要介绍了实时画像维表的建设过程以及详细的技术方案。</p><p>最后一节对本文进行了总结。</p><p>如果你也建设过实时画像维表，或者有相同的需求，欢迎留言或者留下你的文章链接，相互交流~</p>]]></content>
    
    <summary type="html">
    
      本系列每篇文章都是从一些实际生产实践需求出发，解决一些生产实践中的问题，抛砖引玉，以帮助小伙伴们解决一些实际生产问题。本篇文章主要介绍直播间画像实时维表建设的整个过程，如果对小伙伴有帮助的话，欢迎点赞 + 再看~
    
    </summary>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/categories/Apache-Flink/"/>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/tags/Apache-Flink/"/>
    
  </entry>
  
  <entry>
    <title>生产实践 | 基于 Flink 的直播实时数据建设 （一）| 需求和架构篇</title>
    <link href="https://yangyichao-mango.github.io/2020/10/12/wechat-blog/apache-flink:realtime-live-stream-1/"/>
    <id>https://yangyichao-mango.github.io/2020/10/12/wechat-blog/apache-flink:realtime-live-stream-1/</id>
    <published>2020-10-12T06:21:53.000Z</published>
    <updated>2021-04-04T11:09:09.227Z</updated>
    
    <content type="html"><![CDATA[<h1 id="生产实践-基于-Flink-的直播实时数据建设-（一）-需求和架构篇"><a href="#生产实践-基于-Flink-的直播实时数据建设-（一）-需求和架构篇" class="headerlink" title="生产实践 | 基于 Flink 的直播实时数据建设 （一）| 需求和架构篇"></a>生产实践 | 基于 Flink 的直播实时数据建设 （一）| 需求和架构篇</h1><blockquote><p>本系列每篇文章都是从一些实际生产实践需求出发，解决一些生产实践中的问题，抛砖引玉，以帮助小伙伴们解决一些实际生产问题。相信大家或多或少都观看过直播，那大家有没有想过，如果自己负责建设公司内整体直播实时数据，会怎样去建设呢？本系列文章主要介绍直播实时数据建设的整个过程，如果对小伙伴有帮助的话，欢迎点赞 + 再看~</p></blockquote><h2 id="首先思考几个问题"><a href="#首先思考几个问题" class="headerlink" title="首先思考几个问题"></a>首先思考几个问题</h2><ul><li><strong>WHAT：相信大家或多或少都观看过直播，甚至自己就是一名主播或负责的业务就是直播相关的，那大家有没有思考过，在直播业务场景中，你最关心什么指标以及需要关注、建设什么数据？</strong></li><li><strong>WHY：为什么需要建设直播实时数据？离线建设不能满足吗？</strong></li><li><strong>HOW：直播实时数据怎样赋能业务的？怎样根据公司直播场景的需求去划分直播实时数据？怎样去建设直播实时数据体？</strong></li><li><strong>WHO：在建设直播实时数据的过程中，需要使用什么样的组件进行建设？每个组件都负责哪一部分？</strong></li></ul><p>让我们带着以上几个问题出发~</p><h2 id="直播-短视频，内容运营的下一个战场"><a href="#直播-短视频，内容运营的下一个战场" class="headerlink" title="直播 + 短视频，内容运营的下一个战场"></a>直播 + 短视频，内容运营的下一个战场</h2><p>随着互联网络技术的发展，网络直播受到越来越多人的关注，直播在经过几年前的喷涌式大爆发之后，近段时间热度有所降低。内容的同质化和变现困难是直播现在面临的主要问题，随着移动终端普及和网络的提速，短视频以短平快的大流量传播方式快速获得各大平台、粉丝和资本的青睐，所以众多直播软件开始接入短视频的功能。<br>同时，一些以短视频为主发展起来的 app 也在软件中加入了直播功能，直播和短视频两者互相弥补不足，相辅相成，给用户带来了更好的使用体验，也给各大平台带来更多的流量，”直播 + 短视频”的模式已经也成为新的发展趋势。</p><p>本系列文章主要围绕着直播实时数据建设而展开。本文是本系列文章的的第一篇，需求和架构篇，主要分为三个部分，按顺序为<strong>WHY - WHAT - HOW</strong>，以这三个角度出发，解答开头提出的三个问题，其中 <strong>WHO</strong>部分在本系列文章的后续建设细节章节进行介绍！</p><h2 id="WHY：为什么建设直播实时数据？"><a href="#WHY：为什么建设直播实时数据？" class="headerlink" title="WHY：为什么建设直播实时数据？"></a>WHY：为什么建设直播实时数据？</h2><p>相比短视频的生产消费来说，直播的主播和观看直播的观众的纽带都是在直播间建立的，相互之间的互动行为也都只在直播间内产生，并且通常情况下，一场直播的时长也就在几个小时之内，因此直播的生产消费时效性相比短视频会更强，因而直播数据对于实时性的诉求也就更高。</p><h2 id="WHAT：需要关注、建设什么直播实时数据？"><a href="#WHAT：需要关注、建设什么直播实时数据？" class="headerlink" title="WHAT：需要关注、建设什么直播实时数据？"></a>WHAT：需要关注、建设什么直播实时数据？</h2><p>需要关注、建设什么直播实时数据？换一句话来说就是根据<strong>数据分析业务的需求</strong>出发，决定建设什么样的直播实时数据？</p><p>直播就是一个主播和观众联络互动的纽带，其中一切操作都是围绕着主播和观众而展开的，数据分析的同学都会以这个最基础的角度出发进行分析，因此首先我们就可以将整个直播的数据按照<strong>直播生产</strong>和<strong>直播消费</strong>进最基本的划分。</p><p>除此角度之外，数据分析的同学也还会从<strong>全局直播业务洞察</strong>和<strong>单个直播间洞察</strong>不同粒度上进行分析洞察，因此还可以按照<strong>大盘数据</strong>、<strong>单直播间数据</strong>进行划分。</p><p>从这两个角度出发，基本可以涵盖对于直播业务分析场景的诉求，因此直播实时数据也自然可以从这两个角度进行划分和建设。</p><p>综上则整体<strong>直播实时数据业务划分和赋能应用架构</strong>如下图所示。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-1/biz-arc.png" alt="业务划分和应用架构"></p><p>其中</p><p><strong>直播大盘实时数据</strong>在宏观上监控直播业务，提供预测大盘的能力；其中分钟粒度时间序列可快速定位直播各行为的高峰时刻，可以基于该时刻进行详细归因。除此之外，当直播在做运营活动时，也能快速基于实时数据来看运营活动的活动效果，赋能活动策略实时优化。</p><p><strong>单直播间直播实时数据</strong>可以以细粒度监控单直播间的直播业务，用来在直播过程中对外输出直播数据战报、以及可基于数据战报效果实时对单直播间进资源投放进行实时效果评估和合理调配。</p><p>详细的直播实时数据需求和样例如下文。</p><h3 id="大盘"><a href="#大盘" class="headerlink" title="大盘"></a>大盘</h3><p><strong>生产侧</strong></p><ul><li><strong>指标</strong>：总体开播直播间数…</li><li><strong>维度</strong>：直播间画像、主播用户画像</li><li><strong>举例</strong>：[开播直播间为游戏类直播]的[总开播主播数]</li></ul><p><strong>消费侧</strong></p><ul><li><strong>指标</strong>：总体观众观看、点赞、评论数…</li><li><strong>维度</strong>：观众用户画像、日志上报其他维度</li><li><strong>举例</strong>：[目前在河北观看直播]的[总观众数]</li></ul><h3 id="单直播间"><a href="#单直播间" class="headerlink" title="单直播间"></a>单直播间</h3><p><strong>生产侧</strong><br>单直播间一般都是一些画像信息，所以此类指标较少，暂时不做讨论。</p><p><strong>消费侧</strong></p><ul><li><strong>指标</strong>：单直播间观众观看、点赞、评论数…</li><li><strong>维度</strong>：观众用户画像、日志上报其他维度</li><li><strong>举例</strong>：某直播间[18-23岁年龄段]的[总观众数]</li></ul><p>目前已经了解了要建设直播实时数据都包含了什么内容，接下来就是大干一场的时候了。</p><h2 id="HOW：怎样去建设？"><a href="#HOW：怎样去建设？" class="headerlink" title="HOW：怎样去建设？"></a>HOW：怎样去建设？</h2><p>怎样去建设？换一句话来说就是从技术的角度出发，怎样将<strong>直播实时数据的业务需求</strong>转化为<strong>直播实时数据的技术方案</strong>进行落地？</p><p>从技术角度出发，上述直播实时数据需要建设的需求内容总结下来就是一个词：<strong>直播实时多维指标</strong>。</p><h3 id="多维"><a href="#多维" class="headerlink" title="多维"></a>多维</h3><p>即产出指标是多维度的，包含公共维度和非公共维度。</p><p>第一类是<strong>公共维度</strong>。包含三部分，直播间画像，主播用户画像，观众用户画像，公共两字代表这类维度是可以被多个指标进行共享使用的。举例：某直播间开播之后，该直播间画像只需要一次建设，就可以被多个指标多次重复使用，不但可以作为大盘侧生产、消费指标的维度，也可以作为单直播间生产、消费指标的维度。</p><p>第二类是<strong>非公共维度</strong>。非公共维度是和特定消费行为绑定的，也就是和某个指标绑定的，随着日志上报一同上报的维度。举例：某观众观看直播时的客户端类型（安卓？IOS？），观看直播时的省份等维度，这类维度只和当前的消费行为相关，不能被其他指标所共享。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-1/dim.png" alt="多维"></p><h3 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h3><p>其实都是 pv，uv 类指标。简单理解就是各个维度下对应的 xx 量。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-1/metric.png" alt="指标"></p><h3 id="实时数据建设技术架构"><a href="#实时数据建设技术架构" class="headerlink" title="实时数据建设技术架构"></a>实时数据建设技术架构</h3><p>对应到直播实时数据建设的过程主要包含两部分：公共部分和非公共部分。</p><p>公共部分就是实时公共维表的建设。</p><p>非公共部分就是指标非公共维度以及对应生产、消费指标建设。</p><p>直接给出总体<strong>技术架构</strong>图，本系列后续的文章进行介绍这样进行整体架构设计的详细原因。</p><p><img src="/blog-img/apache-flink:realtime-live-stream-1/tec-arc.png" alt="技术架构"></p><p>简单说明下。</p><p>其中数据源包含生产侧，消费侧数据源；</p><p>数据处理部分包含公共实时维表建设，和指标建设，其中一部分公共维表的建设也使用了离线的方式提供了支持；</p><p>最后就是数据汇部分，产出了生产侧，消费侧的多维指标供数据分析师使用。</p><h2 id="下节预告"><a href="#下节预告" class="headerlink" title="下节预告"></a>下节预告</h2><p>下节主要介绍<strong>直播实时公共画像的建设</strong>，其中是技术架构图中的<strong>主播用户、关注用户画像、以及直播间画像</strong>的建设方案。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文首先提出了几个关于直播实时数据建设的问题。以这几个问题触发，引出了一下三小节。</p><p>第一节简单介绍了直播时效性强的原因，因此直播对于实时数据的需求更加强烈。</p><p>第二节从数据分析的角度出发，引出了我们需要建设的直播实时数据都包含哪些内容，并且从大盘/单直播间，生产/消费角度进行了模块划分。</p><p>第三节对数据需求进行了技术方案的整体架构设计。</p><p>最后一节对本文进行了总结。</p><p>如果你也有相同的建设需求或者你以及建设了直播实时数据，欢迎留言或者留下你的文章链接，相互交流~</p>]]></content>
    
    <summary type="html">
    
      本系列每篇文章都比较短小，不定期更新，从一些实际的 case 出发抛砖引玉，提高小伙伴的姿♂势水平。本文介绍 Flink sink schema 字段设计小技巧，阅读时长大概 2 分钟，话不多说，直接进入正文！
    
    </summary>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/categories/Apache-Flink/"/>
    
    
      <category term="Apache Flink" scheme="https://yangyichao-mango.github.io/tags/Apache-Flink/"/>
    
  </entry>
  
  <entry>
    <title>Tips | Flink 使用 union 代替 join、cogroup</title>
    <link href="https://yangyichao-mango.github.io/2020/10/03/wechat-blog/apache-flink:realtime-tips-2-union-join/"/>
    <id>https://yangyichao-mango.github.io/2020/10/03/wechat-blog/apache-flink:realtime-tips-2-union-join/</id>
    <published>2020-10-03T06:21:53.000Z</published>
    <updated>2021-04-04T11:12:18.034Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tips-Flink-使用-union-代替-join、cogroup"><a href="#Tips-Flink-使用-union-代替-join、cogroup" class="headerlink" title="Tips | Flink 使用 union 代替 join、cogroup"></a>Tips | Flink 使用 union 代替 join、cogroup</h1><blockquote><p>本系列每篇文章都比较短小，不定期更新，从一些实际的 case 出发抛砖引玉，提高小伙伴的姿♂势水平。本文介绍在满足原有需求、实现原有逻辑的场景下，在 Flink 中使用 union 代替 cogroup(或者join) ，简化任务逻辑，提升任务性能的方法，阅读时长大概一分钟，话不多说，直接进入正文！</p></blockquote><h2 id="需求场景分析"><a href="#需求场景分析" class="headerlink" title="需求场景分析"></a>需求场景分析</h2><h3 id="需求场景"><a href="#需求场景" class="headerlink" title="需求场景"></a>需求场景</h3><p>需求诱诱诱来了。。。数据产品妹妹想要统计单个短视频粒度的<str