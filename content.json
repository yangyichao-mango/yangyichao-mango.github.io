[{"title":"Tips | Flink ä½¿ç”¨ union ä»£æ›¿ joinã€cogroup","date":"2020-10-03T06:21:53.000Z","path":"2020/10/03/wechat-blog/apache-flink:realtime-tips-2-union-join/","text":"Tips | Flink ä½¿ç”¨ union ä»£æ›¿ joinã€cogroup æœ¬ç³»åˆ—æ¯ç¯‡æ–‡ç« éƒ½æ¯”è¾ƒçŸ­å°ï¼Œä¸å®šæœŸæ›´æ–°ï¼Œä»ä¸€äº›å®é™…çš„ case å‡ºå‘æŠ›ç –å¼•ç‰ï¼Œæé«˜å°ä¼™ä¼´çš„å§¿â™‚åŠ¿æ°´å¹³ã€‚æœ¬æ–‡ä»‹ç»åœ¨æ»¡è¶³åŸæœ‰éœ€æ±‚ã€å®ç°åŸæœ‰é€»è¾‘çš„åœºæ™¯ä¸‹ï¼Œåœ¨ Flink ä¸­ä½¿ç”¨ union ä»£æ›¿ cogroup(æˆ–è€…join) ï¼Œç®€åŒ–ä»»åŠ¡é€»è¾‘ï¼Œæå‡ä»»åŠ¡æ€§èƒ½çš„æ–¹æ³•ï¼Œé˜…è¯»æ—¶é•¿å¤§æ¦‚ä¸€åˆ†é’Ÿï¼Œè¯ä¸å¤šè¯´ï¼Œç›´æ¥è¿›å…¥æ­£æ–‡ï¼ éœ€æ±‚åœºæ™¯åˆ†æéœ€æ±‚åœºæ™¯éœ€æ±‚è¯±è¯±è¯±æ¥äº†ã€‚ã€‚ã€‚æ•°æ®äº§å“å¦¹å¦¹æƒ³è¦ç»Ÿè®¡å•ä¸ªçŸ­è§†é¢‘ç²’åº¦çš„ç‚¹èµï¼Œæ’­æ”¾ï¼Œè¯„è®ºï¼Œåˆ†äº«ï¼Œä¸¾æŠ¥äº”ç±»å®æ—¶æŒ‡æ ‡ï¼Œå¹¶ä¸”æ±‡æ€»æˆ photo_idã€1 åˆ†é’Ÿæ—¶é—´ç²’åº¦çš„å®æ—¶è§†é¢‘æ¶ˆè´¹å®½è¡¨ï¼ˆå³å®½è¡¨å­—æ®µè‡³å°‘ä¸ºï¼šphoto_id + play_cnt + like_cnt + comment_cnt + share_cnt + negative_cnt + minute_timestampï¼‰äº§å‡ºè‡³å®æ—¶å¤§å±ã€‚ é—®é¢˜åœ¨äºå¯¹åŒä¸€ä¸ªè§†é¢‘ï¼Œäº”ç±»è§†é¢‘æ¶ˆè´¹è¡Œä¸ºçš„è§¦å‘æœºåˆ¶ä»¥åŠä¸ŠæŠ¥æ—¶é—´æ˜¯ä¸åŒï¼Œä¹Ÿå°±å†³å®šäº†å¯¹å®æ—¶å¤„ç†æ¥è¯´äº”ç±»è¡Œä¸ºæ—¥å¿—å¯¹åº”ç€äº”ä¸ªä¸åŒçš„æ•°æ®æºã€‚sql boy ä»¬è‡ªç„¶å°±æƒ³åˆ°äº† join æ“ä½œå°†äº”ç±»æ¶ˆè´¹è¡Œä¸ºæ—¥å¿—åˆå¹¶ï¼Œå¯æ˜¯å®æ—¶ join(cogroup) çœŸçš„é‚£ä¹ˆå®Œç¾å’©~ï¼Œä¸‹æ–‡ç»†è°ˆã€‚ source è¾“å…¥ä»¥åŠç‰¹ç‚¹é¦–å…ˆæˆ‘ä»¬åˆ†æä¸‹éœ€æ±‚ä¸­çš„ source ç‰¹ç‚¹ï¼š photo_id ç²’åº¦ playï¼ˆæ’­æ”¾ï¼‰ã€likeï¼ˆç‚¹èµï¼‰ã€commentï¼ˆè¯„è®ºï¼‰ã€shareï¼ˆåˆ†äº«ï¼‰ã€negativeï¼ˆä¸¾æŠ¥ï¼‰æ˜ç»†æ•°æ®ï¼Œç”¨æˆ·æ’­æ”¾ï¼ˆç‚¹èµã€è¯„è®ºâ€¦ï¼‰n æ¬¡ï¼Œå®¢æˆ·ç«¯\\æœåŠ¡ç«¯å°±ä¼šä¸Šä¼  n æ¡æ’­æ”¾ï¼ˆç‚¹èµã€è¯„è®ºâ€¦ï¼‰æ—¥å¿—è‡³æ•°æ®æº äº”ç±»è§†é¢‘æ¶ˆè´¹è¡Œä¸ºæ—¥å¿—çš„ source schema éƒ½ä¸ºï¼šphoto_id + timestamp + å…¶ä»–ç»´åº¦ sink è¾“å‡ºä»¥åŠç‰¹ç‚¹sink ç‰¹ç‚¹å¦‚ä¸‹ï¼š photo_id ç²’åº¦ playï¼ˆæ’­æ”¾ï¼‰ã€likeï¼ˆç‚¹èµï¼‰ã€commentï¼ˆè¯„è®ºï¼‰ã€shareï¼ˆåˆ†äº«ï¼‰ã€negativeï¼ˆä¸¾æŠ¥ï¼‰1 åˆ†é’Ÿçº§åˆ«çª—å£èšåˆæ•°æ® å®æ—¶è§†é¢‘æ¶ˆè´¹å®½è¡¨ sink schema ä¸ºï¼šphoto_id + play_cnt + like_cnt + comment_cnt + share_cnt + negative_cnt + minute_timestamp sourceã€sink æ ·ä¾‹æ•°æ®source æ•°æ®ï¼š| photo_id | timestamp | user_id | è¯´æ˜ || â€”â€”â€” | â€“ | â€”â€”â€”â€“ | â€”â€”â€”â€“ || 1 | 2020/10/3 11:30:33 | 3 | æ’­æ”¾ || 1 | 2020/10/3 11:30:33 | 4 | æ’­æ”¾ || 1 | 2020/10/3 11:30:33 | 5 | æ’­æ”¾ || 1 | 2020/10/3 11:30:33 | 4 | ç‚¹èµ || 2 | 2020/10/3 11:30:33 | 5 | ç‚¹èµ || 1 | 2020/10/3 11:30:33 | 5 | è¯„è®º | sink æ•°æ®ï¼š| photo_id | timestamp | play_cnt | like_cnt | comment_cnt| â€”â€”â€” | â€“ | â€”â€”â€”â€“ | â€”â€”â€”â€“ | â€”â€”â€”â€“ || 1 | 2020/10/3 11:30:00 | 3 | 1 | 1 || 2 | 2020/10/3 11:30:00 | 0 | 1 | 0 | æˆ‘ä»¬å·²ç»å¯¹æ•°æ®æºè¾“å…¥å’Œè¾“å‡ºæœ‰äº†å®Œæ•´çš„åˆ†æï¼Œé‚£å°±ç§ç§æœ‰ä»€ä¹ˆæ–¹æ¡ˆå¯ä»¥å®ç°ä¸Šè¿°éœ€æ±‚å§ã€‚ å®ç°æ–¹æ¡ˆ æ–¹æ¡ˆ1ï¼šæœ¬å°èŠ‚ cogroup æ–¹æ¡ˆç›´æ¥æ¶ˆè´¹åŸå§‹æ—¥å¿—æ•°æ®ï¼Œå¯¹äº”ç±»ä¸åŒçš„è§†é¢‘æ¶ˆè´¹è¡Œä¸ºæ—¥å¿—ä½¿ç”¨ cogroup æˆ–è€… join è¿›è¡Œçª—å£èšåˆè®¡ç®— æ–¹æ¡ˆ2ï¼šå¯¹äº”ç±»ä¸åŒçš„è§†é¢‘æ¶ˆè´¹è¡Œä¸ºæ—¥å¿—åˆ†åˆ«å•ç‹¬èšåˆè®¡ç®—å‡ºåˆ†é’Ÿç²’åº¦æŒ‡æ ‡æ•°æ®ï¼Œä¸‹æ¸¸å†å¯¹èšåˆå¥½çš„æŒ‡æ ‡æ•°æ®æŒ‰ç…§ photo_id è¿›è¡Œåˆå¹¶ æ–¹æ¡ˆ3ï¼šæœ¬å°èŠ‚ union æ–¹æ¡ˆæ—¢ç„¶æ•°æ®æº schema ç›¸åŒï¼Œç›´æ¥å¯¹äº”ç±»ä¸åŒçš„è§†é¢‘æ¶ˆè´¹è¡Œä¸ºæ—¥å¿—åš union æ“ä½œï¼Œåœ¨åç»­çš„çª—å£å‡½æ•°ä¸­å¯¹äº”ç±»æŒ‡æ ‡è¿›è¡Œèšåˆè®¡ç®—ã€‚åæ–‡ä»‹ç» union æ–¹æ¡ˆçš„è®¾è®¡è¿‡ç¨‹ æˆ‘ä»¬å…ˆä¸Š cogroup æ–¹æ¡ˆçš„ç¤ºä¾‹ä»£ç ã€‚ cogroupcogroup å®ç°ç¤ºä¾‹å¦‚ä¸‹ï¼Œç¤ºä¾‹ä»£ç ç›´æ¥ä½¿ç”¨äº†å¤„ç†æ—¶é—´ï¼ˆä¹Ÿå¯æ›¿æ¢ä¸ºäº‹ä»¶æ—¶é—´~ï¼‰ï¼Œå› æ­¤å¯¹æ•°æ®æºçš„æ—¶é—´æˆ³åšäº†ç®€åŒ–ï¼ˆç›´æ¥å¹²æ‰ï¼‰ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Cogroup &#123; public static void main(String[] args) throws Exception &#123; final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // Long -&gt; photo_id æ’­æ”¾ä¸€æ¬¡ DataStream&lt;Long&gt; play = SourceFactory.getDataStream(xxx); // Long -&gt; photo_id ç‚¹èµä¸€æ¬¡ DataStream&lt;Long&gt; like = SourceFactory.getDataStream(xxx); // Long -&gt; photo_id è¯„è®ºä¸€æ¬¡ DataStream&lt;Long&gt; comment = SourceFactory.getDataStream(xxx); // Long -&gt; photo_id åˆ†äº«ä¸€æ¬¡ DataStream&lt;Long&gt; share = SourceFactory.getDataStream(xxx); // Long -&gt; photo_id ä¸¾æŠ¥ä¸€æ¬¡ DataStream&lt;Long&gt; negative = SourceFactory.getDataStream(xxx); // Tuple3&lt;Long, Long, Long&gt; -&gt; photo_id + play_cnt + like_cnt æ’­æ”¾å’Œç‚¹èµçš„æ•°æ®åˆå¹¶ DataStream&lt;Tuple3&lt;Long, Long, Long&gt;&gt; playAndLikeCnt = play .coGroup(like) .where(KeySelectorFactory.get(Function.identity())) .equalTo(KeySelectorFactory.get(Function.identity())) .window(TumblingProcessingTimeWindows.of(Time.seconds(60))) .apply(xxx1); // Tuple4&lt;Long, Long, Long, Long&gt; -&gt; photo_id + play_cnt + like_cnt + comment_cnt æ’­æ”¾ã€ç‚¹èµã€è¯„è®ºçš„æ•°æ®åˆå¹¶ DataStream&lt;Tuple4&lt;Long, Long, Long, Long, Long&gt;&gt; playAndLikeAndComment = playAndLikeCnt .coGroup(comment) .where(KeySelectorFactory.get(playAndLikeModel -&gt; playAndLikeModel.f0)) .equalTo(KeySelectorFactory.get(Function.identity())) .window(TumblingProcessingTimeWindows.of(Time.seconds(60))) .apply(xxx2); // Tuple5&lt;Long, Long, Long, Long, Long&gt; -&gt; photo_id + play_cnt + like_cnt + comment_cnt + share_cnt æ’­æ”¾ã€ç‚¹èµã€è¯„è®ºã€åˆ†äº«çš„æ•°æ®åˆå¹¶ DataStream&lt;Tuple5&lt;Long, Long, Long, Long, Long, Long&gt;&gt; playAndLikeAndCommentAndShare = playAndLikeAndComment .coGroup(share) .where(KeySelectorFactory.get(playAndLikeAndCommentModel -&gt; playAndLikeAndCommentModel.f0)) .equalTo(KeySelectorFactory.get(Function.identity())) .window(TumblingProcessingTimeWindows.of(Time.seconds(60))) .apply(xxx2); // Tuple7&lt;Long, Long, Long, Long, Long, Long, Long&gt; -&gt; photo_id + play_cnt + like_cnt + comment_cnt + share_cnt + negative_cnt + minute_timestamp æ’­æ”¾ã€ç‚¹èµã€è¯„è®ºã€åˆ†äº«ã€ä¸¾æŠ¥çš„æ•°æ®åˆå¹¶ // åŒä¸Š~ DataStream&lt;Tuple7&lt;Long, Long, Long, Long, Long, Long, Long&gt;&gt; playAndLikeAndCommentAndShare = ***; env.execute(); &#125;&#125; ç²—æš´ä¸€æƒ³ï¼Œä¸Šé¢è¿™æ ·ä¸€æä¸å°±ç»“æŸäº†ä¹ˆï¼Œäº‹æƒ…æ²¡é‚£ä¹ˆç®€å•ï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªè¯¦ç»†ç‚¹çš„åˆ†æã€‚ ä¸Šè¿°å®ç°å¯èƒ½ä¼šå­˜åœ¨çš„é—®é¢˜ç‚¹ ä» flink æ¶ˆè´¹åˆ° play æ•°æ®æºçš„ä¸€æ¡æ•°æ®åˆ°æœ€ç»ˆäº§å‡ºè¿™æ¡æ•°æ®è¢«èšåˆåçš„æ•°æ®ï¼Œæ•´ä¸ªè¿‡ç¨‹çš„æ•°æ®å»¶è¿Ÿ &gt; 3 åˆ†é’Ÿâ€¦ å¦‚æœæ•°æ®æºæŒç»­å¢åŠ ï¼ˆæ¯”å¦‚æ·»åŠ å…¶ä»–è§†é¢‘æ¶ˆè´¹æ“ä½œæ•°æ®æºï¼‰ï¼Œåˆ™æ•´ä¸ªä»»åŠ¡ç®—å­å˜å¤šï¼Œæ•°æ®é“¾è·¯æ›´é•¿ï¼Œä»»åŠ¡ç¨³å®šæ€§ä¼šå˜å·®ï¼Œäº§å‡ºæ•°æ®å»¶è¿Ÿä¹Ÿä¼šéšç€çª—å£è®¡ç®—å˜å¤šï¼Œå»¶è¿Ÿæ›´ä¹… æ•°æ®äº§å“å¦¹å¦¹ï¼šğŸ¤©ï¼Œå°å“¥å“¥å¥½æ£’ï¼Œæ—¢ç„¶é—®é¢˜ç‚¹éƒ½åˆ†æå‡ºæ¥äº†ï¼ŒæŠ€æœ¯å°å“¥å“¥å°±å¸®äººå®¶è§£å†³ä¸€ä¸‹å˜›~ å¤´æ–‡å­— âˆ© æŠ€æœ¯å°å“¥å“¥ï¼šæã€‚ å¤´æ–‡å­— âˆ© æŠ€æœ¯å°å“¥å“¥ï¼šæ—¢ç„¶å¯èƒ½ç”±äºè¿‡å¤šçš„çª—å£å¯¼è‡´æ•°æ®äº§å‡ºå»¶è¿Ÿï¼Œjob ä¸ç¨³å®šï¼Œé‚£æœ‰æ²¡æœ‰ä»€ä¹ˆæ–¹æ³•å‡å°‘çª—å£æ•°é‡å‘¢ï¼Œæ€è·¯è½¬æ¢ä¸€ä¸‹ã€‚æˆ‘ä»¬ç›´æ¥ä»¥æ•´ä¸ª job ä¸­åªåŒ…å«ä¸€ä¸ªçª—å£ç®—å­æ“ä½œä¸ºåŸºç‚¹ï¼Œé€†æ¨ä¸€ä¸‹ï¼Œåˆ™æœ‰ä»¥ä¸‹æ•°æ®é“¾è·¯ã€‚ é€†æ¨é“¾è·¯1 - 5 ä¸ºé€†æ¨çš„æ•´æ¡é“¾è·¯ã€‚ 1.äº”ç±»æŒ‡æ ‡çš„æ•°æ®éƒ½åœ¨å•ä¸ªçª—å£ä¸­è®¡ç®— 2.äº”ç±»æŒ‡æ ‡çš„çª—å£ model ç›¸åŒ 3.keyby ä¸­çš„ key ä¸€è‡´ï¼ˆphoto_idï¼‰ 4.äº”ç±»æŒ‡æ ‡çš„æ•°æ®æºéƒ½ä¸º photo_id ç²’åº¦ï¼Œå¹¶ä¸”äº”ç±»æ•°æ®æºçš„ model éƒ½å¿…é¡»ç›¸åŒï¼Œå¹¶ä¸”å¯ä»¥åšåˆå¹¶ 5.union ç®—å­å¯ä»¥å¯¹äº”ç±»æ•°æ®æºåšåˆå¹¶ï¼ï¼ï¼ è¯ä¸å¤šè¯´ç›´æ¥ä¸Š union æ–¹æ¡ˆä»£ç ã€‚ union123456789101112131415161718192021222324252627282930public class Union &#123; public static void main(String[] args) throws Exception &#123; final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // Tuple2&lt;Long, String&gt; -&gt; photo_id + \"PLAY\"æ ‡ç­¾ DataStream&lt;Tuple2&lt;Long, String&gt;&gt; play = SourceFactory.getDataStream(xxx); // Tuple2&lt;Long, String&gt; -&gt; photo_id + \"LIKE\"æ ‡ç­¾ DataStream&lt;Tuple2&lt;Long, String&gt;&gt; like = SourceFactory.getDataStream(xxx); // Tuple2&lt;Long, String&gt; -&gt; photo_id + \"COMMENT\"æ ‡ç­¾ DataStream&lt;Tuple2&lt;Long, String&gt;&gt; comment = SourceFactory.getDataStream(xxx); // Tuple2&lt;Long, String&gt; -&gt; photo_id + \"SHARE\"æ ‡ç­¾ DataStream&lt;Tuple2&lt;Long, String&gt;&gt; share = SourceFactory.getDataStream(xxx); // Tuple2&lt;Long, String&gt; -&gt; photo_id + \"NEGATIVE\"æ ‡ç­¾ DataStream&lt;Tuple2&lt;Long, String&gt;&gt; negative = SourceFactory.getDataStream(xxx); // Tuple5&lt;Long, Long, Long, Long&gt; -&gt; photo_id + play_cnt + like_cnt + comment_cnt + window_start_timestamp DataStream&lt;Tuple3&lt;Long, Long, Long&gt;&gt; playAndLikeCnt = play .union(like) .union(comment) .union(share) .union(negative) .keyBy(KeySelectorFactory.get(i -&gt; i.f0)) .timeWindow(Time.seconds(60)) .process(xxx); env.execute(); &#125;&#125; å¯ä»¥å‘ç°ï¼Œæ— è®ºä¸Šæ¸¸æ•°æ®æºæ€æ ·è¿›è¡Œå˜åŒ–ï¼Œä¸Šè¿° union æ–¹æ¡ˆä¸­å§‹ç»ˆå¯ä»¥ä¿æŒåªæœ‰ä¸€ä¸ªçª—å£ç®—å­å¤„ç†å’Œè®¡ç®—æ•°æ®ï¼Œåˆ™å¯ä»¥è§£å†³ä¹‹å‰åˆ—ä¸¾çš„æ•°æ®å»¶è¿Ÿä»¥åŠ flink ä»»åŠ¡ç®—å­è¿‡å¤šçš„é—®é¢˜ã€‚ åœ¨æ•°æ®æºçš„ schema ç›¸åŒï¼ˆæˆ–è€…ä¸åŒä½†ç»è¿‡å¤„ç†ä¹‹åå¯ä»¥ format æˆç›¸åŒæ ¼å¼ï¼‰çš„æƒ…å†µä¸‹ï¼Œæˆ–è€…å¤„ç†é€»è¾‘ç›¸åŒçš„è¯ï¼Œå¯ä»¥ä½¿ç”¨ union è¿›è¡Œé€»è¾‘ç®€åŒ–ã€‚ æ€»ç»“æœ¬æ–‡é¦–å…ˆä»‹ç»äº†æˆ‘ä»¬çš„éœ€æ±‚åœºæ™¯ï¼Œç¬¬äºŒéƒ¨åˆ†åˆ†æäº†ä½¿ç”¨ cogroupï¼ˆæ¡ˆä¾‹ä»£ç ï¼‰æ˜¯å¦‚ä½•è§£å†³æ­¤éœ€æ±‚åœºæ™¯ï¼Œå†åˆ†æäº†æ­¤å®ç°æ–¹æ¡ˆå¯èƒ½ä¼šå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå¹¶å¼•å‡ºäº† union è§£å†³æ–¹æ¡ˆçš„é€†æ¨å’Œè®¾è®¡æ€è·¯ã€‚åœ¨ç¬¬ä¸‰éƒ¨åˆ†é’ˆå¯¹æ­¤åœºæ™¯ä½¿ç”¨ union ä»£æ›¿ cogroup è¿›è¡Œäº†ä¸€å®šç¨‹åº¦ä¸Šçš„ä¼˜åŒ–ã€‚å¦‚æœé’ˆå¯¹æ­¤åœºæ™¯ï¼Œå¤§ä½¬ä»¬æœ‰æ›´å¥½çš„ä¼˜åŒ–æ–¹æ¡ˆçš„è¯ï¼ŒæœŸå¾…ç•™è¨€å–”ã€‚ å…¬ä¼—å·","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Tips | Flink sink schema å­—æ®µè®¾è®¡å°æŠ€å·§","date":"2020-09-12T06:21:53.000Z","path":"2020/09/12/wechat-blog/apache-flink:realtime-tips-1/","text":"Tips | Flink sink schema å­—æ®µè®¾è®¡å°æŠ€å·§ æœ¬ç³»åˆ—æ¯ç¯‡æ–‡ç« éƒ½æ¯”è¾ƒçŸ­å°ï¼Œä¸å®šæœŸæ›´æ–°ï¼Œä»ä¸€äº›å®é™…çš„ case å‡ºå‘æŠ›ç –å¼•ç‰ï¼Œæé«˜å°ä¼™ä¼´çš„å§¿â™‚åŠ¿æ°´å¹³ã€‚æœ¬æ–‡ä»‹ç» Flink sink schema å­—æ®µè®¾è®¡å°æŠ€å·§ï¼Œé˜…è¯»æ—¶é•¿å¤§æ¦‚ 2 åˆ†é’Ÿï¼Œè¯ä¸å¤šè¯´ï¼Œç›´æ¥è¿›å…¥æ­£æ–‡ï¼ sink schema ä¸­æ·»åŠ  version ç‰ˆæœ¬å­—æ®µå¦‚ titleï¼Œç›´æ¥ä¸Šå®è·µæ¡ˆä¾‹å’Œä½¿ç”¨æ–¹å¼ã€‚ å®è·µæ¡ˆä¾‹åŠä½¿ç”¨æ–¹å¼ éæ•…éšœåœºæ™¯ä¸‹äº§å‡ºçš„æ¯æ¡è®°å½•çš„ version å­—æ®µå€¼ä¸º 1 æ•…éšœåœºæ™¯ä¸‹ï¼Œå¯ä»¥åœ¨åŒä¸€ sink ä¸­äº§å‡º version &gt; 1ï¼ˆé 1ï¼‰çš„æ•°æ®ï¼Œä»£è¡¨æ•…éšœä¿®å¤æ•°æ®æä¾›ç»™ä¸‹æ¸¸æ¶ˆè´¹ å¯åº”å¯¹çš„æ•…éšœåœºæ™¯ä¸Šæ¸¸ flink ä»»åŠ¡ A å‘ç”Ÿæ•…éšœå¯¼è‡´äº§å‡ºè„æ•°æ®è‡³ kafka Xï¼Œå¹¶ä¸”ä¸‹æ¸¸æ¶ˆè´¹æ–¹å¯ä»¥æŒ‰ç…§ä¸‹é¢ä¸¤ç±»è¿›è¡Œåˆ’åˆ†ï¼š ä¸‹æ¸¸ä¸º flink ä»»åŠ¡ï¼šflink ä»»åŠ¡ B æ¶ˆè´¹ kafka X ä¸­çš„è„æ•°æ®ï¼Œç»“æœè®¡ç®—å¹¶äº§å‡ºé”™è¯¯æ•°æ® ä¸‹æ¸¸ä¸º OLAP å¼•æ“ä»¥åŠ BI çœ‹æ¿ï¼šç»“æœå¯¼è‡´çœ‹æ¿å±•ç¤ºæ•°æ®å¼‚å¸¸ é¦–å…ˆä»‹ç»ä¸‹é¿å…ä»¥åŠå¤„ç†ä¸Šè¿°é—®é¢˜çš„æ•´ä½“æ€è·¯ï¼š 1.ä¼˜åŒ–é€»è¾‘ï¼Œä¿éšœä¸Šæ¸¸ä»»åŠ¡ç¨³å®šæ€§ï¼šé¦–å…ˆé€šè¿‡ä¸€äº›ä¼˜åŒ–æ‰‹æ®µï¼Œå°½å¯èƒ½ä¿è¯ä¸Šæ¸¸ flink ä»»åŠ¡ A ä¸å‡ºç°æ•…éšœ 2.é…ç½®ä½œä¸šç›‘æ§æŠ¥è­¦ï¼šé’ˆå¯¹æ•´æ¡é“¾è·¯é…ç½®å¯¹åº”çš„ç›‘æ§æŠ¥è­¦ç­‰ï¼Œä»¥åŠæ—¶å‘ç°å’Œå®šä½é—®é¢˜ 3.åˆ¶å®šæ•…éšœå¤„ç†ã€ä¿®å¤é¢„æ¡ˆï¼šéœ€è¦åˆ¶å®šå¯¹åº”çš„æ•…éšœå¤„ç†ã€ä¿®å¤é¢„æ¡ˆï¼Œä¸€æ—¦å‡ºç°æ•…éšœï¼Œéœ€è¦æœ‰å¯å¤„ç†æ•…éšœçš„èƒ½åŠ› 4.ä¸‹æ¸¸é’ˆå¯¹æ•°æ®æºç‰¹æ€§æ”¹è¿›æ¶ˆè´¹å’Œå¤„ç†æ–¹å¼ï¼šä¿éšœå³ä½¿æ¶ˆè´¹äº†è„æ•°æ®ä¹Ÿä¸ä¼šå¯¹ä¸šåŠ¡é€»è¾‘äº§ç”Ÿå½±å“ ä¸‹æ–‡ä¸»è¦ä»‹ç»ç¬¬ 2 ç‚¹ï¼Œå‡ºç°ä¸Šè¿°æ•…éšœæ—¶ä¿®å¤çš„æ–¹æ¡ˆï¼Œé’ˆå¯¹ä»¥ä¸Šåœºæ™¯ï¼Œç›®å‰æœ‰å¦‚ä¸‹ 3 ç§å¯é€‰æ–¹æ¡ˆä¿®å¤æ•°æ®ï¼š æ–¹æ¡ˆ 1 - ç¦»çº¿æ–¹å¼ä¿®å¤ï¼šé€šè¿‡ç¦»çº¿æ–¹å¼äº§å‡ºä¿®å¤æ•°æ®ï¼Œå¯¹è„æ•°æ®è¿›è¡Œè¦†ç›–æ“ä½œã€‚ç¼ºç‚¹æ˜¯æ•…éšœä¿®å¤å»¶è¿Ÿè¾ƒé«˜ï¼Œéœ€è¦åˆ‡æ¢ç¦»çº¿ã€å®æ—¶æ•°æ®æºï¼Œäººå·¥æ“ä½œæˆæœ¬è¾ƒé«˜ æ–¹æ¡ˆ 2 - å®æ—¶æ–¹å¼ä¿®å¤ï¼šé‡è·‘ä¿®æ•°é€»è¾‘ï¼Œäº§å‡ºä¿®å¤æ•°æ®è‡³ kafka X-fixï¼Œä¸‹æ¸¸ flink ä»»åŠ¡ B é‡æ–°ä» kafka X-fix ä¸­çš„æŒ‡å®š offset å¼€å§‹æ¶ˆè´¹ï¼Œè®¡ç®—å¹¶äº§å‡ºæ­£ç¡®çš„æ•°æ®ã€‚æ­¤æ–¹æ¡ˆå¯¹ä¸‹æ¸¸ flink ä»»åŠ¡ B æ¥è¯´ï¼Œéœ€è¦æ”¹åŠ¨ä»£ç é€»è¾‘ï¼Œå­˜åœ¨ä¿®æ•° topic å’ŒåŸ topic åˆ‡æ¢é€»è¾‘ï¼Œä¿®å¤é€»è¾‘è¾ƒä¸ºå¤æ‚ æ–¹æ¡ˆ 3 - å®æ—¶æ–¹å¼ä¿®å¤ï¼ˆæœ¬å°èŠ‚ version å­—æ®µæ–¹æ¡ˆï¼‰ï¼šä¸ºé¿å…ä¸‹æ¸¸äº§ç”Ÿæ•°æ®æºåˆ‡æ¢æ“ä½œå¸¦æ¥çš„é«˜æˆæœ¬æ“ä½œï¼Œå¯åœ¨åŸæœ‰ kafka topic ä¸­äº§å‡ºä¿®å¤æ•°æ®ï¼Œé€šè¿‡ version å­—æ®µåŒºåˆ†æ­£å¸¸äº§å‡ºæ•°æ®ä»¥åŠä¿®å¤æ•°æ®ï¼Œç›¸å¯¹æ–¹æ¡ˆ 1 å’Œ 2 çš„ä¼˜ç‚¹åœ¨äºï¼Œä¸å­˜åœ¨æ•°æ®æºåˆ‡æ¢é€»è¾‘ï¼Œä¸‹æ¸¸é€šè¿‡æ§åˆ¶ version å­—æ®µå€¼å°±å¯æ¶ˆè´¹åˆ°å¯¹åº”çš„ä¿®å¤æ•°æ®ï¼Œæ˜æ˜¾é™ä½äººå·¥æ“ä½œæˆæœ¬ï¼Œä¸”ä¿®å¤é€»è¾‘ç›¸å¯¹ç®€å• Note: æ–¹æ¡ˆ 3 éœ€è¦å¯¹ Kafka X é¢„ç•™ä¸€å®šçš„ bufferï¼Œå¦åˆ™åœ¨äº§å‡ºä¿®å¤æ•°æ®æ—¶ï¼Œç”±äºå†™å…¥æˆ–è¯»å‡º Kafka X çš„ QPS è¿‡é«˜ï¼Œä¼šå½±å“æ­£å¸¸äº§å‡ºæ•°æ®çš„ä»»åŠ¡ã€‚ sink schema ä¸­æ·»åŠ æ—¶é—´æˆ³å­—æ®µå®è·µæ¡ˆä¾‹åŠä½¿ç”¨æ–¹å¼æœ‰çª—å£åœºæ™¯ä¸­ï¼Œsink schema ä¸­å¯æ·»åŠ ä»¥ä¸‹å­—æ®µï¼š flink_process_start_time(long)ï¼šä»£è¡¨ flink çª—å£å¼€å§‹é€»è¾‘å¤„ç†çš„æ—¶é—´æˆ³ flink_process_end_time(long)ï¼šä»£è¡¨ flink çª—å£ç»“æŸé€»è¾‘å¤„ç†çš„æ—¶é—´æˆ³ window_start(long)ï¼šä»£è¡¨ flink çª—å£å¼€å§‹æ—¶é—´æˆ³ window_end(long)ï¼šä»£è¡¨ flink çª—å£ç»“æŸæ—¶é—´æˆ³ ç”Ÿäº§å®è·µæ¡ˆä¾‹ flink_process_start_timeï¼Œflink_process_end_time åœ¨å¼€å‘ã€æµ‹è¯•ã€éªŒæ•°é˜¶æ®µå¯å¸®åŠ©ç”¨æˆ·å®šä½æ•°æ®åå·®åŸå›  window_startï¼Œwindow_end å¯ä»¥å¸®åŠ©ç”¨æˆ·å®šä½æ¯ä¸ªçª—å£å¤„ç†æ˜¯å¦æœ‰ä¸¢æ•°ï¼ŒåŠæ¯ä¸ªçª—å£å¤„ç†çš„å…·ä½“æ•°æ® æ€»ç»“æœ¬æ–‡ä¸»è¦ä»‹ç»äº†åœ¨ sink schema ä¸­æ·»åŠ  versionï¼ˆç‰ˆæœ¬ï¼‰ï¼Œæ—¶é—´æˆ³æ‰©å±•å­—æ®µçš„å°æŠ€å·§ï¼Œä»¥å¸®åŠ©ç”¨æˆ·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æå‡å®æ—¶æ•°æ®æ•…éšœä¿®å¤æ•ˆç‡ä»¥åŠå¯ç”¨æ€§ã€‚ å…¬ä¼—å·","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"è¸©å‘è®° | Flink äº‹ä»¶æ—¶é—´è¯­ä¹‰ä¸‹æ•°æ®ä¹±åºä¸¢æ•°è¸©å‘","date":"2020-09-11T06:21:53.000Z","path":"2020/09/11/wechat-blog/apache-flink:realtime-out-of-order/","text":"è¸©å‘è®° | Flink äº‹ä»¶æ—¶é—´è¯­ä¹‰ä¸‹æ•°æ®ä¹±åºä¸¢æ•°è¸©å‘ æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†åœ¨ä¸Šæ¸¸ä½¿ç”¨å¤„ç†æ—¶é—´è¯­ä¹‰çš„ flink ä»»åŠ¡å‡ºç°æ•…éšœåï¼Œé‡å¯æ¶ˆè´¹å¤§é‡ç§¯å‹åœ¨ä¸Šæ¸¸çš„æ•°æ®å¹¶äº§å‡ºè‡³ä¸‹æ¸¸æ•°æ®ä¹±åºç‰¹åˆ«ä¸¥é‡æ—¶ï¼Œä¸‹æ¸¸ flink ä»»åŠ¡ä½¿ç”¨äº‹ä»¶æ—¶é—´è¯­ä¹‰æ—¶é‡åˆ°çš„å¤§é‡ä¸¢æ•°é—®é¢˜ä»¥åŠç›¸å…³çš„è§£å†³æ–¹æ¡ˆã€‚ æœ¬æ–‡åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š 1.æœ¬æ¬¡è¸©å‘çš„åº”ç”¨åœºæ™¯ 2.åº”ç”¨åœºæ™¯ä¸­å‘ç”Ÿçš„ä¸¢æ•°æ•…éšœåˆ†æ 3.å¾…ä¿®å¤çš„æ•…éšœç‚¹ 4.ä¸¢æ•°æ•…éšœè§£å†³æ–¹æ¡ˆåŠåŸç† 5.æ€»ç»“ åº”ç”¨åœºæ™¯åº”ç”¨åœºæ™¯å¦‚ä¸‹ï¼š flink ä»»åŠ¡ A ä»¥å¤„ç†æ—¶é—´è¯­ä¹‰åšè¿‡æ»¤äº§å‡ºæ–°å¢ xx æ˜ç»†æ•°æ®è‡³ Kafka Y flink ä»»åŠ¡ B ä»¥äº‹ä»¶æ—¶é—´è¯­ä¹‰æ¶ˆè´¹ Kafka Y åšçª—å£èšåˆæ“ä½œäº§å‡ºåˆ†é’Ÿçº§åˆ«èšåˆæŒ‡æ ‡è‡³ Kafka Z Kafka Z å®æ—¶å¯¼å…¥è‡³ Druid ä»¥åšå³æ—¶ OLAP åˆ†æï¼Œå¹¶ä¸”å±•ç¤ºåœ¨ BI åº”ç”¨çœ‹æ¿ ä¸¢æ•°æ•…éšœåˆ†æç®€è¦ä»‹ç»ä¸‹è¿™æ¬¡ç”Ÿäº§ä¸­æ•…éšœåœºæ™¯ã€‚æ•´æ¡æ•…éšœè¿½è¸ªé“¾è·¯å¦‚ä¸‹ï¼š æ•…éšœä¸€ï¼š æ”¶åˆ°æŠ¥è­¦åé¦ˆ flink ä»»åŠ¡ A å…¥å£æµé‡ä¸º 0 å®šä½ flink ä»»åŠ¡ A ä¸­æŸä¸ªç®—å­çš„æ•…éšœå¯¼è‡´æ•´ä¸ª job å¡ä½ å¯¼è‡´æ­¤ flink ä»»åŠ¡ A ä¸Šæ¸¸ kafka X ç§¯å‹äº†å¤§é‡æ•°æ® é‡å¯ flink ä»»åŠ¡ Aåï¼Œæ¶ˆè´¹å¤§é‡ç§¯å‹åœ¨ä¸Šæ¸¸ kafka X æ•°æ®å®Œæˆï¼Œä»»åŠ¡æ¢å¤æ­£å¸¸ æ•…éšœä¸€ä»è€Œå¼•å‘ä¸‹æ¸¸çš„æ•…éšœäºŒï¼š ç”±äº flink ä»»åŠ¡ A ä½¿ç”¨äº†å¤„ç†æ—¶é—´è¯­ä¹‰å¤„ç†æ•°æ®ï¼Œå¹¶ä¸”æœ‰è¿‡æ»¤å’Œ keyBy åˆ†æ¡¶çª—å£é€»è¾‘ï¼Œåœ¨é‡å¯åæ¶ˆè´¹å¤§é‡ç§¯å‹åœ¨ä¸Šæ¸¸çš„æ•°æ®æ—¶ï¼Œå¯¼è‡´ sink rebalance åäº§å‡ºåˆ°ä¸‹æ¸¸ kafka Y å„ä¸ªåˆ†åŒºæ•°æ®ä¸­çš„ server_timestamp æ˜¯ä¹±åºçš„ ä¸‹æ¸¸ flink ä»»åŠ¡ B åœ¨æ¶ˆè´¹ Kafka Y æ—¶ä½¿ç”¨äº†äº‹ä»¶æ—¶é—´è¯­ä¹‰å¤„ç†æ•°æ®ï¼Œå¹¶ä¸”ä½¿ç”¨äº†æ•°æ®ä¸­çš„ server_timestamp ä½œä¸ºäº‹ä»¶æ—¶é—´æ—¶é—´æˆ³ flink ä»»åŠ¡ B æ¶ˆè´¹äº†ä¹±åºå¾ˆä¸¥é‡çš„æ•°æ®ä¹‹åï¼Œå¯¼è‡´åœ¨çª—å£èšåˆè®¡ç®—æ—¶ä¸¢å¤±äº†å¤§é‡æ•°æ® æœ€ç»ˆå±•ç¤ºåœ¨ BI åº”ç”¨ä¸­çš„æŠ¥è¡¨æœ‰ä¸¢å¤±æ•°æ®çš„æƒ…å†µ å¾…ä¿®å¤çš„æ•…éšœç‚¹ 1.flink ä»»åŠ¡ A çš„ç¨³å®šæ€§æ•…éšœï¼Œè¿™éƒ¨åˆ†è§£å†³æ–¹æ¡ˆæš‚ä¸åœ¨æœ¬æ–‡ä¸­ä»‹ç» 2.flink ä»»åŠ¡ B æ¶ˆè´¹ä¸Šæ¸¸ä¹±åºä¸¢æ•°æ•…éšœï¼Œè§£å†³æ–¹æ¡ˆåœ¨ä¸‹æ–‡ä»‹ç» è§£å†³æ–¹æ¡ˆä»¥åŠåŸç†ä¸¢æ•°æ•…éšœè§£å†³æ–¹æ¡ˆè§£å†³æ–¹æ¡ˆæ˜¯ä»¥ä¸‹æ¸¸ flink ä»»åŠ¡ B ä½œä¸ºåˆ‡å…¥ç‚¹ï¼Œç›´æ¥ç»™å‡º flink ä»»åŠ¡ B çš„ sql ä»£ç è§£å†³æ–¹æ¡ˆï¼Œjava code ä¹Ÿå¯ä»¥æŒ‰ç…§è¿™ä¸ªæ–¹æ¡ˆå®ç°ï¼Œå…¶æœ¬è´¨åŸç†ç›¸åŒã€‚ä¸‹æ–‡è¿›è¡ŒåŸç†è§£é‡Šã€‚ 123456789SELECT to_unix_timestamp(server_timestamp / bucket) AS timestamp, -- format æˆåŸæœ‰çš„äº‹ä»¶æ—¶é—´æˆ³ count(id) as id_cnt, sum(duration) as duration_sumFROM source_tableGROUP BY TUMBLE(proctime, INTERVAL '1' MINUTE), server_timestamp / bucket -- æ ¹æ®äº‹ä»¶æ—¶é—´åˆ†æ¡¶è®¡ç®—ï¼Œå°†ç›¸åŒèŒƒå›´ï¼ˆæ¯”å¦‚ 1 åˆ†é’Ÿï¼‰äº‹ä»¶æ—¶é—´çš„æ•°æ®åˆ†åˆ°ä¸€ä¸ªæ¡¶å†… è§£å†³æ–¹æ¡ˆåŸç†é¦–å…ˆæ˜ç¡®ä¸€ä¸ªæ— æ³•é¿å…çš„é—®é¢˜ï¼Œåœ¨ä¸è€ƒè™‘ watermark å…è®¸å»¶è¿Ÿè®¾ç½®ç‰¹åˆ«å¤§çš„æƒ…å†µä¸‹ï¼Œåªè¦ä¸Šæ¸¸ä½¿ç”¨åˆ°äº†å¤„ç†æ—¶é—´è¯­ä¹‰ï¼Œä¸‹æ¸¸ä½¿ç”¨äº‹ä»¶æ—¶é—´è¯­ä¹‰ï¼Œä¸€æ—¦ä¸Šæ¸¸å‘ç”Ÿæ•…éšœé‡å¯å¹¶åœ¨çŸ­æ—¶é—´å†…æ¶ˆè´¹å¤§é‡æ•°æ®ï¼Œå°±ä¸å¯é¿å…çš„ä¼šå‡ºç°ä¸Šè¿°é”™è¯¯ä»¥åŠæ•…éšœã€‚ åœ¨ä¸‹æ¸¸æ¶ˆè´¹æ–¹ä»ç„¶éœ€è¦å°†å¯¹åº”äº‹ä»¶æ—¶é—´æˆ³çš„æ•°æ®å±•ç¤ºåœ¨ BI å¹³å°æŠ¥è¡¨ä¸­ã€å¹¶ä¸”å…¨é“¾è·¯æ—¶é—´è¯­ä¹‰éƒ½ä¸ºå¤„ç†æ—¶é—´ä¿éšœä¸ä¸¢æ•°çš„å‰æä¸‹ã€‚è§£å†³æ–¹æ¡ˆå°±æ˜¯åœ¨èšåˆå¹¶æœ€ç»ˆäº§å‡ºå¯¹åº”äº‹ä»¶æ—¶é—´æˆ³çš„æ•°æ®ã€‚ æœ€åçš„æ–¹æ¡ˆå¦‚ä¸‹ï¼šæ•´æ¡é“¾è·¯å…¨éƒ¨ä¸ºå¤„ç†æ—¶é—´è¯­ä¹‰ï¼Œçª—å£è®¡ç®—ä¹Ÿä½¿ç”¨å¤„ç†æ—¶é—´ï¼Œä½†æ˜¯äº§å‡ºæ•°æ®ä¸­çš„æ—¶é—´æˆ³å…¨éƒ¨ä¸ºäº‹ä»¶æ—¶é—´æˆ³ã€‚åœ¨å‡ºç°æ•…éšœçš„åœºæ™¯ä¸‹ï¼Œä¸€åˆ†é’Ÿçš„çª—å£å†…çš„æ•°æ®çš„äº‹ä»¶æ—¶é—´æˆ³å¯èƒ½ç›¸å·®å‡ ä¸ªå°æ—¶ï¼Œä½†åœ¨æœ€ç»ˆçª—å£èšåˆæ—¶å¯ä»¥æ ¹æ®äº‹ä»¶æ—¶é—´æˆ³åˆ’åˆ†åˆ°å¯¹åº”çš„äº‹ä»¶æ—¶é—´çª—å£å†…ï¼Œä¸‹æ¸¸ BI åº”ç”¨å±•ç¤ºæ—¶ä½¿ç”¨æ­¤äº‹ä»¶æ—¶é—´æˆ³å³å¯ã€‚ æ³¨æ„ï¼šsql ä¸­çš„ bucket éœ€è¦æ ¹æ®å…·ä½“ä½¿ç”¨åœºæ™¯è¿›è¡Œè®¾ç½®ï¼Œå¦‚æœè®¾ç½®è¿‡äºå°ï¼Œæ¯”å¦‚éæ•…éšœåœºæ™¯ä¸‹æŒ‰ç…§å¤„ç†æ—¶é—´å¼€ 1 åˆ†é’Ÿçš„çª—å£ï¼Œbucketè®¾ä¸º 60000ï¼ˆ1 åˆ†é’Ÿï¼‰ï¼Œé‚£ä¹ˆææœ‰å¯èƒ½ï¼Œè¿™ä¸ªæ—¶é—´çª—å£ä¸­æ‰€æœ‰æ•°æ®çš„ server_timestamp éƒ½é›†ä¸­åœ¨æŸä¸¤åˆ†é’Ÿå†…ï¼Œé‚£ä¹ˆè¿™äº›æ•°æ®å°±ä¼šè¢«åˆ†åˆ°ä¸¤ä¸ªæ¡¶ï¼ˆbucketï¼‰å†…ï¼Œåˆ™ä¼šå¯¼è‡´ä¸¥é‡çš„æ•°æ®å€¾æ–œã€‚ è¾“å…¥æ•°æ®æ ·ä¾‹æ¨¡æ‹Ÿä¸Šè¿°æ•…éšœï¼Œflink B çš„ä»»åŠ¡æŸä¸€ä¸ªçª—å£å†…çš„æ•°æ®è¾“å…¥å¦‚ä¸‹ã€‚ server_timestamp id duration 2020/9/01 21:14:38 1 300 2020/9/01 21:14:50 1 500 2020/9/01 21:25:38 2 600 2020/9/01 21:25:38 3 900 2020/9/01 21:25:38 2 800 è¾“å‡ºæ•°æ®æ ·ä¾‹æŒ‰ç…§ä¸Šè¿°è§£å†³æ–¹æ¡ˆä¸­çš„ sql å¤„ç†è¿‡åï¼Œè¾“å‡ºæ•°æ®å¦‚ä¸‹ï¼Œåˆ™å¯ä»¥è§£å†³æ­¤ç±»å‹ä¸¢æ•°æ•…éšœã€‚ timestamp id_cnt duration_sum 2020/9/01 21:14:00 2 900 2020/9/01 21:25:00 3 2300 æ€»ç»“æœ¬æ–‡åˆ†æäº†åœ¨ flink åº”ç”¨ä¸­ï¼š ä¸Šæ¸¸ä½¿ç”¨å¤„ç†æ—¶é—´è¯­ä¹‰çš„ flink ä»»åŠ¡å‡ºç°æ•…éšœã€é‡å¯æ¶ˆè´¹å¤§é‡ç§¯å‹æ•°æ®å¹¶äº§å‡ºè‡³ä¸‹æ¸¸æ•°æ®ä¹±åºç‰¹åˆ«ä¸¥é‡æ—¶ï¼Œä¸‹æ¸¸ä½¿ç”¨äº‹ä»¶æ—¶é—´è¯­ä¹‰æ—¶é‡åˆ°çš„å¤§é‡ä¸¢æ•°é—®é¢˜ ä»¥æ•´æ¡é“¾è·¯ä¸ºå¤„ç†æ—¶é—´è¯­ä¹‰çš„å‰æä¸‹ï¼Œäº§å‡ºçš„æ•°æ®æ—¶é—´æˆ³ä¸ºäº‹ä»¶æ—¶é—´æˆ³è§£å†³ä¸Šè¿°é—®é¢˜ ä»¥ sql ä»£ç ç»™å‡ºäº†ä¸¢æ•°æ•…éšœè§£å†³æ–¹æ¡ˆæ ·ä¾‹ å­¦ä¹ èµ„æ–™flink https://github.com/flink-china/flink-training-course/blob/master/README.md https://ververica.cn/developers-resources/ https://space.bilibili.com/33807709","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/broadcast/","text":"å®æ—¶æ–°å¢ç±»æŒ‡æ ‡æ ‡å‡†åŒ–å¤„ç†æ–¹æ¡ˆ å®æ—¶æŒ‡æ ‡æ•´ä¸ªé“¾è·¯å¼€å‘è¿‡ç¨‹ä¸­çš„ä¸€äº›ç»éªŒã€‚ å®æ—¶æ–°å¢ç±»æŒ‡æ ‡å¤§ä½“ä¸Šå¯ä»¥å°†å®æ—¶æ–°å¢ç±»æŒ‡æ ‡ä»¥ä»¥ä¸‹ä¸¤ç§ç»´åº¦è¿›è¡Œåˆ†ç±»ã€‚ identity id ç±»å‹ç»´åº¦ identity id ç±»å‹ å¤‡æ³¨ number(long) ç±»å‹ identity id æ•°å€¼ç±»å‹ identity id çš„å¥½å¤„åœ¨äºå¯ä»¥ä½¿ç”¨ Bitmap ç±»ç»„ä»¶åšåˆ°ç²¾ç¡®å»é‡ã€‚ å­—ç¬¦ç±»å‹ identity id å­—ç¬¦ç±»å‹ identity id å»é‡ç›¸å¯¹å¤æ‚ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼Œåœ¨è¯¯å·®å…è®¸èŒƒå›´ä¹‹å†…ä½¿ç”¨ BloomFilter è¿›è¡Œå»é‡ï¼Œæˆ–è€…ä½¿ç”¨ key-value ç»„ä»¶è¿›è¡Œç²¾ç¡®å»é‡ã€‚ äº§å‡ºæ•°æ®ç±»å‹ç»´åº¦ äº§å‡ºæ•°æ®ç±»å‹ å¤‡æ³¨ æ˜ç»†ç±»æ•°æ® æ­¤ç±»æ•°æ®ä¸€èˆ¬æ˜¯è¦æ±‚å°†æ–°å¢çš„æ•°æ®æ˜ç»†äº§å‡ºï¼Œuv çš„å«ä¹‰æ˜¯åšè¿‡æ»¤ï¼Œäº§å‡ºçš„æ˜ç»†æ•°æ®ä¸­çš„ identity id ä¸ä¼šæœ‰é‡å¤ã€‚è¾“å‡ºæ˜ç»†æ•°æ®çš„å¥½å¤„åœ¨äºï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨ OLAP å¼•æ“å¯¹æ˜ç»†æ•°æ®è¿›è¡Œå„ç§ç»´åº¦çš„èšåˆè®¡ç®—ï¼Œä»è€Œå¾ˆæ–¹ä¾¿çš„äº§å‡ºä¸åŒç»´åº¦ä¸‹çš„ uv æ•°æ®ã€‚ èšåˆç±»æ•°æ® å°†ä¸€ä¸ªæ—¶é—´çª—å£å†…çš„ uv è¿›è¡Œèšåˆï¼Œå¹¶ä¸”å¯ä»¥è®¡ç®—å‡ºåˆ†ç»´åº¦çš„ uvï¼Œå…¶äº§å‡ºæ•°æ®ä¸€èˆ¬éƒ½æ˜¯[ç»´åº¦ + uv_count]ï¼Œä½†æ˜¯è¿™é‡Œçš„ç»´åº¦ä¸€èˆ¬æƒ…å†µä¸‹æ˜¯éƒ½æ˜¯å›ºå®šç»´åº¦ã€‚å¦‚æœéœ€è¦æ‹“å±•åˆ™éœ€è¦æ”¹åŠ¨æºç ã€‚ è®¡ç®—é“¾è·¯å› æ­¤æ–°å¢äº§å‡ºçš„é“¾è·¯å¤šæ•°å°±æ˜¯ä»¥ä¸Šä¸¤ç§ç»´åº¦å› å­çš„ç›¸äº’ç»„åˆã€‚ number(long) ç±»å‹ identity id ä½¿ç”¨ RoaringBitmap çš„ uv è®¡ç®—é“¾è·¯ ä»£ç ç¤ºä¾‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public interface RoaringBitmapDuplicateable&lt;Model&gt; &#123; long DEFAULT_DUPLICATE_MILLS = 24 * 3600 * 1000L; BiPredicate&lt;Long, Long&gt; ROARING_BIT_MAP_CLEAR_BI_PREDICATE = (start, end) -&gt; end - start &gt;= DEFAULT_DUPLICATE_MILLS; // åˆå§‹åŒ– default ValueState&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt; getBitMapValueState(String name) &#123; return this.getRuntimeContext().getState( new ValueStateDescriptor&lt;&gt;(name, TypeInformation.of( new TypeHint&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt;() &#123; &#125;)) ); &#125; RuntimeContext getRuntimeContext(); long getLongId(Model model); Optional&lt;Logger&gt; getLogger(); default BiPredicate&lt;Long, Long&gt; roaringBitMapClearBiPredicate() &#123; return ROARING_BIT_MAP_CLEAR_BI_PREDICATE; &#125; default List&lt;Model&gt; duplicateAndGet(List&lt;Model&gt; models, long windowStartTimestamp , ValueState&lt;Tuple2&lt;Date, Roaring64NavigableMap&gt;&gt; bitMapValueState) throws IOException &#123; Tuple2&lt;Date, Roaring64NavigableMap&gt; bitMap = checkAndGetState(windowStartTimestamp, bitMapValueState); Map&lt;Long, Model&gt; idModelsMap = models .stream() .collect(Collectors.toMap(this::getLongId, Function.identity(), (oldOne, newOne) -&gt; oldOne)); Set&lt;Long&gt; ids = idModelsMap.keySet(); List&lt;Model&gt; newModels = Lists.newArrayList(); for (Long id : ids) &#123; if (!bitMap.f1.contains(id)) &#123; if (idModelsMap.containsKey(id)) &#123; newModels.add(idModelsMap.get(id)); &#125; &#125; &#125; newModels.stream() .map(this::getLongId) .forEach(bitMap.f1::add); bitMapValueState.update(bitMap); return newModels; &#125; default long duplicateAndCount(List&lt;Model&gt; models, long windowStartTimestamp , ValueState&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt; bitMapValueState) throws IOException &#123; Tuple2&lt;Long, Roaring64NavigableMap&gt; bitMap = checkAndGetState(windowStartTimestamp, bitMapValueState); Set&lt;Long&gt; ids = models .stream() .map(this::getLongId) .collect(Collectors.toSet()); List&lt;Long&gt; newIds = Lists.newArrayList(); int count = 0; for (Long id : ids) &#123; if (!bitMap.f1.contains(id)) &#123; newIds.add(id); count++; &#125; &#125; newIds.forEach(bitMap.f1::add); bitMapValueState.update(bitMap); return count; &#125; default Tuple2&lt;Long, Roaring64NavigableMap&gt; checkAndGetState(long windowStartTimestamp , ValueState&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt; bitMapValueState) throws IOException &#123; Tuple2&lt;Long, Roaring64NavigableMap&gt; bitmap = bitMapValueState.value(); if (null == bitmap) &#123; this.getLogger().ifPresent(logger -&gt; logger.info(\"New RoaringBitMapValueState Timestamp=&#123;&#125;\", windowStartTimestamp)); Tuple2&lt;Long, Roaring64NavigableMap&gt; newBitMap = Tuple2.of(windowStartTimestamp, new Roaring64NavigableMap()); bitMapValueState.update(newBitMap); return newBitMap; &#125; else if (this.roaringBitMapClearBiPredicate().test(bitmap.f0, windowStartTimestamp)) &#123; this.getLogger().ifPresent(logger -&gt; logger.info(\"Clear RoaringBitMapValueState, from start=&#123;&#125; to end=&#123;&#125;\", bitmap.f0, windowStartTimestamp)); bitMapValueState.clear(); bitmap.f1.clear(); Tuple2&lt;Long, Roaring64NavigableMap&gt; newBitMap = Tuple2.of(windowStartTimestamp, new Roaring64NavigableMap()); bitMapValueState.update(newBitMap); return newBitMap; &#125; else &#123; return bitmap; &#125; &#125;&#125; å­—ç¬¦ç±»å‹ identity idä½¿ç”¨ Flink state ä½¿ç”¨ flink state çš„ uv è®¡ç®—é“¾è·¯ ä½¿ç”¨ key-value å¤–å­˜ ä½¿ç”¨ key-value çš„ uv è®¡ç®—é“¾è·¯ å¦‚æœé€‰ç”¨çš„æ˜¯ Redis ä½œä¸º key-value è¿‡æ»¤ï¼Œé‚£ä¹ˆè¿™é‡Œä¼šæœ‰ä¸€ä¸ªå·§ç”¨ Redis bit ç‰¹æ€§çš„ä¼˜åŒ–ã€‚ä¸¾ä¸€ä¸ªä¸€èˆ¬åœºæ™¯ä¸‹çš„æ–¹æ¡ˆä¸ä½¿ç”¨ Redis bit ç‰¹æ€§çš„æ–¹æ¡ˆåšå¯¹æ¯”ï¼š åœºæ™¯ï¼šå‡å¦‚éœ€è¦åŒä¸€å¤©æœ‰å‡ ååœºæ´»åŠ¨ï¼Œå¹¶ä¸”éƒ½å¸Œæœ›è®¡ç®—å‡ºè¿™å‡ ååœºæ´»åŠ¨çš„ uvï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æŒ‰ç…§ä¸‹å›¾è®¾è®¡ Redis bit ç»“æ„ã€‚ é€šå¸¸æ–¹æ¡ˆï¼š ä½¿ç”¨ Redis çš„ å¤š uv æŒ‡æ ‡è®¡ç®—é“¾è·¯ è¿™ç§åœºæ™¯ä¸‹ï¼Œå¦‚æœæœ‰ 1 äº¿ç”¨æˆ·ï¼Œéœ€è¦åŒæ—¶è®¡ç®— 50 ä¸ªæ´»åŠ¨æˆ–è€… 50 ä¸ªä¸åŒç»´åº¦ä¸‹çš„ uvã€‚é‚£ä¹ˆç†è®ºä¸Šæœ€å¤§ key æ•°é‡ä¸º 1 äº¿ * 50 = 50 äº¿ä¸ª keyã€‚ Redis bit æ–¹æ¡ˆï¼š ä½¿ç”¨ Redis bit ç‰¹æ€§çš„ å¤š uv æŒ‡æ ‡è®¡ç®—é“¾è·¯ è¿™æ ·åšçš„ä¸€ä¸ªä¼˜ç‚¹ï¼Œå°±æ˜¯è¿™å‡ ååœºæ´»åŠ¨çš„ uv è®¡ç®—éƒ½ä½¿ç”¨äº†ç›¸åŒçš„ Redis key æ¥è®¡ç®—ï¼Œå¯ä»¥å¤§å¹…åº¦å‡å°‘ Redis çš„å®¹é‡å ç”¨ã€‚ä½¿ç”¨æ­¤æ–¹æ¡ˆçš„è¯ï¼Œä»¥ä¸Šè¿°ç›¸åŒçš„ç”¨æˆ·å’Œæ´»åŠ¨åœºæ•°ï¼Œç†è®ºä¸Šæœ€å¤§key æ•°é‡ä»…ä»…ä¸º 1 äº¿ï¼Œåªæ˜¯ value æ•°é‡ä¼šå¤šå å‡ åä¸ª bitã€‚","tags":[{"name":"Apache Druid","slug":"Apache-Druid","permalink":"https://yangyichao-mango.github.io/tags/Apache-Druid/"},{"name":"Apache Zookeeper","slug":"Apache-Zookeeper","permalink":"https://yangyichao-mango.github.io/tags/Apache-Zookeeper/"}]},{"title":"å®æ—¶æ–°å¢ç±»æŒ‡æ ‡æ ‡å‡†åŒ–å¤„ç†æ–¹æ¡ˆ","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/apache-flink:realtime-new-id/","text":"å®æ—¶æ–°å¢ç±»æŒ‡æ ‡æ ‡å‡†åŒ–å¤„ç†æ–¹æ¡ˆ å®æ—¶æŒ‡æ ‡æ•´ä¸ªé“¾è·¯å¼€å‘è¿‡ç¨‹ä¸­çš„ä¸€äº›ç»éªŒã€‚ å®æ—¶æ–°å¢ç±»æŒ‡æ ‡å¤§ä½“ä¸Šå¯ä»¥å°†å®æ—¶æ–°å¢ç±»æŒ‡æ ‡ä»¥ä»¥ä¸‹ä¸¤ç§ç»´åº¦è¿›è¡Œåˆ†ç±»ã€‚ identity id ç±»å‹ç»´åº¦ identity id ç±»å‹ å¤‡æ³¨ number(long) ç±»å‹ identity id æ•°å€¼ç±»å‹ identity id çš„å¥½å¤„åœ¨äºå¯ä»¥ä½¿ç”¨ Bitmap ç±»ç»„ä»¶åšåˆ°ç²¾ç¡®å»é‡ã€‚ å­—ç¬¦ç±»å‹ identity id å­—ç¬¦ç±»å‹ identity id å»é‡ç›¸å¯¹å¤æ‚ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼Œåœ¨è¯¯å·®å…è®¸èŒƒå›´ä¹‹å†…ä½¿ç”¨ BloomFilter è¿›è¡Œå»é‡ï¼Œæˆ–è€…ä½¿ç”¨ key-value ç»„ä»¶è¿›è¡Œç²¾ç¡®å»é‡ã€‚ äº§å‡ºæ•°æ®ç±»å‹ç»´åº¦ äº§å‡ºæ•°æ®ç±»å‹ å¤‡æ³¨ æ˜ç»†ç±»æ•°æ® æ­¤ç±»æ•°æ®ä¸€èˆ¬æ˜¯è¦æ±‚å°†æ–°å¢çš„æ•°æ®æ˜ç»†äº§å‡ºï¼Œuv çš„å«ä¹‰æ˜¯åšè¿‡æ»¤ï¼Œäº§å‡ºçš„æ˜ç»†æ•°æ®ä¸­çš„ identity id ä¸ä¼šæœ‰é‡å¤ã€‚è¾“å‡ºæ˜ç»†æ•°æ®çš„å¥½å¤„åœ¨äºï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨ OLAP å¼•æ“å¯¹æ˜ç»†æ•°æ®è¿›è¡Œå„ç§ç»´åº¦çš„èšåˆè®¡ç®—ï¼Œä»è€Œå¾ˆæ–¹ä¾¿çš„äº§å‡ºä¸åŒç»´åº¦ä¸‹çš„ uv æ•°æ®ã€‚ èšåˆç±»æ•°æ® å°†ä¸€ä¸ªæ—¶é—´çª—å£å†…çš„ uv è¿›è¡Œèšåˆï¼Œå¹¶ä¸”å¯ä»¥è®¡ç®—å‡ºåˆ†ç»´åº¦çš„ uvï¼Œå…¶äº§å‡ºæ•°æ®ä¸€èˆ¬éƒ½æ˜¯[ç»´åº¦ + uv_count]ï¼Œä½†æ˜¯è¿™é‡Œçš„ç»´åº¦ä¸€èˆ¬æƒ…å†µä¸‹æ˜¯éƒ½æ˜¯å›ºå®šç»´åº¦ã€‚å¦‚æœéœ€è¦æ‹“å±•åˆ™éœ€è¦æ”¹åŠ¨æºç ã€‚ è®¡ç®—é“¾è·¯å› æ­¤æ–°å¢äº§å‡ºçš„é“¾è·¯å¤šæ•°å°±æ˜¯ä»¥ä¸Šä¸¤ç§ç»´åº¦å› å­çš„ç›¸äº’ç»„åˆã€‚ number(long) ç±»å‹ identity id ä½¿ç”¨ RoaringBitmap çš„ uv è®¡ç®—é“¾è·¯ ä»£ç ç¤ºä¾‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public interface RoaringBitmapDuplicateable&lt;Model&gt; &#123; long DEFAULT_DUPLICATE_MILLS = 24 * 3600 * 1000L; BiPredicate&lt;Long, Long&gt; ROARING_BIT_MAP_CLEAR_BI_PREDICATE = (start, end) -&gt; end - start &gt;= DEFAULT_DUPLICATE_MILLS; // åˆå§‹åŒ– default ValueState&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt; getBitMapValueState(String name) &#123; return this.getRuntimeContext().getState( new ValueStateDescriptor&lt;&gt;(name, TypeInformation.of( new TypeHint&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt;() &#123; &#125;)) ); &#125; RuntimeContext getRuntimeContext(); long getLongId(Model model); Optional&lt;Logger&gt; getLogger(); default BiPredicate&lt;Long, Long&gt; roaringBitMapClearBiPredicate() &#123; return ROARING_BIT_MAP_CLEAR_BI_PREDICATE; &#125; default List&lt;Model&gt; duplicateAndGet(List&lt;Model&gt; models, long windowStartTimestamp , ValueState&lt;Tuple2&lt;Date, Roaring64NavigableMap&gt;&gt; bitMapValueState) throws IOException &#123; Tuple2&lt;Date, Roaring64NavigableMap&gt; bitMap = checkAndGetState(windowStartTimestamp, bitMapValueState); Map&lt;Long, Model&gt; idModelsMap = models .stream() .collect(Collectors.toMap(this::getLongId, Function.identity(), (oldOne, newOne) -&gt; oldOne)); Set&lt;Long&gt; ids = idModelsMap.keySet(); List&lt;Model&gt; newModels = Lists.newArrayList(); for (Long id : ids) &#123; if (!bitMap.f1.contains(id)) &#123; if (idModelsMap.containsKey(id)) &#123; newModels.add(idModelsMap.get(id)); &#125; &#125; &#125; newModels.stream() .map(this::getLongId) .forEach(bitMap.f1::add); bitMapValueState.update(bitMap); return newModels; &#125; default long duplicateAndCount(List&lt;Model&gt; models, long windowStartTimestamp , ValueState&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt; bitMapValueState) throws IOException &#123; Tuple2&lt;Long, Roaring64NavigableMap&gt; bitMap = checkAndGetState(windowStartTimestamp, bitMapValueState); Set&lt;Long&gt; ids = models .stream() .map(this::getLongId) .collect(Collectors.toSet()); List&lt;Long&gt; newIds = Lists.newArrayList(); int count = 0; for (Long id : ids) &#123; if (!bitMap.f1.contains(id)) &#123; newIds.add(id); count++; &#125; &#125; newIds.forEach(bitMap.f1::add); bitMapValueState.update(bitMap); return count; &#125; default Tuple2&lt;Long, Roaring64NavigableMap&gt; checkAndGetState(long windowStartTimestamp , ValueState&lt;Tuple2&lt;Long, Roaring64NavigableMap&gt;&gt; bitMapValueState) throws IOException &#123; Tuple2&lt;Long, Roaring64NavigableMap&gt; bitmap = bitMapValueState.value(); if (null == bitmap) &#123; this.getLogger().ifPresent(logger -&gt; logger.info(\"New RoaringBitMapValueState Timestamp=&#123;&#125;\", windowStartTimestamp)); Tuple2&lt;Long, Roaring64NavigableMap&gt; newBitMap = Tuple2.of(windowStartTimestamp, new Roaring64NavigableMap()); bitMapValueState.update(newBitMap); return newBitMap; &#125; else if (this.roaringBitMapClearBiPredicate().test(bitmap.f0, windowStartTimestamp)) &#123; this.getLogger().ifPresent(logger -&gt; logger.info(\"Clear RoaringBitMapValueState, from start=&#123;&#125; to end=&#123;&#125;\", bitmap.f0, windowStartTimestamp)); bitMapValueState.clear(); bitmap.f1.clear(); Tuple2&lt;Long, Roaring64NavigableMap&gt; newBitMap = Tuple2.of(windowStartTimestamp, new Roaring64NavigableMap()); bitMapValueState.update(newBitMap); return newBitMap; &#125; else &#123; return bitmap; &#125; &#125;&#125; å­—ç¬¦ç±»å‹ identity idä½¿ç”¨ Flink state ä½¿ç”¨ flink state çš„ uv è®¡ç®—é“¾è·¯ ä½¿ç”¨ key-value å¤–å­˜ ä½¿ç”¨ key-value çš„ uv è®¡ç®—é“¾è·¯ å¦‚æœé€‰ç”¨çš„æ˜¯ Redis ä½œä¸º key-value è¿‡æ»¤ï¼Œé‚£ä¹ˆè¿™é‡Œä¼šæœ‰ä¸€ä¸ªå·§ç”¨ Redis bit ç‰¹æ€§çš„ä¼˜åŒ–ã€‚ä¸¾ä¸€ä¸ªä¸€èˆ¬åœºæ™¯ä¸‹çš„æ–¹æ¡ˆä¸ä½¿ç”¨ Redis bit ç‰¹æ€§çš„æ–¹æ¡ˆåšå¯¹æ¯”ï¼š åœºæ™¯ï¼šå‡å¦‚éœ€è¦åŒä¸€å¤©æœ‰å‡ ååœºæ´»åŠ¨ï¼Œå¹¶ä¸”éƒ½å¸Œæœ›è®¡ç®—å‡ºè¿™å‡ ååœºæ´»åŠ¨çš„ uvï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æŒ‰ç…§ä¸‹å›¾è®¾è®¡ Redis bit ç»“æ„ã€‚ é€šå¸¸æ–¹æ¡ˆï¼š ä½¿ç”¨ Redis çš„ å¤š uv æŒ‡æ ‡è®¡ç®—é“¾è·¯ è¿™ç§åœºæ™¯ä¸‹ï¼Œå¦‚æœæœ‰ 1 äº¿ç”¨æˆ·ï¼Œéœ€è¦åŒæ—¶è®¡ç®— 50 ä¸ªæ´»åŠ¨æˆ–è€… 50 ä¸ªä¸åŒç»´åº¦ä¸‹çš„ uvã€‚é‚£ä¹ˆç†è®ºä¸Šæœ€å¤§ key æ•°é‡ä¸º 1 äº¿ * 50 = 50 äº¿ä¸ª keyã€‚ Redis bit æ–¹æ¡ˆï¼š ä½¿ç”¨ Redis bit ç‰¹æ€§çš„ å¤š uv æŒ‡æ ‡è®¡ç®—é“¾è·¯ è¿™æ ·åšçš„ä¸€ä¸ªä¼˜ç‚¹ï¼Œå°±æ˜¯è¿™å‡ ååœºæ´»åŠ¨çš„ uv è®¡ç®—éƒ½ä½¿ç”¨äº†ç›¸åŒçš„ Redis key æ¥è®¡ç®—ï¼Œå¯ä»¥å¤§å¹…åº¦å‡å°‘ Redis çš„å®¹é‡å ç”¨ã€‚ä½¿ç”¨æ­¤æ–¹æ¡ˆçš„è¯ï¼Œä»¥ä¸Šè¿°ç›¸åŒçš„ç”¨æˆ·å’Œæ´»åŠ¨åœºæ•°ï¼Œç†è®ºä¸Šæœ€å¤§key æ•°é‡ä»…ä»…ä¸º 1 äº¿ï¼Œåªæ˜¯ value æ•°é‡ä¼šå¤šå å‡ åä¸ª bitã€‚","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"å®æ—¶å¼€å‘æ ‡å‡†åŒ–å¤„ç†æ–¹æ¡ˆ","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/realtime/","text":"å®æ—¶å¼€å‘æ ‡å‡†åŒ–å¤„ç†æ–¹æ¡ˆ å®æ—¶æŒ‡æ ‡æ•´ä¸ªé“¾è·¯å¼€å‘è¿‡ç¨‹ä¸­çš„ä¸€äº›ç»éªŒã€‚ æŒ‡æ ‡ç±»å‹ æŒ‡æ ‡ç±»å‹ å¤‡æ³¨ pv ç®€å• pv ç±»å‹æŒ‡æ ‡ï¼Œæ¥ä¸€æ¡æ—¥å¿—ä¿¡æ¯åŠ ä¸€ï¼Œè®¡ç®— count uv uv ç±»å‹æŒ‡æ ‡ï¼Œéœ€è¦åœ¨ä¸€æ®µæ—¶é—´èŒƒå›´å†…ï¼ˆä¸€å°æ—¶ã€ä¸€å¤©ã€ä¸€åœºæ´»åŠ¨ï¼‰æ­£å¯¹ user_id ç­‰ identity_id å»é‡è®¡æ•°ã€‚ ç›‘æ§åœˆå®šé›†åˆå†…çš„ identity_id æ•°æ®è¡¨ç° æœ‰ä¸€ç»„é‰´å®šçš„ identity_id é›†åˆï¼Œå®æ—¶çš„ç›‘æ§æˆ–è€…è®¡ç®—è¿™ç»„ identity_id ç›¸å…³çš„æ•°æ® æ’å å®æ—¶ç›‘æ§æŸäº›æ•°æ®å¹¶æ ¹æ®æŸäº›æŒ‡æ ‡è¿›è¡Œæ’åº","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"ç”Ÿäº§å®è·µ | åŸºäº Flink çš„è§†é¢‘ç›´æ’­æ ¸å¿ƒæŒ‡æ ‡ç›‘æ§","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/apache-flink:learning-files/","text":"Flink å­¦ä¹ èµ„æ–™ Flink ç³»åˆ—å®˜ç½‘æ–‡æ¡£è¿˜æ˜¯æœ€å‡†ç¡®çš„ã€‚ç›´æ¥ä¸Šè§†é¢‘å’Œèµ„æ–™ï¼Œæ‡’ç™Œæ‚£è€…ç›´æ¥æ‹¿èµ°å³å¯~ è§†é¢‘bç«™é“¾æ¥ï¼Œå¾ˆå¤šå¤§å‚çš„å®æˆ˜ï¼Œè®²è§£å¾ˆè¯¦ç»†ï¼Œå¾ˆé€‚åˆåˆå­¦è€…ã€‚ èµ„æ–™ é“¾æ¥ï¼šhttps://pan.baidu.com/s/1GzVJYpUxkucLS9ZikZWuRwã€æå–ç ï¼š64n4 å…¶ä»–è§†é¢‘é“¾æ¥å¯ç‚¹å‡»å…¬ä¼—å· [call me] è”ç³»åšä¸»ç§èŠè·å– æ–‡æ¡£1.Flink å®˜ç½‘æ–‡æ¡£ã€Flink å®˜ç½‘ä¸­æ–‡æ–‡æ¡£ 2.ã€ŠStream Processing with Apache Flinkã€‹ è¿™æœ¬ç”± Flink PMC å†™çš„ Flink ä¹¦ç±ä¹Ÿæ˜¯å¾ˆé€‚åˆåˆå­¦è€…ï¼Œå¹¶ä¸”ä¸­æ–‡ç‰ˆå·²ç»å‡ºç‰ˆäº† ï¼šã€ŠåŸºäº Apache Flink çš„æµå¤„ç†ã€‹ï¼Œç”± Flink committer å´”æ˜Ÿç¿å¤§ä½¬ç¿»è¯‘ 3.ververica ä¸­æ–‡ç½‘å’Œ Flink é’‰é’‰ç¾¤ç›´æ’­æ•™ç¨‹ 4.å¾®ä¿¡å…¬ä¼—å·(ç”±Flink ä¸­æ–‡ç¤¾åŒºç»´æŠ¤)ï¼šFlink ä¸­æ–‡ç¤¾åŒº ä»¥åŠ Flink 5.Flink çŸ¥è¯†å›¾è°±ä»¥åŠç¤¾åŒºä¸“åˆŠ 6.åŠ å…¥ Apache Flink Chinaç¤¾åŒº é’‰é’‰ç¾¤ï¼ˆç¾¤å·ï¼š23138101ï¼‰ï¼Œå¾ˆå¤šå¤§ä½¬æ´»è·ƒ 7.è®¢é˜… Flink userã€user-zh é‚®ä»¶åˆ—è¡¨ï¼Œå¯åœ¨å®˜ç½‘æŸ¥çœ‹è®¢é˜…æ–¹å¼ï¼Œé‚®ä»¶åˆ—è¡¨ä¸­æœ‰å¾ˆå¤šè§£å†³æ–¹æ¡ˆï¼Œä¹Ÿæœ‰å¤§ä½¬ä»¬æ´»è·ƒè§£ç­” 8.Flink è§†é¢‘ç³»åˆ— githubåœ°å€ oreilly æµæ¨¡å‹ä»‹ç» Streaming 101: The world beyond batch Streaming 102: The world beyond batch Flink æºç  github gitee ä¹¦ç±ç¤¾åˆŠä¹¦ç±ã€ŠStream Processing with Apache Flinkã€‹ ã€ŠåŸºäº Apache Flink çš„æµå¤„ç†ã€‹ ç¤¾åˆŠæºè‡ª ververicaï¼Œç¤¾åˆŠé“¾æ¥ï¼Œæ€»å…±åˆ†ä¸º 4 æœŸï¼Œå¯ä»¥ç›´æ¥åœ¨ ververica å®˜ç½‘ä¸‹è½½ã€‚ ç³»åˆ—åšå®¢1.äº‘é‚ªåŸç†ç³»åˆ— 2.é‡‘ç«¹æ¼«è°ˆç³»åˆ— 3.æ¨åçš„æºç  4.Apache Flink é›¶åŸºç¡€å…¥é—¨ç³»åˆ— 5.zhisheng 6.å½»åº•æ˜ç™½Flinkç³»ç»Ÿå­¦ä¹ ç³»åˆ— 7.kangqi 8.flinkèœé¸Ÿ","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"ç”Ÿäº§å®è·µ | åŸºäº Flink çš„è§†é¢‘ç›´æ’­æ ¸å¿ƒæŒ‡æ ‡ç›‘æ§","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/apache-flink:realtime-live-stream/","text":"ç”Ÿäº§å®è·µ | åŸºäº Flink çš„è§†é¢‘ç›´æ’­æ ¸å¿ƒæŒ‡æ ‡ç›‘æ§ æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨å®æ—¶è®¡ç®—å®Œæˆè§†é¢‘ç›´æ’­çš„æ ¸å¿ƒæŒ‡æ ‡ç›‘æ§ã€‚ çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹ç›‘æ§éšç€äº’è”ç½‘ç»œæŠ€æœ¯çš„å‘å±•ï¼Œç½‘ç»œç›´æ’­å—åˆ°è¶Šæ¥è¶Šå¤šäººçš„å…³æ³¨ï¼Œç‰¹åˆ«æ˜¯è§†é¢‘ç›´æ’­ç”Ÿæ€é“¾ã€‚é€šè¿‡ç½‘ç»œä¿¡å·ï¼Œæˆ‘ä»¬åœ¨çº¿æ”¶çœ‹ä½“è‚²èµ›äº‹ã€é‡å¤§æ´»åŠ¨å’Œæ–°é—»ç­‰ï¼ŒçœŸæ­£åœ°ä½“éªŒç›´æ’­çš„ä¹è¶£ã€‚ åœ¨ä½“éªŒä¸ºç‹çš„æ—¶ä»£ï¼Œä»»ä½•ä½“éªŒä¸ä½³å‡ä¼šå¯¼è‡´å®¢æˆ·ç¾¤ä½“å¤§è§„æ¨¡çš„æµå¤±ã€‚å¯¹äºç½‘ç«™ç›´æ’­å¹³å°è€Œè¨€ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨ä»¥ä¸‹å‡ ç‚¹ï¼š æœ¬æ–‡å°†å®Œæ•´åˆ†æå‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®çš„æ•´æ¡é“¾è·¯æµè½¬æ–¹å¼ï¼Œå¹¶åŸºäº Flink æä¾›å‡ ç§å¯¹äºå‚ç±»è§†é¢‘ç”Ÿäº§æ¶ˆè´¹ç›‘æ§çš„æ–¹æ¡ˆè®¾è®¡ã€‚é€šè¿‡æœ¬æ–‡ï¼Œä½ å¯ä»¥äº†è§£åˆ°ï¼š å¹³å°è¿è¥æ–¹åŠæ—¶è·Ÿè¸ªå’Œäº†è§£ç›´æ’­æ•´ä½“çš„å¤§ç›˜æƒ…å†µ å®æ—¶ç›‘æ§çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹çš„æ–¹æ¡ˆè®¾è®¡ ä¸åŒç›‘æ§é‡çº§åœºæ™¯ä¸‹çš„ä»£ç å®ç° flink å­¦ä¹ èµ„æ–™ é¡¹ç›®ç®€ä»‹å‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯æµè½¬æ¶æ„å›¾å¦‚ä¸‹ï¼Œæ­¤æ•°æ®æµè½¬å›¾ä¹Ÿé€‚ç”¨äºå…¶ä»–åœºæ™¯ï¼š é“¾è·¯ åœ¨ä¸Šè¿°åœºæ™¯ä¸­ï¼Œç”¨æˆ·ç”Ÿäº§å’Œæ¶ˆè´¹çŸ­è§†é¢‘ï¼Œä»è€Œå®¢æˆ·ç«¯ã€æœåŠ¡ç«¯ä»¥åŠæ•°æ®åº“ä¼šäº§ç”Ÿç›¸åº”çš„è¡Œä¸ºæ“ä½œæ—¥å¿—ï¼Œè¿™äº›æ—¥å¿—ä¼šé€šè¿‡æ—¥å¿—æŠ½å–ä¸­é—´ä»¶æŠ½å–åˆ°æ¶ˆæ¯é˜Ÿåˆ—ä¸­ï¼Œæˆ‘ä»¬ç›®å‰çš„åœºæ™¯ä¸­æ˜¯ä½¿ç”¨ Kafka ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—ï¼›ç„¶åä½¿ç”¨ flink å¯¹å‚ç±»ç”Ÿæ€ä¸­çš„è§†é¢‘è¿›è¡Œç”Ÿäº§æˆ–æ¶ˆè´¹ç›‘æ§ï¼ˆå†…å®¹ç”Ÿäº§é€šå¸¸æ˜¯åœˆå®šå‚ç±»ä½œè€… id æ± ï¼Œå†…å®¹æ¶ˆè´¹é€šå¸¸æ˜¯åœˆå®šå‚ç±»è§†é¢‘ id æ± ï¼‰ï¼Œæœ€åå°†å®æ—¶èšåˆæ•°æ®äº§å‡ºåˆ°ä¸‹æ¸¸ï¼›ä¸‹æ¸¸å¯ä»¥ä»¥æ•°æ®æœåŠ¡ï¼Œå®æ—¶çœ‹æ¿çš„æ–¹å¼å±•ç°ï¼Œè¿è¥åŒå­¦æˆ–è€…è‡ªåŠ¨åŒ–å·¥å…·æœ€ç»ˆä¼šå¸®åŠ©æˆ‘ä»¬åˆ†æå½“å‰å‚ç±»ä¸‹çš„ç”Ÿäº§æˆ–è€…æ¶ˆè´¹çƒ­ç‚¹ï¼Œä»è€Œç”Ÿæˆæ¨èç­–ç•¥ã€‚ æ–¹æ¡ˆè®¾è®¡ æ¶æ„ å…¶ä¸­æ•°æ®æºå¦‚ä¸‹ï¼š Kafka ä¸ºå…¨é‡å†…å®¹ç”Ÿäº§å’Œå†…å®¹æ¶ˆè´¹çš„æ—¥å¿—ã€‚ Rpc/Http/Mysql/é…ç½®ä¸­å¿ƒ/Redis/HBase ä¸ºéœ€è¦ç›‘æ§çš„å‚ç±»ç”Ÿæ€å†…å®¹ id æ± ï¼ˆå†…å®¹ç”Ÿäº§åˆ™ä¸ºä½œè€… id æ± ï¼Œå†…å®¹æ¶ˆè´¹åˆ™ä¸ºè§†é¢‘ id æ± ï¼‰ï¼Œå…¶ä¸»è¦æ˜¯æä¾›ç»™è¿è¥åŒå­¦åŠ¨æ€é…ç½®éœ€è¦ç›‘æ§çš„ id èŒƒå›´ï¼Œå…¶å¯ä»¥åœ¨ flink ä¸­è¿›è¡Œå®æ—¶æŸ¥è¯¢ï¼Œè§£æè¿è¥åŒå­¦æƒ³è¦çš„ç›‘æ§æŒ‡æ ‡èŒƒå›´ï¼Œä»¥åŠç›‘æ§çš„æŒ‡æ ‡å’Œè®¡ç®—æ–¹å¼ï¼Œç„¶ååŠ å·¥æ•°æ®äº§å‡ºï¼Œå¯ä»¥æ”¯æŒéšæ—¶é…ç½®ï¼Œå®æ—¶æ•°æ®éšæ—¶è®¡ç®—äº§å‡ºã€‚ å…¶ä¸­æ•°æ®æ±‡ä¸ºèšç±»å¥½çš„å†…å®¹ç”Ÿäº§æˆ–è€…æ¶ˆè´¹çƒ­ç‚¹è¯é¢˜æˆ–è€…äº‹ä»¶æŒ‡æ ‡ï¼š Redis/HBase ä¸»è¦æ˜¯ä»¥ä½å»¶è¿Ÿï¼ˆRedis 5ms p99ï¼ŒHBase 100ms p99ï¼Œä¸åŒå…¬å¸çš„æœåŠ¡èƒ½åŠ›ä¸åŒï¼‰å¹¶ä¸”é«˜ QPS æä¾›æ•°æ®æœåŠ¡ï¼Œç»™ Server ç«¯æˆ–è€…çº¿ä¸Šç”¨æˆ·æä¾›ä½å»¶è¿Ÿçš„æ•°æ®æŸ¥è¯¢ã€‚ Druid/Mysql å¯ä»¥åšä¸º OLAP å¼•æ“ä¸º BI åˆ†ææä¾›çµæ´»çš„ä¸Šå·ä¸‹é’»èšåˆåˆ†æèƒ½åŠ›ï¼Œä¾›è¿è¥åŒå­¦é…ç½®å¯è§†åŒ–å›¾è¡¨ä½¿ç”¨ã€‚ Kafka å¯ä»¥ä»¥æµå¼æ•°æ®äº§å‡ºï¼Œä»è€Œæä¾›ç»™ä¸‹æ¸¸ç»§ç»­æ¶ˆè´¹æˆ–è€…è¿›è¡Œç‰¹å¾æå–ã€‚ åºŸè¯ä¸å¤šè¯´ï¼Œæˆ‘ä»¬ç›´æ¥ä¸Šæ–¹æ¡ˆå’Œä»£ç ï¼Œä¸‹è¿°å‡ ç§æ–¹æ¡ˆæŒ‰ç…§ç›‘æ§ id èŒƒå›´é‡çº§åŒºåˆ†ï¼Œä¸åŒçš„é‡çº§å¯¹åº”ç€ä¸åŒçš„æ–¹æ¡ˆï¼Œå…¶ä¸­çš„ä»£ç ç¤ºä¾‹ä¸º ProcessWindowFunctionï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ AggregateFunction ä»£æ›¿ï¼Œå…¶ä¸­ä¸»è¦ç›‘æ§é€»è¾‘éƒ½ç›¸åŒã€‚ æ–¹æ¡ˆ 11.éœ€æ±‚ï¼š ç›´æ’­ç”Ÿäº§ä¾§1.å¤§ç›˜æ•´ä½“ç²’åº¦ï¼šè®¡ç®—åˆ†ç»´åº¦ä¸‹ï¼ˆç›´æ’­é—´ç”»åƒï¼šå¼€æ’­çš„å¹³å°ï¼Œä¸»æ’­ç”¨æˆ·ç”»åƒç­‰ç»´åº¦ï¼‰çš„æ­£åœ¨ç›´æ’­çš„ç›´æ’­é—´æ•°ï¼Œæ­£åœ¨ç›´æ’­çš„xxæ•°ï¼Œæ­£åœ¨ç›´æ’­çš„ç›´æ’­é—´çš„ç›´æ’­æ—¶é•¿ ç›´æ’­æ¶ˆè´¹ä¾§1.å¤§ç›˜æ•´ä½“ç²’åº¦ï¼šè®¡ç®—åˆ†ç»´åº¦ä¸‹ï¼ˆç›´æ’­é—´ç”»åƒï¼šå¼€æ’­çš„å¹³å°ï¼Œä¸»æ’­ç”¨æˆ·ç”»åƒç­‰ç»´åº¦ï¼›è§‚ä¼—ç”»åƒï¼šæ€§åˆ«ï¼Œç²‰ä¸èŒƒå›´ç­‰ç»´åº¦ï¼‰çš„è§‚çœ‹ç›´æ’­çš„è§‚ä¼—æ•°ï¼Œç›´æ’­ç‚¹èµæ•°ç­‰æŒ‡æ ‡2.ç›´æ’­é—´ç²’åº¦ï¼šå¡«å……ç›´æ’­é—´ç”»åƒï¼ˆç›´æ’­é—´ç”»åƒï¼šå¼€æ’­çš„å¹³å°ï¼Œä¸»æ’­ç”¨æˆ·ç”»åƒï¼‰å¹¶è®¡ç®—åˆ†ç»´åº¦ä¸‹ï¼ˆè§‚ä¼—ç”»åƒï¼šæ€§åˆ«ï¼Œç²‰ä¸èŒƒå›´ç­‰ç»´åº¦ï¼‰çš„ç›´æ’­é—´è§‚ä¼—æ•°ï¼Œç‚¹èµæ•°ç­‰æŒ‡æ ‡ æ•´ä½“éœ€æ±‚åˆ’åˆ†ï¼š ä»ä¸Šè¿°éœ€æ±‚æŒ‡æ ‡å¯ä»¥çœ‹å‡ºï¼Œæ•´ä½“çš„å†…å®¹åˆ†ä¸ºä¸¤ç±»ï¼Œç¬¬ä¸€ç±»æ˜¯ç»´è¡¨çš„å»ºè®¾ï¼Œç¬¬äºŒç±»æ˜¯åŸºäºäº§å‡ºçš„ç»´è¡¨çš„å®æ—¶æŒ‡æ ‡çš„å»ºè®¾ã€‚ ç»´è¡¨ï¼šæ— è®ºæ˜¯ç›´æ’­é—´ä¾§è¿˜æ˜¯è§‚ä¼—ä¾§ç›¸å…³çš„æŒ‡æ ‡ï¼Œæœ€ç»ˆäº§å‡ºçš„æŒ‡æ ‡éƒ½éœ€è¦æ˜¯å¸¦æœ‰ç»´åº¦çš„æŒ‡æ ‡ï¼Œå…¶ä¸­éœ€è¦å¡«å……çš„ç»´åº¦ä»¥åŠç”»åƒå¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼Œç¬¬ä¸€ç±»æ˜¯ç›´æ’­é—´çš„ç”»åƒï¼Œç¬¬äºŒç±»ä¸»æ’­çš„ç”¨æˆ·ç”»åƒï¼Œç¬¬ä¸‰ç±»æ˜¯è§‚ä¼—çš„ç”¨æˆ·ç”»åƒã€‚1.ç›´æ’­é—´çš„ç”»åƒå»ºè®¾ï¼šç”±äºç›´æ’­é—´ç›¸å…³çš„ç”»åƒä¿¡æ¯æ˜¯ä¸»æ’­å¼€æ’­ä¹‹åæ‰ä¼šæœ‰ï¼Œæ‰€ä»¥ç›´æ’­é—´çš„ç”»åƒä¿¡æ¯æ˜¯éœ€è¦è¿›è¡Œå®æ—¶å»ºè®¾ï¼Œæ‰€ä»¥éœ€è¦ç›´æ’­é—´çš„ç”»åƒç»´è¡¨æ˜¯å®æ—¶ç»´è¡¨ã€‚2.ä¸»æ’­å’Œè§‚ä¼—çš„ç”¨æˆ·ç”»åƒå»ºè®¾ï¼šä¸»æ’­å’Œå…³æ³¨çš„ç”¨æˆ·ç”»åƒä¸€èˆ¬æƒ…å†µä¸‹æ˜¯å›ºå®šçš„ï¼Œå¾ˆå°‘è¿›è¡Œå˜åŠ¨ï¼Œæ‰€ä»¥è¿™é‡Œçš„ç”¨æˆ·ç”»åƒæˆ‘ä»¬å–ç¦»çº¿ t - 1 æˆ–è€… t - 2 çš„æ•°æ®å³å¯ï¼Œæ‰€ä»¥ç”¨æˆ·ç”»åƒç»´è¡¨æ˜¯ç¦»çº¿ç»´è¡¨ã€‚æ³¨ï¼šå¯¹äºç¬¬ä¸€æ¬¡å¼€æ’­çš„æ–°ä¸»æ’­ï¼Œå…¶ç”¨æˆ·ç”»åƒç›´æ¥ä½¿ç”¨ UNKNOWN è¿›è¡Œä»£æ›¿ï¼Œå®é™…æƒ…å†µæ–°å¼€æ’­çš„ä¸»æ’­å æ¯”éå¸¸å°‘ï¼ŒUNKNOWN çš„æ¯”ä¾‹ä¹Ÿå¾ˆä½ã€‚ æŒ‡æ ‡ï¼šæŒ‡æ ‡æ€»å…±åˆ†ä¸ºä¸¤ç±»ï¼Œå…¶ä¸­ä½¿ç”¨åˆ°çš„æ‰€æœ‰ç»´åº¦ç›¸å…³æ•°æ®éƒ½ç”±ä¸Šè¿°ç»´è¡¨å»ºè®¾çš„æ•°æ®æä¾›ã€‚1.å¤§ç›˜æ•´ä½“ç²’åº¦çš„æŒ‡æ ‡å»ºè®¾ï¼šäº§å‡ºç»†åˆ†åˆ°å„ä¸ªç»´åº¦çš„æŒ‡æ ‡ã€‚2.ç›´æ’­é—´ç²’åº¦çš„æŒ‡æ ‡å»ºè®¾ï¼šäº§å‡ºç»†åˆ†åˆ°ç›´æ’­é—´id + å„ä¸ªç»´åº¦çš„æŒ‡æ ‡ã€‚ æ•´ä½“æ¶æ„æ–¹æ¡ˆï¼š 1.ç»´è¡¨ç›´æ’­é—´çš„ç”»åƒå»ºè®¾ï¼š æ•´ä½“è®¡ç®—æµç¨‹ï¼š ä¸€ï¼šå¡«å……ç›´æ’­é—´ç»´åº¦æµç¨‹ å°†ã€å¼€æ’­ç›´æ’­é—´ã€‘ï¼Œã€å…³æ’­ç›´æ’­é—´åŒºã€‘åˆ†å‡ºæ¥ åˆ©ç”¨ã€æ­£åœ¨ç›´æ’­çš„ç›´æ’­é—´æ± ã€‘ï¼Œã€å¼€æ’­ç›´æ’­é—´ã€‘ï¼Œã€å…³æ’­ç›´æ’­é—´ã€‘ä¸‰ç±»ç›´æ’­é—´å°†ã€åœ¨å½“å‰çª—å£ä¸­å¼€æ’­ã€‘ï¼Œã€åœ¨å½“å‰çª—å£ä¸­å¼€æ’­ä¸”å…³æ’­ã€‘ï¼Œã€ç›´æ’­é—´æ± ä¸­çš„ç›´æ’­é—´å…³æ’­ã€‘åŒºåˆ†å‡ºæ¥ ç»Ÿè®¡æ‰€æœ‰ã€éœ€è¦è·å–ç›´æ’­é—´ç»´åº¦æ•°æ®çš„ç›´æ’­é—´ã€‘ = ã€æ­£åœ¨ç›´æ’­çš„ç›´æ’­é—´ã€‘+ã€å¼€æ’­ç›´æ’­é—´ã€‘ å…ˆä» local cache è·å–ï¼Œå†ä» redis è·å–ï¼Œå†å¯¹æ²¡æœ‰è·å–åˆ°ç»´åº¦çš„ç›´æ’­é—´å¡«å……é»˜è®¤ç»´åº¦ï¼ˆå¡«å……è§„åˆ™ï¼Œå¦‚æœæ˜¯å¼€æ’­ç›´æ’­é—´ï¼Œå¯ä»¥å¡«å…… author idï¼Œå‰©ä½™çš„éƒ½æ˜¯æ— ç»´åº¦æ•°æ®ï¼‰ äºŒï¼šä¸‹é’»æµç¨‹ é’ˆå¯¹ã€å¼€æ’­ç›´æ’­é—´ã€‘æŒ‡æ ‡ä¸‹é’»ï¼Œå°†ç›´æ’­é—´ id å’Œç›´æ’­é—´ç»´åº¦ä¿¡æ¯æ˜ å°„æˆ List&lt;Tuple2&lt;LiveStreamId, LiveStreamDimInfo&gt;&gt; é’ˆå¯¹ã€å¼€æ’­ä¸»æ’­æ•°ã€‘æŒ‡æ ‡ä¸‹é’»ï¼Œå°†ä¸»æ’­ id å’Œç›´æ’­é—´ç»´åº¦ä¿¡æ¯æ˜ å°„æˆ List&lt;Tuple2&lt;LiveStreamAuthorId, LiveStreamDimInfo&gt;&gt; é’ˆå¯¹ã€å¼€æ’­æ—¶é•¿ã€‘æŒ‡æ ‡ä¸‹é’»ï¼Œå°†å¼€æ’­æ—¶é•¿ å’Œç›´æ’­é—´ç»´åº¦ä¿¡æ¯æ˜ å°„æˆ List&lt;Tuple2&lt;LiveStreamDuration, LiveStreamDimInfo&gt;&gt; ã€å¼€æ’­æ—¶é•¿ã€‘è®¡ç®—æµç¨‹ç›¸å¯¹å¤æ‚ a. å¦‚æœä¸ºã€åœ¨å½“å‰çª—å£ä¸­å¼€æ’­ã€‘ï¼Œåˆ™å¼€æ’­æ—¶é•¿ = windowEnd - startTimestamp b. å¦‚æœä¸ºã€åœ¨å½“å‰çª—å£ä¸­å¼€æ’­ä¸”å…³æ’­ã€‘ï¼Œåˆ™å¼€æ’­æ—¶é•¿ = endTimestamp - startTimestamp c. å¦‚æœä¸ºã€ç›´æ’­é—´æ± ä¸­çš„ç›´æ’­é—´å…³æ’­ã€‘ï¼Œåˆ™å¼€æ’­æ—¶é•¿ = endTimestamp - windowStart ä¸‰ï¼šäº§å‡º mi æ•°æ® é’ˆå¯¹ä¸‹é’»å®Œæˆçš„æ•°æ®ï¼Œäº§å‡ºæ˜ç»†æ•°æ® å››ï¼šæ ¹æ®å½“å‰åˆ†é’Ÿçš„ mi æ•°æ®ï¼Œäº§å‡º mf æ•°æ® æ­£å¯¹äº§å‡ºçš„ mi æ•°æ®ï¼Œæ ¹æ® ç›‘æ§çš„ id æ± å¯ä»¥æŒ‰ç…§å›ºå®šæˆ–è€…å¯é…ç½®ä»è€Œåˆ†å‡ºä¸¤ç§è·å–æ–¹å¼ï¼šç¬¬ä¸€ç§æ˜¯åœ¨ flink ä»»åŠ¡å¼€å§‹æ—¶å°±å…¨éƒ¨åŠ è½½è¿›å†…å­˜ä¸­ï¼Œè¿™ç§æ–¹å¼é€‚åˆç›‘æ§ id æ± ä¸å˜çš„æƒ…å†µï¼›ç¬¬äºŒç§æ˜¯ä½¿ç”¨åŠ¨æ€é…ç½®ä¸­å¿ƒï¼Œæ¯æ¬¡éƒ½ä»é…ç½®ä¸­å¿ƒè®¿é—®åˆ°æœ€æ–°çš„ç›‘æ§ id æ± ï¼Œå…¶å¯ä»¥æ»¡è¶³åŠ¨æ€é…ç½®æˆ–è€…æ›´æ”¹ id æ± çš„éœ€æ±‚ï¼Œå¹¶ä¸”è¿™ç§å®ç°æ–¹å¼é€šå¸¸å¯ä»¥å®æ—¶æ„ŸçŸ¥åˆ°é…ç½®æ›´æ”¹ï¼Œå‡ ä¹æ— å»¶è¿Ÿã€‚ æ–¹æ¡ˆ 2é€‚åˆç›‘æ§ id æ•°æ®é‡é€‚ä¸­ï¼ˆå‡ åä¸‡ idï¼‰ï¼Œç›‘æ§æ•°æ®èŒƒå›´ä¼šä¸å®šæ—¶å‘ç”Ÿå˜åŠ¨çš„åœºæ™¯ã€‚å…¶å®ç°æ–¹å¼æ˜¯åœ¨ flink ç®—å­ä¸­å®šæ—¶è®¿é—®æ¥å£è·å–æœ€æ–°çš„ç›‘æ§ id æ± ï¼Œä»¥è·å–æœ€æ–°ç›‘æ§æ•°æ®èŒƒå›´ã€‚ 1234567891011121314151617181920212223242526272829ProcessWindowFunction p = new ProcessWindowFunction&lt;CommonModel, CommonModel, Long, TimeWindow&gt;() &#123; private long lastRefreshTimestamp; private Set&lt;Long&gt; needMonitoredIds; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); this.refreshNeedMonitoredIds(System.currentTimeMillis()); &#125; @Override public void process(Long bucket, Context context, Iterable&lt;CommonModel&gt; iterable, Collector&lt;CommonModel&gt; collector) throws Exception &#123; long windowStart = context.window().getStart(); this.refreshNeedMonitoredIds(windowStart); /** * åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ */ &#125; public void refreshNeedMonitoredIds(long windowStart) &#123; // æ¯éš” 10 ç§’è®¿é—®ä¸€æ¬¡ if (windowStart - this.lastRefreshTimestamp &gt;= 10000L) &#123; this.lastRefreshTimestamp = windowStart; this.needMonitoredIds = Rpc.get(...) &#125; &#125;&#125; æ ¹æ®ä¸Šè¿°ä»£ç å®ç°æ–¹å¼ï¼ŒæŒ‰ç…§æ—¶é—´é—´éš”çš„æ–¹å¼åˆ·æ–° id æ± ï¼Œå…¶ç¼ºç‚¹åœ¨äºä¸èƒ½å®æ—¶æ„ŸçŸ¥ç›‘æ§ id æ± çš„å˜åŒ–ï¼Œæ‰€ä»¥åˆ·æ–°æ—¶é—´å¯èƒ½ä¼šå’Œéœ€æ±‚åœºæ™¯å¼ºè€¦åˆï¼ˆå¦‚æœ id æ± ä¼šé¢‘ç¹æ›´æ–°ï¼Œé‚£ä¹ˆå°±éœ€è¦ç¼©å°åˆ·æ–°æ—¶é—´é—´éš”ï¼‰ã€‚ä¹Ÿå¯æ ¹æ®éœ€æ±‚åœºæ™¯åœ¨æ¯ä¸ªçª—å£å¼€å§‹å‰åˆ·æ–° id æ± ï¼Œè¿™æ ·å¯ä¿è¯æ¯ä¸ªçª—å£ä¸­çš„ id æ± ä¸­çš„æ•°æ®ä¸€ç›´ä¿æŒæ›´æ–°ã€‚ æ–¹æ¡ˆ 3æ–¹æ¡ˆ 3 å¯¹æ–¹æ¡ˆ 2 çš„ä¸€ä¸ªä¼˜åŒ–ï¼ˆå‡ åä¸‡ idï¼Œæˆ‘ä»¬ç”Ÿäº§ç¯å¢ƒä¸­æœ€å¸¸ç”¨çš„ï¼‰ã€‚å…¶å®ç°æ–¹å¼æ˜¯åœ¨ flink ä¸­ä½¿ç”¨ broadcast ç®—å­å®šæ—¶è®¿é—®ç›‘æ§ id æ± ï¼Œå¹¶å°† id æ± ä»¥å¹¿æ’­çš„å½¢å¼ä¸‹å‘ç»™ä¸‹æ¸¸å‚ä¸è®¡ç®—çš„å„ä¸ªç®—å­ã€‚å…¶ä¼˜åŒ–ç‚¹åœ¨äºï¼šæ¯”å¦‚ä»»åŠ¡çš„å¹¶è¡Œåº¦ä¸º 500ï¼Œæ¯ 1s è®¿é—®ä¸€æ¬¡ï¼Œé‡‡ç”¨æ–¹æ¡ˆ 2 åˆ™è®¿é—®ç›‘æ§ id æ± æ¥å£çš„ QPS ä¸º 500ï¼Œåœ¨ä½¿ç”¨ broadcast ç®—å­ä¹‹åï¼Œå…¶è®¿é—® QPS å¯ä»¥å‡å°‘åˆ° 1ï¼Œå¯ä»¥å¤§å¤§å‡å°‘å¯¹æ¥å£çš„è®¿é—®é‡ï¼Œå‡è½»æ¥å£å‹åŠ›ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class Example &#123; @Slf4j static class NeedMonitorIdsSource implements SourceFunction&lt;Map&lt;Long, Set&lt;Long&gt;&gt;&gt; &#123; private volatile boolean isCancel; @Override public void run(SourceContext&lt;Map&lt;Long, Set&lt;Long&gt;&gt;&gt; sourceContext) throws Exception &#123; while (!this.isCancel) &#123; try &#123; TimeUnit.SECONDS.sleep(1); Set&lt;Long&gt; needMonitorIds = Rpc.get(...); // å¯ä»¥å’Œä¸Šä¸€æ¬¡è®¿é—®çš„æ•°æ®åšæ¯”è¾ƒæŸ¥çœ‹æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæœ‰å˜åŒ–ï¼Œæ‰å‘é€å‡ºå» if (CollectionUtils.isNotEmpty(needMonitorIds)) &#123; sourceContext.collect(new HashMap&lt;Long, Set&lt;Long&gt;&gt;() &#123;&#123; put(0L, needMonitorIds); &#125;&#125;); &#125; &#125; catch (Throwable e) &#123; // é˜²æ­¢æ¥å£è®¿é—®å¤±è´¥å¯¼è‡´çš„é”™è¯¯å¯¼è‡´ flink job æŒ‚æ‰ log.error(\"need monitor ids error\", e); &#125; &#125; &#125; @Override public void cancel() &#123; this.isCancel = true; &#125; &#125; public static void main(String[] args) &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); InputParams inputParams = new InputParams(parameterTool); StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(); final MapStateDescriptor&lt;Long, Set&lt;Long&gt;&gt; broadcastMapStateDescriptor = new MapStateDescriptor&lt;&gt;( \"config-keywords\", BasicTypeInfo.LONG_TYPE_INFO, TypeInformation.of(new TypeHint&lt;Set&lt;Long&gt;&gt;() &#123; &#125;)); /********************* kafka source *********************/ BroadcastStream&lt;Map&lt;Long, Set&lt;Long&gt;&gt;&gt; broadcastStream = env .addSource(new NeedMonitorIdsSource()) // redis photoId æ•°æ®å¹¿æ’­ .setParallelism(1) .broadcast(broadcastMapStateDescriptor); DataStream&lt;CommonModel&gt; logSourceDataStream = SourceFactory.getSourceDataStream(...); /********************* dag *********************/ DataStream&lt;CommonModel&gt; resultDataStream = logSourceDataStream .keyBy(KeySelectorFactory.getStringKeySelector(CommonModel::getKeyField)) .connect(broadcastStream) .process(new KeyedBroadcastProcessFunction&lt;String, CommonModel, Map&lt;Long, Set&lt;Long&gt;&gt;, CommonModel&gt;() &#123; private Set&lt;Long&gt; needMonitoredIds; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); this.needMonitoredIds = Rpc.get(...) &#125; @Override public void processElement(CommonModel commonModel, ReadOnlyContext readOnlyContext, Collector&lt;CommonModel&gt; collector) throws Exception &#123; // åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ &#125; @Override public void processBroadcastElement(Map&lt;Long, Set&lt;Long&gt;&gt; longSetMap, Context context, Collector&lt;CommonModel&gt; collector) throws Exception &#123; // éœ€è¦ç›‘æ§çš„å­—æ®µ Set&lt;Long&gt; needMonitorIds = longSetMap.get(0L); if (CollectionUtils.isNotEmpty(needMonitorIds)) &#123; this.needMonitoredIds = needMonitorIds; &#125; &#125; &#125;); /********************* kafka sink *********************/ SinkFactory.setSinkDataStream(...); env.execute(inputParams.jobName); &#125;&#125; æ–¹æ¡ˆ 4é€‚åˆäºè¶…å¤§ç›‘æ§èŒƒå›´çš„æ•°æ®ï¼ˆå‡ ç™¾ä¸‡ï¼Œæˆ‘ä»¬è‡ªå·±çš„ç”Ÿäº§å®è·µä¸­ä½¿ç”¨æ‰©é‡åˆ° 500 ä¸‡ï¼‰ã€‚å…¶åŸç†æ˜¯å°†ç›‘æ§èŒƒå›´æ¥å£æŒ‰ç…§ id æŒ‰ç…§ä¸€å®šè§„åˆ™åˆ†æ¡¶ã€‚flink æ¶ˆè´¹åˆ°æ—¥å¿—æ•°æ®åå°† id æŒ‰ç…§ ç›‘æ§èŒƒå›´æ¥å£ id ç›¸åŒçš„åˆ†æ¡¶æ–¹æ³•è¿›è¡Œåˆ†æ¡¶ keyByï¼Œè¿™æ ·åœ¨ä¸‹æ¸¸ç®—å­ä¸­æ¯ä¸ªç®—å­ä¸­å°±å¯ä»¥æŒ‰ç…§æ¡¶åç§°ï¼Œä»æ¥å£ä¸­æ‹¿åˆ°å¯¹åº”æ¡¶çš„ç›‘æ§ id æ•°æ®ï¼Œè¿™æ · flink ä¸­å¹¶è¡Œçš„æ¯ä¸ªç®—å­åªéœ€è¦è·å–åˆ°è‡ªå·±å¯¹åº”çš„æ¡¶çš„æ•°æ®ï¼Œå¯ä»¥å¤§å¤§å‡å°‘è¯·æ±‚çš„å‹åŠ›ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Example &#123; public static void main(String[] args) &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); InputParams inputParams = new InputParams(parameterTool); StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(); final MapStateDescriptor&lt;Long, Set&lt;Long&gt;&gt; broadcastMapStateDescriptor = new MapStateDescriptor&lt;&gt;( \"config-keywords\", BasicTypeInfo.LONG_TYPE_INFO, TypeInformation.of(new TypeHint&lt;Set&lt;Long&gt;&gt;() &#123; &#125;)); /********************* kafka source *********************/ DataStream&lt;CommonModel&gt; logSourceDataStream = SourceFactory.getSourceDataStream(...); /********************* dag *********************/ DataStream&lt;CommonModel&gt; resultDataStream = logSourceDataStream .keyBy(KeySelectorFactory.getLongKeySelector(CommonModel::getKeyField)) .timeWindow(Time.seconds(inputParams.accTimeWindowSeconds)) .process(new ProcessWindowFunction&lt;CommonModel, CommonModel, Long, TimeWindow&gt;() &#123; private long lastRefreshTimestamp; private Set&lt;Long&gt; oneBucketNeedMonitoredIds; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); &#125; @Override public void process(Long bucket, Context context, Iterable&lt;CommonModel&gt; iterable, Collector&lt;CommonModel&gt; collector) throws Exception &#123; long windowStart = context.window().getStart(); this.refreshNeedMonitoredIds(windowStart, bucket); /** * åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ */ &#125; public void refreshNeedMonitoredIds(long windowStart, long bucket) &#123; // æ¯éš” 10 ç§’è®¿é—®ä¸€æ¬¡ if (windowStart - this.lastRefreshTimestamp &gt;= 10000L) &#123; this.lastRefreshTimestamp = windowStart; this.oneBucketNeedMonitoredIds = Rpc.get(bucket, ...) &#125; &#125; &#125;); /********************* kafka sink *********************/ SinkFactory.setSinkDataStream(...); env.execute(inputParams.jobName); &#125;&#125; æ€»ç»“æœ¬æ–‡é¦–å…ˆä»‹ç»äº†ï¼Œåœ¨çŸ­è§†é¢‘é¢†åŸŸä¸­ï¼ŒçŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯çš„æ•´ä¸ªé—­ç¯ï¼Œå¹¶ä¸”å…¶æ•°æ®é“¾è·¯é—­ç¯ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿé€‚ç”¨äºå…¶ä»–åœºæ™¯ï¼›ä»¥åŠå¯¹åº”çš„å®æ—¶ç›‘æ§æ–¹æ¡ˆçš„è®¾è®¡å’Œä¸åŒåœºæ™¯ä¸‹çš„ä»£ç å®ç°ï¼ŒåŒ…æ‹¬ï¼š å‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯é—­ç¯ï¼šç”¨æˆ·æ“ä½œè¡Œä¸ºæ—¥å¿—çš„æµè½¬ï¼Œæ—¥å¿—ä¸Šä¼ ï¼Œå®æ—¶è®¡ç®—ï¼Œä»¥åŠæµè½¬åˆ° BIï¼Œæ•°æ®æœåŠ¡ï¼Œæœ€åæ•°æ®èµ‹èƒ½çš„æ•´ä¸ªæµç¨‹ å®æ—¶ç›‘æ§æ–¹æ¡ˆè®¾è®¡ï¼šç›‘æ§ç±»å®æ—¶è®¡ç®—æµç¨‹ä¸­å„ç±»æ•°æ®æºï¼Œæ•°æ®æ±‡çš„é€‰å‹ ç›‘æ§ id æ± åœ¨ä¸åŒé‡çº§åœºæ™¯ä¸‹å…·ä½“ä»£ç å®ç° å­¦ä¹ èµ„æ–™flink https://github.com/flink-china/flink-training-course/blob/master/README.md https://ververica.cn/developers-resources/ https://space.bilibili.com/33807709","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"å®æ—¶å¼€å‘éœ€æ±‚ç¡®è®¤æ¨¡æ¿","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/apache-flink:realtime-demand-template/","text":"å®æ—¶å¼€å‘éœ€æ±‚ç¡®è®¤æ¨¡æ¿ å®æ—¶æŒ‡æ ‡æ•´ä¸ªé“¾è·¯å¼€å‘è¿‡ç¨‹ä¸­çš„ä¸€äº›ç»éªŒã€‚ éœ€æ±‚è¯„ä¼°åˆ†æå®æ—¶æŒ‡æ ‡æ˜¯å¦ç¬¦åˆè¯¥éœ€æ±‚åœºæ™¯ï¼Œä»¥åŠåœ¨è¯¥åœºæ™¯ä¸­å®æ—¶æŒ‡æ ‡èƒ½å¤Ÿå‘æŒ¥çš„ä»·å€¼ã€‚ 1.å®æ—¶æŒ‡æ ‡æ‰€èƒ½æä¾›çš„åˆ†æèƒ½åŠ›å®æ—¶è®¡ç®—çš„è¾“å‡ºå†…å®¹ï¼Œä»¥åŠæä¾›çš„åˆ†æèƒ½åŠ›ï¼šOLAP åˆ†æï¼Œkey-value å®æ—¶æ•°æ®æœåŠ¡ï¼Œç»´åº¦å¡«å……ï¼Œæ•°æ®æ‰“æ ‡ç­‰ã€‚ 2.äº§å‡ºç»´åº¦ï¼ŒæŒ‡æ ‡çš„åˆç†æ€§ä»éœ€æ±‚å‡ºå‘ï¼Œè¯„ä¼°å®æ—¶æŒ‡æ ‡äº§å‡ºçš„ç»´åº¦å’ŒæŒ‡æ ‡çš„åˆç†æ€§ã€‚ 3.éœ€æ±‚å¯é…ç½®å˜é‡ è¯„ä¼°ç»´åº¦ è¯„ä¼°æŒ‡æ ‡ ç›‘æ§æ•°æ®èŒƒå›´ ç›‘æ§æ•°æ®èŒƒå›´åŠ¨æ€é…ç½®æ”¹å˜ï¼Ÿ ç›‘æ§æ•°æ®èµ·æ­¢æ—¶é—´ ç›‘æ§æ•°æ®çš„èµ·æ­¢æ—¶é—´åŠ¨æ€é…ç½®æ”¹å˜ï¼Ÿ ç›‘æ§æ•°æ®çš„æŸäº›é…ç½®å˜é‡ å½“å˜é‡å‘ç”Ÿå˜åŠ¨æ—¶ï¼Œå¯èƒ½ä¼šå¯¹äº§å‡ºçš„å®æ—¶æ•°æ®æœ‰ä»€ä¹ˆå½±å“ï¼Œå¯¹è®¡ç®—é“¾è·¯æœ‰ä»€ä¹ˆå½±å“ï¼Œä¼šå†³å®šå®æ—¶è®¡ç®—é“¾è·¯çš„å®ç°æ–¹å¼ã€‚ 4.é¢å‘ç”¨æˆ·èŒƒå›´è¯„ä¼° SLA ç­‰æœåŠ¡è´¨é‡ç­‰çº§ä¿éšœï¼Œä»¥åŠæä¾›çš„å®æ—¶æ•°æ®æœåŠ¡çš„å¯ç”¨æ€§ç­‰çº§ï¼Œå¹¶ä¸”æå‰å’Œä¸šåŠ¡æ–¹ç¡®è®¤å¯ç”¨æ€§å’Œå‡ºç°æ•…éšœæ—¶çš„æ¢å¤æ—¶é—´ç­‰é—®é¢˜ã€‚ è¯„ä¼°ç»´åº¦ è¯„ä¼°æŒ‡æ ‡ æ—¶é—´è¯­ä¹‰ äº‹ä»¶æ—¶é—´ã€å¤„ç†æ—¶é—´ï¼Ÿäº‹ä»¶æ—¶é—´ï¼šå¯ä»¥é€šè¿‡è·å–æ•°æ®çš„æ—¶é—´æˆ³ï¼Œä½¿ç”¨å¤„ç†æ—¶é—´æ¥çœŸå®åæ˜ å’Œè¿˜åŸäº‹ä»¶ï¼Œä½†æ˜¯å¯èƒ½ä¼šå‡ºç°æ•°æ®æ¡æ•°è¿‡å°çª—å£ä¸èƒ½è§¦å‘ï¼Œæˆ–è€…åœ¨ä¸€äº›æœ‰æˆªæ­¢æ—¥æœŸçš„æ´»åŠ¨ç»“æŸçš„æœ€åä¸€ä¸ªçª—å£ä¸èƒ½è§¦å‘çš„é—®é¢˜ï¼›å¤„ç†æ—¶é—´ï¼šå¤„ç†æ—¶é—´ä¸€èˆ¬å’Œäº‹ä»¶æ—¶é—´å·®è·å¾ˆå°ï¼Œç»éªŒå€¼ä¸€èˆ¬ diff å°äº 1%ï¼Œåªèƒ½åæ˜ æµå¼æ¡†æ¶å¤„ç†æ•°æ®æ—¶çš„æ—¶é—´æˆ³ï¼Œä½†æ˜¯ä¸ä¼šå‡ºç°ä¸Šè¿°äº‹ä»¶æ—¶é—´çš„ä¸¤ä¸ªé—®é¢˜ã€‚å› æ­¤éœ€è¦è¯„ä¼°éœ€æ±‚çš„é€»è¾‘ç²¾ç¡®åº¦æ˜¯å¦è¦æ±‚å¾ˆé«˜ï¼Ÿ æ•°æ®ä¸€è‡´æ€§ è‡³å°‘ä¸€æ¬¡ã€ç²¾ç¡®ä¸€æ¬¡ï¼Ÿè‡³å°‘ä¸€æ¬¡ï¼šå—é™äºç›®å‰çš„ä¸Šä¸‹æ¸¸ä»¥åŠä¾èµ–ä¸­é—´ä»¶çš„èƒ½åŠ›ï¼Œæ¯”å¦‚ 010 ç‰ˆæœ¬åŠä»¥ä¸‹çš„ Kafka ä¸æ”¯æŒä¸¤é˜¶æ®µæäº¤ï¼Œæ‰€ä»¥åªèƒ½è¾¾åˆ°è‡³å°‘ä¸€æ¬¡çš„è¯­ä¹‰ï¼›ç²¾ç¡®ä¸€æ¬¡ï¼šæ•´æ¡å®æ—¶è®¡ç®—é“¾è·¯ä¸­çš„æ‰€æœ‰ç»„ä»¶éƒ½éœ€è¦æ”¯æŒç²¾ç¡®ä¸€æ¬¡çš„è¯­ä¹‰ï¼ˆä»æŠ€æœ¯å±‚é¢æˆ–è€…ä¸šåŠ¡é€»è¾‘å±‚é¢è¾¾åˆ°ç²¾ç¡®ä¸€æ¬¡ï¼‰ã€‚è¯„ä¼°éœ€æ±‚é€»è¾‘æ˜¯å¦å¯æ¥å—ä»»åŠ¡å‘ç”Ÿå¤±è´¥æ—¶æœ‰é‡å¤æ•°æ®äº§ç”Ÿï¼Ÿ SLA è¦æ±‚ è¯„ä¼°éœ€æ±‚çš„ SLA è¦æ±‚ï¼Œæ•´æ¡å®æ—¶è®¡ç®—é“¾è·¯çš„ SLA è¦æ±‚ï¼Œäº§å‡ºæ•°æ®æœ€å¤šå»¶è¿Ÿå¤šé•¿æ—¶é—´ï¼Ÿæ•°æ®å‡†ç¡®ç‡å‡ ä¸ª9ï¼Ÿæä¾›çš„æ¥å£æœåŠ¡æ˜¯å¦éœ€è¦è€ƒè™‘è·¨é›†ç¾¤ã€æœºæˆ¿å¤‡ä»½ã€åŒå†™ï¼›æ˜¯å¦éœ€è¦å»ºç«‹å¤šæ¡è®¡ç®—é“¾è·¯ä»¥ä¾›æ•…éšœåˆ‡æ¢ï¼Ÿä¸€æ—¦å‘ç”Ÿæ•…éšœï¼Œä¸‹æ¸¸æ¶ˆè´¹æ–¹èƒ½å®¹å¿çš„æœ€å¤§æ•…éšœæ—¶é•¿ï¼Ÿä¸‹æ¸¸æ¶ˆè´¹æ–¹åœ¨å‘ç”Ÿæ•…éšœæ—¶çš„å…œåº•ç­–ç•¥ï¼Ÿ å¯è¡Œæ€§è¯„ä¼°1.æŠ€æœ¯å¯è¡Œæ€§ è¯„ä¼°ç»´åº¦ è¯„ä¼°æŒ‡æ ‡ QPS ç¡®å®š QPS ä»¥è¯„ä¼°å®æ—¶ä¸Šä¸‹æ¸¸ä»¥åŠä¾èµ–ç»„ä»¶çš„é€‰å‹ä»¥åŠèƒ½åŠ›ã€‚ æ•°æ®è¾“å…¥ é¦–å…ˆç¡®å®šæ•°æ®è¾“å…¥æ˜¯å¦èƒ½å¤Ÿè®¡ç®—å®æ—¶æŒ‡æ ‡ï¼Œç„¶åè¯„ä¼°ä¸Šæ¸¸æä¾›çš„æ•°æ®åœ¨è®¡ç®—å®æ—¶æŒ‡æ ‡æ—¶æ•´ä¸ªå®æ—¶è®¡ç®—é“¾è·¯çš„é€»è¾‘ä»¥åŠå¤æ‚åº¦ã€‚æ¯”å¦‚ï¼šæ˜¯å¦éœ€è¦ç”¨åˆ°åŒæµ joinï¼Œéœ€è¦è¯„ä¼°åŒæµ join æ‰€å­˜åœ¨çš„è¯¯å·®æ˜¯å¦åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä¸€èˆ¬å¯é€šè¿‡ç¦»çº¿è¯¯å·®å¯¹æ¯”æˆ–ç»éªŒå€¼ç»™å‡ºç»“è®ºã€‚å¸¸è§è¾“å…¥ä¸­é—´ä»¶ï¼šæ¶ˆæ¯é˜Ÿåˆ—ï¼Œæ¥å£ç­‰ï¼Œå¸¸ç”¨ä¸­é—´ä»¶ï¼šKafkaï¼Œrpcï¼Œhttpã€‚ æ•°æ®ä¾èµ– è°ƒç ”ç›®å‰å¯ç”¨çš„å“ªäº›ä¸­é—´ä»¶å¯ä»¥æä¾›èƒ½åŠ›æ¥æ”¯æŒå½“å‰æŒ‡æ ‡è®¡ç®—ï¼Ÿä¸¾ä¾‹ï¼škey-valueç­‰ï¼Œå¸¸ç”¨ä¾èµ–ä¸­é—´ä»¶ï¼šRedisã€‚ æ•°æ®è¾“å‡º ç¡®å®šè¾“å‡ºä¸‹æ¸¸æ¶ˆè´¹æ–¹çš„æ¶ˆè´¹éœ€æ±‚ä»¥åŠèƒ½åŠ›ï¼Œä»¥è¯„ä¼°å®æ—¶äº§å‡ºçš„æ•°æ®ä»¥åŠå­˜å‚¨ç»„ä»¶æ˜¯å¦èƒ½å¤Ÿæ»¡è¶³å…¶éœ€æ±‚ï¼Ÿå¸¸è§è¾“å‡ºä¸­é—´ä»¶ï¼šæ¶ˆæ¯é˜Ÿåˆ—ï¼ŒOLAPï¼Œkey-valueï¼Œæ¥å£ç­‰ï¼Œå¸¸ç”¨ä¸­é—´ä»¶ï¼šKafkaï¼ŒDruidï¼ŒRedisï¼Œrpcã€‚äº§å‡ºç»´åº¦ï¼Œä¸€èˆ¬åœºæ™¯ä¸‹ï¼Œç»´åº¦å€¼ä¸å»ºè®®æ˜¯å¤§æ•°é‡çº§åˆ«çš„æ•°æ®ï¼Œæ¯”å¦‚è¯´ä½¿ç”¨ user_idï¼Œdevice_idã€‚ 2.æˆæœ¬å¯è¡Œæ€§ è¯„ä¼°ç»´åº¦ è¯„ä¼°æŒ‡æ ‡ QPS ç¡®å®š QPS ä»¥è¯„ä¼°å®æ—¶ä¸Šä¸‹æ¸¸ä»¥åŠä¾èµ–ä¸­é—´ä»¶çš„èµ„æºæ¶ˆè€—ã€‚ç¡®å®šèµ„æºæ¶ˆè€—æ˜¯å¦åœ¨å¯æ¥å—èŒƒå›´ä¹‹å†…ï¼Ÿ æ•°æ®è¾“å…¥ ç¡®å®šæ•´ä¸ªå®æ—¶è®¡ç®—é“¾è·¯çš„é€»è¾‘ä»¥åŠå¤æ‚åº¦ï¼Œæ¥è¯„ä¼°å¯èƒ½çš„èµ„æºæ¶ˆè€—ã€‚ æ•°æ®ä¾èµ– ç¡®å®šæ•´ä¸ªå®æ—¶è®¡ç®—é“¾è·¯çš„é€»è¾‘ä»¥åŠå¤æ‚åº¦ï¼Œæ¥è¯„ä¼°å¯èƒ½çš„èµ„æºæ¶ˆè€—ã€‚ æ•°æ®è¾“å‡º ç”±è¾“å‡ºå†…å®¹ä»¥åŠå­˜å‚¨ç»„ä»¶æ¥è¯„ä¼°ä¸‹æ¸¸å­˜å‚¨ä¸­é—´ä»¶çš„èµ„æºæ¶ˆè€—ã€‚ä¸¾ä¾‹ï¼šç»´åº¦å€¼ä¸å»ºè®®æ˜¯å¤§æ•°é‡çº§åˆ«çš„æ•°æ®ï¼Œæ¯”å¦‚è¯´ä½¿ç”¨ user_idï¼Œdevice_id ä½œä¸ºç»´åº¦æˆ–è€…äº§å‡ºæ˜ç»†æ•°æ®ï¼Œè™½ç„¶ä½¿ç”¨ OLAP åœ¨ç»´åº¦èšåˆåœºæ™¯ä¸‹å¾ˆçµæ´»ï¼Œä½†æ˜¯è¿™äº›åœºæ™¯ä¸‹ä½¿ç”¨ OLAP å¯èƒ½ä¼šé€ æˆå¾ˆå¤§çš„èµ„æºæ¶ˆè€—ã€‚ ç»¼åˆä»¥ä¸ŠæŠ€æœ¯å’Œæˆæœ¬å¯è¡Œæ€§ä»¥åŠéœ€æ±‚æ”¶ç›Šç­‰æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°å®æ—¶æŒ‡æ ‡çš„ ROIã€‚ 3.æ•°æ®è¾“å…¥æ¶ˆæ¯é˜Ÿåˆ—æ—¥å¿—æœ€å¸¸è§çš„å®æ—¶æ•°æ®æºå°±æ˜¯æ¶ˆæ¯é˜Ÿåˆ—æ—¥å¿—ï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦ç¡®å®šæ—¥å¿—ç±»å‹ï¼Œä¸åŒçš„æ—¥å¿—ç±»å‹å†³å®šäº†æŒ‡æ ‡æˆ–è€…ç»´åº¦å­—æ®µæ˜¯å¦å¯ä»¥äº§å‡ºä»¥åŠå…¶å‡†ç¡®æ€§ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æœ‰ä»¥ä¸‹ä¸‰ç§ç±»å‹æ—¥å¿—ï¼š æ—¥å¿—ç±»å‹ å¤‡æ³¨ åŸ‹ç‚¹æ—¥å¿— ç»´åº¦æœ€å…¨ï¼Œæ•°æ®å‡†ç¡® web server log ç»´åº¦æ¬¡å…¨ï¼Œæ•°æ®å‡†ç¡®åº¦ä¸€èˆ¬ binlog æ•°æ®åº“çœŸå®æ•°æ®ï¼Œåæ˜ çš„æ˜¯çœŸå®æ•°æ®ï¼Œæ•°æ®æœ€å‡†ç¡®ï¼Œç»´åº¦ä¿¡æ¯ä¸€èˆ¬å¾ˆå°‘ æ¥å£è¿™é‡Œçš„æ¥å£ä¸€èˆ¬æ˜¯ç”¨æ¥æ ¹æ®éœ€æ±‚åœˆå®šä¸€æ‰¹éœ€è¦è¿›è¡Œç›‘æ§çš„æ•°æ®å†…å®¹ã€‚æ¥å£çš„æä¾›æ–¹å¼å¯ä»¥æ˜¯httpï¼Œé…ç½®ä¸­å¿ƒé…ç½®ï¼Œrpcæ¥å£ç­‰ã€‚ 4.æ•°æ®ä¾èµ–å®æ—¶ä¸€èˆ¬æƒ…å†µä¸‹éƒ½ä¼šæˆ–å¤šæˆ–å°‘ä¾èµ–åˆ°å¤–éƒ¨ç»„ä»¶ï¼Œæœ€å¸¸è§çš„å°±æ˜¯ key-value å­˜å‚¨ã€‚åœºæ™¯ï¼šå¾ˆå¸¸è§çš„ä¸€ç±»éœ€æ±‚å°±æ˜¯å¯¹æ•°æ®æºä¸­çš„æ•°æ®è¿›è¡Œæ‰“æ ‡ç„¶åäº§å‡ºï¼Œè¿™é‡Œçš„æ ‡ç­¾æ•°æ®å°±ä¼šå­˜å‚¨åœ¨ key-value ä¸­é—´ä»¶ä¸­ã€‚éœ€è¦è¯„ä¼°è®¿é—®å¤–å­˜çš„ QPSï¼Œä»¥åŠå¤–å­˜æä¾›çš„èƒ½åŠ›ã€‚ 5.æ•°æ®è¾“å‡º è¾“å‡ºç»„ä»¶ å¤‡æ³¨ æ¶ˆæ¯é˜Ÿåˆ— å¸¸è§ä¸­é—´ä»¶ï¼škafkaç­‰ key-valueå­˜å‚¨ å¸¸è§ä¸­é—´ä»¶ï¼šRedisï¼ŒHBaseï¼ŒæœåŠ¡åŒ–æ¥å£ç­‰ OLAP å¸¸è§ä¸­é—´ä»¶ï¼šDruidï¼ŒClickHouseç­‰ æŠ€æœ¯æ–¹æ¡ˆè¯„ä¼°","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"ç”Ÿäº§å®è·µ | åŸºäº Flink çš„çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹ç›‘æ§","date":"2020-09-01T06:21:53.000Z","path":"2020/09/01/wechat-blog/apache-flink:realtime-monitor-video/","text":"ç”Ÿäº§å®è·µ | åŸºäº Flink çš„çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹ç›‘æ§ æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†å®æ—¶ç›‘æ§ç±»æŒ‡æ ‡çš„æ•°æ®æµè½¬é“¾è·¯ä»¥åŠæŠ€æœ¯æ–¹æ¡ˆï¼Œå¤§å¤šæ•°çš„å®æ—¶ç›‘æ§ç±»æŒ‡æ ‡éƒ½å¯æŒ‰ç…§æœ¬æ–‡ä¸­çš„å‡ ç§æ–¹æ¡ˆå®ç°ã€‚ çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹ç›‘æ§çŸ­è§†é¢‘å¸¦æ¥äº†å…¨æ–°çš„ä¼ æ’­åœºåŸŸå’ŒèŠ‚ç›®å½¢æ€ï¼Œå°å±å¹•ã€å¿«èŠ‚å¥æˆä¸ºè¡Œä¸šæ½®æµçš„åŒæ—¶ï¼Œä¹Ÿå‚¬ç”Ÿäº†æ–°çš„ç”¨æˆ·æ¶ˆè´¹ä¹ æƒ¯ï¼Œä¸ºåˆ›ä½œè€…å’Œå•†æˆ·å¸¦æ¥æ”¶ç›Šã€‚è€Œå¤šå…ƒåŒ–çš„çŸ­è§†é¢‘ä¹Ÿå¯ä»¥ä¸ºå“ç‰Œæ–¹æä¾›è¥é”€æœºé‡ã€‚ å…¶ä¸­å¯¹äºå‚ç±»ç”Ÿæ€çŸ­è§†é¢‘çš„ç”Ÿäº§æ¶ˆè´¹çƒ­ç‚¹çš„ç›‘æ§åˆ†æç›®å‰æˆä¸ºäº†å®æ—¶æ•°æ®å¤„ç†å¾ˆå¸¸è§çš„ä¸€ä¸ªåº”ç”¨åœºæ™¯ï¼Œæ¯”å¦‚å¯¹æŸä¸ªåœˆå®šçš„å‚ç±»ç”Ÿæ€ä¸‹çš„è§†é¢‘ç”Ÿäº§æˆ–è€…è§†é¢‘æ¶ˆè´¹è¿›è¡Œç›‘æ§ï¼Œå¯¹çƒ­ç‚¹è§†é¢‘ç”Ÿæˆå¯¹åº”çš„ä¼˜åŒ–æ¨èç­–ç•¥ï¼Œä¿ƒè¿›çƒ­ç‚¹è§†é¢‘çš„ç”Ÿäº§æˆ–è€…æ¶ˆè´¹ï¼Œæ„å»ºæ•´ä¸ªç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯çš„é—­ç¯ï¼Œä»è€Œæé«˜åˆ›ä½œè€…æ”¶ç›Šä»¥åŠæ¶ˆè´¹è€…ç•™å­˜ã€‚ æœ¬æ–‡å°†å®Œæ•´åˆ†æå‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®çš„æ•´æ¡é“¾è·¯æµè½¬æ–¹å¼ï¼Œå¹¶åŸºäº Flink æä¾›å‡ ç§å¯¹äºå‚ç±»è§†é¢‘ç”Ÿäº§æ¶ˆè´¹ç›‘æ§çš„æ–¹æ¡ˆè®¾è®¡ã€‚é€šè¿‡æœ¬æ–‡ï¼Œä½ å¯ä»¥äº†è§£åˆ°ï¼š å‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯é—­ç¯ å®æ—¶ç›‘æ§çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹çš„æ–¹æ¡ˆè®¾è®¡ ä¸åŒç›‘æ§é‡çº§åœºæ™¯ä¸‹çš„ä»£ç å®ç° flink å­¦ä¹ èµ„æ–™ é¡¹ç›®ç®€ä»‹å‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯æµè½¬æ¶æ„å›¾å¦‚ä¸‹ï¼Œæ­¤æ•°æ®æµè½¬å›¾ä¹Ÿé€‚ç”¨äºå…¶ä»–åœºæ™¯ï¼š é“¾è·¯ åœ¨ä¸Šè¿°åœºæ™¯ä¸­ï¼Œç”¨æˆ·ç”Ÿäº§å’Œæ¶ˆè´¹çŸ­è§†é¢‘ï¼Œä»è€Œå®¢æˆ·ç«¯ã€æœåŠ¡ç«¯ä»¥åŠæ•°æ®åº“ä¼šäº§ç”Ÿç›¸åº”çš„è¡Œä¸ºæ“ä½œæ—¥å¿—ï¼Œè¿™äº›æ—¥å¿—ä¼šé€šè¿‡æ—¥å¿—æŠ½å–ä¸­é—´ä»¶æŠ½å–åˆ°æ¶ˆæ¯é˜Ÿåˆ—ä¸­ï¼Œæˆ‘ä»¬ç›®å‰çš„åœºæ™¯ä¸­æ˜¯ä½¿ç”¨ Kafka ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—ï¼›ç„¶åä½¿ç”¨ flink å¯¹å‚ç±»ç”Ÿæ€ä¸­çš„è§†é¢‘è¿›è¡Œç”Ÿäº§æˆ–æ¶ˆè´¹ç›‘æ§ï¼ˆå†…å®¹ç”Ÿäº§é€šå¸¸æ˜¯åœˆå®šå‚ç±»ä½œè€… id æ± ï¼Œå†…å®¹æ¶ˆè´¹é€šå¸¸æ˜¯åœˆå®šå‚ç±»è§†é¢‘ id æ± ï¼‰ï¼Œæœ€åå°†å®æ—¶èšåˆæ•°æ®äº§å‡ºåˆ°ä¸‹æ¸¸ï¼›ä¸‹æ¸¸å¯ä»¥ä»¥æ•°æ®æœåŠ¡ï¼Œå®æ—¶çœ‹æ¿çš„æ–¹å¼å±•ç°ï¼Œè¿è¥åŒå­¦æˆ–è€…è‡ªåŠ¨åŒ–å·¥å…·æœ€ç»ˆä¼šå¸®åŠ©æˆ‘ä»¬åˆ†æå½“å‰å‚ç±»ä¸‹çš„ç”Ÿäº§æˆ–è€…æ¶ˆè´¹çƒ­ç‚¹ï¼Œä»è€Œç”Ÿæˆæ¨èç­–ç•¥ã€‚ æ–¹æ¡ˆè®¾è®¡ æ¶æ„ å…¶ä¸­æ•°æ®æºå¦‚ä¸‹ï¼š Kafka ä¸ºå…¨é‡å†…å®¹ç”Ÿäº§å’Œå†…å®¹æ¶ˆè´¹çš„æ—¥å¿—ã€‚ Rpc/Http/Mysql/é…ç½®ä¸­å¿ƒ/Redis/HBase ä¸ºéœ€è¦ç›‘æ§çš„å‚ç±»ç”Ÿæ€å†…å®¹ id æ± ï¼ˆå†…å®¹ç”Ÿäº§åˆ™ä¸ºä½œè€… id æ± ï¼Œå†…å®¹æ¶ˆè´¹åˆ™ä¸ºè§†é¢‘ id æ± ï¼‰ï¼Œå…¶ä¸»è¦æ˜¯æä¾›ç»™è¿è¥åŒå­¦åŠ¨æ€é…ç½®éœ€è¦ç›‘æ§çš„ id èŒƒå›´ï¼Œå…¶å¯ä»¥åœ¨ flink ä¸­è¿›è¡Œå®æ—¶æŸ¥è¯¢ï¼Œè§£æè¿è¥åŒå­¦æƒ³è¦çš„ç›‘æ§æŒ‡æ ‡èŒƒå›´ï¼Œä»¥åŠç›‘æ§çš„æŒ‡æ ‡å’Œè®¡ç®—æ–¹å¼ï¼Œç„¶ååŠ å·¥æ•°æ®äº§å‡ºï¼Œå¯ä»¥æ”¯æŒéšæ—¶é…ç½®ï¼Œå®æ—¶æ•°æ®éšæ—¶è®¡ç®—äº§å‡ºã€‚ å…¶ä¸­æ•°æ®æ±‡ä¸ºèšç±»å¥½çš„å†…å®¹ç”Ÿäº§æˆ–è€…æ¶ˆè´¹çƒ­ç‚¹è¯é¢˜æˆ–è€…äº‹ä»¶æŒ‡æ ‡ï¼š Redis/HBase ä¸»è¦æ˜¯ä»¥ä½å»¶è¿Ÿï¼ˆRedis 5ms p99ï¼ŒHBase 100ms p99ï¼Œä¸åŒå…¬å¸çš„æœåŠ¡èƒ½åŠ›ä¸åŒï¼‰å¹¶ä¸”é«˜ QPS æä¾›æ•°æ®æœåŠ¡ï¼Œç»™ Server ç«¯æˆ–è€…çº¿ä¸Šç”¨æˆ·æä¾›ä½å»¶è¿Ÿçš„æ•°æ®æŸ¥è¯¢ã€‚ Druid/Mysql å¯ä»¥åšä¸º OLAP å¼•æ“ä¸º BI åˆ†ææä¾›çµæ´»çš„ä¸Šå·ä¸‹é’»èšåˆåˆ†æèƒ½åŠ›ï¼Œä¾›è¿è¥åŒå­¦é…ç½®å¯è§†åŒ–å›¾è¡¨ä½¿ç”¨ã€‚ Kafka å¯ä»¥ä»¥æµå¼æ•°æ®äº§å‡ºï¼Œä»è€Œæä¾›ç»™ä¸‹æ¸¸ç»§ç»­æ¶ˆè´¹æˆ–è€…è¿›è¡Œç‰¹å¾æå–ã€‚ åºŸè¯ä¸å¤šè¯´ï¼Œæˆ‘ä»¬ç›´æ¥ä¸Šæ–¹æ¡ˆå’Œä»£ç ï¼Œä¸‹è¿°å‡ ç§æ–¹æ¡ˆæŒ‰ç…§ç›‘æ§ id èŒƒå›´é‡çº§åŒºåˆ†ï¼Œä¸åŒçš„é‡çº§å¯¹åº”ç€ä¸åŒçš„æ–¹æ¡ˆï¼Œå…¶ä¸­çš„ä»£ç ç¤ºä¾‹ä¸º ProcessWindowFunctionï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ AggregateFunction ä»£æ›¿ï¼Œå…¶ä¸­ä¸»è¦ç›‘æ§é€»è¾‘éƒ½ç›¸åŒã€‚ æ–¹æ¡ˆ 1é€‚åˆç›‘æ§ id æ•°æ®é‡å°çš„åœºæ™¯ï¼ˆå‡ åƒ idï¼‰ï¼Œå…¶å®ç°æ–¹å¼æ˜¯åœ¨ flink ä»»åŠ¡åˆå§‹åŒ–æ—¶å°†éœ€è¦ç›‘æ§çš„ id æ± æˆ–åŠ¨æ€é…ç½®ä¸­å¿ƒçš„ id æ± åŠ è½½åˆ°å†…å­˜å½“ä¸­ï¼Œä¹‹ååªéœ€è¦åœ¨å†…å­˜ä¸­åˆ¤æ–­å†…å®¹ç”Ÿäº§æˆ–è€…æ¶ˆè´¹æ•°æ®æ˜¯å¦åœ¨è¿™ä¸ªç›‘æ§æ± å½“ä¸­ã€‚ 12345678910111213141516171819ProcessWindowFunction p = new ProcessWindowFunction&lt;CommonModel, CommonModel, Long, TimeWindow&gt;() &#123; // é…ç½®ä¸­å¿ƒåŠ¨æ€ id æ±  private Config&lt;Set&lt;Long&gt;&gt; needMonitoredIdsConfig; @Override public void open(Configuration parameters) throws Exception &#123; this.needMonitoredIdsConfig = ConfigBuilder .buildSet(\"needMonitoredIds\", Long.class); &#125; @Override public void process(Long bucket, Context context, Iterable&lt;CommonModel&gt; iterable, Collector&lt;CommonModel&gt; collector) throws Exception &#123; Set&lt;Long&gt; needMonitoredIds = needMonitoredIdsConfig.get(); /** * åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ */ &#125;&#125; ç›‘æ§çš„ id æ± å¯ä»¥æŒ‰ç…§å›ºå®šæˆ–è€…å¯é…ç½®ä»è€Œåˆ†å‡ºä¸¤ç§è·å–æ–¹å¼ï¼šç¬¬ä¸€ç§æ˜¯åœ¨ flink ä»»åŠ¡å¼€å§‹æ—¶å°±å…¨éƒ¨åŠ è½½è¿›å†…å­˜ä¸­ï¼Œè¿™ç§æ–¹å¼é€‚åˆç›‘æ§ id æ± ä¸å˜çš„æƒ…å†µï¼›ç¬¬äºŒç§æ˜¯ä½¿ç”¨åŠ¨æ€é…ç½®ä¸­å¿ƒï¼Œæ¯æ¬¡éƒ½ä»é…ç½®ä¸­å¿ƒè®¿é—®åˆ°æœ€æ–°çš„ç›‘æ§ id æ± ï¼Œå…¶å¯ä»¥æ»¡è¶³åŠ¨æ€é…ç½®æˆ–è€…æ›´æ”¹ id æ± çš„éœ€æ±‚ï¼Œå¹¶ä¸”è¿™ç§å®ç°æ–¹å¼é€šå¸¸å¯ä»¥å®æ—¶æ„ŸçŸ¥åˆ°é…ç½®æ›´æ”¹ï¼Œå‡ ä¹æ— å»¶è¿Ÿã€‚ æ–¹æ¡ˆ 2é€‚åˆç›‘æ§ id æ•°æ®é‡é€‚ä¸­ï¼ˆå‡ åä¸‡ idï¼‰ï¼Œç›‘æ§æ•°æ®èŒƒå›´ä¼šä¸å®šæ—¶å‘ç”Ÿå˜åŠ¨çš„åœºæ™¯ã€‚å…¶å®ç°æ–¹å¼æ˜¯åœ¨ flink ç®—å­ä¸­å®šæ—¶è®¿é—®æ¥å£è·å–æœ€æ–°çš„ç›‘æ§ id æ± ï¼Œä»¥è·å–æœ€æ–°ç›‘æ§æ•°æ®èŒƒå›´ã€‚ 1234567891011121314151617181920212223242526272829ProcessWindowFunction p = new ProcessWindowFunction&lt;CommonModel, CommonModel, Long, TimeWindow&gt;() &#123; private long lastRefreshTimestamp; private Set&lt;Long&gt; needMonitoredIds; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); this.refreshNeedMonitoredIds(System.currentTimeMillis()); &#125; @Override public void process(Long bucket, Context context, Iterable&lt;CommonModel&gt; iterable, Collector&lt;CommonModel&gt; collector) throws Exception &#123; long windowStart = context.window().getStart(); this.refreshNeedMonitoredIds(windowStart); /** * åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ */ &#125; public void refreshNeedMonitoredIds(long windowStart) &#123; // æ¯éš” 10 ç§’è®¿é—®ä¸€æ¬¡ if (windowStart - this.lastRefreshTimestamp &gt;= 10000L) &#123; this.lastRefreshTimestamp = windowStart; this.needMonitoredIds = Rpc.get(...) &#125; &#125;&#125; æ ¹æ®ä¸Šè¿°ä»£ç å®ç°æ–¹å¼ï¼ŒæŒ‰ç…§æ—¶é—´é—´éš”çš„æ–¹å¼åˆ·æ–° id æ± ï¼Œå…¶ç¼ºç‚¹åœ¨äºä¸èƒ½å®æ—¶æ„ŸçŸ¥ç›‘æ§ id æ± çš„å˜åŒ–ï¼Œæ‰€ä»¥åˆ·æ–°æ—¶é—´å¯èƒ½ä¼šå’Œéœ€æ±‚åœºæ™¯å¼ºè€¦åˆï¼ˆå¦‚æœ id æ± ä¼šé¢‘ç¹æ›´æ–°ï¼Œé‚£ä¹ˆå°±éœ€è¦ç¼©å°åˆ·æ–°æ—¶é—´é—´éš”ï¼‰ã€‚ä¹Ÿå¯æ ¹æ®éœ€æ±‚åœºæ™¯åœ¨æ¯ä¸ªçª—å£å¼€å§‹å‰åˆ·æ–° id æ± ï¼Œè¿™æ ·å¯ä¿è¯æ¯ä¸ªçª—å£ä¸­çš„ id æ± ä¸­çš„æ•°æ®ä¸€ç›´ä¿æŒæ›´æ–°ã€‚ æ–¹æ¡ˆ 3æ–¹æ¡ˆ 3 å¯¹æ–¹æ¡ˆ 2 çš„ä¸€ä¸ªä¼˜åŒ–ï¼ˆå‡ åä¸‡ idï¼Œæˆ‘ä»¬ç”Ÿäº§ç¯å¢ƒä¸­æœ€å¸¸ç”¨çš„ï¼‰ã€‚å…¶å®ç°æ–¹å¼æ˜¯åœ¨ flink ä¸­ä½¿ç”¨ broadcast ç®—å­å®šæ—¶è®¿é—®ç›‘æ§ id æ± ï¼Œå¹¶å°† id æ± ä»¥å¹¿æ’­çš„å½¢å¼ä¸‹å‘ç»™ä¸‹æ¸¸å‚ä¸è®¡ç®—çš„å„ä¸ªç®—å­ã€‚å…¶ä¼˜åŒ–ç‚¹åœ¨äºï¼šæ¯”å¦‚ä»»åŠ¡çš„å¹¶è¡Œåº¦ä¸º 500ï¼Œæ¯ 1s è®¿é—®ä¸€æ¬¡ï¼Œé‡‡ç”¨æ–¹æ¡ˆ 2 åˆ™è®¿é—®ç›‘æ§ id æ± æ¥å£çš„ QPS ä¸º 500ï¼Œåœ¨ä½¿ç”¨ broadcast ç®—å­ä¹‹åï¼Œå…¶è®¿é—® QPS å¯ä»¥å‡å°‘åˆ° 1ï¼Œå¯ä»¥å¤§å¤§å‡å°‘å¯¹æ¥å£çš„è®¿é—®é‡ï¼Œå‡è½»æ¥å£å‹åŠ›ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class Example &#123; @Slf4j static class NeedMonitorIdsSource implements SourceFunction&lt;Map&lt;Long, Set&lt;Long&gt;&gt;&gt; &#123; private volatile boolean isCancel; @Override public void run(SourceContext&lt;Map&lt;Long, Set&lt;Long&gt;&gt;&gt; sourceContext) throws Exception &#123; while (!this.isCancel) &#123; try &#123; TimeUnit.SECONDS.sleep(1); Set&lt;Long&gt; needMonitorIds = Rpc.get(...); // å¯ä»¥å’Œä¸Šä¸€æ¬¡è®¿é—®çš„æ•°æ®åšæ¯”è¾ƒæŸ¥çœ‹æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæœ‰å˜åŒ–ï¼Œæ‰å‘é€å‡ºå» if (CollectionUtils.isNotEmpty(needMonitorIds)) &#123; sourceContext.collect(new HashMap&lt;Long, Set&lt;Long&gt;&gt;() &#123;&#123; put(0L, needMonitorIds); &#125;&#125;); &#125; &#125; catch (Throwable e) &#123; // é˜²æ­¢æ¥å£è®¿é—®å¤±è´¥å¯¼è‡´çš„é”™è¯¯å¯¼è‡´ flink job æŒ‚æ‰ log.error(\"need monitor ids error\", e); &#125; &#125; &#125; @Override public void cancel() &#123; this.isCancel = true; &#125; &#125; public static void main(String[] args) &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); InputParams inputParams = new InputParams(parameterTool); StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(); final MapStateDescriptor&lt;Long, Set&lt;Long&gt;&gt; broadcastMapStateDescriptor = new MapStateDescriptor&lt;&gt;( \"config-keywords\", BasicTypeInfo.LONG_TYPE_INFO, TypeInformation.of(new TypeHint&lt;Set&lt;Long&gt;&gt;() &#123; &#125;)); /********************* kafka source *********************/ BroadcastStream&lt;Map&lt;Long, Set&lt;Long&gt;&gt;&gt; broadcastStream = env .addSource(new NeedMonitorIdsSource()) // redis photoId æ•°æ®å¹¿æ’­ .setParallelism(1) .broadcast(broadcastMapStateDescriptor); DataStream&lt;CommonModel&gt; logSourceDataStream = SourceFactory.getSourceDataStream(...); /********************* dag *********************/ DataStream&lt;CommonModel&gt; resultDataStream = logSourceDataStream .keyBy(KeySelectorFactory.getStringKeySelector(CommonModel::getKeyField)) .connect(broadcastStream) .process(new KeyedBroadcastProcessFunction&lt;String, CommonModel, Map&lt;Long, Set&lt;Long&gt;&gt;, CommonModel&gt;() &#123; private Set&lt;Long&gt; needMonitoredIds; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); this.needMonitoredIds = Rpc.get(...) &#125; @Override public void processElement(CommonModel commonModel, ReadOnlyContext readOnlyContext, Collector&lt;CommonModel&gt; collector) throws Exception &#123; // åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ &#125; @Override public void processBroadcastElement(Map&lt;Long, Set&lt;Long&gt;&gt; longSetMap, Context context, Collector&lt;CommonModel&gt; collector) throws Exception &#123; // éœ€è¦ç›‘æ§çš„å­—æ®µ Set&lt;Long&gt; needMonitorIds = longSetMap.get(0L); if (CollectionUtils.isNotEmpty(needMonitorIds)) &#123; this.needMonitoredIds = needMonitorIds; &#125; &#125; &#125;); /********************* kafka sink *********************/ SinkFactory.setSinkDataStream(...); env.execute(inputParams.jobName); &#125;&#125; æ–¹æ¡ˆ 4é€‚åˆäºè¶…å¤§ç›‘æ§èŒƒå›´çš„æ•°æ®ï¼ˆå‡ ç™¾ä¸‡ï¼Œæˆ‘ä»¬è‡ªå·±çš„ç”Ÿäº§å®è·µä¸­ä½¿ç”¨æ‰©é‡åˆ° 500 ä¸‡ï¼‰ã€‚å…¶åŸç†æ˜¯å°†ç›‘æ§èŒƒå›´æ¥å£æŒ‰ç…§ id æŒ‰ç…§ä¸€å®šè§„åˆ™åˆ†æ¡¶ã€‚flink æ¶ˆè´¹åˆ°æ—¥å¿—æ•°æ®åå°† id æŒ‰ç…§ ç›‘æ§èŒƒå›´æ¥å£ id ç›¸åŒçš„åˆ†æ¡¶æ–¹æ³•è¿›è¡Œåˆ†æ¡¶ keyByï¼Œè¿™æ ·åœ¨ä¸‹æ¸¸ç®—å­ä¸­æ¯ä¸ªç®—å­ä¸­å°±å¯ä»¥æŒ‰ç…§æ¡¶åç§°ï¼Œä»æ¥å£ä¸­æ‹¿åˆ°å¯¹åº”æ¡¶çš„ç›‘æ§ id æ•°æ®ï¼Œè¿™æ · flink ä¸­å¹¶è¡Œçš„æ¯ä¸ªç®—å­åªéœ€è¦è·å–åˆ°è‡ªå·±å¯¹åº”çš„æ¡¶çš„æ•°æ®ï¼Œå¯ä»¥å¤§å¤§å‡å°‘è¯·æ±‚çš„å‹åŠ›ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Example &#123; public static void main(String[] args) &#123; ParameterTool parameterTool = ParameterTool.fromArgs(args); InputParams inputParams = new InputParams(parameterTool); StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(); final MapStateDescriptor&lt;Long, Set&lt;Long&gt;&gt; broadcastMapStateDescriptor = new MapStateDescriptor&lt;&gt;( \"config-keywords\", BasicTypeInfo.LONG_TYPE_INFO, TypeInformation.of(new TypeHint&lt;Set&lt;Long&gt;&gt;() &#123; &#125;)); /********************* kafka source *********************/ DataStream&lt;CommonModel&gt; logSourceDataStream = SourceFactory.getSourceDataStream(...); /********************* dag *********************/ DataStream&lt;CommonModel&gt; resultDataStream = logSourceDataStream .keyBy(KeySelectorFactory.getLongKeySelector(CommonModel::getKeyField)) .timeWindow(Time.seconds(inputParams.accTimeWindowSeconds)) .process(new ProcessWindowFunction&lt;CommonModel, CommonModel, Long, TimeWindow&gt;() &#123; private long lastRefreshTimestamp; private Set&lt;Long&gt; oneBucketNeedMonitoredIds; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); &#125; @Override public void process(Long bucket, Context context, Iterable&lt;CommonModel&gt; iterable, Collector&lt;CommonModel&gt; collector) throws Exception &#123; long windowStart = context.window().getStart(); this.refreshNeedMonitoredIds(windowStart, bucket); /** * åˆ¤æ–­ commonModel ä¸­çš„ id æ˜¯å¦åœ¨ needMonitoredIds æ± ä¸­ */ &#125; public void refreshNeedMonitoredIds(long windowStart, long bucket) &#123; // æ¯éš” 10 ç§’è®¿é—®ä¸€æ¬¡ if (windowStart - this.lastRefreshTimestamp &gt;= 10000L) &#123; this.lastRefreshTimestamp = windowStart; this.oneBucketNeedMonitoredIds = Rpc.get(bucket, ...) &#125; &#125; &#125;); /********************* kafka sink *********************/ SinkFactory.setSinkDataStream(...); env.execute(inputParams.jobName); &#125;&#125; æ€»ç»“æœ¬æ–‡é¦–å…ˆä»‹ç»äº†ï¼Œåœ¨çŸ­è§†é¢‘é¢†åŸŸä¸­ï¼ŒçŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯çš„æ•´ä¸ªé—­ç¯ï¼Œå¹¶ä¸”å…¶æ•°æ®é“¾è·¯é—­ç¯ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿé€‚ç”¨äºå…¶ä»–åœºæ™¯ï¼›ä»¥åŠå¯¹åº”çš„å®æ—¶ç›‘æ§æ–¹æ¡ˆçš„è®¾è®¡å’Œä¸åŒåœºæ™¯ä¸‹çš„ä»£ç å®ç°ï¼ŒåŒ…æ‹¬ï¼š å‚ç±»ç”Ÿæ€çŸ­è§†é¢‘ç”Ÿäº§æ¶ˆè´¹æ•°æ®é“¾è·¯é—­ç¯ï¼šç”¨æˆ·æ“ä½œè¡Œä¸ºæ—¥å¿—çš„æµè½¬ï¼Œæ—¥å¿—ä¸Šä¼ ï¼Œå®æ—¶è®¡ç®—ï¼Œä»¥åŠæµè½¬åˆ° BIï¼Œæ•°æ®æœåŠ¡ï¼Œæœ€åæ•°æ®èµ‹èƒ½çš„æ•´ä¸ªæµç¨‹ å®æ—¶ç›‘æ§æ–¹æ¡ˆè®¾è®¡ï¼šç›‘æ§ç±»å®æ—¶è®¡ç®—æµç¨‹ä¸­å„ç±»æ•°æ®æºï¼Œæ•°æ®æ±‡çš„é€‰å‹ ç›‘æ§ id æ± åœ¨ä¸åŒé‡çº§åœºæ™¯ä¸‹å…·ä½“ä»£ç å®ç° å­¦ä¹ èµ„æ–™flink https://github.com/flink-china/flink-training-course/blob/master/README.md https://ververica.cn/developers-resources/ https://space.bilibili.com/33807709","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"ä¸ºä»€ä¹ˆhashmapçš„æ•°ç»„åˆå§‹åŒ–å¤§å°éƒ½æ˜¯2çš„æ¬¡æ–¹å¤§å°æ—¶ï¼Œhashmapçš„æ•ˆç‡æœ€é«˜","date":"2020-01-06T12:39:35.000Z","path":"2020/01/06/java:study-hashmap/","text":"ä¸ºä»€ä¹ˆhashmapçš„æ•°ç»„åˆå§‹åŒ–å¤§å°éƒ½æ˜¯2çš„æ¬¡æ–¹å¤§å°æ—¶ï¼Œhashmapçš„æ•ˆç‡æœ€é«˜ 123static int indexFor(int hashcode, int length) &#123; return hashcode &amp; (length-1); &#125; æ€æ ·æé«˜get(key)æ•ˆç‡ï¼Ÿæ€æ ·æé«˜get(key)æ•ˆç‡ = æ€æ ·æé«˜ç¡®å®škeyçš„æ‰€åœ¨hashmapä¸­æ•°ç»„indexçš„æ•ˆç‡ hashmapçš„æ•°æ®ç»“æ„æ˜¯æ•°ç»„å’Œé“¾è¡¨çš„ç»“åˆï¼Œæ‰€ä»¥æˆ‘ä»¬å½“ç„¶å¸Œæœ›è¿™ä¸ªhashmapé‡Œé¢çš„å…ƒç´ ä½ç½®å°½é‡çš„åˆ†å¸ƒå‡åŒ€äº›ï¼Œå°½é‡ä½¿å¾—æ¯ä¸ªä½ç½®ä¸Šçš„å…ƒç´ æ•°é‡åªæœ‰ä¸€ä¸ªï¼Œé‚£ä¹ˆå½“æˆ‘ä»¬ç”¨hashç®—æ³•æ±‚å¾—è¿™ä¸ªä½ç½®çš„æ—¶å€™ï¼Œé©¬ä¸Šå°±å¯ä»¥çŸ¥é“å¯¹åº”ä½ç½®çš„å…ƒç´ å°±æ˜¯æˆ‘ä»¬è¦çš„ï¼Œè€Œä¸ç”¨å†å»éå†é“¾è¡¨ã€‚ çœ‹ä¸‹å›¾ï¼Œå·¦è¾¹ä¸¤ç»„æ˜¯æ•°ç»„é•¿åº¦ä¸º16ï¼ˆ2çš„4æ¬¡æ–¹ï¼‰ï¼Œå³è¾¹ä¸¤ç»„æ˜¯æ•°ç»„é•¿åº¦ä¸º15ã€‚ä¸¤ç»„çš„hashcodeå‡ä¸º8å’Œ9ï¼Œä½†æ˜¯å¾ˆæ˜æ˜¾ï¼Œå½“å®ƒä»¬å’Œ1110â€œä¸â€çš„æ—¶å€™ï¼Œäº§ç”Ÿäº†ç›¸åŒçš„ç»“æœï¼Œä¹Ÿå°±æ˜¯è¯´å®ƒä»¬ä¼šå®šä½åˆ°æ•°ç»„ä¸­çš„åŒä¸€ä¸ªä½ç½®ä¸Šå»ï¼Œè¿™å°±äº§ç”Ÿäº†ç¢°æ’ï¼Œ8å’Œ9ä¼šè¢«æ”¾åˆ°åŒä¸€ä¸ªé“¾è¡¨ä¸Šï¼Œé‚£ä¹ˆæŸ¥è¯¢çš„æ—¶å€™å°±éœ€è¦éå†è¿™ä¸ªé“¾è¡¨ï¼Œå¾—åˆ°8æˆ–è€…9ï¼Œè¿™æ ·å°±é™ä½äº†æŸ¥è¯¢çš„æ•ˆç‡ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å‘ç°ï¼Œå½“æ•°ç»„é•¿åº¦ä¸º15çš„æ—¶å€™ï¼Œhashcodeçš„å€¼ä¼šä¸14ï¼ˆ1110ï¼‰è¿›è¡Œâ€œä¸â€ï¼Œé‚£ä¹ˆæœ€åä¸€ä½æ°¸è¿œæ˜¯0ï¼Œè€Œ0001ï¼Œ0011ï¼Œ0101ï¼Œ1001ï¼Œ1011ï¼Œ0111ï¼Œ1101è¿™å‡ ä¸ªä½ç½®æ°¸è¿œéƒ½ä¸èƒ½å­˜æ”¾å…ƒç´ äº†ï¼Œç©ºé—´æµªè´¹ç›¸å½“å¤§ï¼Œæ›´ç³Ÿçš„æ˜¯è¿™ç§æƒ…å†µä¸­ï¼Œæ•°ç»„å¯ä»¥ä½¿ç”¨çš„ä½ç½®æ¯”æ•°ç»„é•¿åº¦å°äº†å¾ˆå¤šï¼Œè¿™æ„å‘³ç€è¿›ä¸€æ­¥å¢åŠ äº†ç¢°æ’çš„å‡ ç‡ï¼Œå‡æ…¢äº†æŸ¥è¯¢çš„æ•ˆç‡ï¼ hashmap-index 1.å‡è®¾keyçš„hashcodeä¸ºhï¼Œæ•°ç»„é•¿åº¦ä¸ºlengthï¼Œä¸ºäº†å°†æ•°æ®æ‰“æ•£ï¼Œä½¿hashmapä¸­çš„æ•°ç»„ä¸‹æ ‡å¯¹åº”çš„Entryé“¾è¡¨éƒ½æœ‰æ•°æ®ï¼Œé¦–å…ˆæƒ³åˆ°çš„å°±æ˜¯å¯¹lengthå–æ¨¡ï¼Œè®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š 123static int indexFor(int h, int length) &#123; return h % length;&#125; å› æ­¤ç¡®å®šäº†hashmapçš„indexForå‡½æ•°çš„è®¡ç®—æ–¹å¼ã€‚ æ€æ ·ç¡®å®šhashmapæ•°ç»„çš„lengthâ€œæ¨¡â€è¿ç®—çš„æ¶ˆè€—è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ï¼Œèƒ½ä¸èƒ½æ‰¾ä¸€ç§æ›´å¿«é€Ÿï¼Œæ¶ˆè€—æ›´å°çš„æ–¹å¼ï¼Ÿæˆ‘ä»¬å‘ç°åšä½è¿ç®—çš„æ¶ˆè€—æ˜¯å¾ˆå°çš„ï¼Œæ‰€ä»¥å°è¯•å°†å–æ¨¡è¿ç®—è½¬æ¢æˆä½é¢„ç®—ï¼Œç”±æ­¤å‘ç°lengthä¸º2çš„næ¬¡æ–¹æ—¶ä¼šæœ‰ 123static int indexFor(int h, int length) &#123; return h % length; // ç­‰ä»·äº h &amp; (length - 1);&#125; ç”±äº &amp; è¿ç®—ç¬¦è®¡ç®—æ•ˆç‡å¤§å¤§é«˜äº % è¿ç®—ç¬¦ï¼Œæ‰€ä»¥ä¸Šè¿°è®¡ç®—è½¬æ¢ä¸ºï¼š 123static int indexFor(int h, int length) &#123; return h &amp; (length - 1);&#125; ä¹Ÿè§„å®šäº† length å¿…é¡»æ˜¯2çš„næ¬¡æ–¹ï¼ˆn&gt;0ï¼‰é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å‘ç°ï¼Œå½“æ•°ç»„é•¿åº¦ä¸º15çš„æ—¶å€™ï¼Œhashcodeçš„å€¼ä¼šä¸14ï¼ˆ1110ï¼‰è¿›è¡Œâ€œä¸â€ï¼Œé‚£ä¹ˆæœ€åä¸€ä½æ°¸è¿œæ˜¯0ï¼Œè€Œ0001ï¼Œ0011ï¼Œ0101ï¼Œ1001ï¼Œ1011ï¼Œ0111ï¼Œ1101è¿™å‡ ä¸ªä½ç½®æ°¸è¿œéƒ½ä¸èƒ½å­˜æ”¾å…ƒç´ äº†ï¼Œç©ºé—´æµªè´¹ç›¸å½“å¤§ï¼Œæ›´ç³Ÿçš„æ˜¯è¿™ç§æƒ…å†µä¸­ï¼Œæ•°ç»„å¯ä»¥ä½¿ç”¨çš„ä½ç½®æ¯”æ•°ç»„é•¿åº¦å°äº†å¾ˆå¤šï¼Œè¿™æ„å‘³ç€è¿›ä¸€æ­¥å¢åŠ äº†ç¢°æ’çš„å‡ ç‡ï¼Œå‡æ…¢äº†æŸ¥è¯¢çš„æ•ˆç‡ï¼","tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://yangyichao-mango.github.io/tags/JAVA/"}]},{"title":"apache-flink:study-flink","date":"2019-11-22T03:30:41.000Z","path":"2019/11/22/apache-flink:study-flink/","text":"æ‰€æœ‰operatorä¸­çš„åˆå§‹åŒ–å¦‚æœå†™åœ¨æ„é€ å‡½æ•°å½“ä¸­å°±ä¼šå‡ºé”™ï¼Œé—®é¢˜æ˜¯åºåˆ—åŒ–æ—¶çš„é—®é¢˜flinkä»jobmanageråºåˆ—åŒ–åˆ°å„ä¸ª taskmanageræ—¶å¯èƒ½ä¼šå‡ºé—®é¢˜ splitç»„ä»¶åŠŸèƒ½å¯ä»¥å‡å°‘å¤šä¸ªflatmapçš„æ€§èƒ½æŸå¤±å¤šä¸ªflatmapæ•°æ®æ¯ä¸ªéƒ½æ˜¯ä½¿ç”¨å…¨éƒ¨çš„æµè¿›è¡Œfiltersplitä¸€ä¸ªå°±å¯ä»¥æ»¡è¶³","tags":[]},{"title":"Apache Flink å­¦ä¹ ï¼šJobs å’Œ Scheduling","date":"2019-11-20T03:27:03.000Z","path":"2019/11/20/apache-flink:study-flink-jobs-and-scheduling/","text":"Apache Flink å­¦ä¹ ï¼šJobs å’Œ Scheduling SchedulingFlinkä¸­çš„æ‰§è¡Œèµ„æºæ˜¯é€šè¿‡ Task Slots å®šä¹‰çš„ã€‚æ¯ä¸ª TaskManager éƒ½æœ‰ä¸€ä¸ªæˆ–å¤šä¸ª Task Slotsï¼Œæ¯ä¸ª Slot å¯ä»¥è¿è¡Œä¸€ä¸ªå¹¶è¡Œä»»åŠ¡æµã€‚å¹¶è¡Œä»»åŠ¡æµç”±å¤šä¸ªè¿ç»­çš„ä»»åŠ¡ç»„æˆï¼Œä¾‹å¦‚ MapFunction çš„ç¬¬nä¸ªå¹¶è¡Œå®ä¾‹å’Œ ReduceFunction çš„ç¬¬nä¸ªå¹¶è¡Œå®ä¾‹ã€‚è¯·æ³¨æ„ï¼ŒFlink ç»å¸¸å¹¶å‘åœ°æ‰§è¡Œè¿ç»­çš„ä»»åŠ¡ï¼šå¯¹äºæµå¼ç¨‹åºï¼ŒåŸºæœ¬ä¸Šéƒ½ä¼šä½¿ç”¨å¹¶è¡Œä»»åŠ¡ï¼Œå¯¹äºæ‰¹å¤„ç†ç¨‹åºï¼Œä¹Ÿä¼šç»å¸¸ä½¿ç”¨å¹¶è¡Œä»»åŠ¡ã€‚ ä¸‹å›¾è¯´æ˜äº†è¿™ä¸€ç‚¹ã€‚ä¸€ä¸ªå…·æœ‰æ•°æ®æºã€MapFunction å’Œ ReduceFunction çš„ç¨‹åºã€‚æºå‡½æ•°å’Œ MapFunction çš„å¹¶è¡Œåº¦ä¸º4ï¼Œè€Œ ReduceFunction çš„å¹¶è¡Œåº¦ä¸º3ã€‚æµç”± Source - Map - Reduce ç»„æˆã€‚åœ¨è¿™ä¸ªé›†ç¾¤ä¸­ï¼Œæœ‰ä¸¤ä¸ª TaskManagerï¼Œæ¯ä¸ª TaskManager æœ‰ä¸‰ä¸ª slotï¼Œåˆ™ç¨‹åºå°†æŒ‰å¦‚ä¸‹æ‰€è¿°æ‰§è¡Œã€‚","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ State å’Œå®¹é”™â€”â€”State çš„ä½¿ç”¨","date":"2019-11-19T07:48:16.000Z","path":"2019/11/19/apache-flink:study-flink-datastream-state-and-fault-tolerance-working-with-state/","text":"flinkæœ‰ä¸¤ç§åŸºæœ¬çš„stateï¼Œåˆ†åˆ«æ˜¯Keyed Stateä»¥åŠOperator State(non-keyed state)ï¼›å…¶ä¸­Keyed Stateåªèƒ½åœ¨KeyedStreamä¸Šçš„functionsåŠoperatorsä¸Šä½¿ç”¨ï¼›æ¯ä¸ªoperator stateä¼šè·Ÿparallel operatorä¸­çš„ä¸€ä¸ªå®ä¾‹ç»‘å®šï¼›Operator Stateæ”¯æŒparallelismå˜æ›´æ—¶è¿›è¡ŒredistributingKeyed StateåŠOperator Stateéƒ½åˆ†åˆ«æœ‰managedåŠrawä¸¤ç§å½¢å¼ï¼Œmanagedç”±flink runtimeæ¥ç®¡ç†ï¼Œç”±runtimeè´Ÿè´£encodeåŠå†™å…¥checkpointï¼›rawå½¢å¼çš„stateç”±operatorsè‡ªå·±ç®¡ç†ï¼Œflink runtimeæ— æ³•äº†è§£è¯¥stateçš„æ•°æ®ç»“æ„ï¼Œå°†å…¶è§†ä¸ºraw bytesï¼›æ‰€æœ‰çš„datastream functionéƒ½å¯ä»¥ä½¿ç”¨managed stateï¼Œè€Œraw stateä¸€èˆ¬ä»…é™äºè‡ªå·±å®ç°operatorsæ¥ä½¿ç”¨stateful functionå¯ä»¥é€šè¿‡CheckpointedFunctionæ¥å£æˆ–è€…ListCheckpointedæ¥å£æ¥ä½¿ç”¨managed operator stateï¼›CheckpointedFunctionå®šä¹‰äº†snapshotStateã€initializeStateä¸¤ä¸ªæ–¹æ³•ï¼›æ¯å½“checkpointæ‰§è¡Œçš„æ—¶å€™ï¼ŒsnapshotStateä¼šè¢«è°ƒç”¨ï¼›è€ŒinitializeStateæ–¹æ³•åœ¨æ¯æ¬¡ç”¨æˆ·å®šä¹‰çš„functionåˆå§‹åŒ–çš„æ—¶å€™(ç¬¬ä¸€æ¬¡åˆå§‹åŒ–æˆ–è€…ä»å‰ä¸€æ¬¡checkpoint recoverçš„æ—¶å€™)è¢«è°ƒç”¨ï¼Œè¯¥æ–¹æ³•ä¸ä»…å¯ä»¥ç”¨æ¥åˆå§‹åŒ–stateï¼Œè¿˜å¯ä»¥ç”¨äºå¤„ç†state recoveryçš„é€»è¾‘å¯¹äºmanageed operator stateï¼Œç›®å‰ä»…ä»…æ”¯æŒlist-styleçš„å½¢å¼ï¼Œå³è¦æ±‚stateæ˜¯serializable objectsçš„Listç»“æ„ï¼Œæ–¹ä¾¿åœ¨rescaleçš„æ—¶å€™è¿›è¡Œredistributedï¼›å…³äºredistribution schemesçš„æ¨¡å¼ç›®å‰æœ‰ä¸¤ç§ï¼Œåˆ†åˆ«æ˜¯Even-split redistribution(åœ¨restore/redistributionçš„æ—¶å€™æ¯ä¸ªoperatorä»…ä»…å¾—åˆ°æ•´ä¸ªstateçš„sublist)åŠUnion redistribution(åœ¨restore/redistributionçš„æ—¶å€™æ¯ä¸ªoperatorå¾—åˆ°æ•´ä¸ªstateçš„å®Œæ•´list)FunctionSnapshotContextç»§æ‰¿äº†ManagedSnapshotContextæ¥å£ï¼Œå®ƒå®šä¹‰äº†getCheckpointIdã€getCheckpointTimestampæ–¹æ³•ï¼›FunctionInitializationContextç»§æ‰¿äº†ManagedInitializationContextæ¥å£ï¼Œå®ƒå®šä¹‰äº†isRestoredã€getOperatorStateStoreã€getKeyedStateStoreæ–¹æ³•ï¼Œå¯ä»¥ç”¨æ¥åˆ¤æ–­æ˜¯å¦æ˜¯åœ¨å‰ä¸€æ¬¡executionçš„snapshotä¸­restoredï¼Œä»¥åŠè·å–OperatorStateStoreã€KeyedStateStoreå¯¹è±¡","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Hadoop å­¦ä¹ ï¼šhdfsæ¶æ„","date":"2019-11-13T06:04:52.000Z","path":"2019/11/13/apache-hadoop:study-hadoop-hdfs-design/","text":"Apache Hadoop å­¦ä¹ ï¼šhdfsæ¶æ„ æ–‡ä»¶ç³»ç»Ÿ Namespace hdfsæ¶æ„ HDFSæ”¯æŒä¼ ç»Ÿçš„åˆ†å±‚æ–‡ä»¶ç»„ç»‡ã€‚ç”¨æˆ·æˆ–åº”ç”¨ç¨‹åºå¯ä»¥åœ¨è¿™äº›ç›®å½•ä¸­åˆ›å»ºç›®å½•å¹¶å­˜å‚¨æ–‡ä»¶ã€‚æ–‡ä»¶ç³»ç»Ÿå‘½åç©ºé—´å±‚æ¬¡ç»“æ„ä¸å¤§å¤šæ•°å…¶ä»–ç°æœ‰æ–‡ä»¶ç³»ç»Ÿç›¸ä¼¼ï¼›å¯ä»¥åˆ›å»ºå’Œåˆ é™¤æ–‡ä»¶ï¼Œå°†æ–‡ä»¶ä»ä¸€ä¸ªç›®å½•ç§»åŠ¨åˆ°å¦ä¸€ä¸ªç›®å½•ï¼Œæˆ–è€…é‡å‘½åæ–‡ä»¶ã€‚HDFSæ”¯æŒç”¨æˆ·é…é¢å’Œè®¿é—®æƒé™ã€‚HDFSä¸æ”¯æŒç¡¬é“¾æ¥æˆ–è½¯é“¾æ¥ã€‚ç„¶è€Œï¼ŒHDFSä½“ç³»ç»“æ„å¹¶ä¸æ’é™¤å®ç°è¿™äº›ç‰¹æ€§ã€‚ è™½ç„¶HDFSéµå¾ªæ–‡ä»¶ç³»ç»Ÿçš„å‘½åçº¦å®šï¼Œä½†æŸäº›è·¯å¾„å’Œåç§°ï¼ˆä¾‹å¦‚/.reservedå’Œ.snapshotï¼‰æ˜¯ä¿ç•™çš„ã€‚é€æ˜åŠ å¯†å’Œå¿«ç…§ç­‰åŠŸèƒ½ä½¿ç”¨ä¿ç•™è·¯å¾„ã€‚ NameNodeç»´æŠ¤æ–‡ä»¶ç³»ç»Ÿåç§°ç©ºé—´ã€‚å¯¹æ–‡ä»¶ç³»ç»Ÿå‘½åç©ºé—´æˆ–å…¶å±æ€§çš„ä»»ä½•æ›´æ”¹éƒ½ç”±NameNodeè®°å½•ã€‚åº”ç”¨ç¨‹åºå¯ä»¥æŒ‡å®šHDFSåº”è¯¥ç»´æŠ¤çš„æ–‡ä»¶å‰¯æœ¬çš„æ•°é‡ã€‚æ–‡ä»¶çš„å‰¯æœ¬æ•°ç§°ä¸ºè¯¥æ–‡ä»¶çš„å¤åˆ¶å› å­ã€‚æ­¤ä¿¡æ¯ç”±NameNodeå­˜å‚¨ã€‚","tags":[{"name":"Apache Hadoop","slug":"Apache-Hadoop","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hadoop/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šTable Api & SQL","date":"2019-11-12T01:51:01.000Z","path":"2019/11/12/apache-flink:study-flink-table-api-and-sql/","text":"Apache Flink å­¦ä¹ ï¼šTable Api &amp; SQL","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ Operatorsï¼ˆç®—å­ï¼‰â€”â€”Joining","date":"2019-11-11T10:30:13.000Z","path":"2019/11/11/apache-flink:study-flink-datastream-operators-joining/","text":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ Operatorsï¼ˆç®—å­ï¼‰â€”â€”Joining Window JoinWindow Join å¯ä»¥å°†ä¸¤ä¸ªæµä¸­ç›¸åŒkeyå¹¶ä¸”åœ¨åŒä¸€ä¸ªçª—å£ä¸­çš„å…ƒç´ è¿›è¡Œé“¾æ¥ã€‚çª—å£å¯ä»¥ä½¿ç”¨ Window Assigner è¿›è¡Œå®šä¹‰ï¼Œå¹¶ä¸”å¯¹æ¥è‡ªä¸åŒçš„æµçš„å…ƒç´ è¿›è¡Œè®¡ç®—ã€‚ 12345stream.join(otherStream) .where(&lt;KeySelector&gt;) .equalTo(&lt;KeySelector&gt;) .window(&lt;WindowAssigner&gt;) .apply(&lt;JoinFunction&gt;) å…³äºä¸€äº›è¯­ä¹‰çš„è§£é‡Šï¼š1.ä¸¤ä¸ªæµçš„æˆå¯¹ç»„åˆçš„è¿‡ç¨‹ç±»ä¼¼äº Inner Joinï¼Œæ„å‘³ç€å¦‚æœä¸€ä¸ªæµä¸­çš„å…ƒç´ æ²¡æœ‰å¦ä¸€ä¸ªæµçš„å…ƒç´ è¦ä¸ä¹‹è¿æ¥ï¼Œåˆ™ä¸ä¼šå‘å‡ºè¿™äº›å…ƒç´ ã€‚ 2.é‚£äº›è¢«è¿æ¥çš„å…ƒç´ çš„æ—¶é—´æˆ³æ˜¯ä½äºç›¸åº”çª—å£ä¸­çš„æœ€å¤§æ—¶é—´æˆ³ã€‚ä¾‹å¦‚ï¼Œä»¥[5ï¼Œ10)ä¸ºè¾¹ç•Œçš„çª—å£ï¼Œåˆ™è¿›è¡Œè¿æ¥çš„å…ƒç´ çš„æ—¶é—´æˆ³ä¸º9ã€‚ Tumbling Window Joinæ‰§è¡Œ Tumbling Window Joinï¼Œåœ¨ç›¸åŒ keyï¼Œç›¸åŒæ—¶é—´çª—å£å†…çš„å…ƒç´ ä¼šè¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆï¼Œè¿™ç§ç»„åˆç±»ä¼¼äº inner joinï¼Œå¦‚æœä¸€ä¸ªæµçš„å¯¹åº”æµçš„åŒä¸€çª—å£ä¸­æ²¡æœ‰å…ƒç´ ï¼Œåˆ™è¿™ä¸ªæµçš„å½“å‰çª—å£æ•°æ®ä¸ä¼šå‘å‡ºå»ã€‚ tumbling-window-join 12345678910111213141516171819import org.apache.flink.api.java.functions.KeySelector;import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;import org.apache.flink.streaming.api.windowing.time.Time; ...DataStream&lt;Integer&gt; orangeStream = ...DataStream&lt;Integer&gt; greenStream = ...orangeStream.join(greenStream) .where(&lt;KeySelector&gt;) .equalTo(&lt;KeySelector&gt;) .window(TumblingEventTimeWindows.of(Time.milliseconds(2))) .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123; @Override public String join(Integer first, Integer second) &#123; return first + \",\" + second; &#125; &#125;); Sliding Window Joinæ‰§è¡Œ Sliding Window Joinï¼Œå…·æœ‰å…¬å…± key å’Œå…¬å…±æ»‘åŠ¨çª—å£çš„æ‰€æœ‰å…ƒç´ éƒ½ä½œä¸ºæˆå¯¹ç»„åˆè¿›è¡Œè¿æ¥ï¼Œå¹¶ä¼ é€’ç»™ JoinFunction æˆ– FlatJoinFunctionã€‚ä¹Ÿæ˜¯ inner joinï¼Œå½“å‰æµçª—å£åŒ¹é…ä¸åˆ°å¯¹åº”æµçª—å£çš„å…ƒç´ åˆ™ä¸ä¼šå‘é€æ•°æ®åˆ°ä¸‹æ¸¸ï¼è¯·æ³¨æ„ï¼ŒæŸäº›å…ƒç´ å¯èƒ½åœ¨ä¸€ä¸ªæ»‘åŠ¨çª—å£ä¸­è¿æ¥ï¼Œåœ¨å¦ä¸€ä¸ªæ»‘åŠ¨çª—å£ä¸­ä¸ä¼šè¿›è¡Œè¿æ¥ï¼ sliding-window-join 12345678910111213141516171819import org.apache.flink.api.java.functions.KeySelector;import org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows;import org.apache.flink.streaming.api.windowing.time.Time;...DataStream&lt;Integer&gt; orangeStream = ...DataStream&lt;Integer&gt; greenStream = ...orangeStream.join(greenStream) .where(&lt;KeySelector&gt;) .equalTo(&lt;KeySelector&gt;) .window(SlidingEventTimeWindows.of(Time.milliseconds(2) /* size */, Time.milliseconds(1) /* slide */)) .apply (new JoinFunction&lt;Integer, Integer, String&gt; ()&#123; @Override public String join(Integer first, Integer second) &#123; return first + \",\" + second; &#125; &#125;); Session Window Joinæ‰§è¡Œ Session Window Joinï¼Œå…·æœ‰ç›¸åŒ key çš„æ‰€æœ‰å…ƒç´ ï¼ˆå½“â€œç»„åˆâ€æ»¡è¶³ä¼šè¯æ¡ä»¶æ—¶ï¼‰å°†ä»¥æˆå¯¹ç»„åˆè”æ¥ï¼Œå¹¶ä¼ é€’ç»™JoinFunctionæˆ–FlatJoinFunctionã€‚åŒæ ·ï¼Œä¹Ÿæ˜¯ inner joinï¼Œå½“å‰æµçª—å£åŒ¹é…ä¸åˆ°å¯¹åº”æµçª—å£çš„å…ƒç´ åˆ™ä¸ä¼šå‘é€æ•°æ®åˆ°ä¸‹æ¸¸ï¼ session-window-join Interval Joininterval join ç”¨ä¸€ä¸ªå…¬å…± key è¿æ¥ä¸¤ä¸ªæµçš„å…ƒç´ ï¼ˆæµAå’ŒæµBï¼‰ï¼Œå…¶ä¸­æµBçš„å…ƒç´ å…·æœ‰ä¸æµAä¸­å…ƒç´ çš„æ—¶é—´æˆ³ç›¸å¯¹æ—¶é—´é—´éš”å†…çš„æ—¶é—´æˆ³ï¼Œé‚£ä¹ˆè¿™ä¸ªæ—¶é—´é—´éš”å†…ä¸¤ä¸ªæµçš„å…ƒç´ å°±ä¼š joinã€‚ å³ï¼šb.timestamp âˆˆ [a.timestamp + lowerBound; a.timestamp + upperBound] or a.timestamp + lowerBound &lt;= b.timestamp &lt;= a.timestamp + upperBound å…¶ä¸­ lowerBound å’Œ upperBound å¯æ­£å¯è´Ÿï¼Œåªè¦ lowerBound &lt;= upperBoundã€‚ interval-join 1234567891011121314151617181920import org.apache.flink.api.java.functions.KeySelector;import org.apache.flink.streaming.api.functions.co.ProcessJoinFunction;import org.apache.flink.streaming.api.windowing.time.Time;...DataStream&lt;Integer&gt; orangeStream = ...DataStream&lt;Integer&gt; greenStream = ...orangeStream .keyBy(&lt;KeySelector&gt;) .intervalJoin(greenStream.keyBy(&lt;KeySelector&gt;)) .between(Time.milliseconds(-2), Time.milliseconds(1)) .process (new ProcessJoinFunction&lt;Integer, Integer, String()&#123; @Override public void processElement(Integer left, Integer right, Context ctx, Collector&lt;String&gt; out) &#123; out.collect(first + \",\" + second); &#125; &#125;);","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"apache-flink:study-allowedLateness-and-maxOutOfOrderness","date":"2019-11-11T02:32:17.000Z","path":"2019/11/11/apache-flink:study-allowedLateness-and-maxOutOfOrderness/","text":"","tags":[]},{"title":"Apache Kafka å­¦ä¹ ï¼škafkaåœ¨æ•°æ®å¤„ç†ä¸­çš„åº”ç”¨","date":"2019-11-10T15:12:14.000Z","path":"2019/11/10/apache-kafka:study-kafka-in-data-process/","text":"Apache Kafka å­¦ä¹ ï¼škafkaåœ¨æ•°æ®å¤„ç†ä¸­çš„åº”ç”¨çš„ä¸€äº›ä¸ªäººç†è§£ã€‚ ç¦»çº¿æ•°æ®å¤„ç†åœºæ™¯åœ¨ç¦»çº¿æ•°æ®å¤„ç†çš„è¿‡ç¨‹ä¸­ã€‚å¦‚æœä¸ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ï¼Œåœ¨å¹¶å‘é‡å¾ˆå°çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰çš„å®¢æˆ·ç«¯æ•°æ®æ—¥å¿—ç›´æ¥å‘hdfså†™æ•°æ®æš‚æ—¶ä¸ä¼šäº§ç”Ÿä»€ä¹ˆé—®é¢˜ã€‚å¦‚æœä¸ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ï¼Œåœ¨å¹¶å‘é‡å¾ˆå¤§çš„æƒ…å†µä¸‹ï¼Œå‘ hdfs å†™æ•°æ®å°±ä¼šå‡ºç°é—®é¢˜ï¼Œé¦–å…ˆï¼Œå‘hdfså†™æ•°æ®ä¼šæœ‰é”ç«äº‰çš„æƒ…å†µï¼Œå¯èƒ½ä¼šå¯¼è‡´å¤§éƒ¨åˆ†å†™è¯·æ±‚å¾ˆé•¿æ—¶é—´å¾—ä¸åˆ°é”ï¼Œå¯¼è‡´å¤§é‡è¯·æ±‚å»¶è¿Ÿæˆ–è€…è¶…æ—¶ï¼Œè¿™æ˜¯ä¸èƒ½æ¥å—çš„ï¼›å¹¶ä¸” hdfs ä½œä¸ºæ–‡ä»¶ç³»ç»Ÿä¸èƒ½æ‰¿å—å¤ªå¤§çš„å¹¶å‘é‡ï¼Œåœ¨å¹¶å‘å¾ˆé«˜çš„æƒ…å†µä¸‹ï¼Œé›†ç¾¤å¯èƒ½ä¼šå´©æºƒã€‚ é—®é¢˜åŸå› æ€»ç»“æ€»çš„æ¥è¯´ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé—®é¢˜çš„æ ¹æœ¬åœ¨äºé«˜å¹¶å‘æƒ…å†µä¸‹ï¼Œhdfs ä½œä¸ºæ–‡ä»¶ç³»ç»Ÿä¸èƒ½æ‰¿å—é«˜å¹¶å‘è¯·æ±‚çš„é—®é¢˜ã€‚ å®æ–½æ–¹æ¡ˆæ‰€ä»¥éœ€è¦ä¸€ç§å·¥å…·å¯ä»¥å°†å®¢æˆ·ç«¯æ—¥å¿—è¿™ç§é«˜å¹¶å‘è¯·æ±‚è½¬æ¢ä¸ºä½å¹¶å‘çš„è¯·æ±‚ï¼Œè¿™æ—¶å€™å°±å¯ä»¥ä½¿ç”¨kafkaè¿™æ ·çš„æ¶ˆæ¯é˜Ÿåˆ—ï¼Œå®¢æˆ·ç«¯çš„é«˜å¹¶å‘è¯·æ±‚ç›´æ¥å†™å…¥ kafkaï¼Œç„¶å hdfs ä»¥ä½å¹¶å‘æ¶ˆè´¹ kafka ä¸­çš„æ•°æ®ã€‚è¿™æ ·å°±è§£å†³äº†æ–‡ä»¶ç³»ç»Ÿä¸èƒ½æ”¯æŒé«˜å¹¶å‘çš„æƒ…å†µã€‚å¹¶ä¸”ç”±äº kafka çš„HAç‰¹æ€§ï¼Œå¯ä»¥ä¿è¯æ•°æ®çš„æ­£ç¡®æ€§ã€‚ kafkaä½œç”¨å°†é«˜å¹¶å‘è¯·æ±‚ä»¥ä½å¹¶å‘æ–¹å¼å¤„ç†ã€‚è¿™ç§æ–¹å¼ä¸­è§£è€¦æ•ˆæœä¸æ˜æ˜¾ï¼Œä¸‹é¢çš„å®æ—¶æ•°æ®å¤„ç†ä½¿ç”¨åˆ°çš„è§£è€¦æ•ˆæœæ¯”è¾ƒæ˜æ˜¾ã€‚ å®æ—¶æ•°æ®å¤„ç†åœºæ™¯åœ¨å®æ—¶æ•°æ®å¤„ç†çš„è¿‡ç¨‹ä¸­ã€‚å¦‚æœä¸ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ï¼Œä¸Šæ¸¸æ•°æ®å†™å…¥åˆ°ç±»ä¼¼ flink è¿™æ ·çš„å®æ—¶å¤„ç†å¼•æ“å½“ä¸­ï¼Œflinkå¤„ç†å®Œæˆåå‘ä¸‹æ¸¸ olap å¼•æ“ï¼ˆdruidï¼Œclickhouseç­‰ï¼‰æˆ–è€…hdfsï¼Œhiveï¼Œesç­‰çš„æ–‡ä»¶ç³»ç»Ÿå†™æ•°æ®æ—¶ï¼Œå°±éœ€è¦ä¸ºæ¯ä¸€ç§ olap å¼•æ“å¼€å‘ä¸€ç§ connectorï¼Œè¿™æ ·çš„æƒ…å†µä¸‹ï¼Œæ¯å‡ºç°ä¸€ç§ olap å¼•æ“æˆ–è€…æ¯å½“ä¸‹æ¸¸çš„ olap å¼•æ“å‡çº§ç‰ˆæœ¬å¼•å…¥æ–°ç‰¹æ€§æ—¶ï¼Œå°±éœ€è¦ flink å¼€å‘å·¥ç¨‹å¸ˆå¼€å‘ä¸€ç§æ–°çš„ connector æˆ–è€…è·Ÿéš olap å¼•æ“çš„å‡çº§è€Œå‡çº§è‡ªå·±çš„ connectorï¼Œè¿™æ · flink å¼€å‘å·¥ç¨‹å¸ˆçš„ç»´æŠ¤æˆæœ¬ä¹‹åå°±ä¼šç‰¹åˆ«é«˜ã€‚è¿™é‡Œæœ‰åŒå­¦å¯èƒ½ä¼šè¯´å¯ä»¥åœ¨æ•°æ®å¤„ç†çš„è¿‡ç¨‹ä¸­ä½¿ç”¨ä¸‹æ¸¸ olap ç­‰çš„å¼•æ“æä¾›çš„ sdkï¼Œè¿™ç§æ–¹æ³•æ˜¯å¯ä»¥çš„ï¼Œä½†æ˜¯å®æ—¶å¤„ç†æ‰“ä¸é£æƒ…å†µä¸‹å¹¶å‘é‡å¾ˆé«˜ï¼Œolap å¼•æ“æä¾›çš„ sdk åº”å¯¹è¿™ç§é«˜å¹¶å‘çš„åœºæ™¯å¯èƒ½ä¼šæœ‰å¾ˆå¤šé—®é¢˜ã€‚ é—®é¢˜åŸå› æ€»ç»“é—®é¢˜çš„æ ¹æœ¬åœ¨äºå®æ—¶å¤„ç†å¼•æ“å’Œä¸‹æ¸¸ä¹‹é—´çš„è€¦åˆé—®é¢˜ï¼Œè¿™å°±éœ€è¦ä¸€ç§HAçš„ä¸­é—´ä»¶æ¥å°†å„ä¸ªæ¨¡å—è¿›è¡Œè§£è€¦ï¼Œkafkaè¿™æ ·çš„æ¶ˆæ¯é˜Ÿåˆ—å¯ä»¥å¾ˆå¥½çš„è§£å†³è¿™ä¸­æ¨¡å—ä¹‹é—´é«˜åº¦è€¦åˆçš„æƒ…å†µã€‚ å®æ–½æ–¹æ¡ˆåœ¨ flink å’Œ druidä¸­é—´ä½¿ç”¨ kafka è¿›è¡Œè§£è€¦ï¼Œè®© flink å‘ kafka ç”Ÿæˆæ•°æ®ï¼Œdruid æ¶ˆè´¹ kafka çš„æ•°æ®ã€‚è¿™æ ·å°±ä½¿å¾— flink å¯ä»¥åªå¼€å‘å’Œç»´æŠ¤ä¸€å¥—é’ˆå¯¹äº kafka çš„ connectorï¼Œdruidä¹Ÿåªç”¨å¼€å‘å’Œç»´æŠ¤ä¸€å¥—é’ˆå¯¹ kafka çš„ connectorï¼Œè¿™æ ·æ— è®ºæ˜¯å®æ—¶å¤„ç†å¼•æ“çš„å‡çº§æˆ–æ›¿æ¢ï¼Œæˆ–è€…æ˜¯å®æ—¶å¤„ç†å¼•æ“ä¸‹æ¸¸çš„æ¨¡å—çš„å‡çº§æˆ–æ›¿æ¢ï¼Œéƒ½ä¸ä¼šäº’ç›¸å½±å“ï¼Œå¹¶ä¸”è¿™äº›æ¨¡å—çš„å·¥ç¨‹å¸ˆåªéœ€è¦å¯¹æ¶ˆæ¯é˜Ÿåˆ—çš„ connector è¿›è¡Œç»´æŠ¤å³å¯ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®å…¶ç‰¹æ€§è¿›è¡Œæ›´å¥½çš„ä¼˜åŒ–ã€‚ kafkaä½œç”¨æ¨¡å—ä¹‹é—´çš„è§£è€¦ã€‚è®©å„ä¸ªæ¨¡å—å„å¸å…¶èŒã€‚æ‹“å±•ï¼š1.Java è™šæ‹Ÿæœºåœ¨ Java è¯­è¨€å’Œå„ä¸ªç³»ç»Ÿä¹‹é—´çš„ä½œç”¨ã€‚2.Sql è¿›è¡Œä¸‰èŒƒå¼ä¼˜åŒ–ï¼Œä¸éœ€è¦å°†æ‰€æœ‰æ•°æ®éƒ½æ”¾åœ¨ä¸€å¼ è¡¨å½“ä¸­ï¼Œå°†nå¯¹nçš„è¡¨æ‹†åˆ†å‡ºä¸€å¼ ç»´è¡¨è¿›è¡Œè§£è€¦ã€‚å°†ç»´åº¦æ‹†åˆ†ä¸ºç»´è¡¨å¯ä»¥å‡å°‘æ•°æ®é‡ï¼Œæ›´å¥½åˆ’åˆ†å’Œä½¿ç”¨ç»´åº¦æ•°æ®ã€‚3.ç»å…¸ç½‘ç»œäº”å±‚æ¨¡å‹ï¼Œåˆ’åˆ†ä¸ºäº”å±‚ï¼Œåˆ™åœ¨æ¯ä¸€å±‚ä¸­æ›´æ–°æˆ–è€…æ–°å»ºåè®®æ ˆåªéœ€è¦å¯¹ä¸Šä¸‹å±‚è¿›è¡Œå…¼å®¹å³å¯ï¼Œä¸éœ€è¦å¯¹æ•´ä¸ªç½‘ç»œæ¶æ„æ¨¡å‹åšè°ƒæ•´ã€‚4.Maven multiModule åˆ’åˆ†ã€‚5.springMvcã€‚ç­‰ç­‰ã€‚","tags":[{"name":"Apache Kafka","slug":"Apache-Kafka","permalink":"https://yangyichao-mango.github.io/tags/Apache-Kafka/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ Operatorsï¼ˆç®—å­ï¼‰â€”â€”çª—å£","date":"2019-11-09T14:48:53.000Z","path":"2019/11/09/apache-flink:study-flink-datastream-operators-windows/","text":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ Operatorsï¼ˆç®—å­ï¼‰â€”â€”çª—å£ Keyed Windows 123456789stream .keyBy(...) &lt;- keyed versus non-keyed windows .window(...) &lt;- required: \"assigner\" [.trigger(...)] &lt;- optional: \"trigger\" (else default trigger) [.evictor(...)] &lt;- optional: \"evictor\" (else no evictor) [.allowedLateness(...)] &lt;- optional: \"lateness\" (else zero) [.sideOutputLateData(...)] &lt;- optional: \"output tag\" (else no side output for late data) .reduce/aggregate/fold/apply() &lt;- required: \"function\" [.getSideOutput(...)] &lt;- optional: \"output tag\" Non-Keyed Windows 12345678stream .windowAll(...) &lt;- required: \"assigner\" [.trigger(...)] &lt;- optional: \"trigger\" (else default trigger) [.evictor(...)] &lt;- optional: \"evictor\" (else no evictor) [.allowedLateness(...)] &lt;- optional: \"lateness\" (else zero) [.sideOutputLateData(...)] &lt;- optional: \"output tag\" (else no side output for late data) .reduce/aggregate/fold/apply() &lt;- required: \"function\" [.getSideOutput(...)] &lt;- optional: \"output tag\" Window ç”Ÿå‘½å‘¨æœŸç®€è€Œè¨€ä¹‹ï¼Œå½“å±äºè¯¥çª—å£çš„ç¬¬ä¸€ä¸ªå…ƒç´ åˆ°è¾¾æ—¶ï¼Œå°†ä¼šåˆ›å»ºä¸€ä¸ªçª—å£ï¼Œå¹¶ä¸”å½“æ—¶é—´ï¼ˆEvent Time æˆ–è€… Processing Timeï¼‰è¶…è¿‡å…¶ç»“æŸæ—¶é—´æˆ³åŠ ä¸Šç”¨æˆ·æŒ‡å®šçš„å…è®¸å»¶è¿Ÿæ—¶é—´æ—¶ï¼Œå°†å®Œå…¨åˆ é™¤è¯¥çª—å£ï¼Œæ³¨æ„çª—å£éƒ½æ˜¯å·¦å¼€å³é—­ï¼Œæ¯”å¦‚ï¼š[0, 5)ã€‚Flink ä¿è¯åªåˆ é™¤åŸºäºæ—¶é—´çš„çª—å£ï¼Œè€Œä¸åˆ é™¤å…¶ä»–ç±»å‹çš„çª—å£ï¼Œä¾‹å¦‚ Global Windowã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŸºäºäº‹ä»¶æ—¶é—´çš„çª—å£ï¼Œå¹¶ä¸”åˆ›å»ºä¸€ä¸ªçª—å£å¤§å°ä¸º5åˆ†é’Ÿçš„æ»šåŠ¨ï¼ˆTumbingï¼‰çª—å£ï¼Œå¹¶ä¸”å…è®¸å»¶è¿Ÿ1åˆ†é’Ÿã€‚å½“æ—¶é—´æˆ³å±äº12:00åˆ°12:05ä¹‹é—´çš„ç¬¬ä¸€ä¸ªå…ƒç´ åˆ°è¾¾æ—¶ï¼ŒFlink å°†åˆ›å»ºä¸€ä¸ªæ–°çª—å£ï¼Œå½“ Watermark é€šè¿‡12:06æ—¶é—´æˆ³æ—¶ï¼Œå°±ä¼šæŠŠè¿™ä¸ªçª—å£åˆ é™¤ã€‚ æ­¤å¤–ï¼Œæ¯ä¸ªçª—å£éƒ½åŒ…å«ä¸€ä¸ª Trigger å’Œä¸€ä¸ªå‡½æ•°ï¼ˆProcessWindowFunction, ReduceFunction, AggregateFunction or FoldFunctionï¼‰ã€‚å‡½æ•°åŒ…å«äº†è¦åº”ç”¨äºçª—å£å†…å®¹çš„è®¡ç®—ï¼Œè€Œ Trigger åˆ¶å®šäº†ä»€ä¹ˆæƒ…å†µä¸‹æ‰è§¦å‘æ‰§è¡Œè¿™äº›å‡½æ•°ã€‚æ¯”å¦‚ï¼Œè§¦å‘ç­–ç•¥å¯èƒ½ç±»ä¼¼äºâ€œå½“çª—å£ä¸­çš„å…ƒç´ æ•°è¶…è¿‡4æ—¶â€æˆ–â€œå½“ WaterMark é€šè¿‡çª—å£ç»“æŸæ—¶â€è¿›è¡Œè§¦å‘ã€‚Trigger è¿˜å¯ä»¥å†³å®šä»€ä¹ˆæ—¶å€™åˆ é™¤çª—å£ä¸­çš„å…ƒç´ ã€‚ é™¤ä¸Šè¿°å†…å®¹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥æŒ‡å®šä¸€ä¸ª Evictorï¼Œè¯¥ Evictor å°†èƒ½å¤Ÿåœ¨ Trigger è§¦å‘åã€åº”ç”¨å‡½æ•°ä¹‹å‰å’Œ/æˆ–ä¹‹åä»çª—å£ä¸­ç§»é™¤å…ƒç´ ã€‚ ä¸‹é¢ä¾‹å­ä¸­çš„çª—å£éƒ½æ˜¯æŒ‰ç…§ Event Time æˆ–è€… Processing Timeè¿›è¡ŒæŒ‡å®šã€‚ Keyed vs Non-Keyed Windowsé¦–å…ˆè¦æŒ‡å®šçš„æ˜¯æ˜¯å¦åº”è¯¥ä¸ºæµè®¾ç½® keyã€‚ä½¿ç”¨keyByï¼ˆâ€¦ï¼‰å¯ä»¥å°†æ— é™æµæ‹†åˆ†ä¸ºé€»è¾‘ keyed æµã€‚ åœ¨ Keyed Stream çš„æƒ…å†µä¸‹ï¼Œä¼ å…¥ event çš„ä»»ä½•å±æ€§éƒ½å¯ä»¥ç”¨ä½œé”®ã€‚æ‹¥æœ‰ä¸€ä¸ª Keyed Stream å°†å…è®¸æ‚¨çš„çª—å£è®¡ç®—ç”±å¤šä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œå› ä¸ºæ¯ä¸ªé€»è¾‘ Keyed Stream éƒ½å¯ä»¥ç‹¬ç«‹äºå…¶ä»–ä»»åŠ¡è¿›è¡Œå¤„ç†ã€‚æ‰€æœ‰å¼•ç”¨åŒä¸€ä¸ªé”®çš„ event éƒ½å°†è¢«å‘é€åˆ°åŒä¸€ä¸ªå¹¶è¡Œä»»åŠ¡ï¼ˆé€šè¿‡ partitioner å®Œæˆï¼‰ã€‚ å¦‚æœä¸æ˜¯ Keyed Streamï¼Œåˆ™ä¸ä¼šå°†åŸå§‹æµæ‹†åˆ†ä¸ºå¤šä¸ªé€»è¾‘æµï¼Œæ‰€æœ‰çª—å£é€»è¾‘å°†ç”±å•ä¸ªä»»åŠ¡æ‰§è¡Œï¼Œå³å¹¶è¡Œåº¦ä¸º1ã€‚ Tumbling Windows æ»šåŠ¨çª—å£ æ»šåŠ¨çª—å£ï¼Œå¦‚æœä½ æŒ‡å®šçš„æ»šåŠ¨çª—å£å¤§å°ä¸ºä¸€å¤©è®¡ç®—ä¸€æ¬¡ï¼Œå¹¶ä¸”ä½ éœ€è¦æ›´å…·ä½ æœ¬åœ°çš„æ—¶é—´çš„ 00:00:00 å¼€å§‹ï¼Œåˆ™å¿…é¡»æŒ‰ç…§æ—¶åŒºæ¥æŒ‡å®šçª—å£ã€‚å¯ä»¥çœ‹åˆ°ä¸Šå›¾ä¸­ï¼Œæ— è®ºæ˜¯å¤šå°‘ä¸ª keyï¼Œæ¯ä¸ª key çš„çª—å£çš„èµ·å§‹å’Œæˆªæ­¢æ—¶é—´éƒ½ç›¸åŒã€‚ 1234567891011121314151617181920212223242526272829303132333435363738/** * Creates a new &#123;@code TumblingEventTimeWindows&#125; &#123;@link WindowAssigner&#125; that assigns * elements to time windows based on the element timestamp and offset. * * å¯ä»¥æ ¹æ® æ—¶é—´æˆ³ ä»¥åŠ åç§»é‡ æ¥æŒ‡å®š çª—å£çš„èŒƒå›´ * * &lt;p&gt;For example, if you want window a stream by hour,but window begins at the 15th minutes * of each hour, you can use &#123;@code of(Time.hours(1),Time.minutes(15))&#125;,then you will get * time windows start at 0:15:00,1:15:00,2:15:00,etc. * * æ¯”å¦‚ï¼Œå¦‚æœéœ€è¦ä¸€ä¸ªçª—å£å¤§å°ä¸ºä¸€ä¸ªå°æ—¶ï¼Œä»æ¯ä¸ªå°æ—¶çš„ç¬¬15åˆ†é’Ÿå¼€å§‹è®¡æ•°çš„çª—å£ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç å®ç° * of(Time.hours(1),Time.minutes(15)) * è¿™æ ·è·å¾—çš„çª—å£å°±æ˜¯ 0:15:00ï¼Œ1:15:00ï¼Œ2:15:00 ... * * &lt;p&gt;Rather than that,if you are living in somewhere which is not using UTCÂ±00:00 time, * such as China which is using UTC+08:00,and you want a time window with size of one day, * and window begins at every 00:00:00 of local time,you may use &#123;@code of(Time.days(1),Time.hours(-8))&#125;. * The parameter of offset is &#123;@code Time.hours(-8))&#125; since UTC+08:00 is 8 hours earlier than UTC time. * * é™¤æ­¤ä¹‹å¤–ï¼Œå¦‚æœæ‚¨çš„æ—¶åŒºä¸æ˜¯ UTCÂ±00:00 æ—¶é—´ï¼Œæ¯”å¦‚åœ¨ ä¸­å›½ï¼ˆæ—¶åŒºæ˜¯ UTC+08:00ï¼‰ï¼Œå¹¶ä¸”ä½ éœ€è¦ä¸€ä¸ªä¸€å¤©å¤§å°çš„çª—å£ï¼Œ * å¹¶ä¸”çª—å£æ—¶é—´æ˜¯æœ¬åœ° 00:00:00å¼€å§‹ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç å®ç° * of(Time.days(1), Time.hours(-8)) * * @param size The size of the generated windows. * @param offset The offset which window start would be shifted by. * @return The time policy. */public static TumblingEventTimeWindows of(Time size, Time offset) &#123; return new TumblingEventTimeWindows(size.toMilliseconds(), offset.toMilliseconds());&#125;public static void main(String[] args) &#123; // daily tumbling event-time windows offset by -8 hours. input .keyBy(&lt;key selector&gt;) .window(TumblingEventTimeWindows.of(Time.days(1), Time.hours(-8))) .&lt;windowed transformation&gt;(&lt;window function&gt;);&#125; Sliding Windows æ»‘åŠ¨çª—å£ æ»‘åŠ¨çª—å£ï¼Œå¦‚æœä½ æŒ‡å®šçª—å£å¤§å°å’Œæ»‘åŠ¨æ­¥é•¿ä¸€æ ·ï¼Œé‚£ä¹ˆå’Œæ»šåŠ¨çª—å£çš„ä½œç”¨ä¸€æ ·ï¼Œæ»‘åŠ¨çª—å£çš„ä¸€ä¸ªæ˜æ˜¾çš„ç‰¹å¾å°±æ˜¯ï¼šçª—å£å¯èƒ½ä¼šé‡å ï¼Œå³åŒä¸€ä¸ªå…ƒç´ å¯èƒ½ä¼šå±äºä¸åŒçš„çª—å£ã€‚ å’Œæ»šåŠ¨çª—å£ç›¸åŒï¼Œå¦‚æœä½ æŒ‡å®šçš„æ»šåŠ¨çª—å£å¤§å°ä¸ºä¸€å¤©è®¡ç®—ä¸€æ¬¡ï¼Œä½ éœ€è¦æ›´å…·ä½ æœ¬åœ°çš„æ—¶é—´çš„ 00:00:00 å¼€å§‹ï¼Œåˆ™å¿…é¡»æŒ‰ç…§æ—¶åŒºæ¥æŒ‡å®šçª—å£ã€‚ 1234567public static void main(String[] args) &#123; // sliding processing-time windows offset by -8 hours input .keyBy(&lt;key selector&gt;) .window(SlidingProcessingTimeWindows.of(Time.hours(12), Time.hours(1), Time.hours(-8))) .&lt;windowed transformation&gt;(&lt;window function&gt;);&#125; Session Windows ä¼šè¯çª—å£ ä¼šè¯çª—å£ï¼Œæ ¹æ®ä¼šè¯æ¥æŒ‡å®šçª—å£ï¼Œä¸æ»šåŠ¨å’Œæ»‘åŠ¨çª—å£ç›¸æ¯”ï¼Œä¼šè¯çª—å£ä¸é‡å ï¼Œå¹¶ä¸”æ²¡æœ‰å›ºå®šçš„å¼€å§‹å’Œç»“æŸæ—¶é—´ã€‚ä¼šè¯çª—å£å¯ä»¥æŒ‡å®šé™æ€æŒ‡å®šä¼šè¯é—´éš”ï¼Œæˆ–è€…å¯ä»¥è®©ç”¨æˆ·åŠ¨æ€æŒ‡å®šä¼šè¯é—´éš”ã€‚ 123456789101112131415DataStream&lt;T&gt; input = ...;// event-time session windows with static gapinput .keyBy(&lt;key selector&gt;) .window(EventTimeSessionWindows.withGap(Time.minutes(10))) .&lt;windowed transformation&gt;(&lt;window function&gt;); // event-time session windows with dynamic gapinput .keyBy(&lt;key selector&gt;) .window(EventTimeSessionWindows.withDynamicGap((element) -&gt; &#123; // determine and return session gap &#125;)) .&lt;windowed transformation&gt;(&lt;window function&gt;); Global Windows å…¨å±€çª—å£ å…¨å±€çª—å£ï¼ˆå³æ— çª—å£ï¼‰ï¼Œä»£è¡¨æ‰€æœ‰å…ƒç´ æ–—æ•°ä»¥ä¸€ä¸ªå…¨å±€çª—å£ï¼Œå¦‚æœä½ ä¸æŒ‡å®š Triggerï¼Œé‚£ä¹ˆæ°¸è¿œä¹Ÿä¸ä¼šç”Ÿäº§å‡ºæ•°æ®ï¼Œå› ä¸ºå…¨å±€çª—å£æ²¡æœ‰çª—å£å¼€å§‹å’Œçª—å£ç»“æŸçš„æ¦‚å¿µã€‚ 123456DataStream&lt;T&gt; input = ...;input .keyBy(&lt;key selector&gt;) .window(GlobalWindows.create()) .&lt;windowed transformation&gt;(&lt;window function&gt;); çª—å£å‡½æ•°åœ¨å®šä¹‰ window assigner ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦æŒ‡å®šè¦åœ¨æ¯ä¸ªçª—å£ä¸Šæ‰§è¡Œçš„è®¡ç®—ã€‚å½“ç³»ç»Ÿç¡®å®šçª—å£å‡†å¤‡å¥½å¤„ç†æ—¶ï¼ˆTriggerå†³å®šï¼‰ï¼Œè¿™äº›çª—å£å‡½æ•°å°±å¯ä»¥ç”¨äºå¤„ç†æ¯ä¸ªï¼ˆKeyed / Non-Keyedï¼‰çª—å£çš„å…ƒç´ ã€‚ çª—å£å‡½æ•°å¯ä»¥æ˜¯ReduceFunctionã€AggregateFunctionã€FoldFunctionæˆ–ProcessWindowFunctionä¹‹ä¸€ã€‚å‰ä¸¤ä¸ªå‡½æ•°æ‰§è¡Œèµ·æ¥ä¼šæ›´é«˜æ•ˆï¼Œå› ä¸º Flink å¯ä»¥åœ¨æ¯ä¸ªçª—å£ä¸­çš„å…ƒç´ åˆ°è¾¾æ—¶é€’å¢åœ°èšåˆå…ƒç´ ã€‚ProcessWindowFunctionè·å–åŒ…å«åœ¨çª—å£ä¸­çš„æ‰€æœ‰å…ƒç´ çš„Iterableï¼Œä»¥åŠæœ‰å…³å…ƒç´ æ‰€å±çª—å£çš„å…¶ä»–å…ƒä¿¡æ¯ã€‚ ä½¿ç”¨ProcessWindowFunctionçš„çª—å£å‡½æ•°ä¸èƒ½åƒå…¶ä»–å‡½æ•°é‚£æ ·é«˜æ•ˆåœ°æ‰§è¡Œï¼Œå› ä¸ºFlinkåœ¨è°ƒç”¨å‡½æ•°ä¹‹å‰å¿…é¡»åœ¨å†…éƒ¨ç¼“å†²çª—å£çš„æ‰€æœ‰å…ƒç´ ã€‚è¿™å¯ä»¥é€šè¿‡å°†ProcessWindowFunctionä¸ReduceFunctionã€AggregateFunctionæˆ–FoldFunctionç»„åˆä½¿ç”¨æ¥æé«˜æ•ˆç‡ï¼Œä»è€Œä½¿å¾—å…¶ä»–çª—å£å…ƒæ•°æ®æˆ–è€…çª—å£å…ƒç´ çš„è¿›è¡Œå¢é‡èšåˆã€‚ ReduceFunctionå˜é‡ï¼šä¸¤ä¸ªè¾“å…¥ç”Ÿæˆä¸€ä¸ªè¾“å‡ºï¼Œä¸‰ä¸ªå˜é‡çš„ç±»å‹å¿…é¡»ç›¸åŒã€‚è§¦å‘æ—¶é—´ï¼šåœ¨æ¯ä¸ªçª—å£çš„å…ƒç´ åˆ°æ¥çš„æ—¶å€™è¿›è¡Œå¢é‡èšåˆã€‚ 12345678910DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;input .keyBy(&lt;key selector&gt;) .window(&lt;window assigner&gt;) .reduce(new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt; &#123; public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; v1, Tuple2&lt;String, Long&gt; v2) &#123; return new Tuple2&lt;&gt;(v1.f0, v1.f1 + v2.f1); &#125; &#125;); AggregateFunctionAggregateFunction æ˜¯ ReduceFunction çš„ä¸€ä¸ªæ‰©å±•ç‰ˆæœ¬ã€‚ å˜é‡ï¼šä¸‰ä¸ªå˜é‡ï¼Œä¸€ä¸ªæ˜¯è¾“å…¥ï¼Œä¸€ä¸ªæ˜¯ accumulator ç´¯åŠ å™¨ï¼Œè¿˜æœ‰ä¸€ä¸ªæ˜¯è¾“å‡ºï¼Œä¸‰ä¸ªå˜é‡çš„ç±»å‹å¯ä»¥ä¸åŒã€‚è§¦å‘æ—¶é—´ï¼šåœ¨æ¯ä¸ªçª—å£çš„å…ƒç´ åˆ°æ¥çš„æ—¶å€™è¿›è¡Œå¢é‡èšåˆã€‚ 123456789101112131415161718192021222324252627282930313233/** * The accumulator is used to keep a running sum and a count. The &#123;@code getResult&#125; method * computes the average. */private static class AverageAggregate implements AggregateFunction&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;Long, Long&gt;, Double&gt; &#123; @Override public Tuple2&lt;Long, Long&gt; createAccumulator() &#123; return new Tuple2&lt;&gt;(0L, 0L); &#125; @Override public Tuple2&lt;Long, Long&gt; add(Tuple2&lt;String, Long&gt; value, Tuple2&lt;Long, Long&gt; accumulator) &#123; return new Tuple2&lt;&gt;(accumulator.f0 + value.f1, accumulator.f1 + 1L); &#125; @Override public Double getResult(Tuple2&lt;Long, Long&gt; accumulator) &#123; return ((double) accumulator.f0) / accumulator.f1; &#125; @Override public Tuple2&lt;Long, Long&gt; merge(Tuple2&lt;Long, Long&gt; a, Tuple2&lt;Long, Long&gt; b) &#123; return new Tuple2&lt;&gt;(a.f0 + b.f0, a.f1 + b.f1); &#125;&#125;DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;input .keyBy(&lt;key selector&gt;) .window(&lt;window assigner&gt;) .aggregate(new AverageAggregate()); FoldFunctionFoldFunction æ˜¯ AggregateFunction çš„ä¸€ä¸ªç®€æ˜“ç‰ˆæœ¬ã€‚ å˜é‡ï¼šä¸‰ä¸ªä¸ªå˜é‡ï¼Œä¸€ä¸ªæ˜¯è¾“å‡ºå€¼çš„åˆå§‹åŒ–å€¼ï¼Œä¸€ä¸ªæ˜¯è¾“å…¥ï¼Œè¿˜æœ‰ä¸€ä¸ªæ˜¯è¾“å‡ºï¼Œä¸‰ä¸ªå˜é‡ä¸­è¾“å…¥å’Œè¾“å‡ºçš„ç±»å‹å¯ä»¥ä¸åŒï¼Œä½†æ˜¯è¾“å‡ºå’Œè¾“å‡ºåˆå§‹åŒ–å€¼å¿…é¡»ç›¸åŒã€‚è§¦å‘æ—¶é—´ï¼šåœ¨æ¯ä¸ªçª—å£çš„å…ƒç´ åˆ°æ¥çš„æ—¶å€™è¿›è¡Œå¢é‡èšåˆã€‚ FoldFunction æŒ‡å®šå¦‚ä½•å°†çª—å£çš„è¾“å…¥å…ƒç´ ä¸è¾“å‡ºç±»å‹çš„å…ƒç´ ç»„åˆã€‚å¯¹æ·»åŠ åˆ°çª—å£çš„æ¯ä¸ªå…ƒç´ å’Œå½“å‰è¾“å‡ºå€¼å¢é‡è°ƒç”¨ FoldFunctionã€‚ 12345678910DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;input .keyBy(&lt;key selector&gt;) .window(&lt;window assigner&gt;) .fold(\"\", new FoldFunction&lt;Tuple2&lt;String, Long&gt;, String&gt;&gt; &#123; public String fold(String acc, Tuple2&lt;String, Long&gt; value) &#123; return acc + value.f1; &#125; &#125;); ProcessWindowFunctionProcessWindowFunction å¯ä»¥å¾—åˆ°ä¸€ä¸ªåŒ…å«çª—å£çš„æ‰€æœ‰å…ƒç´ çš„è¿­ä»£å™¨ï¼Œä»¥åŠä¸€ä¸ªè®¿é—®æ—¶é—´å’ŒçŠ¶æ€ä¿¡æ¯çš„ä¸Šä¸‹æ–‡å¯¹è±¡ï¼Œä½¿å¾—å®ƒèƒ½å¤Ÿæä¾›æ¯”å…¶ä»–çª—å£å‡½æ•°æ›´å¥½çš„çµæ´»æ€§ã€‚ä½†æ˜¯è¿™æ˜¯ä»¥æ€§èƒ½å’Œèµ„æºæ¶ˆè€—ä¸ºä»£ä»·çš„ï¼Œå› ä¸ºå…ƒç´ ä¸èƒ½å¢é‡èšåˆï¼Œè€Œæ˜¯éœ€è¦åœ¨å†…éƒ¨ç¼“å†²ï¼Œç›´åˆ°çª—å£å¯ä»¥å¤„ç†ä¸ºæ­¢ã€‚ å˜é‡ï¼šå››ä¸ªå˜é‡ï¼Œä¸€ä¸ªæ˜¯çª—å£çš„keyï¼Œä¸€ä¸ªæ˜¯åŒ…å«äº†çª—å£ä¿¡æ¯çš„ä¸Šä¸‹æ–‡ï¼Œä¸€ä¸ªæ˜¯çª—å£å†…æ‰€æœ‰å…ƒç´ çš„è¿­ä»£å™¨ï¼Œä¸€ä¸ªæ˜¯è¾“å‡ºæ•°æ®çš„æ”¶é›†å™¨ã€‚è§¦å‘æ—¶é—´ï¼šçª—å£å†…æœ‰æ•°æ®å¹¶ä¸” Watermark åˆ°è¾¾äº†çª—å£ç»“æŸæ—¶é—´æ—¶è§¦å‘ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public abstract class ProcessWindowFunction&lt;IN, OUT, KEY, W extends Window&gt; implements Function &#123; /** * Evaluates the window and outputs none or several elements. * * @param key The key for which this window is evaluated. * @param context The context in which the window is being evaluated. * @param elements The elements in the window being evaluated. * @param out A collector for emitting elements. * * @throws Exception The function may throw exceptions to fail the program and trigger recovery. */ public abstract void process( KEY key, Context context, Iterable&lt;IN&gt; elements, Collector&lt;OUT&gt; out) throws Exception; /** * The context holding window metadata. */ public abstract class Context implements java.io.Serializable &#123; /** * Returns the window that is being evaluated. */ public abstract W window(); /** Returns the current processing time. */ public abstract long currentProcessingTime(); /** Returns the current event-time watermark. */ public abstract long currentWatermark(); /** * State accessor for per-key and per-window state. * * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt;If you use per-window state you have to ensure that you clean it up * by implementing &#123;@link ProcessWindowFunction#clear(Context)&#125;. */ public abstract KeyedStateStore windowState(); /** * State accessor for per-key global state. */ public abstract KeyedStateStore globalState(); &#125;&#125; 123456789101112131415161718192021DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;input .keyBy(t -&gt; t.f0) .timeWindow(Time.minutes(5)) .process(new MyProcessWindowFunction());/* ... */public class MyProcessWindowFunction extends ProcessWindowFunction&lt;Tuple2&lt;String, Long&gt;, String, String, TimeWindow&gt; &#123; @Override public void process(String key, Context context, Iterable&lt;Tuple2&lt;String, Long&gt;&gt; input, Collector&lt;String&gt; out) &#123; long count = 0; for (Tuple2&lt;String, Long&gt; in: input) &#123; count++; &#125; out.collect(\"Window: \" + context.window() + \"count: \" + count); &#125;&#125; ä½¿ç”¨ ProcessWindowFunction è¿›è¡Œå…ƒç´  count æ˜¯éå¸¸ä½æ•ˆçš„ï¼Œä¸‹é¢ä¼šè®²åˆ°æ€æ ·å°† ReduceFunction æˆ–è€… AggregateFunction ä¸ ProcessWindowFunction ç»“åˆä½¿ç”¨å°†å¢é‡çš„æ•°æ®çš„ä¸ ProcessWindowFunction é…åˆè¿›è¡Œä½¿ç”¨ã€‚ ä¸ºä»€ä¹ˆéœ€è¦ç”¨åˆ° ProcessWindowFunctionï¼šå¦‚æœå¿…è¦çš„è¯ï¼Œä¸€èˆ¬çš„ä¸šåŠ¡é€»è¾‘æ˜¯æ²¡å¿…è¦ä½¿ç”¨åˆ° ProcessWindowFunction çš„ï¼Œä½†æ˜¯æœ‰çš„éœ€æ±‚éœ€è¦è·å–åˆ°å½“å‰å…ƒç´ æ—¶é—´æˆ³ï¼Œçª—å£å¼€å§‹ç»“æŸç­‰ç­‰çš„ä¿¡æ¯ï¼Œè¿™æ—¶å°±éœ€è¦ä½¿ç”¨ ProcessWindowFunction æ¥è·å–è¿™äº›ä¿¡æ¯äº†ã€‚ ProcessWindowFunction ä¸ ReduceFunction123456789101112131415161718192021222324252627DataStream&lt;SensorReading&gt; input = ...;input .keyBy(&lt;key selector&gt;) .timeWindow(&lt;duration&gt;) .reduce(new MyReduceFunction(), new MyProcessWindowFunction());// Function definitionsprivate static class MyReduceFunction implements ReduceFunction&lt;SensorReading&gt; &#123; public SensorReading reduce(SensorReading r1, SensorReading r2) &#123; return r1.value() &gt; r2.value() ? r2 : r1; &#125;&#125;private static class MyProcessWindowFunction extends ProcessWindowFunction&lt;SensorReading, Tuple2&lt;Long, SensorReading&gt;, String, TimeWindow&gt; &#123; public void process(String key, Context context, Iterable&lt;SensorReading&gt; minReadings, Collector&lt;Tuple2&lt;Long, SensorReading&gt;&gt; out) &#123; SensorReading min = minReadings.iterator().next(); out.collect(new Tuple2&lt;Long, SensorReading&gt;(context.window().getStart(), min)); &#125;&#125; ProcessWindowFunction ä¸ AggregateFunction1234567891011121314151617181920212223242526272829303132333435363738394041424344454647DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;input .keyBy(&lt;key selector&gt;) .timeWindow(&lt;duration&gt;) .aggregate(new AverageAggregate(), new MyProcessWindowFunction());// Function definitions/** * The accumulator is used to keep a running sum and a count. The &#123;@code getResult&#125; method * computes the average. */private static class AverageAggregate implements AggregateFunction&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;Long, Long&gt;, Double&gt; &#123; @Override public Tuple2&lt;Long, Long&gt; createAccumulator() &#123; return new Tuple2&lt;&gt;(0L, 0L); &#125; @Override public Tuple2&lt;Long, Long&gt; add(Tuple2&lt;String, Long&gt; value, Tuple2&lt;Long, Long&gt; accumulator) &#123; return new Tuple2&lt;&gt;(accumulator.f0 + value.f1, accumulator.f1 + 1L); &#125; @Override public Double getResult(Tuple2&lt;Long, Long&gt; accumulator) &#123; return ((double) accumulator.f0) / accumulator.f1; &#125; @Override public Tuple2&lt;Long, Long&gt; merge(Tuple2&lt;Long, Long&gt; a, Tuple2&lt;Long, Long&gt; b) &#123; return new Tuple2&lt;&gt;(a.f0 + b.f0, a.f1 + b.f1); &#125;&#125;private static class MyProcessWindowFunction extends ProcessWindowFunction&lt;Double, Tuple2&lt;String, Double&gt;, String, TimeWindow&gt; &#123; public void process(String key, Context context, Iterable&lt;Double&gt; averages, Collector&lt;Tuple2&lt;String, Double&gt;&gt; out) &#123; Double average = averages.iterator().next(); out.collect(new Tuple2&lt;&gt;(key, average)); &#125;&#125; ProcessWindowFunction ä¸ FoldFunction123456789101112131415161718192021222324252627282930DataStream&lt;SensorReading&gt; input = ...;input .keyBy(&lt;key selector&gt;) .timeWindow(&lt;duration&gt;) .fold(new Tuple3&lt;String, Long, Integer&gt;(\"\",0L, 0), new MyFoldFunction(), new MyProcessWindowFunction())// Function definitionsprivate static class MyFoldFunction implements FoldFunction&lt;SensorReading, Tuple3&lt;String, Long, Integer&gt; &gt; &#123; public Tuple3&lt;String, Long, Integer&gt; fold(Tuple3&lt;String, Long, Integer&gt; acc, SensorReading s) &#123; Integer cur = acc.getField(2); acc.setField(cur + 1, 2); return acc; &#125;&#125;private static class MyProcessWindowFunction extends ProcessWindowFunction&lt;Tuple3&lt;String, Long, Integer&gt;, Tuple3&lt;String, Long, Integer&gt;, String, TimeWindow&gt; &#123; public void process(String key, Context context, Iterable&lt;Tuple3&lt;String, Long, Integer&gt;&gt; counts, Collector&lt;Tuple3&lt;String, Long, Integer&gt;&gt; out) &#123; Integer count = counts.iterator().next().getField(2); out.collect(new Tuple3&lt;String, Long, Integer&gt;(key, context.window().getEnd(),count)); &#125;&#125; ProcessWindowFunction ä¸­ä½¿ç”¨ stateWindowFunctionï¼ˆé—ç•™ï¼‰åœ¨ä¸€äº›å¯ä»¥ä½¿ç”¨ ProcessWindowFunction çš„åœ°æ–¹ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ WindowFunctionï¼Œè¿™æ˜¯è¾ƒæ—§ç‰ˆæœ¬çš„ ProcessWindowFunctionï¼Œå®ƒæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯è¾ƒå°‘ï¼Œå¹¶ä¸”æ²¡æœ‰ä¸€äº›é«˜çº§åŠŸèƒ½ï¼Œä¾‹å¦‚ per-window keyed stateã€‚ 1234567891011121314public interface WindowFunction&lt;IN, OUT, KEY, W extends Window&gt; extends Function, Serializable &#123; /** * Evaluates the window and outputs none or several elements. * * @param key The key for which this window is evaluated. * @param window The window that is being evaluated. * @param input The elements in the window being evaluated. * @param out A collector for emitting elements. * * @throws Exception The function may throw exceptions to fail the program and trigger recovery. */ void apply(KEY key, W window, Iterable&lt;IN&gt; input, Collector&lt;OUT&gt; out) throws Exception;&#125; 123456DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;input .keyBy(&lt;key selector&gt;) .window(&lt;window assigner&gt;) .apply(new MyWindowFunction()); Triggersè§¦å‘å™¨å†³å®šäº†çª—å£å‡½æ•°ä»€ä¹ˆæ—¶å€™å¤„ç†çª—å£ä¸­çš„æ•°æ®ã€‚æ¯ä¸€ä¸ª WindowAssigner éƒ½ä¼šå¸¦æœ‰ä¸€ä¸ªé»˜è®¤çš„ Triggerï¼Œå¦‚æœé»˜è®¤çš„ Trigger ä¸ç¬¦åˆéœ€æ±‚ï¼Œä½ å¯ä»¥ä½¿ç”¨ trigger(â€¦) æŒ‡å®šä½ éœ€è¦çš„è§¦å‘å™¨ã€‚ ä¸€ä¸ª Trigger æ¥å£æœ‰äº”ä¸ªæ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡ç¼–å†™å‡½æ•°æŒ‡å®šå¦‚ä½•å¯¹ä¸åŒçš„ event åšå‡ºç›¸åº”ã€‚ Function ä½œç”¨ TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) æ¯å‘çª—å£æ·»åŠ ä¸€ä¸ªå…ƒç´ æ—¶è§¦å‘ä¸€æ¬¡ã€‚ TriggerResult onEventTime(long time, W window, TriggerContext ctx) Event Time timer è§¦å‘æ—¶è°ƒç”¨ã€‚ TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) Processing Time timer è°ƒç”¨æ—¶è§¦å‘ã€‚ void onMerge(W window, OnMergeContext ctx) æ–¹æ³•ä¸æœ‰çŠ¶æ€ Trigger ç›¸å…³ï¼Œå¹¶åœ¨ä¸¤ä¸ªè§¦å‘å™¨çš„ç›¸åº”çª—å£åˆå¹¶æ—¶åˆå¹¶å®ƒä»¬çš„çŠ¶æ€ï¼Œä¾‹å¦‚åœ¨ä½¿ç”¨ä¼šè¯çª—å£æ—¶ï¼ˆä¼šè¯çª—å£æ¯æ·»åŠ ä¸€ä¸ªå…ƒç´ å°±ä¼šäº§ç”Ÿä¸€ä¸ªçª—å£ï¼‰ã€‚ void clear(W window, TriggerContext ctx) å°†å½“å‰çª—å£çš„ state æ¸…é™¤ã€‚ å‰ä¸‰ä¸ªå‡½æ•°é€šè¿‡ TriggerResult å†³å®šå¦‚ä½•å¤„ç†å®ƒä»¬çš„è°ƒç”¨äº‹ä»¶ã€‚ TriggerResult ä½œç”¨ TriggerResult.CONTINUE ä»€ä¹ˆéƒ½ä¸åšã€‚ TriggerResult.FIRE è§¦å‘è®¡ç®—ã€‚ TriggerResult.PURGE æ¸…é™¤çª—å£å†…çš„å…ƒç´ ã€‚ TriggerResult.FIRE_AND_PURGE è§¦å‘è®¡ç®—ï¼Œå¹¶ä¸”åœ¨æ­¤ä¹‹åæ¸…é™¤çª—å£å†…çš„å…ƒç´ ã€‚ è§¦å‘è¿ç®—å¹¶ä¸”æ¸…é™¤å…ƒç´ WindowAssigners çš„é»˜è®¤ Triggerså¾ˆå¤š WindowAssigners çš„é»˜è®¤ Triggersæ˜¯é€‚ç”¨äºå¾ˆå¤šåœºæ™¯çš„ã€‚ä¾‹å¦‚ï¼Œæ‰€æœ‰çš„ event-time window assigners éƒ½å°† EventTimeTrigger ä½œä¸ºé»˜è®¤çš„ Triggerã€‚è¿™ä¸ª Trigger çš„ä½œç”¨å°±æ˜¯å½“ Watermark åˆ°è¾¾äº†çª—å£ç»“æŸæ—¶é—´æ—¶å°±è§¦å‘ã€‚æç¤º1ï¼šGlobalWindow çš„é»˜è®¤ Trigger æ˜¯æ°¸è¿œä¸ä¼šè§¦å‘çš„ NeverTriggerã€‚æç¤º2ï¼šé€šè¿‡ä½¿ç”¨ trigger() æŒ‡å®šè§¦å‘å™¨ï¼Œæ‚¨å°†è¦†ç›– WindowAssigner çš„é»˜è®¤è§¦å‘å™¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸º TumblingEventTimeWindows æŒ‡å®š CountTriggerï¼Œåˆ™ä¸ä¼šå†æ ¹æ®æ—¶é—´è¿›åº¦è€Œä»…æŒ‰ count è§¦å‘çª—å£ã€‚ é€šç”¨çš„ Triggers Trigger ä½œç”¨ EventTimeTrigger æ ¹æ®ç”± Watermark è®¡ç®—çš„ Event Time è¿›åº¦è§¦å‘ã€‚ ProcessingTimeTrigger æ ¹æ® Processing Time è§¦å‘ã€‚ CountTrigger åœ¨çª—å£ä¸­çš„å…ƒç´ æ•°è¶…è¿‡ç»™å®šé™é¢æ—¶è§¦å‘ã€‚ PurgingTrigger å°†å¦ä¸€ä¸ª Trigger ä½œä¸ºå‚æ•°ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ¸…é™¤è§¦å‘å™¨ã€‚ EvictorsFlink çš„çª—å£æ¨¡å‹ä¸­å…è®¸æŒ‡å®šé™¤ WindowAssigner å’Œ Trigger ä¹‹å¤–çš„å¯é€‰é€å‡ºå™¨ï¼ˆEvictorï¼‰ã€‚å¯ä»¥ä½¿ç”¨exictor(â€¦)æ–¹æ³•æŒ‡å®šã€‚Exictor èƒ½å¤Ÿåœ¨è§¦å‘å™¨è§¦å‘ä¹‹åï¼Œå¹¶åœ¨ä½¿ç”¨çª—å£å‡½æ•°ä¹‹å‰æˆ–è€…ä¹‹åç§»é™¤å…ƒç´ ã€‚ä¸ºæ­¤ï¼Œé€å‡ºå™¨æ¥å£æœ‰ä¸¤ä¸ªæ–¹æ³•ï¼š 123456789101112131415161718192021/** * Optionally evicts elements. Called before windowing function. * åœ¨æ‰§è¡Œçª—å£å‡½æ•°ä¹‹å‰æ‰§è¡Œã€‚ * * @param elements The elements currently in the pane. * @param size The current number of elements in the pane. * @param window The &#123;@link Window&#125; * @param evictorContext The context for the Evictor */void evictBefore(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext);/** * Optionally evicts elements. Called after windowing function. * åœ¨æ‰§è¡Œçª—å£å‡½æ•°ä¹‹åæ‰§è¡Œã€‚ * * @param elements The elements currently in the pane. * @param size The current number of elements in the pane. * @param window The &#123;@link Window&#125; * @param evictorContext The context for the Evictor */void evictAfter(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext); Evictor ä½œç”¨ CountEvictor ä¿æŒçª—å£å†…å…ƒç´ æ•°é‡ç¬¦åˆç”¨æˆ·æŒ‡å®šæ•°é‡ï¼Œå¦‚æœå¤šäºç”¨æˆ·æŒ‡å®šçš„æ•°é‡ï¼Œä»çª—å£ç¼“å†²åŒºçš„å¼€å¤´ä¸¢å¼ƒå‰©ä½™çš„å…ƒç´ ã€‚ DeltaEvictor ä½¿ç”¨ DeltaFunction å’Œä¸€ä¸ªé˜ˆå€¼ï¼Œè®¡ç®—çª—å£ç¼“å†²åŒºä¸­çš„æœ€åä¸€ä¸ªå…ƒç´ ä¸å…¶ä½™æ¯ä¸ªå…ƒç´ ä¹‹é—´çš„ delta å€¼ï¼Œå¹¶åˆ é™¤ delta å€¼å¤§äºæˆ–ç­‰äºé˜ˆå€¼çš„å…ƒç´ ã€‚ TimeEvictor ä»¥æ¯«ç§’ä¸ºå•ä½çš„æ—¶é—´é—´éš”ä½œä¸ºå‚æ•°ï¼Œå¯¹äºç»™å®šçš„çª—å£ï¼Œæ‰¾åˆ°å…ƒç´ ä¸­çš„æœ€å¤§çš„æ—¶é—´æˆ³max_tsï¼Œå¹¶åˆ é™¤æ—¶é—´æˆ³å°äºmax_ts - intervalçš„æ‰€æœ‰å…ƒç´ ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œéƒ½åªä¼šåœ¨æ‰§è¡Œ WindowFunction ä¹‹å‰æ‰§è¡Œ Evictorã€‚ æç¤ºï¼šFlink ä¸èƒ½ä¿è¯çª—å£ä¸­å…ƒç´ çš„é¡ºåºã€‚è¿™æ„å‘³ç€å°½ç®¡é€å‡ºå™¨å¯èƒ½ä¼šä»çª—å£çš„å¼€å¤´ç§»é™¤å…ƒç´ ï¼Œä½†è¿™äº›å…ƒç´ ä¸ä¸€å®šæ˜¯æœ€å…ˆåˆ°è¾¾æˆ–æœ€ååˆ°è¾¾çš„å…ƒç´ ã€‚ Allowed Latenessæ¦‚å¿µä½¿ç”¨ Event Time çª—å£æ—¶ï¼Œå¯èƒ½ä¼šå‘ç”Ÿå…ƒç´ åˆ°è¾¾æ™šçš„æƒ…å†µï¼Œå³ Flink ç”¨äºè·Ÿè¸ª Event Time è¿›åº¦çš„ Watermark å·²è¶…è¿‡å…ƒç´ æ‰€å±çª—å£çš„ç»“æŸæ—¶é—´æˆ³ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œå½“å‘ç° Watermark å·²ç»è¶…è¿‡åˆ°è¾¾çš„å…ƒç´ æ‰€å±çš„çª—å£ç»“æŸæ—¶é—´æ—¶ï¼Œå°†åˆ é™¤è¿™ä¸ªå»¶è¿Ÿå…ƒç´ ã€‚ä½†æ˜¯ Flink å¯ä»¥ç»™çª—å£ç®—å­æŒ‡å®šä¸€ä¸ªæœ€å¤§å…è®¸å»¶è¿Ÿæ—¶é—´ã€‚Allowed lateness æŒ‡å®šå…ƒç´ åœ¨è¢«åˆ é™¤ä¹‹å‰å¯ä»¥å»¶è¿Ÿå¤šå°‘æ—¶é—´ï¼Œå…¶é»˜è®¤å€¼ä¸º0ã€‚ åœ¨è¿Ÿåˆ°å…ƒç´ åˆ°è¾¾æ—¶ï¼Œå¦‚æœ Watermark å¤§äºå…¶æ‰€å±çª—å£çš„ç»“æŸæ—¶é—´æ—¶ï¼Œå¹¶ä¸” Watermark å°äºçª—å£ç»“æŸæ—¶é—´åŠ ä¸Š allowed latenessï¼Œè¿™ä¸ªè¿Ÿåˆ°çš„å…ƒç´ ä»ç„¶å¯ä»¥è¢«åŠ åˆ°è¿™ä¸ªçª—å£å†…è¿›è¡Œè¿ç®—ã€‚æœ‰çš„è§¦å‘å™¨ä¼šå‡ºç°åœ¨å»¶è¿Ÿä½†æ˜¯æ²¡æœ‰ä¸¢å¼ƒçš„å…ƒç´ åˆ°è¾¾æ—¶ï¼Œä½¿å¾—çª—å£å†æ¬¡è®¡ç®—ï¼Œæ¯”å¦‚ EventTimeTriggerã€‚ æç¤º1ï¼šåœ¨ assignTimestampsAndWatermarks æ—¶æœ‰ä¸€ä¸ª maxOutOfOrderness çš„æ¦‚å¿µï¼ŒmaxOutOfOrderness æ˜¯ç”Ÿæˆ Watermark æ‰€éœ€è¦çš„ï¼Œæ˜¯æŒ‡å…ƒç´ æœ€å¤§æ— åºæ—¶é—´ã€‚è€Œ Allowed Lateness æ˜¯æŒ‡åœ¨ Watermark åˆ°è¾¾çª—å£ç»“æŸæ—¶é—´ä¹‹åå…è®¸å»¶è¿Ÿå¤šé•¿æ—¶é—´ï¼Œä¸¤ä¸ªæ¦‚å¿µä¸ä¸€æ ·ã€‚æç¤º2ï¼ša.é€šè¿‡ watermark æœºåˆ¶æ¥å¤„ç† out-of-order çš„é—®é¢˜ï¼Œå±äºç¬¬ä¸€å±‚é˜²æŠ¤ï¼Œå±äºå…¨å±€æ€§çš„é˜²æŠ¤ï¼Œé€šå¸¸è¯´çš„ä¹±åºé—®é¢˜çš„è§£å†³åŠæ³•ï¼Œå°±æ˜¯æŒ‡è¿™ç±»ï¼›b.é€šè¿‡çª—å£ä¸Šçš„ allowedLateness æœºåˆ¶æ¥å¤„ç† out-of-order çš„é—®é¢˜ï¼Œå±äºç¬¬äºŒå±‚é˜²æŠ¤ï¼Œå±äºç‰¹å®š window operator çš„é˜²æŠ¤ï¼Œlate element çš„é—®é¢˜å°±æ˜¯æŒ‡è¿™ç±» 1234567DataStream&lt;T&gt; input = ...;input .keyBy(&lt;key selector&gt;) .window(&lt;window assigner&gt;) .allowedLateness(&lt;time&gt;) .&lt;windowed transformation&gt;(&lt;window function&gt;); æç¤ºï¼šå½“ä½¿ç”¨ GlobalWindows æ—¶ï¼Œæ²¡æœ‰å…ƒç´ ä¼šè¢«è®¤ä¸ºæ˜¯è¿Ÿåˆ°çš„ï¼Œå› ä¸ºè¿™ä¸ªçª—å£å“¦çš„ç»“æŸæ—¶é—´æ—¶ Long.MAX_VALUEã€‚ è¿Ÿåˆ°çš„æ•°æ®åšæ—è·¯è¾“å‡ºï¼ˆside outputï¼‰123456789101112final OutputTag&lt;T&gt; lateOutputTag = new OutputTag&lt;T&gt;(\"late-data\")&#123;&#125;;DataStream&lt;T&gt; input = ...;SingleOutputStreamOperator&lt;T&gt; result = input .keyBy(&lt;key selector&gt;) .window(&lt;window assigner&gt;) .allowedLateness(&lt;time&gt;) .sideOutputLateData(lateOutputTag) .&lt;windowed transformation&gt;(&lt;window function&gt;);DataStream&lt;T&gt; lateStream = result.getSideOutput(lateOutputTag); æ‹“å±•æ€è€ƒå½“æŒ‡å®š Allowed Lateness &gt; 0 æ—¶ï¼Œåœ¨ Watermark é€šè¿‡çª—å£ç»“æŸæ—¶é—´åï¼Œå°†ä¿ç•™çª—å£åŠå…¶å†…å®¹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“ä¸€ä¸ªå»¶è¿Ÿä½†æœªè¢«ä¸¢å¼ƒçš„å…ƒç´ åˆ°è¾¾æ—¶ï¼Œå®ƒå¯èƒ½ä¼šå†æ¬¡è§¦å‘çª—å£è¿ç®—ã€‚è¿™äº›è¢«è§¦å‘è¿ç®—çš„è¢«ç§°ä¸º late firingã€‚åœ¨ä½¿ç”¨ä¼šè¯çª—å£æ—¶ï¼Œå®ƒä»¬å¯èƒ½ä¼šå°†ä¸¤ä¸ªé¢„å…ˆå­˜åœ¨çš„æœªåˆå¹¶çª—å£è¿›è¡Œåˆå¹¶ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ã€‚ æ¯”å¦‚ï¼šæœ‰ä¸€ä¸ªä¼šè¯çª—å£ä¸” Gap ä¸º3åˆ†é’Ÿï¼Œç°åœ¨æœ‰ä¸¤ä¸ªçª—å£ï¼Œç¬¬ä¸€ä¸ªçª—å£èµ·å§‹å’Œç»“æŸæ—¶é—´ä¸ºï¼ˆ01:00:00ï¼Œ01:00:05ï¼‰ï¼Œç¬¬äºŒä¸ªçª—å£èµ·å§‹å’Œç»“æŸæ—¶é—´ä¸ºï¼ˆ01:00:09ï¼Œ01:00:15ï¼‰ï¼Œå¦‚æœæˆ‘ä»¬åœ¨æ­¤æ—¶ä¸è®¾ç½® Allowed Lateness æ—¶ï¼Œé‚£ä¹ˆå¦‚æœä¸ä¿å­˜ç¬¬ä¸€ä¸ªçª—å£çš„æ•°æ®ï¼Œè¿ç®—ç¬¬äºŒä¸ªçª—å£çš„æ•°æ®æ—¶ï¼Œä¸ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬è®¾ç½®äº† Allowed Lateness = 5 minï¼Œé‚£ä¹ˆè¿™æ—¶å°±ä¼šæœ‰é—®é¢˜äº†ï¼Œæ¯”å¦‚æœ‰è¿Ÿåˆ°å…ƒç´ 01:00:15æ‰åˆ°è¾¾ï¼Œå…ƒç´ è‡ªå·±çš„æ—¶é—´æˆ³ä¸º01:00:07ï¼Œè¿™æ ·è¿™ä¸ªå…ƒç´ å°±å¯ä»¥å°†ä¸¤ä¸ªçª—å£çš„æ•°æ®ç»“åˆä¸ºä¸€ä¸ªçª—å£ã€‚ æç¤ºï¼šå»¶è¿Ÿæ•°æ®è§¦å‘çš„è¿ç®—åº”è¯¥å°†ä¹‹å‰çš„è®¡ç®—ç»“æœæ›´æ–°ï¼Œæ‰€ä»¥å¦‚æœä¸‹æ¸¸ sink ä½¿ç”¨äº† kafkaï¼Œåˆ™è¿™ç§æƒ…å†µä¸æ˜¯å¾ˆé€‚ç”¨ï¼ˆé™¤éæ¶ˆè´¹ kafka çš„æ˜¯ä¸€äº› updateable dfsï¼‰ï¼Œå¦åˆ™ï¼Œä½ å°†ä¼šå¾—åˆ°å¾ˆå¤šçš„å¯¹ç›¸åŒç»„æ•°æ®è®¡ç®—çš„ç»“æœã€‚ çª—å£ç»“æœçš„ä½¿ç”¨çª—å£è®¡ç®—çš„ç»“æœä¹Ÿä¼šè½¬åŒ–ä¸ºä¸€ä¸ªæ•°æ®æµï¼Œè¿™ä»½ç»“æœä¸­ä¸ä¼šåŒ…å«çª—å£æ“ä½œçš„ä»»ä½•ä¿¡æ¯ï¼Œæ‰€ä»¥å¦‚æœåç»­è®¡ç®—ä¸­éœ€è¦è¿™äº›ä¿¡æ¯ï¼Œä½ å¿…é¡»ä½¿ç”¨ ProcessWindowFunction å°†è¿™äº›ä¿¡æ¯é€šè¿‡ç¼–ç ä¼ è¾“è¿›å»ã€‚ çª—å£å’Œ Watermark çš„è”ç³»å½“ Watermark åˆ°è¾¾çª—å£ç®—å­å¤„æ—¶ï¼Œä¼šè§¦å‘ä¸¤ä¸ªäº‹ä»¶ï¼š1.Watermark ä¼šè§¦å‘æ‰€æœ‰çš„çª—å£ä¸­çš„æœ€å¤§æ—¶é—´æˆ³ï¼ˆçª—å£ç»“æŸæ—¶é—´æˆ³ - 1ï¼‰&lt; åˆ°è¾¾çš„æœ€æ–° Watermarkçš„çª—å£è¿ç®—ã€‚2.å°† Watermark å‘é€åˆ°ä¸‹æ¸¸ç®—å­ã€‚Intuitively, a watermark â€œflushesâ€ out any windows that would be considered late in downstream operations once they receive that watermark. è¿ç»­çš„çª—å£ç®—å­è®¾ç½®çª—å£æ—¶äº§ç”Ÿçš„çŠ¶æ€å¤§å°çš„æ³¨æ„äº‹é¡¹çª—å£å¤§å°å¯ä»¥å®šä¹‰çš„å¾ˆå¤§ï¼ˆå¦‚å¤©ã€å‘¨æˆ–æœˆï¼‰ï¼Œå› æ­¤å¯èƒ½ä¼šç´¯ç§¯éå¸¸å¤§çš„çŠ¶æ€ï¼ˆstateï¼‰ã€‚æ‰€ä»¥åœ¨ä¼°è®¡çª—å£è®¡ç®—çš„å­˜å‚¨éœ€æ±‚æ—¶ï¼Œéœ€è¦è®°ä½ä»¥ä¸‹å‡ ä¸ªè§„åˆ™ï¼š 1.Flink ä¼šä¸ºæ¯ä¸ªå…ƒç´ æ‰€å±çš„çª—å£åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ã€‚å› æ­¤ï¼Œæ»šåŠ¨çš„çª—å£ä¿ç•™æ¯ä¸ªå…ƒç´ çš„ä¸€ä¸ªå‰¯æœ¬ï¼ˆä¸€ä¸ªå…ƒç´ åªå±äºä¸€ä¸ªçª—å£ï¼‰ã€‚ç›¸åï¼Œæ»‘åŠ¨çª—å£å¯èƒ½ä¼šåˆ›å»ºæ¯ä¸ªå…ƒç´ ä¸­çš„å‡ ä¸ªå‰¯æœ¬ã€‚å› æ­¤ï¼Œ1å¤©å¤§å°çš„çª—å£ï¼Œ1ç§’æ»‘åŠ¨æ­¥é•¿çš„æ»‘åŠ¨çª—å£å¯èƒ½ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚ 2.ReduceFunctionã€AggregateFunction å’Œ FoldFunction å¯ä»¥æ˜¾è‘—å‡å°‘å­˜å‚¨éœ€æ±‚ï¼Œå› ä¸ºå®ƒä»¬åœ¨å…ƒç´ åˆ°è¾¾æ—¶å°±èšåˆå…ƒç´ ï¼Œå¹¶ä¸”æ¯ä¸ªçª—å£åªå­˜å‚¨ä¸€ä¸ªå€¼ã€‚ç›¸åï¼Œä»…ä»…ä½¿ç”¨ ProcessWindowFunction å°±éœ€è¦ç´¯ç§¯æ‰€æœ‰å…ƒç´ ã€‚ 3.ä½¿ç”¨ Evictor å¯é˜²æ­¢ä»»ä½•é¢„èšåˆï¼Œå› ä¸ºåœ¨åº”ç”¨è®¡ç®—ä¹‹å‰ï¼Œçª—å£çš„æ‰€æœ‰å…ƒç´ éƒ½å¿…é¡»é€šè¿‡ Evictor ä¼ é€’ã€‚","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ Operatorsï¼ˆç®—å­ï¼‰â€”â€”æ¦‚è§ˆ","date":"2019-11-09T08:22:30.000Z","path":"2019/11/09/apache-flink:study-flink-datastream-operators-overview/","text":"æè¿°äº†åŸºæœ¬ Operators çš„ Transformationsï¼Œåº”ç”¨è¿™äº›è½¬æ¢åå¦‚ä½•è¿›è¡Œ physical partitioningï¼ˆç‰©ç†åˆ†åŒºï¼‰ï¼Œä»¥åŠå¯¹Flinkç®—å­é“¾çš„æ·±å…¥äº†è§£ã€‚ DataStream TransformationsPhysical partitioning Transformation Description Custom partitioning DataStream â†’ DataStream CustomPartitionerWrapper ä½¿ç”¨è‡ªå®šä¹‰çš„ partitioner ä¸ºæ¯ä¸€æ¡ record é€‰æ‹©ä¸‹ä¸€ä¸ª task dataStream.partitionCustom(partitioner, \"someKey\"); dataStream.partitionCustom(partitioner, 0); Random partitioning DataStream â†’ DataStream ShufflePartitioner æŒ‰éšæœºå‡åŒ€åˆ’åˆ†å…ƒç´  dataStream.shuffle(); Rebalancing (Round-robin partitioning) DataStream â†’ DataStream RebalancePartitioner åˆ†åŒºå¾ªç¯åˆ’åˆ†å…ƒç´ ï¼Œä¸ºæ¯ä¸ªä¸‹æ¸¸åˆ›å»ºç›¸ç­‰çš„è´Ÿè½½ã€‚å¯¹äºå­˜åœ¨æ•°æ®å€¾æ–œçš„æ€§èƒ½ä¼˜åŒ–éå¸¸æœ‰ç”¨ã€‚ dataStream.rebalance(); Rescaling DataStream â†’ DataStream RescalePartitioner å°†å…ƒç´ å¾ªç¯ï¼ˆround robinï¼‰åˆ†é…åˆ°ä¸‹æ¸¸ operator çš„å­é›†ã€‚å¦‚æœä½ çš„ pipeline æ˜¯ä¸€ä¸‹çš„æƒ…å†µï¼Œé‚£ä¹ˆè¿™ç§æ–¹å¼ä¼šéå¸¸æœ‰ç”¨ã€‚ ä¾‹å¦‚ï¼Œå°†å¹¶è¡Œæ•°æ®æºçš„æ¯ä¸ªå®ä¾‹çš„æ•°æ®ä¼ è¾“åˆ°çš„ä¸‹æ¸¸å¤šä¸ªç®—å­ï¼ˆoperatorsï¼‰ä¸€ä¸ªå­é›†ä»¥åˆ†é…è´Ÿè½½ã€‚ä½†ä¸å¸Œæœ› full rebalanceï¼Œåˆ™è¿™éå¸¸æœ‰ç”¨ã€‚ å¦‚æœåˆç†é…ç½® TaskManager çš„ slotæ•°é‡ï¼Œåˆ™æ•°æ®ä¼ è¾“åªéœ€è¦æœ¬åœ°ä¼ è¾“ï¼Œè€Œä¸éœ€è¦é€šè¿‡ç½‘ç»œä¼ è¾“æ•°æ®ã€‚ ä¸Šæ¸¸ operators å‘çš„ä¸‹æ¸¸ operators å‘é€ record å–å†³äºä¸Šæ¸¸ operators å’Œä¸‹æ¸¸ operators çš„å¹¶è¡Œåº¦ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä¸Šæ¸¸ operator çš„å¹¶è¡Œåº¦ä¸º2ï¼Œè€Œä¸‹æ¸¸ operator çš„å¹¶è¡Œåº¦ä¸º6ï¼Œåˆ™ä¸€ä¸ªä¸Šæ¸¸ operator å°† record åˆ†é…ç»™ä¸‰ä¸ªä¸‹æ¸¸ operatorï¼Œè€Œå¦ä¸€ä¸ªä¸Šæ¸¸ operator å°† record åˆ†é…ç»™å…¶ä»–ä¸‰ä¸ªä¸‹æ¸¸ operatorã€‚ç›¸åï¼Œå¦‚æœä¸‹æ¸¸ operator çš„å¹¶è¡Œåº¦ä¸º2ï¼Œè€Œä¸Šæ¸¸ operator çš„å¹¶è¡Œåº¦ä¸º6ï¼Œåˆ™ä¸‰ä¸ªä¸Šæ¸¸ operator å°†åˆ†é…ç»™ä¸€ä¸ªä¸‹æ¸¸ operatorï¼Œè€Œå…¶ä»–ä¸‰ä¸ªä¸Šæ¸¸ operator å°†åˆ†é…ç»™å¦ä¸€ä¸ªä¸‹æ¸¸ operatorã€‚ å¦‚æœä¸Šä¸‹æ¸¸ç®—å­çš„å¹¶è¡Œåº¦ä¸æ˜¯å½¼æ­¤çš„å€æ•°ï¼Œåˆ™ä¸€ä¸ªæˆ–å¤šä¸ªä¸‹æ¸¸ operator å°†å…·æœ‰æ¥è‡ªä¸Šæ¸¸ operator çš„ä¸åŒæ•°é‡çš„è¾“å…¥ã€‚ å¦‚ä¸‹å›¾ï¼š dataStream.rescale(); Broadcasting DataStream â†’ DataStream BroadcastPartitioner å¹¿æ’­æ•°æ®åˆ°ä¸‹æ¸¸çš„æ¯ä¸ªpartitionã€‚ dataStream.broadcast(); Local Forward DataStream â†’ DataStream ForwardPartitioner æ•°æ®ä¼ è¾“åˆ°æœ¬åœ°çš„ä¸‹æ¸¸ç®—å­ã€‚ dataStream.forward(); GlobalPartitioner DataStream â†’ DataStream GlobalPartitioner æ•°æ®ä¼ è¾“åˆ°ä¸‹æ¸¸å­ä»»åŠ¡idä¸º0çš„taskä¸­ã€‚ dataStream.forward(); Key Groups DataStream â†’ DataStream KeyGroupStreamPartitioner ç›¸åŒkeyçš„å€¼ä¼šä¼ è¾“åˆ°åŒä¸€ä¸ªä¸‹æ¸¸ã€‚ç±»ä¼¼äºRescalingï¼Œä½†æ˜¯ä¸ç”¨å†apiä¸­æŒ‡å®šï¼Œå†ä½¿ç”¨keyByæ—¶ä¼šè‡ªåŠ¨æŒ‡å®šæ­¤æ–¹æ³•ã€‚ dataStream.keyBy(); Task chaining å’Œ èµ„æºç»„é“¾æ¥ä¸¤ä¸ª Transformations æ„å‘³ç€å¯ä»¥å°†å®ƒä»¬å…±åŒæ”¾åœ¨åœ¨åŒä¸€ä¸ªçº¿ç¨‹ä¸­æ‰§è¡Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒFlinkä¼šå°½å¯èƒ½é“¾æ¥ä¸¤ä¸ªç®—å­ï¼ˆä¾‹å¦‚ï¼Œä¸¤ä¸ª Map Transformationsï¼‰ã€‚å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä½¿ç”¨APIå¯¹ Task chaining è¿›è¡Œç»†ç²’åº¦æ§åˆ¶ï¼š åœ¨ Flink ä¸­ï¼Œä¸€ä¸ª slot å°±æ˜¯ä¸€ä¸ªèµ„æºç»„ã€‚å¦‚æœéœ€è¦çš„è¯ï¼Œä½ å¯ä»¥é€šè¿‡ä½¿ç”¨apiæŠŠä¸Šä¸‹æ¸¸ç®—å­éš”ç¦»åœ¨ä¸åŒçš„ slot ä¸­è¿è¡Œã€‚","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ EventTime","date":"2019-11-09T04:09:56.000Z","path":"2019/11/09/apache-flink:study-flink-datastream-eventtime/","text":"Apache Flink å­¦ä¹ ï¼šDataStream Api ä¸­ EventTime æ—¶é—´ Processing timeå¤„ç†æ—¶é—´æ˜¯æŒ‡æ‰§è¡Œç›¸åº”æ“ä½œçš„æœºå™¨çš„ç³»ç»Ÿæ—¶é—´ Event timeäº‹ä»¶æ—¶é—´æ˜¯æ¯ä¸ªäº‹ä»¶åœ¨å…¶ç”Ÿäº§è®¾å¤‡ï¼ˆç”Ÿäº§eventçš„è®¾å¤‡ï¼Œæ‰‹æœºç­‰çš„æºå¤´è®¾å¤‡ï¼‰ä¸Šå‘ç”Ÿçš„æ—¶é—´ Event Time å’Œ WatermarkFlinkä¸­æµ‹é‡äº‹ä»¶æ—¶é—´è¿›åº¦çš„æœºåˆ¶æ˜¯Watermarkã€‚Watermarkä½œä¸ºæ•°æ®æµçš„ä¸€éƒ¨åˆ†æµåŠ¨ï¼Œå¹¶å¸¦æœ‰æ—¶é—´æˆ³tã€‚Watermarkï¼ˆtï¼‰å£°æ˜è¯¥æµä¸­çš„ Event Time å·²è¾¾åˆ°æ—¶é—´tï¼Œè¿™æ„å‘³ç€æµä¸­ä¸åº”å†æœ‰æ—¶é—´æˆ³tâ€™&lt;=tçš„å…ƒç´ ï¼ˆå³ Event Time æ—©äºæˆ–ç­‰äº Watermark çš„äº‹ä»¶ï¼‰ ä¸‹å›¾æ˜¾ç¤ºäº†å…·æœ‰æ—¶é—´æˆ³çš„äº‹ä»¶æµï¼Œä»¥åŠå†…è”æµåŠ¨çš„æ°´å°ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œäº‹ä»¶æ˜¯æœ‰åºçš„ï¼Œè¿™æ„å‘³ç€ Watermark åªæ˜¯æµä¸­çš„å‘¨æœŸæ€§æ ‡è®°ã€‚ é¡ºåºæµçš„Watermark Watermarkå¯¹äºæ— åºæµæ˜¯è‡³å…³é‡è¦çš„ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­äº‹ä»¶åˆ°è¾¾é¡ºåºä¸æ˜¯æŒ‰æ—¶é—´æˆ³é¡ºåºã€‚Watermarkä»£è¡¨é€šè¿‡æµä¸­çš„è¯¥ç‚¹ï¼Œè¿™ä¸ªæ—¶é—´æˆ³ä¹‹å‰çš„äº‹ä»¶éƒ½åº”è¯¥åˆ°è¾¾äº†ã€‚ä¸€æ—¦Watermarkåˆ°è¾¾ç®—å­ï¼Œç®—å­å°±å¯ä»¥å°†å…¶å†…éƒ¨äº‹ä»¶æ—¶é’Ÿæ›´æ–°åˆ°Watermarkçš„å€¼ã€‚ æ— åºæµçš„Watermark å¹¶è¡Œæµçš„ WatermarksWatermark åœ¨æºæ•°æ® Function å¤„ç”Ÿæˆï¼Œæˆ–ç›´æ¥åœ¨æºæ•°æ® Function ä¹‹åç”Ÿæˆã€‚æºæ•°æ® Function çš„æ¯ä¸ªå¹¶è¡Œå­ä»»åŠ¡é€šå¸¸ç‹¬ç«‹ç”Ÿæˆå…¶ Watermarkã€‚è¿™äº› Watermark å®šä¹‰å¹¶è¡Œæºæ•°æ®çš„ Event Timeã€‚ å½“ Watermark æµè¿‡ç¨‹åºæ—¶ï¼Œä¼šæ›´æ–°åˆ°è¾¾ç®—å­çš„ Event Timeï¼Œå½“ä¸€ä¸ª Watermark æ›´æ–°äº†ç®—å­çš„ Event Time æ—¶ï¼Œå®ƒä¼šä¸ºå…¶ä¸‹æ¸¸çš„åç»­ç®—å­ç”Ÿæˆä¸€ä¸ªæ–°çš„ Watermarkã€‚ æŸäº›ç®—å­æ¶ˆè´¹å¤šä¸ªè¾“å…¥æµï¼Œä¾‹å¦‚ï¼šunion ç®—å­æˆ–è€…è·Ÿåœ¨ keyByï¼Œpartition ç®—å­çš„ä¹‹åçš„ç®—å­ã€‚è¿™æ ·çš„ç®—å­çš„ Event Time æ˜¯æ‰€æœ‰è¾“å…¥ stream ä¸­æœ€å°çš„ Watermarkï¼Œå³ï¼šOperator Event Time = min(Input Stream 1 Watermark, Input Stream 2 Watermarkâ€¦)ç®—å­ä¼šè·Ÿç€è¾“å…¥æµ Watermark çš„æ›´æ–°æ¥æ›´æ–°ç®—å­è‡ªå·±çš„ Event Timeã€‚ ä¸‹å›¾æ˜¾ç¤ºäº†æµç»å¹¶è¡Œæµçš„äº‹ä»¶å’Œ Watermark ä»¥åŠç®—å­è·å– Event Time çš„ç¤ºä¾‹ã€‚ å¹¶è¡Œæµçš„Watermarks æ³¨æ„ï¼ŒKafkaæ”¯æŒåˆ†åŒº Watermark Ingestion timeæ³¨å…¥æ—¶é—´æ˜¯äº‹ä»¶è¿›å…¥Flink Jobçš„æ—¶é—´ã€‚åœ¨æºOperatorå¤„ï¼Œæ¯æ¡Operatorè·å–æºæ•°æ®çš„æ—¶é—´ä½œä¸ºIngestion timeæ—¶é—´æˆ³ ç”Ÿæˆ Timestamps å’Œ Watermarksåˆ†é… Timestampsæ•°æ®æµæºç”Ÿæˆ Timestamps å’Œ Watermarksæ•°æ®æºå¯ä»¥ç›´æ¥ä¸ºå®ƒä»¬äº§ç”Ÿçš„æ•°æ®åˆ†é… Timestampï¼Œå¹¶ä¸”ä»–ä»¬ä¹Ÿèƒ½å‘é€ Watermarkã€‚è¿™æ ·åšçš„è¯ï¼Œåœ¨åé¢çš„å¤„ç†ä¸­å°±æ²¡å¿…è¦å†å»å®šä¹‰ Timestamp åˆ†é…å™¨äº†ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼šå¦‚æœåœ¨åé¢çš„å¤„ç†ä¸­ä½¿ç”¨äº†ä¸€ä¸ª timestamp åˆ†é…å™¨ï¼Œç”±æ•°æ®æºæä¾›çš„ä»»ä½• timestamp å’Œ watermark éƒ½ä¼šè¢«é‡å†™ã€‚ Timestamp åˆ†é…å™¨ / Watermarkç”Ÿæˆå™¨Timestamp åˆ†é…å™¨è·å–ä¸€ä¸ªæµå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„å¸¦æœ‰ Timestamp å…ƒç´ å’Œ Watermark çš„æµã€‚å¦‚æœä¸Šæ¸¸çš„åŸå§‹æ•°æ®æµå·²ç»æœ‰ Timestamp æˆ– Watermarkï¼Œåˆ™ Timestamp åˆ†é…å™¨å°†è¦†ç›–ä¸Šæ¸¸çš„ Timestamp æˆ– Watermark Timestamp åˆ†é…å™¨é€šå¸¸åœ¨æ•°æ®æºä¹‹åç«‹å³æŒ‡å®šï¼Œä½†è¿™å¹¶ä¸æ˜¯ä¸¥æ ¼è¦æ±‚çš„ã€‚é€šå¸¸æ˜¯åœ¨ Timestamp åˆ†é…å™¨ä¹‹å‰å…ˆè§£æï¼ˆMapFunctionï¼‰å’Œè¿‡æ»¤ï¼ˆFilterFunctionï¼‰æ•°æ®æºã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œéƒ½éœ€è¦åœ¨åŸºäº Event Time ç®—å­ï¼ˆä¾‹å¦‚ window æ“ä½œï¼‰è¿è¡Œä¹‹å‰æŒ‡å®š Timestamp åˆ†é…ç¨‹åºã€‚æœ‰ä¸€ä¸ªç‰¹æ®Šæƒ…å†µï¼Œå½“ä½¿ç”¨ Kafka ä½œä¸ºæµä½œä¸šçš„æ•°æ®æºæ—¶ï¼ŒFlink å…è®¸åœ¨æ•°æ®æºå†…éƒ¨æŒ‡å®š Timestamp åˆ†é…å™¨å’Œ Watermark ç”Ÿæˆå™¨ã€‚æ›´å¤šå…³äºå¦‚ä½•è¿›è¡Œçš„ä¿¡æ¯è¯·å‚è€ƒKafka Connectorçš„æ–‡æ¡£ã€‚ ç›´æ¥åœ¨FlinkKafkaConsumer010ä¸Šé¢ä½¿ç”¨assignTimestampsAndWatermarkså¯ä»¥æ ¹æ®kafka sourceçš„partitionsçš„ç‰¹æ€§è¿›è¡Œè®¾ç½®Timestampså’ŒWatermarksï¼Œè®©ç”¨æˆ·åšä¸€äº›ç‰¹æ®Šçš„å¤„ç† Running timestamp extractors / watermark generators directly inside the Kafka source, per Kafkapartition, allows users to let them exploit the per-partition characteristics. Kafka åˆ†åŒºçš„ Timestampå½“ä½¿ç”¨ Apache Kafka ä½œä¸ºæ•°æ®æºæ—¶ï¼Œæ¯ä¸ª Kafka åˆ†åŒºå¯èƒ½æœ‰ä¸€ä¸ªç®€å•çš„ Event Time æ¨¡å¼ï¼ˆé€’å¢çš„æ—¶é—´æˆ³æˆ–æœ‰ç•Œæ— åºï¼‰ã€‚ç„¶è€Œï¼Œå½“ Flink Job ä½¿ç”¨æ¥è‡ªKafkaçš„æµæ—¶ï¼Œå¤šä¸ªåˆ†åŒºå¸¸å¸¸å¹¶è¡Œæ¶ˆè´¹ï¼Œæ¯ä¸€ä¸ª operator ç®—å­å¹¶è¡Œæ¶ˆè´¹æ—¶å°±ä¼šç ´åå„ä¸ªåˆ†åŒºçš„æ—¶é—´æ¨¡å¼ï¼ˆè¿™æ˜¯ Kafka å®¢æˆ·ç«¯æ¶ˆè´¹ Kafka æ•°æ®å¿…ç„¶å‘ç”Ÿçš„ï¼‰ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ Flinkâ€™s Kafka-partition-aware watermark generationï¼Œä½¿ç”¨è¯¥åŠŸèƒ½ï¼Œæ¯ä¸ª Kafka åˆ†åŒºåœ¨ Kafka consumer å†…éƒ¨ç”Ÿæˆ Watermarkï¼Œæ¯ä¸ªåˆ†åŒºåˆå¹¶ Watermark çš„æ–¹å¼ä¸æµ shuffles æ—¶åˆå¹¶ Watermark çš„æ–¹å¼ç›¸åŒã€‚ ä¾‹å¦‚ï¼Œå¦‚æœäº‹ä»¶æ—¶é—´æˆ³ä¸¥æ ¼æŒ‰ç…§ Kafka åˆ†åŒºé€’å¢ï¼Œåˆ™ä½¿ç”¨é€’å¢æ—¶é—´æˆ³ Watermark ç”Ÿæˆå™¨ç”Ÿæˆæ¯ä¸ªåˆ†åŒºçš„ Watermark å°†æ˜¯å®Œç¾çš„å…¨å±€ Watermarkã€‚ ä¸‹å›¾æ˜¾ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Flinkâ€™s Kafka-partition-aware watermark generationï¼Œä»¥åŠåœ¨è¿™ç§æƒ…å†µä¸‹ Watermark å¦‚ä½•é€šè¿‡æµæ•°æ®æµä¼ æ’­ã€‚ KafkaSourceå¤šåˆ†åŒºWatermark","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šslotå’Œparallelismè®¾ç½®çš„å…³ç³»","date":"2019-11-08T07:31:08.000Z","path":"2019/11/08/apache-flink:study-flink-slot-parallelism/","text":"Apache Flink å­¦ä¹ ï¼šslotå’Œparallelismè®¾ç½®çš„å…³ç³» å¦‚ä½•è®¾ç½® parallelismflink-conf.yaml1234cat flink-conf.yaml | grep parallelism# The parallelism used for programs that did not specify and other parallelism.parallelism.default: 1 å‘½ä»¤è¡Œå¯åŠ¨å¦‚æœä½ æ˜¯ç”¨å‘½ä»¤è¡Œå¯åŠ¨ä½ çš„ Flink jobï¼Œé‚£ä¹ˆä½ ä¹Ÿå¯ä»¥è¿™æ ·è®¾ç½®å¹¶è¡Œåº¦(ä½¿ç”¨ -p å¹¶è¡Œåº¦)ï¼š 1./bin/flink run -p 10 ../word-count.jar ä»£ç è®¾ç½®æ•´ä¸ªç¨‹åºçš„å¹¶è¡Œåº¦12StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();env.setParallelism(10); æ³¨æ„ï¼šè¿™æ ·è®¾ç½®çš„å¹¶è¡Œåº¦æ˜¯ä½ æ•´ä¸ªç¨‹åºçš„å¹¶è¡Œåº¦ï¼Œé‚£ä¹ˆåé¢å¦‚æœä½ çš„æ¯ä¸ªç®—å­ä¸å•ç‹¬è®¾ç½®å¹¶è¡Œåº¦è¦†ç›–çš„è¯ï¼Œé‚£ä¹ˆåé¢æ¯ä¸ªç®—å­çš„å¹¶è¡Œåº¦å°±éƒ½æ˜¯è¿™é‡Œè®¾ç½®çš„å¹¶è¡Œåº¦çš„å€¼äº†ã€‚ æ¯ä¸ªç®—å­å•ç‹¬è®¾ç½®å¹¶è¡Œåº¦1234data.keyBy(new xxxKey()) .flatMap(new XxxFlatMapFunction()).setParallelism(5) .map(new XxxMapFunction).setParallelism(5) .addSink(new XxxSink()).setParallelism(1) å¦‚ä¸Šï¼Œå°±æ˜¯åœ¨æ¯ä¸ªç®—å­åé¢å•ç‹¬çš„è®¾ç½®å¹¶è¡Œåº¦ï¼Œè¿™æ ·çš„è¯ï¼Œå°±ç®—ä½ å‰é¢è®¾ç½®äº† env.setParallelism(10) ä¹Ÿæ˜¯ä¼šè¢«è¦†ç›–çš„ã€‚ è¿™ä¹Ÿè¯´æ˜ä¼˜å…ˆçº§æ˜¯ï¼šç®—å­è®¾ç½®å¹¶è¡Œåº¦ &gt; env è®¾ç½®å¹¶è¡Œåº¦ &gt; é…ç½®æ–‡ä»¶é»˜è®¤å¹¶è¡Œåº¦ slot FlinkJobè¿è¡Œæ¶æ„ å›¾ä¸­ Task Manager æ˜¯ä» Job Manager å¤„æ¥æ”¶éœ€è¦éƒ¨ç½²çš„ Taskï¼Œä»»åŠ¡çš„å¹¶è¡Œæ€§ç”±æ¯ä¸ª Task Manager ä¸Šå¯ç”¨çš„ slot å†³å®šã€‚æ¯ä¸ªä»»åŠ¡ä»£è¡¨åˆ†é…ç»™ä»»åŠ¡æ§½çš„ä¸€ç»„èµ„æºï¼Œslot åœ¨ Flink é‡Œé¢å¯ä»¥è®¤ä¸ºæ˜¯èµ„æºç»„ï¼ŒFlink å°†æ¯ä¸ªä»»åŠ¡åˆ†æˆå­ä»»åŠ¡å¹¶ä¸”å°†è¿™äº›å­ä»»åŠ¡åˆ†é…åˆ° slot æ¥å¹¶è¡Œæ‰§è¡Œç¨‹åºã€‚ ä¾‹å¦‚ï¼Œå¦‚æœ Task Manager æœ‰å››ä¸ª slotï¼Œé‚£ä¹ˆå®ƒå°†ä¸ºæ¯ä¸ª slot åˆ†é… 25ï¼… çš„å†…å­˜ã€‚ å¯ä»¥åœ¨ä¸€ä¸ª slot ä¸­è¿è¡Œä¸€ä¸ªæˆ–å¤šä¸ªçº¿ç¨‹ã€‚ åŒä¸€ slot ä¸­çš„çº¿ç¨‹å…±äº«ç›¸åŒçš„ JVMã€‚ åŒä¸€ JVM ä¸­çš„ä»»åŠ¡å…±äº« TCP è¿æ¥å’Œå¿ƒè·³æ¶ˆæ¯ã€‚Task Manager çš„ä¸€ä¸ª Slot ä»£è¡¨ä¸€ä¸ªå¯ç”¨çº¿ç¨‹ï¼Œè¯¥çº¿ç¨‹å…·æœ‰å›ºå®šçš„å†…å­˜ï¼Œæ³¨æ„ Slot åªå¯¹å†…å­˜éš”ç¦»ï¼Œæ²¡æœ‰å¯¹ CPU éš”ç¦»ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒFlink å…è®¸å­ä»»åŠ¡å…±äº« Slotï¼Œå³ä½¿å®ƒä»¬æ˜¯ä¸åŒ task çš„ subtaskï¼Œåªè¦å®ƒä»¬æ¥è‡ªç›¸åŒçš„ jobã€‚è¿™ç§å…±äº«å¯ä»¥æœ‰æ›´å¥½çš„èµ„æºåˆ©ç”¨ç‡ã€‚ TaskSlotsæ‰§è¡Œ é»˜è®¤æƒ…å†µä¸‹ï¼ŒFlink å…è®¸ subtasks å…±äº« slotsï¼Œå³ä½¿å®ƒä»¬æ˜¯ä¸åŒ tasks çš„ subtasksï¼Œåªè¦å®ƒä»¬æ¥è‡ªåŒä¸€ä¸ª jobã€‚å› æ­¤ï¼Œä¸€ä¸ª slot å¯èƒ½ä¼šè´Ÿè´£è¿™ä¸ª job çš„æ•´ä¸ªç®¡é“ï¼ˆpipelineï¼‰ã€‚å…è®¸ slot sharing æœ‰ä¸¤ä¸ªå¥½å¤„ï¼š 1.Flink é›†ç¾¤éœ€è¦ä¸ job ä¸­ä½¿ç”¨çš„æœ€é«˜å¹¶è¡Œåº¦ä¸€æ ·å¤šçš„ slotsã€‚è¿™æ ·ä¸éœ€è¦è®¡ç®—ä½œä¸šæ€»å…±åŒ…å«å¤šå°‘ä¸ª tasksï¼ˆå…·æœ‰ä¸åŒå¹¶è¡Œåº¦ï¼‰ã€‚ 2.æ›´å¥½çš„èµ„æºåˆ©ç”¨ç‡ã€‚åœ¨æ²¡æœ‰ slot sharing çš„æƒ…å†µä¸‹ï¼Œç®€å•çš„ subtasksï¼ˆsource/map()ï¼‰å°†ä¼šå ç”¨å’Œå¤æ‚çš„ subtasks ï¼ˆwindowï¼‰ä¸€æ ·å¤šçš„èµ„æºã€‚é€šè¿‡ slot sharingï¼Œå°†ç¤ºä¾‹ä¸­çš„å¹¶è¡Œåº¦ä» 2 å¢åŠ åˆ° 6 å¯ä»¥å……åˆ†åˆ©ç”¨ slot çš„èµ„æºï¼ŒåŒæ—¶ç¡®ä¿ç¹é‡çš„ subtask åœ¨ TaskManagers ä¹‹é—´å…¬å¹³åœ°è·å–èµ„æºã€‚ ä¸‹å›¾å³ä¸ºFlink subtasks å…±äº« slotsçš„æ¨¡å¼ï¼š TaskSlotsSharingæ‰§è¡Œ ä¸Šé¢å›¾ç‰‡ä¸­æœ‰ä¸¤ä¸ª Task Managerï¼Œæ¯ä¸ª Task Manager æœ‰ä¸‰ä¸ª slotï¼Œè¿™æ ·æˆ‘ä»¬çš„ç®—å­æœ€å¤§å¹¶è¡Œåº¦é‚£ä¹ˆå°±å¯ä»¥è¾¾åˆ° 6 ä¸ªï¼Œåœ¨åŒä¸€ä¸ª slot é‡Œé¢å¯ä»¥æ‰§è¡Œ 1 è‡³å¤šä¸ªå­ä»»åŠ¡ã€‚ é‚£ä¹ˆå†çœ‹ä¸Šé¢çš„å›¾ç‰‡ï¼Œsource/map/keyby/window/apply æœ€å¤§å¯ä»¥æœ‰ 6 ä¸ªå¹¶è¡Œåº¦ï¼Œsink åªç”¨äº† 1 ä¸ªå¹¶è¡Œã€‚ æ¯ä¸ª Flink TaskManager åœ¨é›†ç¾¤ä¸­æä¾› slotã€‚ slot çš„æ•°é‡é€šå¸¸ä¸æ¯ä¸ª TaskManager çš„å¯ç”¨ CPU å†…æ ¸æ•°æˆæ¯”ä¾‹ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ä½ çš„ slot æ•°æ˜¯ä½ æ¯ä¸ª TaskManager çš„ cpu çš„æ ¸æ•°","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šFlink Job ExecutionGraphç”Ÿæˆè¿‡ç¨‹","date":"2019-11-08T01:49:18.000Z","path":"2019/11/08/apache-flink:study-flink-job-ExecutionGraph/","text":"Apache Flink å­¦ä¹ ï¼šFlink Job æ‰§è¡Œè®¡åˆ’ç”Ÿæˆè¿‡ç¨‹ Transformations TransformationClasses å¹¶ä¸æ˜¯æ¯ä¸€ä¸ª Transformation éƒ½ä¼šè½¬æ¢æˆruntimeå±‚ä¸­çš„ç‰©ç†æ“ä½œã€‚æœ‰ä¸€äº›åªæ˜¯é€»è¾‘æ¦‚å¿µï¼Œæ¯”å¦‚unionã€split/selectã€partitionç­‰ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºçš„è½¬æ¢æ ‘ï¼Œåœ¨è¿è¡Œæ—¶ä¼šä¼˜åŒ–æˆä¸‹æ–¹çš„æ“ä½œå›¾ã€‚ Transformations æ‰§è¡Œè®¡åˆ’è½¬æ¢è¿‡ç¨‹ 4å±‚è½¬æ¢ 1.è½¬æ¢è¿‡ç¨‹ StreamExecutionEnvironment å­˜æ”¾çš„ transformation -&gt; StreamGraph -&gt; JobGraph -&gt; ExecutionGraph -&gt; ç‰©ç†æ‰§è¡Œå›¾2.StreamExecutionEnvironment å­˜æ”¾çš„ transformation -&gt; StreamGraph -&gt; JobGraph åœ¨å®¢æˆ·ç«¯å®Œæˆï¼Œç„¶åæäº¤ JobGraph åˆ° JobManager3.JobManager çš„ä¸»èŠ‚ç‚¹ JobMasterï¼Œå°† JobGraph è½¬åŒ–ä¸º ExecutionGraphï¼Œç„¶åå‘é€åˆ°ä¸åŒçš„ taskManagerï¼Œå¾—åˆ°å®é™…çš„ç‰©ç†æ‰§è¡Œå›¾ LocalStreamEnvironment ä¸­ parallelismå…¶ä¸­ LocalStreamEnvironment Task ä¸­çš„ parallelism æ•°é‡æ˜¯æ ¹æ®ä»¥ä¸‹ä»£ç ç”Ÿæˆçš„ 12345678910111213141516171819202122232425262728293031323334@Publicpublic abstract class StreamExecutionEnvironment &#123; ... private static int defaultLocalParallelism = Runtime.getRuntime().availableProcessors(); /** * Creates a &#123;@link LocalStreamEnvironment&#125;. The local execution environment * will run the program in a multi-threaded fashion in the same JVM as the * environment was created in. The default parallelism of the local * environment is the number of hardware contexts (CPU cores / threads), * unless it was specified differently by &#123;@link #setParallelism(int)&#125;. * * @return A local execution environment. */ public static LocalStreamEnvironment createLocalEnvironment() &#123; return createLocalEnvironment(defaultLocalParallelism); &#125; /** * Creates a &#123;@link LocalStreamEnvironment&#125;. The local execution environment * will run the program in a multi-threaded fashion in the same JVM as the * environment was created in. It will use the parallelism specified in the * parameter. * * @param parallelism * The parallelism for the local environment. * @return A local execution environment with the specified parallelism. */ public static LocalStreamEnvironment createLocalEnvironment(int parallelism) &#123; return createLocalEnvironment(parallelism, new Configuration()); &#125; ...&#125;","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šå¼‚æ­¥IOä¹‹RichAsyncFunction","date":"2019-11-06T10:45:59.000Z","path":"2019/11/06/apache-flink:study-async-io-RichAsyncFunction/","text":"Apache Flink å­¦ä¹ ï¼šå¼‚æ­¥IOä¹‹RichAsyncFunction é—®é¢˜è®¾ç½®kafka consumerå¹¶è¡Œåº¦çš„è¯­ä¹‰1.å¦‚æœè®¾ç½®kafka consumerçš„å¹¶å‘åº¦ä¸º100ï¼Œå¹¶ä¸”ç”³è¯·åˆ°é›†ç¾¤ä¸­èµ„æºçš„Task Managerçš„slotä¸ªæ•°ä¹Ÿä¸º100ä¸ªï¼Œåˆ™æ¯ä¸ªslotä¸­è¿è¡Œçš„ä»»åŠ¡éƒ½ç”Ÿæˆè¿™ä¹ˆå¤šæ•°é‡çš„kafka consumerï¼Œè¿˜æ˜¯æ¯ä¸ªslotä¸€ä¸ªkafka consumer? 2.åœºæ™¯ï¼šä¸€ä¸ªkeyByè¿‡åè®¾ç½®äº†ä¸€åˆ†é’Ÿçš„çª—å£dataStreamä¸­ï¼Œå¦‚æœä¿è¯æ¯æ¬¡è§¦å‘è¿™ä¸ªçª—å£æ—¶ï¼Œçª—å£çš„æ•°æ®æ°¸è¿œåªæœ‰ä¸€æ¡çš„è¯ï¼Œå¹¶ä¸”åœ¨ä¿è¯çª—å£ä¸º1åˆ†é’Ÿå¤§å°çš„æƒ…å†µä¸‹ï¼Œæ¥å£è¿”å›é€Ÿåº¦ä¿è¯åœ¨10ç§’ï¼Œä½¿ç”¨Async IOæ˜¯å¦å°±æ²¡æœ‰æ„ä¹‰äº†ï¼Œå› ä¸ºå½“å‰è¯·æ±‚é˜Ÿåˆ—é‡Œé¢åªæœ‰ä¸€æ¡æ•°æ® 3.flink é»˜è®¤æ‰§è¡Œä¸€ä¸ªJobçš„slotä¸­çº¿ç¨‹æ•°ä¸ºä»€ä¹ˆæ˜¯8ï¼Œåœ¨å“ªé‡Œè®¾ç½®çš„ ä½¿ç”¨AsyncIOéœ€è¦è€ƒè™‘çš„æŒ‡æ ‡1.æ¯ä¸ªslotä¸­Flink Jobçš„çº¿ç¨‹æ•°2.å¦‚æœéœ€è¦ä½¿ç”¨æ—¶é—´çª—å£ï¼šæ—¶é—´çª—å£çš„å¤§å°ï¼Œå‡ åˆ†é’Ÿçš„çª—å£2.å¦‚æœéœ€è¦keyByï¼šæ¯ä¸ªslotä¸­Flink Jobçš„å¤§æ¦‚keyçš„ä¸ªæ•°ï¼ˆä»€ä¹ˆæƒ…å†µä½¿ç”¨ï¼Œä»€ä¹ˆæƒ…å†µä¸ä½¿ç”¨ï¼‰ ç®€ä»‹æˆ‘ä»¬çŸ¥é“flinkå¯¹äºå¤–éƒ¨æ•°æ®æºçš„æ“ä½œå¯ä»¥é€šè¿‡è‡ªå¸¦çš„è¿æ¥å™¨ï¼Œæˆ–è€…è‡ªå®šä¹‰sinkå’Œsourceå®ç°æ•°æ®çš„äº¤äº’ï¼Œé‚£ä¹ˆä¸ºå•¥è¿˜éœ€è¦å¼‚æ­¥IOå‘¢ï¼Ÿé‚£æ—¶å› ä¸ºå¯¹äºå®æ—¶å¤„ç†ï¼Œå½“æˆ‘ä»¬éœ€è¦ä½¿ç”¨å¤–éƒ¨å­˜å‚¨æ•°æ®å‚ä¸è®¡ç®—æ—¶ï¼Œä¸å¤–éƒ¨ç³»ç»Ÿä¹‹é—´çš„äº¤äº’å»¶è¿Ÿå¯¹æµå¤„ç†çš„æ•´ä¸ªå·¥ä½œè¿›åº¦èµ·å†³å®šæ€§çš„å½±å“ã€‚å¦‚æœæˆ‘ä»¬æ˜¯ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼mapfunctionç­‰ç®—å­é‡Œè®¿é—®å¤–éƒ¨å­˜å‚¨ï¼Œå®é™…ä¸Šè¯¥äº¤äº’è¿‡ç¨‹æ˜¯åŒæ­¥çš„ï¼Œæ¯”å¦‚ä¸‹å›¾ä¸­ï¼šè¯·æ±‚aå‘é€åˆ°æ•°æ®åº“ï¼Œé‚£ä¹ˆfunctionä¼šä¸€ç›´ç­‰å¾…å“åº”ã€‚åœ¨å¾ˆå¤šæ¡ˆä¾‹ä¸­ï¼Œè¿™ä¸ªç­‰å¾…è¿‡ç¨‹æ˜¯éå¸¸æµªè´¹å‡½æ•°æ—¶é—´çš„ã€‚ å¼‚æ­¥IO å›¾ä¸­æ£•è‰²çš„é•¿æ¡è¡¨ç¤ºç­‰å¾…æ—¶é—´ï¼Œå¯ä»¥å‘ç°ç½‘ç»œç­‰å¾…æ—¶é—´æå¤§åœ°é˜»ç¢äº†ååå’Œå»¶è¿Ÿã€‚ä¸ºäº†è§£å†³åŒæ­¥è®¿é—®çš„é—®é¢˜ï¼Œå¼‚æ­¥æ¨¡å¼å¯ä»¥å¹¶å‘åœ°å¤„ç†å¤šä¸ªè¯·æ±‚å’Œå›å¤ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å¯ä»¥è¿ç»­åœ°å‘æ•°æ®åº“å‘é€ç”¨æˆ·aã€bã€cç­‰çš„è¯·æ±‚ï¼Œä¸æ­¤åŒæ—¶ï¼Œå“ªä¸ªè¯·æ±‚çš„å›å¤å…ˆè¿”å›äº†å°±å¤„ç†å“ªä¸ªå›å¤ï¼Œä»è€Œè¿ç»­çš„è¯·æ±‚ä¹‹é—´ä¸éœ€è¦é˜»å¡ç­‰å¾…ï¼Œå¦‚ä¸Šå›¾å³è¾¹æ‰€ç¤ºã€‚è¿™ä¹Ÿæ­£æ˜¯ Async I/O çš„å®ç°åŸç†ã€‚ ç›®çš„å°†MapFunctionæˆ–è€…FlatMapFunctionä¸­çš„åŒæ­¥è®¿é—®å¤–éƒ¨å­˜å‚¨è®¾å¤‡çš„æ–¹æ³•é€šè¿‡AsyncFunctionæ›¿æ¢ä»¥å®ç°å¼‚æ­¥è®¿é—®åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå¦‚æœä½¿ç”¨äº†keyByï¼Œåˆ™ç›¸åŒçš„keyæ•´ä¸ªæ‰§è¡Œå‘¨æœŸéƒ½ä½¿ç”¨åŒä¸€ä¸ªçº¿ç¨‹ï¼Œä½†æ˜¯ä¸åŒçš„keyä¹Ÿå¯ä»¥ä½¿ç”¨åŒä¸€ä¸ªçº¿ç¨‹ å¦‚ä½•ä½¿ç”¨Async I/Oæˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªç±»å®ç°RichAsyncFunctionè¿™ä¸ªæŠ½è±¡ç±»ï¼Œå®ç°å…¶ä¸­çš„æŠ½è±¡æ–¹æ³•ï¼Œè¿™ç‚¹å’Œè‡ªå®šä¹‰sourceå¾ˆåƒã€‚ä¸»è¦æ˜¯çš„æŠ½è±¡æ–¹æ³•å¦‚ä¸‹ï¼Œç„¶ååœ¨asyncInvoke()ä½¿ç”¨CompletableFutureæ‰§è¡Œå¼‚æ­¥æ“ä½œï¼ˆCompletableFutureä¼šæä¾›ä¸€ä¸ªForkJoinPoolä½œä¸ºè¯·æ±‚çº¿ç¨‹æ± ï¼‰ 123456789public void open(Configuration parameters) throws Exception;public void close() throws Exception;void asyncInvoke(IN var1, ResultFuture&lt;OUT&gt; var2) throws Exception;default void timeout(IN input, ResultFuture&lt;OUT&gt; resultFuture) throws Exception &#123; resultFuture.completeExceptionally(new TimeoutException(\"Async function call has timed out.\"));&#125; ç„¶ååœ¨AsyncDataStreamä¸­ä½¿ç”¨æˆ‘ä»¬å®šä¹‰å¥½çš„ç±»ï¼Œå»å®ç°ä¸»æµå¼‚æ­¥çš„è®¿é—®å¤–éƒ¨æ•°æ®æº åŸç†å®ç°AsyncDataStream.(un)orderedWait çš„ä¸»è¦å·¥ä½œå°±æ˜¯åˆ›å»ºäº†ä¸€ä¸ª AsyncWaitOperatorã€‚AsyncWaitOperator æ˜¯æ”¯æŒå¼‚æ­¥ IO è®¿é—®çš„ç®—å­å®ç°ï¼Œè¯¥ç®—å­ä¼šè¿è¡Œ AsyncFunction å¹¶å¤„ç†å¼‚æ­¥è¿”å›çš„ç»“æœï¼Œå…¶å†…éƒ¨åŸç†å¦‚ä¸‹å›¾æ‰€ç¤º å¼‚æ­¥åŸç† å¦‚å›¾æ‰€ç¤ºï¼ŒAsyncWaitOperator ä¸»è¦ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šStreamElementQueue å’Œ Emitterã€‚StreamElementQueue æ˜¯ä¸€ä¸ª Promise é˜Ÿåˆ—ï¼Œæ‰€è°“ Promise æ˜¯ä¸€ç§å¼‚æ­¥æŠ½è±¡è¡¨ç¤ºå°†æ¥ä¼šæœ‰ä¸€ä¸ªå€¼ï¼ˆå‚è€ƒ Scala Promise äº†è§£æ›´å¤šï¼‰ï¼Œè¿™ä¸ªé˜Ÿåˆ—æ˜¯æœªå®Œæˆçš„ Promise é˜Ÿåˆ—ï¼Œä¹Ÿå°±æ˜¯è¿›è¡Œä¸­çš„è¯·æ±‚é˜Ÿåˆ—ã€‚Emitter æ˜¯ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ï¼Œè´Ÿè´£å‘é€æ¶ˆæ¯ï¼ˆæ”¶åˆ°çš„å¼‚æ­¥å›å¤ï¼‰ç»™ä¸‹æ¸¸ã€‚ å›¾ä¸­E5è¡¨ç¤ºè¿›å…¥è¯¥ç®—å­çš„ç¬¬äº”ä¸ªå…ƒç´ ï¼ˆâ€Element-5â€ï¼‰ï¼Œåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­é¦–å…ˆä¼šå°†å…¶åŒ…è£…æˆä¸€ä¸ª â€œPromiseâ€ P5ï¼Œç„¶åå°†P5æ”¾å…¥é˜Ÿåˆ—ã€‚æœ€åè°ƒç”¨ AsyncFunction çš„ ayncInvoke æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¼šå‘å¤–éƒ¨æœåŠ¡å‘èµ·ä¸€ä¸ªå¼‚æ­¥çš„è¯·æ±‚ï¼Œå¹¶æ³¨å†Œå›è°ƒã€‚è¯¥å›è°ƒä¼šåœ¨å¼‚æ­¥è¯·æ±‚æˆåŠŸè¿”å›æ—¶è°ƒç”¨ AsyncCollector.collect æ–¹æ³•å°†è¿”å›çš„ç»“æœäº¤ç»™æ¡†æ¶å¤„ç†ã€‚å®é™…ä¸Š AsyncCollector ä¹Ÿä¸€ä¸ª Promiseï¼Œä¹Ÿå°±æ˜¯ P5ï¼Œåœ¨è°ƒç”¨ collect çš„æ—¶å€™ä¼šæ ‡è®° Promise ä¸ºå®ŒæˆçŠ¶æ€ï¼Œå¹¶é€šçŸ¥ Emitter çº¿ç¨‹æœ‰å®Œæˆçš„æ¶ˆæ¯å¯ä»¥å‘é€äº†ã€‚Emitter å°±ä¼šä»é˜Ÿåˆ—ä¸­æ‹‰å–å®Œæˆçš„ Promise ï¼Œå¹¶ä» Promise ä¸­å–å‡ºæ¶ˆæ¯å‘é€ç»™ä¸‹æ¸¸ã€‚ æ¶ˆæ¯çš„é¡ºåºæ€§ä¸Šæ–‡æåˆ° Async I/O æä¾›äº†ä¸¤ç§è¾“å‡ºæ¨¡å¼ã€‚å…¶å®ç»†åˆ†æœ‰ä¸‰ç§æ¨¡å¼: æœ‰åºï¼ŒProcessingTime æ— åºï¼ŒEventTime æ— åºã€‚Flink ä½¿ç”¨é˜Ÿåˆ—æ¥å®ç°ä¸åŒçš„è¾“å‡ºæ¨¡å¼ï¼Œå¹¶æŠ½è±¡å‡ºä¸€ä¸ªé˜Ÿåˆ—çš„æ¥å£ï¼ˆStreamElementQueueï¼‰ï¼Œè¿™ç§åˆ†å±‚è®¾è®¡ä½¿å¾—AsyncWaitOperatorå’ŒEmitterä¸ç”¨å…³å¿ƒæ¶ˆæ¯çš„é¡ºåºé—®é¢˜ã€‚StreamElementQueueæœ‰ä¸¤ç§å…·ä½“å®ç°ï¼Œåˆ†åˆ«æ˜¯ OrderedStreamElementQueue å’Œ UnorderedStreamElementQueueã€‚UnorderedStreamElementQueue æ¯”è¾ƒæœ‰æ„æ€ï¼Œå®ƒä½¿ç”¨äº†ä¸€å¥—é€»è¾‘å·§å¦™åœ°å®ç°å®Œå…¨æ— åºå’Œ EventTime æ— åº æœ‰åºæœ‰åºæ¯”è¾ƒç®€å•ï¼Œä½¿ç”¨ä¸€ä¸ªé˜Ÿåˆ—å°±èƒ½å®ç°ã€‚æ‰€æœ‰æ–°è¿›å…¥è¯¥ç®—å­çš„å…ƒç´ ï¼ˆåŒ…æ‹¬ watermarkï¼‰ï¼Œéƒ½ä¼šåŒ…è£…æˆ Promise å¹¶æŒ‰åˆ°è¾¾é¡ºåºæ”¾å…¥è¯¥é˜Ÿåˆ—ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå°½ç®¡P4çš„ç»“æœå…ˆè¿”å›ï¼Œä½†å¹¶ä¸ä¼šå‘é€ï¼Œåªæœ‰ P1 ï¼ˆé˜Ÿé¦–ï¼‰çš„ç»“æœè¿”å›äº†æ‰ä¼šè§¦å‘ Emitter æ‹‰å–é˜Ÿé¦–å…ƒç´ è¿›è¡Œå‘é€ æœ‰åº ProcessingTime æ— åºProcessingTime æ— åºä¹Ÿæ¯”è¾ƒç®€å•ï¼Œå› ä¸ºæ²¡æœ‰ watermarkï¼Œä¸éœ€è¦åè°ƒ watermark ä¸æ¶ˆæ¯çš„é¡ºåºæ€§ï¼Œæ‰€ä»¥ä½¿ç”¨ä¸¤ä¸ªé˜Ÿåˆ—å°±èƒ½å®ç°ï¼Œä¸€ä¸ª uncompletedQueue ä¸€ä¸ª completedQueueã€‚æ‰€æœ‰æ–°è¿›å…¥è¯¥ç®—å­çš„å…ƒç´ ï¼ŒåŒæ ·çš„åŒ…è£…æˆ Promise å¹¶æ”¾å…¥ uncompletedQueue é˜Ÿåˆ—ï¼Œå½“uncompletedQueueé˜Ÿåˆ—ä¸­ä»»æ„çš„Promiseè¿”å›äº†æ•°æ®ï¼Œåˆ™å°†è¯¥ Promise ç§»åˆ° completedQueue é˜Ÿåˆ—ä¸­ï¼Œå¹¶é€šçŸ¥ Emitter æ¶ˆè´¹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ProcessingTimeæ— åº EventTime æ— åºEventTime æ— åºç±»ä¼¼äºæœ‰åºä¸ ProcessingTime æ— åºçš„ç»“åˆä½“ã€‚å› ä¸ºæœ‰ watermarkï¼Œéœ€è¦åè°ƒ watermark ä¸æ¶ˆæ¯ä¹‹é—´çš„é¡ºåºæ€§ï¼Œæ‰€ä»¥uncompletedQueueä¸­å­˜æ”¾çš„å…ƒç´ ä»åŸå…ˆçš„ Promise å˜æˆäº† Promise é›†åˆã€‚å¦‚æœè¿›å…¥ç®—å­çš„æ˜¯æ¶ˆæ¯å…ƒç´ ï¼Œåˆ™ä¼šåŒ…è£…æˆ Promise æ”¾å…¥é˜Ÿå°¾çš„é›†åˆä¸­ã€‚å¦‚æœè¿›å…¥ç®—å­çš„æ˜¯ watermarkï¼Œä¹Ÿä¼šåŒ…è£…æˆ Promise å¹¶æ”¾åˆ°ä¸€ä¸ªç‹¬ç«‹çš„é›†åˆä¸­ï¼Œå†å°†è¯¥é›†åˆåŠ å…¥åˆ° uncompletedQueue é˜Ÿå°¾ï¼Œæœ€åå†åˆ›å»ºä¸€ä¸ªç©ºé›†åˆåŠ åˆ° uncompletedQueue é˜Ÿå°¾ã€‚è¿™æ ·ï¼Œwatermark å°±æˆäº†æ¶ˆæ¯é¡ºåºçš„è¾¹ç•Œã€‚åªæœ‰å¤„åœ¨é˜Ÿé¦–çš„é›†åˆä¸­çš„ Promise è¿”å›äº†æ•°æ®ï¼Œæ‰èƒ½å°†è¯¥ Promise ç§»åˆ° completedQueue é˜Ÿåˆ—ä¸­ï¼Œç”± Emitter æ¶ˆè´¹å‘å¾€ä¸‹æ¸¸ã€‚åªæœ‰é˜Ÿé¦–é›†åˆç©ºäº†ï¼Œæ‰èƒ½å¤„ç†ç¬¬äºŒä¸ªé›†åˆã€‚è¿™æ ·å°±ä¿è¯äº†å½“ä¸”ä»…å½“æŸä¸ª watermark ä¹‹å‰æ‰€æœ‰çš„æ¶ˆæ¯éƒ½å·²ç»è¢«å‘é€äº†ï¼Œè¯¥ watermark æ‰èƒ½è¢«å‘é€ã€‚è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š EventTimeæ— åº è¯´æ˜1ã€AsyncDataStreamæœ‰2ä¸ªæ–¹æ³•ï¼ŒunorderedWaitè¡¨ç¤ºæ•°æ®ä¸éœ€è¦å…³æ³¨é¡ºåºï¼Œå¤„ç†å®Œç«‹å³å‘é€ï¼ŒorderedWaitè¡¨ç¤ºæ•°æ®éœ€è¦å…³æ³¨é¡ºåºï¼Œä¸ºäº†å®ç°è¯¥ç›®æ ‡ï¼Œæ“ä½œç®—å­ä¼šåœ¨è¯¥ç»“æœè®°å½•ä¹‹å‰çš„è®°å½•ä¸ºå‘é€ä¹‹å‰ç¼“å­˜è¯¥è®°å½•ã€‚è¿™å¾€å¾€ä¼šå¼•å…¥é¢å¤–çš„å»¶è¿Ÿå’Œä¸€äº›Checkpointè´Ÿè½½ï¼Œå› ä¸ºç›¸æ¯”äºæ— åºæ¨¡å¼ç»“æœè®°å½•ä¼šä¿å­˜åœ¨CheckpointçŠ¶æ€å†…éƒ¨è¾ƒé•¿çš„æ—¶é—´ã€‚2ã€Timeouté…ç½®ï¼Œä¸»è¦æ˜¯ä¸ºäº†å¤„ç†æ­»æ‰æˆ–è€…å¤±è´¥çš„ä»»åŠ¡ï¼Œé˜²æ­¢èµ„æºè¢«é•¿æœŸé˜»å¡å ç”¨ã€‚3ã€æœ€åä¸€ä¸ªå‚æ•°Capacityè¡¨ç¤ºåŒæ—¶æœ€å¤šæœ‰å¤šå°‘ä¸ªå¼‚æ­¥è¯·æ±‚åœ¨å¤„ç†ï¼Œå¼‚æ­¥IOçš„æ–¹å¼ä¼šå¯¼è‡´æ›´é«˜çš„ååé‡ï¼Œä½†æ˜¯å¯¹äºå®æ—¶åº”ç”¨æ¥è¯´è¯¥æ“ä½œä¹Ÿæ˜¯ä¸€ä¸ªç“¶é¢ˆã€‚é™åˆ¶å¹¶å‘è¯·æ±‚æ•°ï¼Œç®—å­ä¸ä¼šç§¯å‹è¿‡å¤šçš„æœªå¤„ç†è¯·æ±‚ï¼Œä½†æ˜¯ä¸€æ—¦è¶…è¿‡å®¹é‡çš„æ˜¾ç¤ºä¼šè§¦å‘èƒŒå‹ã€‚è¯¥å‚æ•°å¯ä»¥ä¸é…ç½®ï¼Œä½†æ˜¯é»˜è®¤æ˜¯100","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Common åŒ…å­¦ä¹ ï¼šå¸¸ç”¨é›†åˆç±»Collections4å­¦ä¹ ","date":"2019-11-06T08:04:06.000Z","path":"2019/11/06/apache-common:study-apache-common-collections4/","text":"Apache Common åŒ…å­¦ä¹ ï¼šå¸¸ç”¨é›†åˆç±»Collections4å­¦ä¹  Mavenä¾èµ–1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-collections4&lt;/artifactId&gt; &lt;version&gt;4.3&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; CollectionUtils&lt;O&gt; Collection&lt;O&gt; subtract(final Iterable&lt;? extends O&gt; a, final Iterable&lt;? extends O&gt; b)aæ˜¯åšå·®é›†è¿ç®—çš„å·¦é›†ï¼Œbæ˜¯åšå·®é›†è¿ç®—çš„å³é›†ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ 1234567891011121314151617181920public class Demo &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Demo.class); public static void main(String[] args) &#123; Set&lt;Pair&lt;String, String&gt;&gt; allProductDevices = Sets.newHashSet(Pair.of(\"a\", \"b\"), Pair.of(\"c\", \"d\")); Set&lt;Pair&lt;String, String&gt;&gt; oldProductDevices = Sets.newHashSet(Pair.of(\"a\", \"b\"), Pair.of(\"e\", \"f\")); List&lt;Pair&lt;String, String&gt;&gt; newProductDevices = (ArrayList&lt;Pair&lt;String, String&gt;&gt;) CollectionUtils.subtract(allProductDevices, oldProductDevices); List&lt;String&gt; list1 = Lists.newArrayList(\"a\", \"b\"); List&lt;String&gt; list2 = Lists.newArrayList(\"c\", \"b\"); List&lt;String&gt; list3 = (ArrayList&lt;String&gt;) CollectionUtils.subtract(list1, list2); &#125;&#125;","tags":[{"name":"Apache CommonåŒ…","slug":"Apache-CommonåŒ…","permalink":"https://yangyichao-mango.github.io/tags/Apache-CommonåŒ…/"}]},{"title":"Google Guava å­¦ä¹ ï¼šguava cacheç¼“å­˜å­¦ä¹ ","date":"2019-11-06T08:03:38.000Z","path":"2019/11/06/google-guava:study-guava-cache/","text":"Google Guava å­¦ä¹ ï¼šguava cacheç¼“å­˜å­¦ä¹  èƒŒæ™¯ç¼“å­˜çš„ä¸»è¦ä½œç”¨æ˜¯æš‚æ—¶åœ¨å†…å­˜ä¸­ä¿å­˜ä¸šåŠ¡ç³»ç»Ÿçš„æ•°æ®å¤„ç†ç»“æœï¼Œå¹¶ä¸”ç­‰å¾…ä¸‹æ¬¡è®¿é—®ä½¿ç”¨ã€‚åœ¨æ—¥é•¿å¼€å‘æœ‰å¾ˆå¤šåœºåˆï¼Œæœ‰ä¸€äº›æ•°æ®é‡ä¸æ˜¯å¾ˆå¤§ï¼Œä¸ä¼šç»å¸¸æ”¹åŠ¨ï¼Œå¹¶ä¸”è®¿é—®éå¸¸é¢‘ç¹ã€‚ä½†æ˜¯ç”±äºå—é™äºç¡¬ç›˜IOçš„æ€§èƒ½æˆ–è€…è¿œç¨‹ç½‘ç»œç­‰åŸå› è·å–å¯èƒ½éå¸¸çš„è´¹æ—¶ã€‚ä¼šå¯¼è‡´æˆ‘ä»¬çš„ç¨‹åºéå¸¸ç¼“æ…¢ï¼Œè¿™åœ¨æŸäº›ä¸šåŠ¡ä¸Šæ˜¯ä¸èƒ½å¿çš„ï¼è€Œç¼“å­˜æ­£æ˜¯è§£å†³è¿™ç±»é—®é¢˜çš„ç¥å™¨ï¼ æ­£æ–‡Guava Cacheä¸ConcurrentMapå¾ˆç›¸ä¼¼ï¼Œä½†ä¹Ÿä¸å®Œå…¨ä¸€æ ·ã€‚æœ€åŸºæœ¬çš„åŒºåˆ«æ˜¯ConcurrentMapä¼šä¸€ç›´ä¿å­˜æ‰€æœ‰æ·»åŠ çš„å…ƒç´ ï¼Œç›´åˆ°æ˜¾å¼åœ°ç§»é™¤ã€‚ç›¸å¯¹åœ°ï¼ŒGuava Cacheä¸ºäº†é™åˆ¶å†…å­˜å ç”¨ï¼Œé€šå¸¸éƒ½è®¾å®šä¸ºè‡ªåŠ¨å›æ”¶å…ƒç´ ã€‚åœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œå°½ç®¡LoadingCache ä¸å›æ”¶å…ƒç´ ï¼Œå®ƒä¹Ÿæ˜¯å¾ˆæœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒä¼šè‡ªåŠ¨åŠ è½½ç¼“å­˜ Guava Cacheæ˜¯åœ¨å†…å­˜ä¸­ç¼“å­˜æ•°æ®ï¼Œç›¸æ¯”è¾ƒäºæ•°æ®åº“æˆ–rediså­˜å‚¨ï¼Œè®¿é—®å†…å­˜ä¸­çš„æ•°æ®ä¼šæ›´åŠ é«˜æ•ˆã€‚Guavaå®˜ç½‘ä»‹ç»ï¼Œä¸‹é¢çš„è¿™å‡ ç§æƒ…å†µå¯ä»¥è€ƒè™‘ä½¿ç”¨Guava Cacheï¼š 1.æ„¿æ„æ¶ˆè€—ä¸€äº›å†…å­˜ç©ºé—´æ¥æå‡é€Ÿåº¦ã€‚ 2.é¢„æ–™åˆ°æŸäº›é”®ä¼šè¢«å¤šæ¬¡æŸ¥è¯¢ã€‚ 3.ç¼“å­˜ä¸­å­˜æ”¾çš„æ•°æ®æ€»é‡ä¸ä¼šè¶…å‡ºå†…å­˜å®¹é‡ã€‚ æ‰€ä»¥ï¼Œå¯ä»¥å°†ç¨‹åºé¢‘ç¹ç”¨åˆ°çš„å°‘é‡æ•°æ®å­˜å‚¨åˆ°Guava Cacheä¸­ï¼Œä»¥æ”¹å–„ç¨‹åºæ€§èƒ½ã€‚ä¸‹é¢å¯¹Guava Cacheçš„ç”¨æ³•è¿›è¡Œè¯¦ç»†çš„ä»‹ç»ã€‚ Mavenä¾èµ–12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; æ„å»ºç¼“å­˜å¯¹è±¡æ¥å£Cacheä»£è¡¨ç¼“å­˜ï¼Œå®ƒæœ‰å¦‚ä¸‹æ–¹æ³•ï¼š 1234567891011121314151617181920212223public interface Cache&lt;K, V&gt; &#123; V get(K key, Callable&lt;? extends V&gt; valueLoader) throws ExecutionException; ImmutableMap&lt;K, V&gt; getAllPresent(Iterable&lt;?&gt; keys); void put(K key, V value); void putAll(Map&lt;? extends K, ? extends V&gt; m); void invalidate(Object key); void invalidateAll(Iterable&lt;?&gt; keys); void invalidateAll(); long size(); CacheStats stats(); ConcurrentMap&lt;K, V&gt; asMap(); void cleanUp();&#125; å¯ä»¥é€šè¿‡CacheBuilderç±»æ„å»ºä¸€ä¸ªç¼“å­˜å¯¹è±¡ï¼Œæ„å»ºä¸€ä¸ªç¼“å­˜å¯¹è±¡ä»£ç å¦‚ä¸‹ 1234567public class StudyGuavaCache &#123; public static void main(String[] args) &#123; Cache&lt;String,String&gt; cache = CacheBuilder.newBuilder().build(); cache.put(\"word\",\"Hello Guava Cache\"); System.out.println(cache.getIfPresent(\"word\")); &#125;&#125; å¯ä»¥çœ‹åˆ°Cacheéå¸¸ç±»ä¼¼äºJDKä¸­çš„Mapï¼Œä½†æ˜¯ç›¸æ¯”äºMapï¼ŒGuava Cacheæä¾›äº†å¾ˆå¤šæ›´å¼ºå¤§çš„åŠŸèƒ½ è®¾ç½®æœ€å¤§å­˜å‚¨Guava Cacheå¯ä»¥åœ¨æ„å»ºç¼“å­˜å¯¹è±¡æ—¶æŒ‡å®šç¼“å­˜æ‰€èƒ½å¤Ÿå­˜å‚¨çš„æœ€å¤§è®°å½•æ•°é‡ã€‚å½“Cacheä¸­çš„è®°å½•æ•°é‡è¾¾åˆ°æœ€å¤§å€¼åå†è°ƒç”¨putæ–¹æ³•å‘å…¶ä¸­æ·»åŠ å¯¹è±¡ï¼ŒGuavaä¼šå…ˆä»å½“å‰ç¼“å­˜çš„å¯¹è±¡è®°å½•ä¸­é€‰æ‹©ä¸€æ¡åˆ é™¤æ‰ï¼Œè…¾å‡ºç©ºé—´åå†å°†æ–°çš„å¯¹è±¡å­˜å‚¨åˆ°Cacheä¸­ 12345678910111213public class StudyGuavaCache &#123; public static void main(String[] args) &#123; Cache&lt;String,String&gt; cache = CacheBuilder.newBuilder() .maximumSize(2) .build(); cache.put(\"key1\", \"value1\"); cache.put(\"key2\", \"value2\"); cache.put(\"key3\", \"value3\"); System.out.println(\"ç¬¬ä¸€ä¸ªå€¼ï¼š\" + cache.getIfPresent(\"key1\")); System.out.println(\"ç¬¬äºŒä¸ªå€¼ï¼š\" + cache.getIfPresent(\"key2\")); System.out.println(\"ç¬¬ä¸‰ä¸ªå€¼ï¼š\" + cache.getIfPresent(\"key3\")); &#125;&#125; ä¸Šé¢ä»£ç åœ¨æ„é€ ç¼“å­˜å¯¹è±¡æ—¶ï¼Œé€šè¿‡CacheBuilderç±»çš„maximumSizeæ–¹æ³•æŒ‡å®šCacheæœ€å¤šå¯ä»¥å­˜å‚¨ä¸¤ä¸ªå¯¹è±¡ï¼Œç„¶åè°ƒç”¨Cacheçš„putæ–¹æ³•å‘å…¶ä¸­æ·»åŠ äº†ä¸‰ä¸ªå¯¹è±¡ã€‚ç¨‹åºæ‰§è¡Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°ç¬¬ä¸‰æ¡å¯¹è±¡è®°å½•çš„æ’å…¥ï¼Œå¯¼è‡´äº†ç¬¬ä¸€æ¡å¯¹è±¡è®°å½•è¢«åˆ é™¤ 123ç¬¬ä¸€ä¸ªå€¼ï¼šnullç¬¬äºŒä¸ªå€¼ï¼švalue2ç¬¬ä¸‰ä¸ªå€¼ï¼švalue3 è®¾ç½®è¿‡æœŸæ—¶é—´åœ¨æ„å»ºCacheå¯¹è±¡æ—¶ï¼Œå¯ä»¥é€šè¿‡CacheBuilderç±»çš„expireAfterAccesså’ŒexpireAfterWriteä¸¤ä¸ªæ–¹æ³•ä¸ºç¼“å­˜ä¸­çš„å¯¹è±¡æŒ‡å®šè¿‡æœŸæ—¶é—´ï¼Œè¿‡æœŸçš„å¯¹è±¡å°†ä¼šè¢«ç¼“å­˜è‡ªåŠ¨åˆ é™¤ã€‚å…¶ä¸­ï¼ŒexpireAfterWriteæ–¹æ³•æŒ‡å®šå¯¹è±¡è¢«å†™å…¥åˆ°ç¼“å­˜åå¤šä¹…è¿‡æœŸï¼ŒexpireAfterAccessæŒ‡å®šå¯¹è±¡å¤šä¹…æ²¡æœ‰è¢«è®¿é—®åè¿‡æœŸ expireAfterWrite1234567891011121314public class StudyGuavaCache &#123; public static void main(String[] args) throws InterruptedException &#123; Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(2) .expireAfterWrite(3, TimeUnit.SECONDS) .build(); cache.put(\"key1\", \"value1\"); int time = 1; while (true) &#123; System.out.println(\"ç¬¬\" + time++ + \"æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼š\" + cache.getIfPresent(\"key1\")); Thread.sleep(1000); &#125; &#125;&#125; ä¸Šé¢çš„ä»£ç åœ¨æ„é€ Cacheå¯¹è±¡æ—¶ï¼Œé€šè¿‡CacheBuilderçš„expireAfterWriteæ–¹æ³•æŒ‡å®šputåˆ°Cacheä¸­çš„å¯¹è±¡åœ¨3ç§’åä¼šè¿‡æœŸã€‚åœ¨Cacheå¯¹è±¡ä¸­å­˜å‚¨ä¸€æ¡å¯¹è±¡è®°å½•åï¼Œæ¯éš”1ç§’è¯»å–ä¸€æ¬¡è¿™æ¡è®°å½•ã€‚ç¨‹åºè¿è¡Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå‰ä¸‰ç§’å¯ä»¥ä»Cacheä¸­è·å–åˆ°å¯¹è±¡ï¼Œè¶…è¿‡ä¸‰ç§’åï¼Œå¯¹è±¡ä»Cacheä¸­è¢«è‡ªåŠ¨åˆ é™¤ 12345678ç¬¬1æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼švalue1ç¬¬2æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼švalue1ç¬¬3æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼švalue1ç¬¬4æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼šnullç¬¬5æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼šnullç¬¬6æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼šnullç¬¬7æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼šnullç¬¬8æ¬¡å–åˆ°key1çš„å€¼ä¸ºï¼šnull expireAfterAccess1234567891011121314public class StudyGuavaCache &#123; public static void main(String[] args) throws InterruptedException &#123; Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(2) .expireAfterAccess(3, TimeUnit.SECONDS) .build(); cache.put(\"key1\", \"value1\"); double time = 1.5; while (true) &#123; Thread.sleep((long) time * 1000L); System.out.println(\"ç¡çœ \" + time++ + \"ç§’åå–åˆ°key1çš„å€¼ä¸ºï¼š\" + cache.getIfPresent(\"key1\")); &#125; &#125;&#125; é€šè¿‡CacheBuilderçš„expireAfterAccessæ–¹æ³•æŒ‡å®šCacheä¸­å­˜å‚¨çš„å¯¹è±¡å¦‚æœè¶…è¿‡3ç§’æ²¡æœ‰è¢«è®¿é—®å°±ä¼šè¿‡æœŸã€‚whileä¸­çš„ä»£ç æ¯sleepä¸€æ®µæ—¶é—´å°±ä¼šè®¿é—®ä¸€æ¬¡Cacheä¸­å­˜å‚¨çš„å¯¹è±¡key1ï¼Œæ¯æ¬¡è®¿é—®key1ä¹‹åä¸‹æ¬¡sleepçš„æ—¶é—´ä¼šåŠ é•¿ä¸€ç§’ã€‚ç¨‹åºè¿è¡Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä»ç»“æœä¸­å¯ä»¥çœ‹å‡ºï¼Œå½“è¶…è¿‡3ç§’æ²¡æœ‰è¯»å–key1å¯¹è±¡ä¹‹åï¼Œè¯¥å¯¹è±¡ä¼šè‡ªåŠ¨è¢«Cacheåˆ é™¤ã€‚ 123ç¡çœ 1.5ç§’åå–åˆ°key1çš„å€¼ä¸ºï¼švalue1ç¡çœ 2.5ç§’åå–åˆ°key1çš„å€¼ä¸ºï¼švalue1ç¡çœ 3.5ç§’åå–åˆ°key1çš„å€¼ä¸ºï¼šnull ä¹Ÿå¯ä»¥åŒæ—¶ç”¨expireAfterAccesså’ŒexpireAfterWriteæ–¹æ³•æŒ‡å®šè¿‡æœŸæ—¶é—´ï¼Œè¿™æ—¶åªè¦å¯¹è±¡æ»¡è¶³ä¸¤è€…ä¸­çš„ä¸€ä¸ªæ¡ä»¶å°±ä¼šè¢«è‡ªåŠ¨è¿‡æœŸåˆ é™¤ã€‚ å¼±å¼•ç”¨å¯ä»¥é€šè¿‡weakKeyså’ŒweakValuesæ–¹æ³•æŒ‡å®šCacheåªä¿å­˜å¯¹ç¼“å­˜è®°å½•keyå’Œvalueçš„å¼±å¼•ç”¨ã€‚è¿™æ ·å½“æ²¡æœ‰å…¶ä»–å¼ºå¼•ç”¨æŒ‡å‘keyå’Œvalueæ—¶ï¼Œkeyå’Œvalueå¯¹è±¡å°±ä¼šè¢«åƒåœ¾å›æ”¶å™¨å›æ”¶ 1234567891011121314public class StudyGuavaCache &#123; public static void main(String[] args) throws InterruptedException &#123; Cache&lt;String, Object&gt; cache = CacheBuilder.newBuilder() .maximumSize(2) .weakValues() .build(); Object value = new Object(); cache.put(\"key1\", value); value = new Object(); // åŸå¯¹è±¡ä¸å†æœ‰å¼ºå¼•ç”¨ System.gc(); System.out.println(cache.getIfPresent(\"key1\")); &#125;&#125; ä¸Šé¢ä»£ç çš„æ‰“å°ç»“æœæ˜¯nullã€‚æ„å»ºCacheæ—¶é€šè¿‡weakValuesæ–¹æ³•æŒ‡å®šCacheåªä¿å­˜è®°å½•å€¼çš„ä¸€ä¸ªå¼±å¼•ç”¨ã€‚å½“ç»™valueå¼•ç”¨èµ‹å€¼ä¸€ä¸ªæ–°çš„å¯¹è±¡ä¹‹åï¼Œå°±ä¸å†æœ‰ä»»ä½•ä¸€ä¸ªå¼ºå¼•ç”¨æŒ‡å‘åŸå¯¹è±¡ã€‚System.gc()è§¦å‘åƒåœ¾å›æ”¶åï¼ŒåŸå¯¹è±¡å°±è¢«æ¸…é™¤äº† 1null æ˜¾ç¤ºæ¸…é™¤å¯ä»¥è°ƒç”¨Cacheçš„invalidateAllæˆ–invalidateæ–¹æ³•æ˜¾ç¤ºåˆ é™¤Cacheä¸­çš„è®°å½•ã€‚invalidateæ–¹æ³•ä¸€æ¬¡åªèƒ½åˆ é™¤Cacheä¸­ä¸€ä¸ªè®°å½•ï¼Œæ¥æ”¶çš„å‚æ•°æ˜¯è¦åˆ é™¤è®°å½•çš„keyã€‚invalidateAllæ–¹æ³•å¯ä»¥æ‰¹é‡åˆ é™¤Cacheä¸­çš„è®°å½•ï¼Œå½“æ²¡æœ‰ä¼ ä»»ä½•å‚æ•°æ—¶ï¼ŒinvalidateAllæ–¹æ³•å°†æ¸…é™¤Cacheä¸­çš„å…¨éƒ¨è®°å½•ã€‚invalidateAllä¹Ÿå¯ä»¥æ¥æ”¶ä¸€ä¸ªIterableç±»å‹çš„å‚æ•°ï¼Œå‚æ•°ä¸­åŒ…å«è¦åˆ é™¤è®°å½•çš„æ‰€æœ‰keyå€¼ã€‚ä¸‹é¢ä»£ç å¯¹æ­¤åšäº†ç¤ºä¾‹ 123456789101112131415161718public class StudyGuavaCache &#123; public static void main(String[] args) &#123; Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder().build(); Object value = new Object(); cache.put(\"key1\", \"value1\"); cache.put(\"key2\", \"value2\"); cache.put(\"key3\", \"value3\"); List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"key1\"); list.add(\"key2\"); cache.invalidateAll(list); // æ‰¹é‡æ¸…é™¤listä¸­å…¨éƒ¨keyå¯¹åº”çš„è®°å½• System.out.println(cache.getIfPresent(\"key1\")); System.out.println(cache.getIfPresent(\"key2\")); System.out.println(cache.getIfPresent(\"key3\")); &#125;&#125; ä»£ç ä¸­æ„é€ äº†ä¸€ä¸ªé›†åˆlistç”¨äºä¿å­˜è¦åˆ é™¤è®°å½•çš„keyå€¼ï¼Œç„¶åè°ƒç”¨invalidateAllæ–¹æ³•æ‰¹é‡åˆ é™¤key1å’Œkey2å¯¹åº”çš„è®°å½•ï¼Œåªå‰©ä¸‹key3å¯¹åº”çš„è®°å½•æ²¡æœ‰è¢«åˆ é™¤ 123nullnullvalue3 ç§»é™¤ç›‘å¬å™¨å¯ä»¥ä¸ºCacheå¯¹è±¡æ·»åŠ ä¸€ä¸ªç§»é™¤ç›‘å¬å™¨ï¼Œè¿™æ ·å½“æœ‰è®°å½•è¢«åˆ é™¤æ—¶å¯ä»¥æ„ŸçŸ¥åˆ°è¿™ä¸ªäº‹ä»¶ 123456789101112131415161718public class StudyGuavaCache &#123; public static void main(String[] args) throws InterruptedException &#123; RemovalListener&lt;String, String&gt; listener = notification -&gt; System.out.println(\"[\" + notification.getKey() + \":\" + notification.getValue() + \"] is removed!\"); Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(3) .removalListener(listener) .build(); cache.put(\"key1\", \"value1\"); cache.put(\"key2\", \"value2\"); cache.put(\"key3\", \"value3\"); cache.put(\"key4\", \"value3\"); cache.put(\"key5\", \"value3\"); cache.put(\"key6\", \"value3\"); cache.put(\"key7\", \"value3\"); cache.put(\"key8\", \"value3\"); &#125;&#125; removalListeneræ–¹æ³•ä¸ºCacheæŒ‡å®šäº†ä¸€ä¸ªç§»é™¤ç›‘å¬å™¨ï¼Œè¿™æ ·å½“æœ‰è®°å½•ä»Cacheä¸­è¢«åˆ é™¤æ—¶ï¼Œç›‘å¬å™¨listenerå°±ä¼šæ„ŸçŸ¥åˆ°è¿™ä¸ªäº‹ä»¶ã€‚ç¨‹åºè¿è¡Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤º 12345[key1:value1] is removed![key2:value2] is removed![key3:value3] is removed![key4:value3] is removed![key5:value3] is removed! è‡ªåŠ¨åŠ è½½Cacheçš„getæ–¹æ³•æœ‰ä¸¤ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¦ä»Cacheä¸­è·å–è®°å½•çš„keyï¼Œç¬¬äºŒä¸ªè®°å½•æ˜¯ä¸€ä¸ªCallableå¯¹è±¡ã€‚å½“ç¼“å­˜ä¸­å·²ç»å­˜åœ¨keyå¯¹åº”çš„è®°å½•æ—¶ï¼Œgetæ–¹æ³•ç›´æ¥è¿”å›keyå¯¹åº”çš„è®°å½•ã€‚å¦‚æœç¼“å­˜ä¸­ä¸åŒ…å«keyå¯¹åº”çš„è®°å½•ï¼ŒGuavaä¼šä½¿ç”¨å½“å‰çº¿ç¨‹æ‰§è¡ŒCallableå¯¹è±¡ä¸­çš„callæ–¹æ³•ï¼Œcallæ–¹æ³•çš„è¿”å›å€¼ä¼šä½œä¸ºkeyå¯¹åº”çš„å€¼è¢«å­˜å‚¨åˆ°ç¼“å­˜ä¸­ï¼Œå¹¶ä¸”è¢«getæ–¹æ³•è¿”å›ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªå¤šçº¿ç¨‹çš„ä¾‹å­ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class StudyGuavaCache &#123; private static final Logger LOGGER = LoggerFactory.getLogger(StudyGuavaCache.class); private static Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(1) .build(); public static void main(String[] args) throws InterruptedException &#123; new Thread(new Runnable() &#123; public void run() &#123; LOGGER.info(\"1\" + Thread.currentThread().getName()); try &#123; String value = cache.get(\"key\", new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; LOGGER.info(\"load1\" + Thread.currentThread().getName()); // åŠ è½½æ•°æ®çº¿ç¨‹æ‰§è¡Œæ ‡å¿— Thread.sleep(1000); // æ¨¡æ‹ŸåŠ è½½æ—¶é—´ return \"auto load by Callable1\"; &#125; &#125;); LOGGER.info(\"thread1 \" + value); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; public void run() &#123; LOGGER.info(\"thread2\"); try &#123; LOGGER.info(\"2\" + Thread.currentThread().getName()); String value = cache.get(\"key1\", new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; LOGGER.info(\"load2\" + Thread.currentThread().getName()); // åŠ è½½æ•°æ®çº¿ç¨‹æ‰§è¡Œæ ‡å¿— Thread.sleep(1000); // æ¨¡æ‹ŸåŠ è½½æ—¶é—´ return \"auto load by Callable2\"; &#125; &#125;); LOGGER.info(\"thread2 \" + value); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125;&#125; è¿™æ®µä»£ç ä¸­æœ‰ä¸¤ä¸ªçº¿ç¨‹å…±äº«åŒä¸€ä¸ªCacheå¯¹è±¡ï¼Œä¸¤ä¸ªçº¿ç¨‹åŒæ—¶è°ƒç”¨getæ–¹æ³•è·å–åŒä¸€ä¸ªkeyå¯¹åº”çš„è®°å½•ã€‚ç”±äºkeyå¯¹åº”çš„è®°å½•ä¸å­˜åœ¨ï¼Œæ‰€ä»¥ä¸¤ä¸ªçº¿ç¨‹éƒ½åœ¨getæ–¹æ³•å¤„é˜»å¡ã€‚æ­¤å¤„åœ¨callæ–¹æ³•ä¸­è°ƒç”¨Thread.sleep(1000)æ¨¡æ‹Ÿç¨‹åºä»å¤–å­˜åŠ è½½æ•°æ®çš„æ—¶é—´æ¶ˆè€— 1234517:49:23.965 [Thread-2] INFO com.github.xxx.other.demo.guava.StudyGuavaCache - thread217:49:23.965 [Thread-1] INFO com.github.xxx.other.demo.guava.StudyGuavaCache - 1Thread-117:49:23.969 [Thread-2] INFO com.github.xxx.other.demo.guava.StudyGuavaCache - 2Thread-217:49:23.983 [Thread-1] INFO com.github.xxx.other.demo.guava.StudyGuavaCache - load1Thread-117:49:23.983 [Thread-2] INFO com.github.xxx.other.demo.guava.StudyGuavaCache - load2Thread-2 ä»ç»“æœä¸­å¯ä»¥çœ‹å‡ºï¼Œè™½ç„¶æ˜¯ä¸¤ä¸ªçº¿ç¨‹åŒæ—¶è°ƒç”¨getæ–¹æ³•ï¼Œä½†åªæœ‰ä¸€ä¸ªgetæ–¹æ³•ä¸­çš„Callableä¼šè¢«æ‰§è¡Œ(æ²¡æœ‰æ‰“å°å‡ºload2)ã€‚Guavaå¯ä»¥ä¿è¯å½“æœ‰å¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®Cacheä¸­çš„ä¸€ä¸ªkeyæ—¶ï¼Œå¦‚æœkeyå¯¹åº”çš„è®°å½•ä¸å­˜åœ¨ï¼ŒGuavaåªä¼šå¯åŠ¨ä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œgetæ–¹æ³•ä¸­Callableå‚æ•°å¯¹åº”çš„ä»»åŠ¡åŠ è½½æ•°æ®å­˜åˆ°ç¼“å­˜ã€‚å½“åŠ è½½å®Œæ•°æ®åï¼Œä»»ä½•çº¿ç¨‹ä¸­çš„getæ–¹æ³•éƒ½ä¼šè·å–åˆ°keyå¯¹åº”çš„å€¼ ç»Ÿè®¡ä¿¡æ¯å¯ä»¥å¯¹Cacheçš„å‘½ä¸­ç‡ã€åŠ è½½æ•°æ®æ—¶é—´ç­‰ä¿¡æ¯è¿›è¡Œç»Ÿè®¡ã€‚åœ¨æ„å»ºCacheå¯¹è±¡æ—¶ï¼Œå¯ä»¥é€šè¿‡CacheBuilderçš„recordStatsæ–¹æ³•å¼€å¯ç»Ÿè®¡ä¿¡æ¯çš„å¼€å…³ã€‚å¼€å…³å¼€å¯åCacheä¼šè‡ªåŠ¨å¯¹ç¼“å­˜çš„å„ç§æ“ä½œè¿›è¡Œç»Ÿè®¡ï¼Œè°ƒç”¨Cacheçš„statsæ–¹æ³•å¯ä»¥æŸ¥çœ‹ç»Ÿè®¡åçš„ä¿¡æ¯ 123456789101112131415161718192021public class StudyGuavaCache &#123; public static void main(String[] args) throws InterruptedException &#123; Cache&lt;String, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(3) .recordStats() // å¼€å¯ç»Ÿè®¡ä¿¡æ¯å¼€å…³ .build(); cache.put(\"key1\", \"value1\"); cache.put(\"key2\", \"value2\"); cache.put(\"key3\", \"value3\"); cache.put(\"key4\", \"value4\"); cache.getIfPresent(\"key1\"); cache.getIfPresent(\"key2\"); cache.getIfPresent(\"key3\"); cache.getIfPresent(\"key4\"); cache.getIfPresent(\"key5\"); cache.getIfPresent(\"key6\"); System.out.println(cache.stats()); // è·å–ç»Ÿè®¡ä¿¡æ¯ &#125;&#125; ç¨‹åºæ‰§è¡Œç»“æœå¦‚ä¸‹æ‰€ç¤º 1CacheStats&#123;hitCount=3, missCount=3, loadSuccessCount=0, loadExceptionCount=0, totalLoadTime=0, evictionCount=1&#125; è¿™äº›ç»Ÿè®¡ä¿¡æ¯å¯¹äºè°ƒæ•´ç¼“å­˜è®¾ç½®æ˜¯è‡³å…³é‡è¦çš„ï¼Œåœ¨æ€§èƒ½è¦æ±‚é«˜çš„åº”ç”¨ä¸­åº”è¯¥å¯†åˆ‡å…³æ³¨è¿™äº›æ•°æ® LoadingCacheLoadingCacheæ˜¯Cacheçš„å­æ¥å£ï¼Œç›¸æ¯”è¾ƒäºCacheï¼Œå½“ä»LoadingCacheä¸­è¯»å–ä¸€ä¸ªæŒ‡å®škeyçš„è®°å½•æ—¶ï¼Œå¦‚æœè¯¥è®°å½•ä¸å­˜åœ¨ï¼Œåˆ™LoadingCacheå¯ä»¥è‡ªåŠ¨æ‰§è¡ŒåŠ è½½æ•°æ®åˆ°ç¼“å­˜çš„æ“ä½œã€‚LoadingCacheæ¥å£çš„å®šä¹‰å¦‚ä¸‹ï¼š 123456789101112131415public interface LoadingCache&lt;K, V&gt; extends Cache&lt;K, V&gt;, Function&lt;K, V&gt; &#123; V get(K key) throws ExecutionException; V getUnchecked(K key); ImmutableMap&lt;K, V&gt; getAll(Iterable&lt;? extends K&gt; keys) throws ExecutionException; V apply(K key); void refresh(K key); @Override ConcurrentMap&lt;K, V&gt; asMap();&#125; ä¸æ„å»ºCacheç±»å‹çš„å¯¹è±¡ç±»ä¼¼ï¼ŒLoadingCacheç±»å‹çš„å¯¹è±¡ä¹Ÿæ˜¯é€šè¿‡CacheBuilderè¿›è¡Œæ„å»ºï¼Œä¸åŒçš„æ˜¯ï¼Œåœ¨è°ƒç”¨CacheBuilderçš„buildæ–¹æ³•æ—¶ï¼Œå¿…é¡»ä¼ é€’ä¸€ä¸ªCacheLoaderç±»å‹çš„å‚æ•°ï¼ŒCacheLoaderçš„loadæ–¹æ³•éœ€è¦æˆ‘ä»¬æä¾›å®ç°ã€‚å½“è°ƒç”¨LoadingCacheçš„getæ–¹æ³•æ—¶ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨å¯¹åº”keyçš„è®°å½•ï¼Œåˆ™CacheLoaderä¸­çš„loadæ–¹æ³•ä¼šè¢«è‡ªåŠ¨è°ƒç”¨ä»å¤–å­˜åŠ è½½æ•°æ®ï¼Œloadæ–¹æ³•çš„è¿”å›å€¼ä¼šä½œä¸ºkeyå¯¹åº”çš„valueå­˜å‚¨åˆ°LoadingCacheä¸­ï¼Œå¹¶ä»getæ–¹æ³•è¿”å› 12345678910111213141516171819public class StudyGuavaCache &#123; public static void main(String[] args) throws ExecutionException &#123; CacheLoader&lt;String, String&gt; loader = new CacheLoader&lt;String, String&gt;() &#123; public String load(String key) throws Exception &#123; Thread.sleep(1000); // ä¼‘çœ 1sï¼Œæ¨¡æ‹ŸåŠ è½½æ•°æ® System.out.println(key + \" is loaded from a cacheLoader!\"); return key + \"'s value\"; &#125; &#125;; LoadingCache&lt;String, String&gt; loadingCache = CacheBuilder.newBuilder() .maximumSize(3) .build(loader); // åœ¨æ„å»ºæ—¶æŒ‡å®šè‡ªåŠ¨åŠ è½½å™¨ loadingCache.get(\"key1\"); loadingCache.get(\"key2\"); loadingCache.get(\"key3\"); &#125;&#125; ç¨‹åºæ‰§è¡Œç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š 123key1 is loaded from a cacheLoader!key2 is loaded from a cacheLoader!key3 is loaded from a cacheLoader! ä»LoadingCacheæŸ¥è¯¢çš„æ­£è§„æ–¹å¼æ˜¯ä½¿ç”¨get(K)æ–¹æ³•ã€‚è¿™ä¸ªæ–¹æ³•è¦ä¹ˆè¿”å›å·²ç»ç¼“å­˜çš„å€¼ï¼Œè¦ä¹ˆä½¿ç”¨CacheLoaderå‘ç¼“å­˜åŸå­åœ°åŠ è½½æ–°å€¼ï¼ˆé€šè¿‡load(String key) æ–¹æ³•åŠ è½½ï¼‰ã€‚ç”±äºCacheLoaderå¯èƒ½æŠ›å‡ºå¼‚å¸¸ï¼ŒLoadingCache.get(K)ä¹Ÿå£°æ˜æŠ›å‡ºExecutionExceptionå¼‚å¸¸ã€‚å¦‚æœä½ å®šä¹‰çš„CacheLoaderæ²¡æœ‰å£°æ˜ä»»ä½•æ£€æŸ¥å‹å¼‚å¸¸ï¼Œåˆ™å¯ä»¥é€šè¿‡getUnchecked(K)æŸ¥æ‰¾ç¼“å­˜ï¼›ä½†å¿…é¡»æ³¨æ„ï¼Œä¸€æ—¦CacheLoaderå£°æ˜äº†æ£€æŸ¥å‹å¼‚å¸¸ï¼Œå°±ä¸å¯ä»¥è°ƒç”¨getUnchecked(K)ã€‚","tags":[{"name":"guava","slug":"guava","permalink":"https://yangyichao-mango.github.io/tags/guava/"}]},{"title":"apache-kafka:study-features","date":"2019-11-06T01:57:17.000Z","path":"2019/11/06/apache-kafka:study-features/","text":"å¦‚ä½•ä¸ºKafkaé›†ç¾¤é€‰æ‹©åˆé€‚çš„Partitionsæ•°é‡è¶Šå¤šçš„åˆ†åŒºå¯ä»¥æä¾›æ›´é«˜çš„ååé‡é¦–å…ˆæˆ‘ä»¬éœ€è¦æ˜ç™½ä»¥ä¸‹äº‹å®ï¼šåœ¨kafkaä¸­ï¼Œå•ä¸ªpatitionæ˜¯kafkaå¹¶è¡Œæ“ä½œçš„æœ€å°å•å…ƒã€‚åœ¨producerå’Œbrokerç«¯ï¼Œå‘æ¯ä¸€ä¸ªåˆ†åŒºå†™å…¥æ•°æ®æ˜¯å¯ä»¥å®Œå…¨å¹¶è¡ŒåŒ–çš„ï¼Œæ­¤æ—¶ï¼Œå¯ä»¥é€šè¿‡åŠ å¤§ç¡¬ä»¶èµ„æºçš„åˆ©ç”¨ç‡æ¥æå‡ç³»ç»Ÿçš„ååé‡ï¼Œä¾‹å¦‚å¯¹æ•°æ®è¿›è¡Œå‹ç¼©ã€‚åœ¨consumeræ®µï¼Œkafkaåªå…è®¸å•ä¸ªpartitionçš„æ•°æ®è¢«ä¸€ä¸ªconsumerçº¿ç¨‹æ¶ˆè´¹ã€‚å› æ­¤ï¼Œåœ¨consumerç«¯ï¼Œæ¯ä¸€ä¸ªConsumer Groupå†…éƒ¨çš„consumerå¹¶è¡Œåº¦å®Œå…¨ä¾èµ–äºè¢«æ¶ˆè´¹çš„åˆ†åŒºæ•°é‡ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œåœ¨ä¸€ä¸ªKafkaé›†ç¾¤ä¸­ï¼Œpartitionçš„æ•°é‡è¶Šå¤šï¼Œæ„å‘³ç€å¯ä»¥åˆ°è¾¾çš„ååé‡è¶Šå¤§ã€‚ æˆ‘ä»¬å¯ä»¥ç²—ç•¥åœ°é€šè¿‡ååé‡æ¥è®¡ç®—kafkaé›†ç¾¤çš„åˆ†åŒºæ•°é‡ã€‚å‡è®¾å¯¹äºå•ä¸ªpartitionï¼Œproducerç«¯çš„å¯è¾¾ååé‡ä¸ºpï¼ŒConsumerç«¯çš„å¯è¾¾ååé‡ä¸ºcï¼ŒæœŸæœ›çš„ç›®æ ‡ååé‡ä¸ºtï¼Œé‚£ä¹ˆé›†ç¾¤æ‰€éœ€è¦çš„partitionæ•°é‡è‡³å°‘ä¸ºmax(t/p,t/c)ã€‚åœ¨producerç«¯ï¼Œå•ä¸ªåˆ†åŒºçš„ååé‡å¤§å°ä¼šå—åˆ°æ‰¹é‡å¤§å°ã€æ•°æ®å‹ç¼©æ–¹æ³•ã€ ç¡®è®¤ç±»å‹ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰ã€å¤åˆ¶å› å­ç­‰é…ç½®å‚æ•°çš„å½±å“ã€‚ç»è¿‡æµ‹è¯•ï¼Œåœ¨producerç«¯ï¼Œå•ä¸ªpartitionçš„ååé‡é€šå¸¸æ˜¯åœ¨10MB/så·¦å³ã€‚åœ¨consumerç«¯ï¼Œå•ä¸ªpartitionçš„ååé‡ä¾èµ–äºconsumerç«¯æ¯ä¸ªæ¶ˆæ¯çš„åº”ç”¨é€»è¾‘å¤„ç†é€Ÿåº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å¯¹consumerç«¯çš„ååé‡è¿›è¡Œæµ‹é‡ã€‚ è™½ç„¶éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå¯¹åˆ†åŒºçš„æ•°é‡è¿›è¡Œæ·»åŠ ï¼Œä½†æ˜¯å¯¹äºåŸºäºKeyæ¥ç”Ÿæˆçš„è¿™ä¸€ç±»æ¶ˆæ¯éœ€è¦æˆ‘ä»¬é‡ç‚¹å…³æ³¨ã€‚å½“producerå‘kafkaå†™å…¥åŸºäºkeyçš„æ¶ˆæ¯æ—¶ï¼Œkafkaé€šè¿‡keyçš„hashå€¼æ¥ç¡®å®šæ¶ˆæ¯éœ€è¦å†™å…¥å“ªä¸ªå…·ä½“çš„åˆ†åŒºã€‚é€šè¿‡è¿™æ ·çš„æ–¹æ¡ˆï¼Œkafkaèƒ½å¤Ÿç¡®ä¿ç›¸åŒkeyå€¼çš„æ•°æ®å¯ä»¥å†™å…¥åŒä¸€ä¸ªpartitionã€‚kafkaçš„è¿™ä¸€èƒ½åŠ›å¯¹äºä¸€éƒ¨åˆ†åº”ç”¨æ˜¯æä¸ºé‡è¦çš„ï¼Œä¾‹å¦‚å¯¹äºåŒä¸€ä¸ªkeyçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œconsumeréœ€è¦æŒ‰æ¶ˆæ¯çš„é¡ºåºè¿›è¡Œæœ‰åºæ¶ˆè´¹ã€‚å¦‚æœpartitionçš„æ•°é‡å‘ç”Ÿæ”¹å˜ï¼Œé‚£ä¹ˆä¸Šé¢çš„æœ‰åºæ€§ä¿è¯å°†ä¸å¤å­˜åœ¨ã€‚ä¸ºäº†é¿å…ä¸Šè¿°æƒ…å†µå‘ç”Ÿï¼Œé€šå¸¸çš„è§£å†³åŠæ³•æ˜¯å¤šåˆ†é…ä¸€äº›åˆ†åŒºï¼Œä»¥æ»¡è¶³æœªæ¥çš„éœ€æ±‚ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®æœªæ¥1åˆ°2å¹´çš„ç›®æ ‡ååé‡æ¥è®¾è®¡kafkaçš„åˆ†åŒºæ•°é‡ã€‚ ä¸€å¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥åŸºäºå½“å‰çš„ä¸šåŠ¡ååé‡ä¸ºkafkaé›†ç¾¤åˆ†é…è¾ƒå°çš„brokeræ•°é‡ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œæˆ‘ä»¬å¯ä»¥å‘é›†ç¾¤ä¸­å¢åŠ æ›´å¤šçš„brokerï¼Œç„¶ååœ¨çº¿æ–¹å¼å°†é€‚å½“æ¯”ä¾‹çš„partitionè½¬ç§»åˆ°æ–°å¢åŠ çš„brokerä¸­å»ã€‚é€šè¿‡è¿™æ ·çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ»¡è¶³å„ç§åº”ç”¨åœºæ™¯ï¼ˆåŒ…æ‹¬åŸºäºkeyæ¶ˆæ¯çš„åœºæ™¯ï¼‰çš„æƒ…å†µä¸‹ï¼Œä¿æŒä¸šåŠ¡ååé‡çš„æ‰©å±•æ€§ã€‚ åœ¨è®¾è®¡åˆ†åŒºæ•°æ—¶ï¼Œé™¤äº†ååé‡ï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–å› ç´ å€¼å¾—è€ƒè™‘ã€‚æ­£å¦‚æˆ‘ä»¬åé¢å³å°†çœ‹åˆ°çš„ï¼Œå¯¹äºä¸€äº›åº”ç”¨åœºæ™¯ï¼Œé›†ç¾¤æ‹¥æœ‰è¿‡çš„åˆ†åŒºå°†ä¼šå¸¦æ¥è´Ÿé¢çš„å½±å“ã€‚","tags":[{"name":"Apache Kafka","slug":"Apache-Kafka","permalink":"https://yangyichao-mango.github.io/tags/Apache-Kafka/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šç³»ç»Ÿç‰¹æ€§å­¦ä¹ ","date":"2019-11-03T08:20:21.000Z","path":"2019/11/03/apache-flink:study-features/","text":"Apache Flink å­¦ä¹ ï¼šç³»ç»Ÿç‰¹æ€§å­¦ä¹  æ•™ç¨‹ windowçª—å£çª—å£å¤§å°çª—å£å¤§å°æ˜¯ç”¨æˆ·è‡ªå·±è®¾å®šçš„ï¼Œä½†æ˜¯çª—å£çš„èµ·å§‹å’Œç»“æŸæ—¶é—´ç‚¹æ˜¯ç³»ç»Ÿæ ¹æ®çª—å£å¤§å°å’Œè‡ªç„¶æ•°è¿›è¡Œè®¾å®šçš„ï¼Œä¸ä¼šå‡ºç°è®¾ç½®äº†ä¸€åˆ†é’Ÿçš„çª—å£ï¼Œç»Ÿè®¡çš„æ•°æ®æ˜¯2:30åˆ°3:30çš„æ•°æ® [window_start_time, window_end_time)æ ¹æ®çª—å£å¤§å°å’Œè‡ªç„¶æ•°è¿›è¡Œè®¾å®š å¦‚æœwindowå¤§å°æ˜¯3ç§’ï¼Œé‚£ä¹ˆ1åˆ†é’Ÿå†…ä¼šæŠŠwindowåˆ’åˆ†ä¸ºå¦‚ä¸‹çš„å½¢å¼: 1234[00:00:00,00:00:03)[00:00:03,00:00:06)...[00:00:57,00:01:00) å¦‚æœwindowå¤§å°æ˜¯10ç§’ï¼Œåˆ™windowä¼šè¢«åˆ†ä¸ºå¦‚ä¸‹çš„å½¢å¼ï¼š 1234[00:00:00,00:00:10)[00:00:10,00:00:20)...[00:00:50,00:01:00) watermark123456789@Overridepublic final Watermark getCurrentWatermark() &#123; // this guarantees that the watermark never goes backwards. long potentialWM = currentMaxTimestamp - maxOutOfOrderness; if (potentialWM &gt;= lastEmittedWatermark) &#123; lastEmittedWatermark = potentialWM; &#125; return new Watermark(lastEmittedWatermark);&#125; watermark = max( [å½“å‰å·²åˆ°è¾¾çš„æ—¶é—´æˆ³æœ€æ–°çš„æ•°æ®(currentMaxTimestamp)] - [æœ€å¤§ä¹±åºç­‰å¾…æ—¶é—´(maxOutOfOrderness)], watermark ) è§¦å‘çª—å£è¿ç®—æ¡ä»¶1.å½“å‰æœ€æ–°æ•°æ®åˆ°è¾¾è¿›è¡Œåˆ¤æ–­ï¼šå½“å‰åˆ°è¾¾eventçš„time(timestamp) ï¼œ watermarkåˆ™è§¦å‘ï¼Œè¡¨ç¤ºæ•°æ®æ˜¯è¶…è¿‡äº†æœ€å¤§ç­‰å¾…æ—¶é—´ï¼Œå·²ç»å»¶è¿Ÿåˆ°è¾¾çš„ï¼Œåˆ™ä¼šè§¦å‘ 2.å½“å‰æœ€æ–°æ•°æ®åˆ°è¾¾è¿›è¡Œåˆ¤æ–­ï¼šæœ€æ–°çš„watermark &gt;= window_end_timeï¼ˆå¯¹äºout-of-orderä»¥åŠæ­£å¸¸çš„æ•°æ®è€Œè¨€ï¼‰ï¼Œåœ¨[window_start_time, window_end_time)ä¸­æœ‰æ•°æ®å­˜åœ¨ 3.è€Œä¸”ï¼Œè¿™é‡Œè¦å¼ºè°ƒä¸€ç‚¹ï¼Œwatermarkå’ŒcurrentMaxTimestampæ˜¯ä¸€ä¸ªå…¨å±€çš„å€¼ï¼Œä¸æ˜¯æŸä¸€ä¸ªkeyä¸‹çš„å€¼ï¼Œæ‰€ä»¥å³ä½¿ä¸æ˜¯åŒä¸€ä¸ªkeyçš„æ•°æ®ï¼Œå…¶warmarkä¹Ÿä¼šå¢åŠ  è¯­ä¹‰æ˜¯ï¼šcurrentMaxTimestampæ˜¯å½“å‰åˆ°è¾¾çš„æœ€å¤§æ—¶é—´æˆ³æ•°æ®ï¼Œä»£è¡¨æ—¶é—´æˆ³ä¸ºcurrentMaxTimestampçš„æ•°æ®å·²ç»åˆ°è¾¾äº†ï¼Œæ‰€ä»¥æ‰€èƒ½ç­‰å¾…çš„æ•°æ®çš„æ—¶é—´æˆ³ï¼ˆmax_out_of_ordernessï¼‰åªèƒ½ä¸ºwatermark = currentMaxTimestamp - maxOutOfOrderness çª—å£è®¡ç®—Window reduceï¼ŒWindow aggregate å’Œ Window Fold æ˜¯å¢é‡èšåˆï¼Œæ¯æ¥ä¸€æ¡æ•°æ®å°±è®¡ç®—ä¸€æ¬¡ï¼Œé«˜æ•ˆ Window applyï¼ˆWindow process çš„è€ç‰ˆæœ¬ï¼‰ å’Œ Window process æ˜¯å…¨é‡èšåˆï¼Œè§¦å‘çª—å£è®¡ç®—æ—¶å…¨é‡è®¡ç®— è¢«KeysåŒ–ä¸éè¢«KeysåŒ–Windowsè¦æŒ‡å®šçš„ç¬¬ä¸€ä»¶äº‹æ˜¯æ‚¨çš„æµæ˜¯å¦åº”è¯¥ä½¿ç”¨keyedWindowï¼Œä¸€èˆ¬éƒ½ä¸ä¸šåŠ¡é€»è¾‘æœ‰å…³ï¼Œæ¯”å¦‚è¯´ä½¿ç”¨ä¸€åˆ†é’Ÿçš„çª—å£è¿›è¡Œå»é‡ã€‚ä½¿ç”¨keyBy(â€¦)å°†æ‚¨çš„æ— é™æµåˆ†æˆé€»è¾‘KeyåŒ–çš„æ•°æ®æµã€‚å¦‚æœkeyBy(â€¦)æœªè°ƒç”¨ï¼Œåˆ™è¡¨ç¤ºæ‚¨çš„æµä¸æ˜¯è¢«KeysåŒ–çš„ã€‚ å¯¹äºè¢«KeyåŒ–çš„æ•°æ®æµï¼Œå¯ä»¥å°†ä¼ å…¥æ•°æ®ï¼ˆObjectï¼‰çš„çš„ä»»ä½•å±æ€§ç”¨ä½œé”®ï¼‰ã€‚æ‹¥æœ‰è¢«KeyåŒ–çš„æ•°æ®æµå°†å…è®¸æ‚¨çš„çª—å£è®¡ç®—ç”±å¤šä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œå› ä¸ºæ¯ä¸ªKeyåŒ–çš„æ•°æ®æµå¯ä»¥ç‹¬ç«‹äºå…¶ä½™ä»»åŠ¡è¿›è¡Œå¤„ç†ã€‚å¼•ç”¨ç›¸åŒKeysçš„æ‰€æœ‰æ•°æ®å°†è¢«å‘é€åˆ°åŒä¸€ä¸ªå¹¶è¡Œä»»åŠ¡è¿›è¡Œè®¡ç®—ã€‚ åœ¨éè¢«KeyåŒ–çš„æ•°æ®æµçš„æƒ…å†µä¸‹ï¼Œæ‚¨çš„åŸå§‹æµå°†ä¸ä¼šè¢«æ‹†åˆ†ä¸ºå¤šä¸ªé€»è¾‘æµï¼Œå¹¶ä¸”æ‰€æœ‰çª—å£é€»è¾‘å°†ç”±å•ä¸ªä»»åŠ¡æ‰§è¡Œï¼Œå³å¹¶è¡Œåº¦ä¸º1ã€‚ sql1.åœ¨flinkSqlä¸­ï¼Œå¦‚æœä½¿ç”¨groupByï¼Œå°½é‡ä½¿ç”¨çª—å£ï¼Œå¦åˆ™ä¼šè®¤ä¸ºè¢«groupByçš„æ•°æ®ä¼šé»˜è®¤äººä¸ºæ•´ä¸ªçª—å£å†…çš„æ•°æ®è¿˜æ²¡æœ‰åˆ°è¾¾ï¼Œæ‰€ä»¥ä¼šä¸€ç›´ç­‰å¾…ï¼Œä¸ä¼šäº§å‡ºæ•°æ® update-mode: append / update åˆ†ä¸º update stream æ¨¡å¼å’Œ append stream æ¨¡å¼ windowèšåˆä¸ºappend mode streamï¼Œgroupbyèšåˆä¸ºupdate mode stream Flinkç”Ÿæˆ Timestamps å’Œ Watermarksä¸ºäº†è®©event timeå·¥ä½œï¼ŒFlinkéœ€è¦çŸ¥é“äº‹ä»¶çš„æ—¶é—´æˆ³ï¼Œè¿™æ„å‘³ç€æµä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½éœ€è¦åˆ†é…å…¶äº‹ä»¶æ—¶é—´æˆ³ã€‚è¿™ä¸ªé€šå¸¸æ˜¯é€šè¿‡æŠ½å–æˆ–è€…è®¿é—®äº‹ä»¶ä¸­æŸäº›å­—æ®µçš„æ—¶é—´æˆ³æ¥è·å–çš„ã€‚ æ—¶é—´æˆ³çš„åˆ†é…ä¼´éšç€æ°´å°çš„ç”Ÿæˆï¼Œå‘Šè¯‰ç³»ç»Ÿäº‹ä»¶æ—¶é—´ä¸­çš„è¿›åº¦ã€‚ è¿™é‡Œæœ‰ä¸¤ç§æ–¹å¼æ¥åˆ†é…æ—¶é—´æˆ³å’Œç”Ÿæˆæ°´å°: ç›´æ¥åœ¨æ•°æ®æµæºä¸­è¿›è¡Œã€‚ é€šè¿‡timestamp assignerå’Œwatermark generatorç”Ÿæˆ:åœ¨Flinkä¸­ï¼Œtimestampåˆ†é…å™¨ä¹Ÿå®šä¹‰äº†ç”¨æ¥å‘å°„çš„æ°´å°ã€‚ æ•°æ®æµæºç”ŸæˆTimestampså’ŒWatermarksæ•°æ®æµæºå¯ä»¥ç›´æ¥ä¸ºå®ƒä»¬äº§ç”Ÿçš„æ•°æ®å…ƒç´ åˆ†é…timestampï¼Œå¹¶ä¸”ä»–ä»¬ä¹Ÿèƒ½å‘é€æ°´å°ã€‚è¿™æ ·åšçš„è¯ï¼Œå°±æ²¡å¿…è¦å†å»å®šä¹‰timestampåˆ†é…å™¨äº†ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯:å¦‚æœä¸€ä¸ªtimestampåˆ†é…å™¨è¢«ä½¿ç”¨çš„è¯ï¼Œç”±æºæä¾›çš„ä»»ä½•timestampå’Œwatermarkéƒ½ä¼šè¢«é‡å†™ã€‚ æ—¶é—´æˆ³åˆ†é…å™¨/æ°´å°ç”Ÿæˆå™¨ï¼ˆTimestamp Assigners / Watermark Generatorsï¼‰Timestampåˆ†é…å™¨è·å–ä¸€ä¸ªæµå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„å¸¦æœ‰Timestampå…ƒç´ å’Œæ°´å°çš„æµã€‚å¦‚æœåŸå§‹æµå·²ç»æœ‰æ—¶é—´æˆ³å’Œ/æˆ–æ°´å°ï¼Œåˆ™Timestampåˆ†é…ç¨‹åºå°†è¦†ç›–å®ƒä»¬ Timestampåˆ†é…å™¨é€šå¸¸åœ¨æ•°æ®æºä¹‹åç«‹å³æŒ‡å®šï¼Œä½†è¿™å¹¶ä¸æ˜¯ä¸¥æ ¼è¦æ±‚çš„ã€‚é€šå¸¸æ˜¯åœ¨timestampåˆ†é…å™¨ä¹‹å‰å…ˆè§£æ(MapFunction)å’Œè¿‡æ»¤(FilterFunction)ã€‚åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œéƒ½éœ€è¦åœ¨äº‹ä»¶æ—¶é—´ä¸Šçš„ç¬¬ä¸€ä¸ªæ“ä½œ(ä¾‹å¦‚ç¬¬ä¸€ä¸ªçª—å£æ“ä½œ)ä¹‹å‰æŒ‡å®štimestampåˆ†é…ç¨‹åºã€‚æœ‰ä¸€ä¸ªç‰¹æ®Šæƒ…å†µï¼Œå½“ä½¿ç”¨Kafkaä½œä¸ºæµä½œä¸šçš„æ•°æ®æºæ—¶ï¼ŒFlinkå…è®¸åœ¨æºå†…éƒ¨æŒ‡å®štimestampåˆ†é…å™¨å’Œwatermarkç”Ÿæˆå™¨ã€‚æ›´å¤šå…³äºå¦‚ä½•è¿›è¡Œçš„ä¿¡æ¯è¯·å‚è€ƒKafka Connectorçš„æ–‡æ¡£ã€‚ ç›´æ¥åœ¨FlinkKafkaConsumer010ä¸Šé¢ä½¿ç”¨assignTimestampsAndWatermarkså¯ä»¥æ ¹æ®kafka sourceçš„partitionsçš„ç‰¹æ€§è¿›è¡Œè®¾ç½®Timestampså’ŒWatermarksï¼Œè®©ç”¨æˆ·åšä¸€äº›ç‰¹æ®Šçš„å¤„ç† Running timestamp extractors / watermark generators directly inside the Kafka source, per Kafkapartition, allows users to let them exploit the per-partition characteristics. logWeb UIæŸ¥æ‰¾logJobManger logï¼š å±•ç¤ºæ•´ä¸ªä½œä¸šçš„çŠ¶æ€å˜åŒ–ï¼ˆä¾‹å¦‚ï¼Œä»create åˆ°deployåˆ°runningå†åˆ°failedï¼‰ï¼Œé€šè¿‡jobManger logå¯ä»¥æŸ¥çœ‹ä½œä¸šå†å²å¤±è´¥çš„è®°å½•å’Œç›´æ¥åŸå› ã€‚ TaskManager logï¼š è°ƒåº¦åˆ°è¯¥TaskManagerä¸Šçš„task çš„æ‰“å°çš„ç›¸å…³logã€‚ shuffleè¢«keyByçš„æ•°æ®æµä¸­ï¼Œç›¸åŒçš„keyçš„æ•°æ®ä¼šè¢«å‘é€åˆ°åŒä¸€ä¸ªslotä¸­è¿è¡Œï¼ˆpartitinerå†³å®šï¼‰ï¼Œä¹Ÿå°±æ˜¯TaskManagerä¸­slotè¿›è¡Œshuffleçš„è¿‡ç¨‹å¦‚æœæœ‰å¤šä¸ªproducerå¹¶ä¸”producerçš„æ•°é‡å’Œpartitionæ•°é‡ç›¸åŒï¼Œåˆ™æ¯ä¸ªproducerå†™ä¸€ä¸ªpartition Savepointså’ŒCheckpointsç”¨ Data Stream API ç¼–å†™çš„ç¨‹åºå¯ä»¥ä» savepoint ç»§ç»­æ‰§è¡Œã€‚Savepoints å…è®¸åœ¨ä¸ä¸¢å¤±ä»»ä½•çŠ¶æ€çš„æƒ…å†µä¸‹å‡çº§ç¨‹åºå’Œ Flink é›†ç¾¤ã€‚ Savepoints æ˜¯æ‰‹åŠ¨è§¦å‘çš„ Checkpointsï¼Œå®ƒä¾é å¸¸è§„çš„ Checkpoint æœºåˆ¶è·å–ç¨‹åºçš„å¿«ç…§å¹¶å°†å…¶å†™å…¥ state backendã€‚åœ¨æ‰§è¡ŒæœŸé—´ï¼Œç¨‹åºä¼šå®šæœŸåœ¨ worker èŠ‚ç‚¹ä¸Šåˆ›å»ºå¿«ç…§å¹¶ç”Ÿæˆ Checkpointsã€‚å¯¹äºæ¢å¤ï¼ŒFlink ä»…éœ€è¦æœ€åå®Œæˆçš„ Checkpointï¼Œè€Œä¸€æ—¦å®Œæˆäº†æ–°çš„ Checkpointï¼Œæ—§çš„å°±å¯ä»¥è¢«ä¸¢å¼ƒã€‚ Savepoints ç±»ä¼¼äºè¿™äº›å®šæœŸçš„ Checkpointsï¼Œé™¤äº†å®ƒä»¬æ˜¯ç”±ç”¨æˆ·è§¦å‘å¹¶ä¸”åœ¨æ–°çš„ Checkpoints å®Œæˆæ—¶ä¸ä¼šè‡ªåŠ¨è¿‡æœŸã€‚ä½ å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œ æˆ–åœ¨å–æ¶ˆä¸€ä¸ª job æ—¶é€šè¿‡ REST API æ¥åˆ›å»º Savepointsã€‚","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šå®æ—¶åœºæ™¯ä¸‹çš„åº”ç”¨","date":"2019-11-03T05:30:05.000Z","path":"2019/11/03/apache-flink:study-realtime-scenario/","text":"Apache Flink å­¦ä¹ ï¼šå®æ—¶åœºæ™¯ä¸‹çš„åº”ç”¨ ç”¨æˆ·éœ€æ±‚åœºæ™¯ç”¨æˆ·æƒ³è¦æŸ¥çœ‹ ç‰ˆæœ¬ï¼Œæœºå‹ï¼Œå›½å®¶ï¼ŒåŸå¸‚ ç­‰ç­‰ç»´åº¦ä¸‹æŒ‰ç…§åˆ†é’Ÿçš„æ—¶é—´ç²’åº¦çš„è®¾å¤‡æ´»è·ƒï¼Œæ–°å¢è®¾å¤‡æ•°ï¼Œé¦–æ¬¡æ´»è·ƒè®¾å¤‡æ•° ç”¨æˆ·éœ€æ±‚-&gt;æ¶æ„æ–¹æ¡ˆè®¾è®¡ æ•°æ®æ‰€å¤„é˜¶æ®µ åŠŸèƒ½æè¿° æ•°æ®source å„ç§å„æ ·çš„æ‰“åˆ°kafkaçš„ç”¨æˆ·è¡Œä¸ºæ•°æ®çš„æ—¥å¿— æ•°æ®process å®æ—¶å¼•æ“æ¶ˆè´¹kafkaï¼Œæ ¹æ®æ•°æ®æœåŠ¡åŒ–æä¾›çš„æ¥å£åˆ¤æ–­å½“å‰ç”¨æˆ·æ˜¯å¦æ˜¯æ–°å¢ï¼Œæ´»è·ƒï¼Œé¦–æ¬¡æ´»è·ƒï¼Œå°†ç”¨æˆ·çš„ç›¸å…³æ•°æ®æ‰“åˆ°ä¸‹æ¸¸kafka æ•°æ®sink ç»“æœkafka olapå¼•æ“ æ¶ˆè´¹sink kafka æ•°æ®äº§å“ é€šè¿‡BIç­‰çš„äº§å“å‘ˆç°ç»™ç”¨æˆ· æ¶æ„è®¾è®¡-&gt;é€‰æ‹©å®æ—¶è®¡ç®—å¼•æ“ä¸ºä»€ä¹ˆä½¿ç”¨flinkï¼š A.ä¿è¯æ¶ˆè´¹ä¸€æ¬¡ï¼šcheckpointå’Œsavepoint å®¹é”™ B.æ—¶é—´å±æ€§ï¼šäº‹ä»¶ï¼Œæ³¨å…¥ï¼Œå¤„ç†æ—¶é—´ ä¼˜ç‚¹ï¼šäº‹ä»¶æ—¶é—´çš„å±æ€§å¯ä»¥è¢«å¹¿æ³›åº”ç”¨ï¼Œæ¯”å¦‚ä¸€èˆ¬çš„åˆ†æåœºæ™¯éƒ½æ˜¯åˆ†æç”¨æˆ·æŸä¸ªæ—¶é—´æ®µçš„ç”¨æˆ·ç›¸å…³æŒ‡æ ‡ï¼Œè€Œä¸æ˜¯äº‹ä»¶å¤„ç†æŸä¸ªæ—¶é—´æ®µçš„ç”¨æˆ·ç›¸å…³æŒ‡æ ‡ flinkå®ç°æ–¹æ¡ˆç¬¬ä¸€ç§æ–¹æ¡ˆæ–¹æ¡ˆæ–°å¢åœºæ™¯ä¸‹ï¼Œæ¯æ¶ˆè´¹ä¸€æ¡source kafkaç”¨æˆ·æ•°æ®å°±åˆ¤æ–­ä¸€æ¬¡æ˜¯å¦ä¸ºæ–°å¢ï¼Œåˆ¤æ–­æ–¹å¼å¯ä»¥é€‰æ‹©è‡ªå·±ç»´æŠ¤å†å²å…¨é‡æ•°æ®ï¼Œæˆ–è€…ä½¿ç”¨æ•°æ®æœåŠ¡åŒ–æä¾›çš„æ¥å£ï¼Œæœ€åå°†ç»“æœå†™å…¥sink kafka å­˜åœ¨çš„é—®é¢˜ æ•°æ®å¤„ç†é˜¶æ®µ é—®é¢˜ ç»“æœï¼ˆä»…ä»…æŒ‡å½“å‰é—®é¢˜ä¼šäº§ç”Ÿçš„ç»“æœï¼‰ æ˜¯å¦å¯è§£å†³ æ•°æ®source åŒä¸€ä¸ªç”¨æˆ·çš„è¡Œä¸ºæ•°æ®åˆ°è¾¾æ—¶é—´é—´éš”å¾ˆå°ï¼Œå‡ ç§’å†…å°±å¯èƒ½ä¼šäº§ç”Ÿå‡ åæ¡è¡Œä¸ºæ—¥å¿—ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºæ–°å¢ï¼Œæ´»è·ƒç”¨æˆ·æ—¶å¯èƒ½ä¼šè¢«é‡å¤åˆ¤æ–­ æœ€ç»ˆæ•°æ®ç»“æœï¼çœŸå®ç»“æœ å¯éƒ¨åˆ†è§£å†³ æ•°æ®process è‡ªå·±ç»´æŠ¤å…¨é‡æ•°æ®1.æ¯åˆ¤æ–­ä¸€æ¡å°±æ›´æ–°å†å²å…¨é‡æ•°æ®å°±ä¸å­˜åœ¨é—®é¢˜2.å¦‚æœå†å²å…¨é‡æ•°æ®æ›´æ–°æœ‰é—®é¢˜å°±ä¼šäº§ç”Ÿå’Œæ•°æ®æœåŠ¡åŒ–ä¸€æ ·çš„ä¸‹é¢ä¸¤ç§é—®é¢˜ å¯éƒ¨åˆ†è§£å†³ æ•°æ®process æ•°æ®æœåŠ¡åŒ–ç»´æŠ¤å…¨é‡æ•°æ®ä¸”æ›´æ–°ä¸åŠæ—¶åœ¨æ–°å¢çš„åœºæ™¯ä¸‹ï¼Œä¸€ä¸ªæ–°å¢ç”¨æˆ·ä½¿ç”¨appå¯èƒ½ä¼šåœ¨çŸ­æ—¶é—´å†…ä¸ŠæŠ¥æˆç™¾ä¸Šåƒæ¡è¡Œä¸ºæ—¥å¿—ï¼Œå¦‚æœç¬¬ä¸€æ¡æ•°æ®åˆ¤æ–­å‡ºæ¥è¿™ä¸ªç”¨æˆ·æ˜¯æ–°å¢ï¼Œä¸‹ä¸€æ¡æ•°æ®åˆ¤æ–­æ—¶ï¼Œæ•°æ®æœåŠ¡åŒ–æä¾›çš„å…¨é‡ç”¨æˆ·é‡Œè¿˜æ²¡æœ‰åŠæ—¶å°†è¿™æ¡æ–°å¢ç”¨æˆ·æ•°æ®æ·»åŠ è¿›å»ï¼Œåˆ™è¿™æ¡æ•°æ®ä¹Ÿä¼šè¢«åˆ¤æ–­ä¸ºæ–°å¢ï¼Œå°±ä¼šå¯¼è‡´æœ€ç»ˆç»“æœé‡å¤ æœ€ç»ˆæ•°æ®ç»“æœï¼çœŸå®ç»“æœ å¯éƒ¨åˆ†è§£å†³ æ•°æ®process æ•°æ®æœåŠ¡åŒ–ç»´æŠ¤å…¨é‡æ•°æ®ä¸”æ›´æ–°è¿‡å¿«æ•°æ®æœåŠ¡åŒ–æ›´æ–°é€Ÿåº¦å¿«äºflinkæ¶ˆè´¹source kafkaçš„é€Ÿåº¦ï¼šå°±ä¼šå¯¼è‡´æœ¬æ¥æ˜¯æ–°å¢çš„è®¾å¤‡è¢«åˆ¤æ–­ä¸æ˜¯æ–°å¢ï¼Œå¯¼è‡´æœ€ç»ˆç»“æœæ¼åˆ¤ æœ€ç»ˆæ•°æ®ç»“æœï¼œçœŸå®ç»“æœ æš‚æ—¶æ— æ³•è§£å†³ è§£å†³æ–¹æ¡ˆåç»­è§£å†³æ–¹æ³•åªè®¨è®ºä¸Šè¿°å¯éƒ¨åˆ†è§£å†³çš„é—®é¢˜ æ•°æ®å¤„ç†é˜¶æ®µ é—®é¢˜ è§£å†³æ–¹æ¡ˆ æ•°æ®source åŒä¸€ä¸ªç”¨æˆ·çš„è¡Œä¸ºæ•°æ®åˆ°è¾¾æ—¶é—´é—´éš”å¾ˆå°ï¼Œå¯èƒ½ä¼šè¢«é‡å¤åˆ¤æ–­ ä½¿ç”¨flinkçª—å£è§£å†³éƒ¨åˆ†é—®é¢˜ä½¿ç”¨æ»šåŠ¨çª—å£è§£å†³ï¼Œå°†ä¸€æ®µæ—¶é—´å†…çš„ç”¨æˆ·è¡Œä¸ºæ”¶é›†ï¼Œç„¶ååˆ°è¾¾çª—å£ç»“æŸæ—¶é—´å¤„ç†åå†è¿›è¡Œä¸ŠæŠ¥ã€‚å‡è®¾è®¾ç½®ä¸€å°æ—¶çš„çª—å£ï¼Œåˆ™å°†è¿™ä¸€å°æ—¶çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®åªå–ä¸€æ¡è¿›è¡Œåˆ¤æ–­æ˜¯å¦ä¸ºæ–°å¢ï¼Œåˆ™å¯ä»¥æå¤§çš„ä¿è¯å½“å‰ç”¨æˆ·åˆ¤æ–­ä¸ºæ–°å¢æ—¶ï¼Œä¸‹ä¸€å°æ—¶çª—å£ä¸­è¿™ä¸ªç”¨æˆ·ä¸å¤ªå¯èƒ½è¢«åˆ¤æ–­ä¸ºæ–°å¢äº†ï¼Œå› ä¸ºæ•°æ®æœåŠ¡åŒ–æ²¡æœ‰é‚£ä¹ˆæ…¢ æ•°æ®process æ•°æ®æœåŠ¡åŒ–ç»´æŠ¤å…¨é‡æ•°æ®ä¸”æ›´æ–°ä¸åŠæ—¶ï¼Œæœ€ç»ˆç»“æœé‡å¤ ç¬¬ä¸€ç§æ–¹æ¡ˆ-&gt;ç¬¬äºŒç§æ–¹æ¡ˆæ–¹æ¡ˆä½¿ç”¨çª—å£å¯ä»¥éƒ¨åˆ†è§£å†³åœ¨æ–°å¢æ´»è·ƒç­‰åœºæ™¯ä¸‹ç”¨æˆ·è¡Œä¸ºæ•°æ®é‡å¤çš„é—®é¢˜ ä½†æ˜¯ä½¿ç”¨äº†çª—å£ä¹Ÿä¼šå¼•å…¥é—®é¢˜ï¼Œå°±æ˜¯è™½ç„¶å¤§çª—å£å¯ä»¥ä¿è¯å°½å¯èƒ½å»é‡ï¼Œä½†æ˜¯æ•°æ®çš„å®æ—¶æ€§å¤§å¤§é™ä½ï¼Œæ‰€ä»¥çª—å£è®¾ç½®ä¸èƒ½å¤§ä¹Ÿä¸èƒ½å°ï¼Œçª—å£å¤§ä¿è¯ä¸äº†æ•°æ®äº§å‡ºåŠæ—¶æ€§ï¼Œçª—å£å°å»é‡æ•ˆæœå·®ï¼Œæ‰€ä»¥æœ€å¤§çª—å£å°±ä¸ºä¸€åˆ†é’Ÿï¼Œå’Œç”¨æˆ·æœŸæœ›çœ‹æ¿ä¸­ç»“æœä¸€è‡´ å­˜åœ¨çš„é—®é¢˜ æ•°æ®å¤„ç†é˜¶æ®µ é—®é¢˜ ç»“æœï¼ˆä»…ä»…æŒ‡å½“å‰é—®é¢˜ä¼šäº§ç”Ÿçš„ç»“æœï¼‰ æ˜¯å¦å¯è§£å†³ æ•°æ®source ç”±äºç”¨æˆ·è¡Œä¸ºæ•°æ®åˆ°è¾¾sourceï¼Œæˆ–è€…ä»sourceåˆ°è¾¾processé˜¶æ®µï¼Œç”±äºç½‘ç»œå»¶è¿Ÿç­‰çš„é—®é¢˜ï¼Œä¼šå¯¼è‡´å¤„ç†ç”¨æˆ·æ•°æ®æ—¶æœ‰ä¹±åºæƒ…å†µæ¯”å¦‚è®¡ç®—å®æ—¶æ´»è·ƒè®¾å¤‡ï¼Œä¸Šä¸€åˆ†é’Ÿçš„æ•°æ®å¦‚æœä¸‹ä¸€åˆ†é’Ÿæ‰åˆ°è¾¾ï¼Œåˆ™è¯¥æ¡æ•°æ®å°±ä¼šè¢«ä¸Šä¸€åˆ†é’Ÿæ¼ç®— æœ€ç»ˆæ•°æ®ç»“æœï¼œçœŸå®ç»“æœ å¯éƒ¨åˆ†è§£å†³ æ•°æ®process è§£å†³æ–¹æ¡ˆ æ•°æ®å¤„ç†é˜¶æ®µ é—®é¢˜ è§£å†³æ–¹æ¡ˆ æ•°æ®source æ•°æ®ä¹±åºå»¶è¿Ÿæ¼ç®— åœ¨flinkçª—å£è®¡ç®—ä¸­ï¼Œé€šè¿‡timestampå’Œwatermarkç‰¹æ€§æ¥å°½å¯èƒ½è§£å†³ æ•°æ®process ç¬¬äºŒç§æ–¹æ¡ˆ-&gt;ç¬¬ä¸‰ç§æ–¹æ¡ˆæ–¹æ¡ˆè®¾ç½®ä¸€åˆ†é’Ÿçš„çª—å£ï¼Œç„¶åè®¾ç½®ä¸€åˆ†é’Ÿçš„æœ€å¤§å»¶è¿Ÿç­‰å¾…æ—¶é—´ï¼Œå…¶è¯­ä¹‰æ˜¯ä¿è¯æ•°æ®æœ€å¤šå»¶è¿Ÿä¸€åˆ†é’Ÿåˆ°è¾¾ï¼Œåªè¦å¯ä»¥ä¿è¯è¿™ä¸ªè¯­ä¹‰å¯ä»¥ä¿è¯æœ€åæ•°æ®çš„æ­£ç¡®æ€§","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"},{"name":"å®æ—¶è®¡ç®—","slug":"å®æ—¶è®¡ç®—","permalink":"https://yangyichao-mango.github.io/tags/å®æ—¶è®¡ç®—/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šBoundedOutOfOrdernessTimestampExtractor","date":"2019-11-02T08:48:43.000Z","path":"2019/11/02/apache-flink:study-BoundedOutOfOrdernessTimestampExtractor/","text":"Apache Flink å­¦ä¹ ï¼šBoundedOutOfOrdernessTimestampExtractor æºç 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/* * Licensed to the Apache Software Foundation (ASF) under one * or more contributor license agreements. See the NOTICE file * distributed with this work for additional information * regarding copyright ownership. The ASF licenses this file * to you under the Apache License, Version 2.0 (the * \"License\"); you may not use this file except in compliance * with the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.flink.streaming.api.functions.timestamps;import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks;import org.apache.flink.streaming.api.watermark.Watermark;import org.apache.flink.streaming.api.windowing.time.Time;/** * This is a &#123;@link AssignerWithPeriodicWatermarks&#125; used to emit Watermarks that lag behind the element with * the maximum timestamp (in event time) seen so far by a fixed amount of time, &lt;code&gt;t_late&lt;/code&gt;. This can * help reduce the number of elements that are ignored due to lateness when computing the final result for a * given window, in the case where we know that elements arrive no later than &lt;code&gt;t_late&lt;/code&gt; units of time * after the watermark that signals that the system event-time has advanced past their (event-time) timestamp. * */public abstract class BoundedOutOfOrdernessTimestampExtractor&lt;T&gt; implements AssignerWithPeriodicWatermarks&lt;T&gt; &#123; private static final long serialVersionUID = 1L; /** The current maximum timestamp seen so far. */ /** æ•°æ®æµçš„æœ€å¤§æ—¶é—´æˆ³ */ private long currentMaxTimestamp; /** The timestamp of the last emitted watermark. */ /** æœ€åä¸€æ¬¡å·²æäº¤çš„æœ€æ–° [æ°´å°]ï¼ˆå½“å‰æ‰¹æ¬¡æ°´å°ï¼‰ */ private long lastEmittedWatermark = Long.MIN_VALUE; /** * The (fixed) interval between the maximum seen timestamp seen in the records * and that of the watermark to be emitted. * æœ€å¤§ä¹±åºæ—¶é—´é—´éš” * å°†è¦è¢«æäº¤çš„ [æ°´å°] å’Œ [æ•°æ®æµçš„æœ€å¤§æ—¶é—´æˆ³] çš„å›ºå®šæ—¶é—´é—´éš” * å¦‚æœ [æ•°æ®æµçš„æœ€å¤§æ—¶é—´æˆ³] - [å½“å‰æ‰¹æ¬¡æ°´å°] &gt; [æœ€å¤§ä¹±åºæ—¶é—´é—´éš”] * åˆ™å°±ä¼šæ‰“ä¸Šä¸€ä¸ªæ–°çš„ [æ°´å°] */ private final long maxOutOfOrderness; public BoundedOutOfOrdernessTimestampExtractor(Time maxOutOfOrderness) &#123; if (maxOutOfOrderness.toMilliseconds() &lt; 0) &#123; throw new RuntimeException(\"Tried to set the maximum allowed \" + \"lateness to \" + maxOutOfOrderness + \". This parameter cannot be negative.\"); &#125; this.maxOutOfOrderness = maxOutOfOrderness.toMilliseconds(); this.currentMaxTimestamp = Long.MIN_VALUE + this.maxOutOfOrderness; &#125; public long getMaxOutOfOrdernessInMillis() &#123; return maxOutOfOrderness; &#125; /** * Extracts the timestamp from the given element. * ä»å½“å‰æ•°æ®æµå…ƒç´ ä¸­è·å– [æ—¶é—´æˆ³] å­—æ®µï¼Œéœ€è¦ç”¨æˆ·æ ¹æ®ä¸šåŠ¡è‡ªå®šä¹‰ * * @param element The element that the timestamp is extracted from. * @return The new timestamp. */ public abstract long extractTimestamp(T element); /** * å¦‚æœ [å½“å‰æ•°æ®æµæœ€å¤§æ—¶é—´æˆ³] - [æœ€å¤§ä¹±åºæ—¶é—´é—´éš”] &gt;= [æœ€åä¸€æ¬¡å·²æäº¤çš„æ—¶é—´æˆ³] * åˆ™æ›´æ–° [æœ€åä¸€æ¬¡å·²æäº¤çš„æ—¶é—´æˆ³] */ @Override public final Watermark getCurrentWatermark() &#123; // this guarantees that the watermark never goes backwards. long potentialWM = currentMaxTimestamp - maxOutOfOrderness; if (potentialWM &gt;= lastEmittedWatermark) &#123; lastEmittedWatermark = potentialWM; &#125; return new Watermark(lastEmittedWatermark); &#125; /** * è·å–æ•°æ®æµä¸­å½“å‰æœ€å¤§æ—¶é—´æˆ³ */ @Override public final long extractTimestamp(T element, long previousElementTimestamp) &#123; long timestamp = extractTimestamp(element); if (timestamp &gt; currentMaxTimestamp) &#123; currentMaxTimestamp = timestamp; &#125; return timestamp; &#125;&#125; ****12345678910111213141516171819/** * Sets the time characteristic for all streams create from this environment, e.g., processing * time, event time, or ingestion time. * * &lt;p&gt;If you set the characteristic to IngestionTime of EventTime this will set a default * watermark update interval of 200 ms. If this is not applicable for your application * you should change it using &#123;@link ExecutionConfig#setAutoWatermarkInterval(long)&#125;. * * @param characteristic The time characteristic. */@PublicEvolvingpublic void setStreamTimeCharacteristic(TimeCharacteristic characteristic) &#123; this.timeCharacteristic = Preconditions.checkNotNull(characteristic); if (characteristic == TimeCharacteristic.ProcessingTime) &#123; getConfig().setAutoWatermarkInterval(0); &#125; else &#123; getConfig().setAutoWatermarkInterval(200); &#125;&#125; windowè§¦å‘æœºåˆ¶windowçš„è§¦å‘æœºåˆ¶ï¼Œæ˜¯å…ˆæŒ‰ç…§è‡ªç„¶æ—¶é—´å°†windowåˆ’åˆ†ï¼Œå¦‚æœwindowå¤§å°æ˜¯3ç§’ï¼Œé‚£ä¹ˆ1åˆ†é’Ÿå†…ä¼šæŠŠwindowåˆ’åˆ†ä¸ºå¦‚ä¸‹çš„å½¢å¼: 1234[00:00:00,00:00:03)[00:00:03,00:00:06)...[00:00:57,00:01:00) å¦‚æœwindowå¤§å°æ˜¯10ç§’ï¼Œåˆ™windowä¼šè¢«åˆ†ä¸ºå¦‚ä¸‹çš„å½¢å¼ï¼š 1234[00:00:00,00:00:10)[00:00:10,00:00:20)...[00:00:50,00:01:00)","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Apache Hadoop å­¦ä¹ ï¼šhdfs shell å‘½ä»¤","date":"2019-10-30T08:27:45.000Z","path":"2019/10/30/apache-hadoop:study-hdfs-shell/","text":"Apache Hadoop å­¦ä¹ ï¼šhdfs shell å‘½ä»¤ ls1hdfs dfs -ls / put1hadoop fs -put localfile /user/hadoop/hadoopfile get1hadoop fs -get /user/hadoop/hadoopfile localfile","tags":[{"name":"Apache Hadoop","slug":"Apache-Hadoop","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hadoop/"},{"name":"Hdfs","slug":"Hdfs","permalink":"https://yangyichao-mango.github.io/tags/Hdfs/"}]},{"title":"Macå®‰è£…Nginx-1.17.3ä»¥åŠç›¸å…³é…ç½®æ–‡ä»¶","date":"2019-10-28T13:19:10.000Z","path":"2019/10/28/nginx:1-17-3-mac-install-and-confs-set/","text":"Macå®‰è£…Nginx-1.17.3ä»¥åŠç›¸å…³é…ç½®æ–‡ä»¶ å®‰è£…1brew install nginx é…ç½®nginxæ˜¯ä¸€ä¸ªåŠŸèƒ½éå¸¸å¼ºå¤§çš„webæœåŠ¡å™¨åŠ åå‘ä»£ç†æœåŠ¡å™¨ï¼ŒåŒæ—¶åˆæ˜¯é‚®ä»¶æœåŠ¡å™¨ç­‰ç­‰ åœ¨é¡¹ç›®ä½¿ç”¨ä¸­ï¼Œä½¿ç”¨æœ€å¤šçš„ä¸‰ä¸ªæ ¸å¿ƒåŠŸèƒ½æ˜¯åå‘ä»£ç†ã€è´Ÿè½½å‡è¡¡å’Œé™æ€æœåŠ¡å™¨ è¿™ä¸‰ä¸ªä¸åŒçš„åŠŸèƒ½çš„ä½¿ç”¨ï¼Œéƒ½è·Ÿnginxçš„é…ç½®å¯†åˆ‡ç›¸å…³ï¼ŒnginxæœåŠ¡å™¨çš„é…ç½®ä¿¡æ¯ä¸»è¦é›†ä¸­åœ¨nginx.confè¿™ä¸ªé…ç½®æ–‡ä»¶ä¸­ï¼Œå¹¶ä¸”æ‰€æœ‰çš„å¯é…ç½®é€‰é¡¹å¤§è‡´åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ† 123456789101112131415161718192021222324252627282930313233343536main # å…¨å±€é…ç½®events &#123; # nginxå·¥ä½œæ¨¡å¼é…ç½®&#125;http &#123; # httpè®¾ç½® .... server &#123; # æœåŠ¡å™¨ä¸»æœºé…ç½® .... location &#123; # è·¯ç”±é…ç½® .... &#125; location path &#123; .... &#125; location otherpath &#123; .... &#125; &#125; server &#123; .... location &#123; .... &#125; &#125; upstream name &#123; # è´Ÿè½½å‡è¡¡é…ç½® .... &#125;&#125; å¦‚ä¸Šè¿°é…ç½®æ–‡ä»¶æ‰€ç¤ºï¼Œä¸»è¦ç”±6ä¸ªéƒ¨åˆ†ç»„æˆï¼š 1.mainï¼šç”¨äºè¿›è¡Œnginxå…¨å±€ä¿¡æ¯çš„é…ç½®2.eventsï¼šç”¨äºnginxå·¥ä½œæ¨¡å¼çš„é…ç½®3.httpï¼šç”¨äºè¿›è¡Œhttpåè®®ä¿¡æ¯çš„ä¸€äº›é…ç½®4.serverï¼šç”¨äºè¿›è¡ŒæœåŠ¡å™¨è®¿é—®ä¿¡æ¯çš„é…ç½®5.locationï¼šç”¨äºè¿›è¡Œè®¿é—®è·¯ç”±çš„é…ç½®6.upstreamï¼šç”¨äºè¿›è¡Œè´Ÿè½½å‡è¡¡çš„é…ç½® mainæ¨¡å—1234567# user nobody nobody;worker_processes 2;# error_log logs/error.log# error_log logs/error.log notice# error_log logs/error.log info# pid logs/nginx.pidworker_rlimit_nofile 1024; ä¸Šè¿°é…ç½®éƒ½æ˜¯å­˜æ”¾åœ¨mainå…¨å±€é…ç½®æ¨¡å—ä¸­çš„é…ç½®é¡¹ 1.userï¼šç”¨æ¥æŒ‡å®šnginx workerè¿›ç¨‹è¿è¡Œç”¨æˆ·ä»¥åŠç”¨æˆ·ç»„ï¼Œé»˜è®¤nobodyè´¦å·è¿è¡Œ2.worker_processesï¼šæŒ‡å®šnginxè¦å¼€å¯çš„å­è¿›ç¨‹æ•°é‡ï¼Œè¿è¡Œè¿‡ç¨‹ä¸­ç›‘æ§æ¯ä¸ªè¿›ç¨‹æ¶ˆè€—å†…å­˜(ä¸€èˆ¬å‡ M~å‡ åMä¸ç­‰)æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé€šå¸¸æ•°é‡æ˜¯CPUå†…æ ¸æ•°é‡çš„æ•´æ•°å€3.error_logï¼šå®šä¹‰é”™è¯¯æ—¥å¿—æ–‡ä»¶çš„ä½ç½®åŠè¾“å‡ºçº§åˆ«ã€debug / info / notice / warn / error / critã€‘4.pidï¼šç”¨æ¥æŒ‡å®šè¿›ç¨‹idçš„å­˜å‚¨æ–‡ä»¶çš„ä½ç½®5.worker_rlimit_nofileï¼šç”¨äºæŒ‡å®šä¸€ä¸ªè¿›ç¨‹å¯ä»¥æ‰“å¼€æœ€å¤šæ–‡ä»¶æ•°é‡çš„æè¿° eventsæ¨¡å—12345events &#123; worker_connections 1024; multi_accept on; use epoll;&#125; ä¸Šè¿°é…ç½®æ˜¯é’ˆå¯¹nginxæœåŠ¡å™¨çš„å·¥ä½œæ¨¡å¼çš„ä¸€äº›æ“ä½œé…ç½® 1.worker_connectionsï¼šæŒ‡å®šæœ€å¤§å¯ä»¥åŒæ—¶æ¥æ”¶çš„è¿æ¥æ•°é‡ï¼Œè¿™é‡Œä¸€å®šè¦æ³¨æ„ï¼Œæœ€å¤§è¿æ¥æ•°é‡æ˜¯å’Œworker processeså…±åŒå†³å®šçš„2.multi_acceptï¼šé…ç½®æŒ‡å®šnginxåœ¨æ”¶åˆ°ä¸€ä¸ªæ–°è¿æ¥é€šçŸ¥åå°½å¯èƒ½å¤šçš„æ¥å—æ›´å¤šçš„è¿æ¥3.use epollï¼šé…ç½®æŒ‡å®šäº†çº¿ç¨‹è½®è¯¢çš„æ–¹æ³•ï¼Œå¦‚æœæ˜¯linux2.6+ï¼Œä½¿ç”¨epollï¼Œå¦‚æœæ˜¯BSDå¦‚Macè¯·ä½¿ç”¨Kqueue httpæ¨¡å—ä½œä¸ºwebæœåŠ¡å™¨ï¼Œhttpæ¨¡å—æ˜¯nginxæœ€æ ¸å¿ƒçš„ä¸€ä¸ªæ¨¡å—ï¼Œé…ç½®é¡¹ä¹Ÿæ˜¯æ¯”è¾ƒå¤šçš„ï¼Œé¡¹ç›®ä¸­ä¼šè®¾ç½®åˆ°å¾ˆå¤šçš„å®é™…ä¸šåŠ¡åœºæ™¯ï¼Œéœ€è¦æ ¹æ®ç¡¬ä»¶ä¿¡æ¯è¿›è¡Œé€‚å½“çš„é…ç½®ï¼Œå¸¸è§„æƒ…å†µä¸‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®å³å¯ï¼ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354http &#123; ## # åŸºç¡€é…ç½® ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSLè¯ä¹¦é…ç½® ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # æ—¥å¿—é…ç½® ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip å‹ç¼©é…ç½® ## gzip on; gzip_disable \"msie6\"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # è™šæ‹Ÿä¸»æœºé…ç½® ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125; åŸºç¡€é…ç½®1.sendfile onï¼šé…ç½®onè®©sendfileå‘æŒ¥ä½œç”¨ï¼Œå°†æ–‡ä»¶çš„å›å†™è¿‡ç¨‹äº¤ç»™æ•°æ®ç¼“å†²å»å»å®Œæˆï¼Œè€Œä¸æ˜¯æ”¾åœ¨åº”ç”¨ä¸­å®Œæˆï¼Œè¿™æ ·çš„è¯åœ¨æ€§èƒ½æå‡æœ‰æœ‰å¥½å¤„2.tc_nopush onï¼šè®©nginxåœ¨ä¸€ä¸ªæ•°æ®åŒ…ä¸­å‘é€æ‰€æœ‰çš„å¤´æ–‡ä»¶ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªä¸€ä¸ªå•ç‹¬å‘3.tcp_nodelay onï¼šè®©nginxä¸è¦ç¼“å­˜æ•°æ®ï¼Œè€Œæ˜¯ä¸€æ®µä¸€æ®µå‘é€ï¼Œå¦‚æœæ•°æ®çš„ä¼ è¾“æœ‰å®æ—¶æ€§çš„è¦æ±‚çš„è¯å¯ä»¥é…ç½®å®ƒï¼Œå‘é€å®Œä¸€å°æ®µæ•°æ®å°±ç«‹åˆ»èƒ½å¾—åˆ°è¿”å›å€¼ï¼Œä½†æ˜¯ä¸è¦æ»¥ç”¨å“¦ 4.keepalive_timeout 10ï¼šç»™å®¢æˆ·ç«¯åˆ†é…è¿æ¥è¶…æ—¶æ—¶é—´ï¼ŒæœåŠ¡å™¨ä¼šåœ¨è¿™ä¸ªæ—¶é—´è¿‡åå…³é—­è¿æ¥ã€‚ä¸€èˆ¬è®¾ç½®æ—¶é—´è¾ƒçŸ­ï¼Œå¯ä»¥è®©nginxå·¥ä½œæŒç»­æ€§æ›´å¥½5.client_header_timeout 10ï¼šè®¾ç½®è¯·æ±‚å¤´çš„è¶…æ—¶æ—¶é—´6.client_body_timeout 10ï¼šè®¾ç½®è¯·æ±‚ä½“çš„è¶…æ—¶æ—¶é—´7.send_timeout 10ï¼šæŒ‡å®šå®¢æˆ·ç«¯å“åº”è¶…æ—¶æ—¶é—´ï¼Œå¦‚æœå®¢æˆ·ç«¯ä¸¤æ¬¡æ“ä½œé—´éš”è¶…è¿‡è¿™ä¸ªæ—¶é—´ï¼ŒæœåŠ¡å™¨å°±ä¼šå…³é—­è¿™ä¸ªé“¾æ¥ 8.limit_conn_zone $binary_remote_addr zone=addr:5m ï¼šè®¾ç½®ç”¨äºä¿å­˜å„ç§keyçš„å…±äº«å†…å­˜çš„å‚æ•°ï¼Œ9.limit_conn addr 100: ç»™å®šçš„keyè®¾ç½®æœ€å¤§è¿æ¥æ•° 10.server_tokensï¼šè™½ç„¶ä¸ä¼šè®©nginxæ‰§è¡Œé€Ÿåº¦æ›´å¿«ï¼Œä½†æ˜¯å¯ä»¥åœ¨é”™è¯¯é¡µé¢å…³é—­nginxç‰ˆæœ¬æç¤ºï¼Œå¯¹äºç½‘ç«™å®‰å…¨æ€§çš„æå‡æœ‰å¥½å¤„å“¦11.include /etc/nginx/mime.typesï¼šæŒ‡å®šåœ¨å½“å‰æ–‡ä»¶ä¸­åŒ…å«å¦ä¸€ä¸ªæ–‡ä»¶çš„æŒ‡ä»¤12.default_type application/octet-streamï¼šæŒ‡å®šé»˜è®¤å¤„ç†çš„æ–‡ä»¶ç±»å‹å¯ä»¥æ˜¯äºŒè¿›åˆ¶13.type_hash_max_size 2048ï¼šæ··æ·†æ•°æ®ï¼Œå½±å“ä¸‰åˆ—å†²çªç‡ï¼Œå€¼è¶Šå¤§æ¶ˆè€—å†…å­˜è¶Šå¤šï¼Œæ•£åˆ—keyå†²çªç‡ä¼šé™ä½ï¼Œæ£€ç´¢é€Ÿåº¦æ›´å¿«ï¼›å€¼è¶Šå°keyï¼Œå ç”¨å†…å­˜è¾ƒå°‘ï¼Œå†²çªç‡è¶Šé«˜ï¼Œæ£€ç´¢é€Ÿåº¦å˜æ…¢ æ—¥å¿—1.access_log logs/access.logï¼šè®¾ç½®å­˜å‚¨è®¿é—®è®°å½•çš„æ—¥å¿—2.error_log logs/error.logï¼šè®¾ç½®å­˜å‚¨è®°å½•é”™è¯¯å‘ç”Ÿçš„æ—¥å¿— å‹ç¼©é…ç½®1.gzipï¼šæ˜¯å‘Šè¯‰nginxé‡‡ç”¨gzipå‹ç¼©çš„å½¢å¼å‘é€æ•°æ®ã€‚è¿™å°†ä¼šå‡å°‘æˆ‘ä»¬å‘é€çš„æ•°æ®é‡ã€‚2.gzip_disableï¼šä¸ºæŒ‡å®šçš„å®¢æˆ·ç«¯ç¦ç”¨gzipåŠŸèƒ½ã€‚æˆ‘ä»¬è®¾ç½®æˆIE6æˆ–è€…æ›´ä½ç‰ˆæœ¬ä»¥ä½¿æˆ‘ä»¬çš„æ–¹æ¡ˆèƒ½å¤Ÿå¹¿æ³›å…¼å®¹ã€‚3.gzip_staticï¼šå‘Šè¯‰nginxåœ¨å‹ç¼©èµ„æºä¹‹å‰ï¼Œå…ˆæŸ¥æ‰¾æ˜¯å¦æœ‰é¢„å…ˆgzipå¤„ç†è¿‡çš„èµ„æºã€‚è¿™è¦æ±‚ä½ é¢„å…ˆå‹ç¼©ä½ çš„æ–‡ä»¶ï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­è¢«æ³¨é‡Šæ‰äº†ï¼‰ï¼Œä»è€Œå…è®¸ä½ ä½¿ç”¨æœ€é«˜å‹ç¼©æ¯”ï¼Œè¿™æ ·nginxå°±ä¸ç”¨å†å‹ç¼©è¿™äº›æ–‡ä»¶äº†ï¼ˆæƒ³è¦æ›´è¯¦å°½çš„gzip_staticçš„ä¿¡æ¯ï¼Œè¯·ç‚¹å‡»è¿™é‡Œï¼‰ã€‚4.gzip_proxiedï¼šå…è®¸æˆ–è€…ç¦æ­¢å‹ç¼©åŸºäºè¯·æ±‚å’Œå“åº”çš„å“åº”æµã€‚æˆ‘ä»¬è®¾ç½®ä¸ºanyï¼Œæ„å‘³ç€å°†ä¼šå‹ç¼©æ‰€æœ‰çš„è¯·æ±‚ã€‚5.gzip_min_lengthï¼šè®¾ç½®å¯¹æ•°æ®å¯ç”¨å‹ç¼©çš„æœ€å°‘å­—èŠ‚æ•°ã€‚å¦‚æœä¸€ä¸ªè¯·æ±‚å°äº1000å­—èŠ‚ï¼Œæˆ‘ä»¬æœ€å¥½ä¸è¦å‹ç¼©å®ƒï¼Œå› ä¸ºå‹ç¼©è¿™äº›å°çš„æ•°æ®ä¼šé™ä½å¤„ç†æ­¤è¯·æ±‚çš„æ‰€æœ‰è¿›ç¨‹çš„é€Ÿåº¦ã€‚6.gzip_comp_levelï¼šè®¾ç½®æ•°æ®çš„å‹ç¼©ç­‰çº§ã€‚è¿™ä¸ªç­‰çº§å¯ä»¥æ˜¯1-9ä¹‹é—´çš„ä»»æ„æ•°å€¼ï¼Œ9æ˜¯æœ€æ…¢ä½†æ˜¯å‹ç¼©æ¯”æœ€å¤§çš„ã€‚æˆ‘ä»¬è®¾ç½®ä¸º4ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒæŠ˜ä¸­çš„è®¾ç½®ã€‚7.gzip_typeï¼šè®¾ç½®éœ€è¦å‹ç¼©çš„æ•°æ®æ ¼å¼ã€‚ä¸Šé¢ä¾‹å­ä¸­å·²ç»æœ‰ä¸€äº›äº†ï¼Œä½ ä¹Ÿå¯ä»¥å†æ·»åŠ æ›´å¤šçš„æ ¼å¼ã€‚ æ–‡ä»¶ç¼“å­˜é…ç½®1.open_file_cacheï¼šæ‰“å¼€ç¼“å­˜çš„åŒæ—¶ä¹ŸæŒ‡å®šäº†ç¼“å­˜æœ€å¤§æ•°ç›®ï¼Œä»¥åŠç¼“å­˜çš„æ—¶é—´ã€‚æˆ‘ä»¬å¯ä»¥è®¾ç½®ä¸€ä¸ªç›¸å¯¹é«˜çš„æœ€å¤§æ—¶é—´ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥åœ¨å®ƒä»¬ä¸æ´»åŠ¨è¶…è¿‡20ç§’åæ¸…é™¤æ‰ã€‚2.open_file_cache_validï¼šåœ¨open_file_cacheä¸­æŒ‡å®šæ£€æµ‹æ­£ç¡®ä¿¡æ¯çš„é—´éš”æ—¶é—´ã€‚3.open_file_cache_min_usesï¼šå®šä¹‰äº†open_file_cacheä¸­æŒ‡ä»¤å‚æ•°ä¸æ´»åŠ¨æ—¶é—´æœŸé—´é‡Œæœ€å°çš„æ–‡ä»¶æ•°ã€‚4.open_file_cache_errorsï¼šæŒ‡å®šäº†å½“æœç´¢ä¸€ä¸ªæ–‡ä»¶æ—¶æ˜¯å¦ç¼“å­˜é”™è¯¯ä¿¡æ¯ï¼Œä¹ŸåŒ…æ‹¬å†æ¬¡ç»™é…ç½®ä¸­æ·»åŠ æ–‡ä»¶ã€‚æˆ‘ä»¬ä¹ŸåŒ…æ‹¬äº†æœåŠ¡å™¨æ¨¡å—ï¼Œè¿™äº›æ˜¯åœ¨ä¸åŒæ–‡ä»¶ä¸­å®šä¹‰çš„ã€‚å¦‚æœä½ çš„æœåŠ¡å™¨æ¨¡å—ä¸åœ¨è¿™äº›ä½ç½®ï¼Œä½ å°±å¾—ä¿®æ”¹è¿™ä¸€è¡Œæ¥æŒ‡å®šæ­£ç¡®çš„ä½ç½®ã€‚ serveræ¨¡å—serveræ¨¡å—é…ç½®æ˜¯httpæ¨¡å—ä¸­çš„ä¸€ä¸ªå­æ¨¡å—ï¼Œç”¨æ¥å®šä¹‰ä¸€ä¸ªè™šæ‹Ÿè®¿é—®ä¸»æœºï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªè™šæ‹ŸæœåŠ¡å™¨çš„é…ç½®ä¿¡æ¯ 12345678910server &#123; listen 80; server_name localhost 192.168.1.100; root /nginx/www; index index.php index.html index.html; charset utf-8; access_log logs/access.log; error_log logs/error.log; ......&#125; æ ¸å¿ƒé…ç½®ä¿¡æ¯å¦‚ä¸‹ï¼š 1.serverï¼šä¸€ä¸ªè™šæ‹Ÿä¸»æœºçš„é…ç½®ï¼Œä¸€ä¸ªhttpä¸­å¯ä»¥é…ç½®å¤šä¸ªserver 2.server_nameï¼šç”¨åŠ›å•ŠæŒ‡å®šipåœ°å€æˆ–è€…åŸŸåï¼Œå¤šä¸ªé…ç½®ä¹‹é—´ç”¨ç©ºæ ¼åˆ†éš” 3.rootï¼šè¡¨ç¤ºæ•´ä¸ªserverè™šæ‹Ÿä¸»æœºå†…çš„æ ¹ç›®å½•ï¼Œæ‰€æœ‰å½“å‰ä¸»æœºä¸­webé¡¹ç›®çš„æ ¹ç›®å½• 4.indexï¼šç”¨æˆ·è®¿é—®webç½‘ç«™æ—¶çš„å…¨å±€é¦–é¡µ 5.charsetï¼šç”¨äºè®¾ç½®www/è·¯å¾„ä¸­é…ç½®çš„ç½‘é¡µçš„é»˜è®¤ç¼–ç æ ¼å¼ 6.access_logï¼šç”¨äºæŒ‡å®šè¯¥è™šæ‹Ÿä¸»æœºæœåŠ¡å™¨ä¸­çš„è®¿é—®è®°å½•æ—¥å¿—å­˜æ”¾è·¯å¾„ 7.error_logï¼šç”¨äºæŒ‡å®šè¯¥è™šæ‹Ÿä¸»æœºæœåŠ¡å™¨ä¸­è®¿é—®é”™è¯¯æ—¥å¿—çš„å­˜æ”¾è·¯å¾„ locationæ¨¡å—locationæ¨¡å—æ˜¯nginxé…ç½®ä¸­å‡ºç°æœ€å¤šçš„ä¸€ä¸ªé…ç½®ï¼Œä¸»è¦ç”¨äºé…ç½®è·¯ç”±è®¿é—®ä¿¡æ¯ åœ¨è·¯ç”±è®¿é—®ä¿¡æ¯é…ç½®ä¸­å…³è”åˆ°åå‘ä»£ç†ã€è´Ÿè½½å‡è¡¡ç­‰ç­‰å„é¡¹åŠŸèƒ½ï¼Œæ‰€ä»¥locationæ¨¡å—ä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„é…ç½®æ¨¡å— åŸºæœ¬é…ç½®1234location / &#123; root /nginx/www; index index.php index.html index.htm;&#125; location /ï¼šè¡¨ç¤ºåŒ¹é…è®¿é—®æ ¹ç›®å½• rootï¼šç”¨äºæŒ‡å®šè®¿é—®æ ¹ç›®å½•æ—¶ï¼Œè®¿é—®è™šæ‹Ÿä¸»æœºçš„webç›®å½• indexï¼šåœ¨ä¸æŒ‡å®šè®¿é—®å…·ä½“èµ„æºæ—¶ï¼Œé»˜è®¤å±•ç¤ºçš„èµ„æºæ–‡ä»¶åˆ—è¡¨ åå‘ä»£ç†é…ç½®æ–¹å¼é€šè¿‡åå‘ä»£ç†ä»£ç†æœåŠ¡å™¨è®¿é—®æ¨¡å¼ï¼Œé€šè¿‡proxy_seté…ç½®è®©å®¢æˆ·ç«¯è®¿é—®é€æ˜åŒ– 12345location / &#123; proxy_pass http://localhost:8888; proxy_set_header X-real-ip $remote_addr; proxy_set_header Host $http_host;&#125; uwsgié…ç½®wsgiæ¨¡å¼ä¸‹çš„æœåŠ¡å™¨é…ç½®è®¿é—®æ–¹å¼ 1234location / &#123; include uwsgi_params; uwsgi_pass localhost:8888&#125; upstreamæ¨¡å—upstreamæ¨¡å—ä¸»è¦è´Ÿè´£è´Ÿè½½å‡è¡¡çš„é…ç½®ï¼Œé€šè¿‡é»˜è®¤çš„è½®è¯¢è°ƒåº¦æ–¹å¼æ¥åˆ†å‘è¯·æ±‚åˆ°åç«¯æœåŠ¡å™¨ ç®€å•çš„é…ç½®æ–¹å¼å¦‚ä¸‹ 12345678upstream name &#123; ip_hash; server 192.168.1.100:8000; server 192.168.1.100:8001 down; server 192.168.1.100:8002 max_fails=3; server 192.168.1.100:8003 fail_timeout=20s; server 192.168.1.100:8004 max_fails=3 fail_timeout=20s;&#125; æ ¸å¿ƒé…ç½®ä¿¡æ¯å¦‚ä¸‹ 1.ip_hashï¼šæŒ‡å®šè¯·æ±‚è°ƒåº¦ç®—æ³•ï¼Œé»˜è®¤æ˜¯weightæƒé‡è½®è¯¢è°ƒåº¦ï¼Œå¯ä»¥æŒ‡å®š 2.server host:portï¼šåˆ†å‘æœåŠ¡å™¨çš„åˆ—è¡¨é…ç½® â€“ downï¼šè¡¨ç¤ºè¯¥ä¸»æœºæš‚åœæœåŠ¡ â€“ max_failsï¼šè¡¨ç¤ºå¤±è´¥æœ€å¤§æ¬¡æ•°ï¼Œè¶…è¿‡å¤±è´¥æœ€å¤§æ¬¡æ•°æš‚åœæœåŠ¡ â€“ fail_timeoutï¼šè¡¨ç¤ºå¦‚æœè¯·æ±‚å—ç†å¤±è´¥ï¼Œæš‚åœæŒ‡å®šçš„æ—¶é—´ä¹‹åé‡æ–°å‘èµ·è¯·æ±‚","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://yangyichao-mango.github.io/tags/Nginx/"}]},{"title":"Elastic-Jobå­¦ä¹ ï¼šåˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦æ¡†æ¶","date":"2019-10-26T14:08:15.000Z","path":"2019/10/26/elastic-job:study-distributed-scheduled-job-framework/","text":"åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦æ¡†æ¶å­¦ä¹  å®˜æ–¹æ–‡æ¡£ elastic-job github","tags":[{"name":"Apache Zookeeper","slug":"Apache-Zookeeper","permalink":"https://yangyichao-mango.github.io/tags/Apache-Zookeeper/"},{"name":"åˆ†å¸ƒå¼è°ƒåº¦æ¡†æ¶","slug":"åˆ†å¸ƒå¼è°ƒåº¦æ¡†æ¶","permalink":"https://yangyichao-mango.github.io/tags/åˆ†å¸ƒå¼è°ƒåº¦æ¡†æ¶/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yangyichao-mango.github.io/tags/SpringBoot/"}]},{"title":"Vueå­¦ä¹ ï¼šVueå‰ç«¯é¡¹ç›®éƒ¨ç½²åˆ°SpringBootå·¥ç¨‹ä¸‹","date":"2019-10-26T07:29:37.000Z","path":"2019/10/26/vue:study-vue-project-deploy-in-springboot-project/","text":"Vueé¡¹ç›®éƒ¨ç½²åˆ°SpringBootå·¥ç¨‹ä¸‹ Vueå‰ç«¯é¡¹ç›®1npm run build è¿è¡Œä¸Šè¿°å‘½ä»¤ï¼Œå°†å‰ç«¯Vueé¡¹ç›®æ‰“åŒ…ï¼Œå‘½ä»¤è¿è¡Œå®Œæˆä¹‹åä¼šåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ç”Ÿæˆä¸€ä¸ªç”Ÿæˆä¸€ä¸ªdistæ–‡ä»¶å¤¹, ç¼–è¯‘å¥½çš„é™æ€æ–‡ä»¶å°±åœ¨è¿™é‡Œé¢ éƒ¨ç½²åœ¨SpringBooté¡¹ç›®ä¸‹å°†å‰ç«¯é¡¹ç›®ä¸­distæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶æ‹·è´åˆ°SpringBootå·¥ç¨‹çš„src/main/resources/staticæ–‡ä»¶å¤¹ä¸‹ è¿è¡Œåç«¯é¡¹ç›®ï¼Œå¯ä»¥çœ‹åˆ°æ§åˆ¶å°ä¼šæœ‰è¿™æ ·çš„è¾“å‡ºï¼Œè¯æ˜å°†é™æ€é¡µé¢åŠ å…¥äº†å®¹å™¨ä¸­ï¼Œç°åœ¨å°±å¯ä»¥è®¿é—®åˆ°å‰ç«¯é¡µé¢äº† 12019-10-26 15:47:09.607 INFO 1967 --- [ main] o.s.b.a.w.s.WelcomePageHandlerMapping : Adding welcome page: class path resource [static/index.html]","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yangyichao-mango.github.io/tags/SpringBoot/"},{"name":"Vue","slug":"Vue","permalink":"https://yangyichao-mango.github.io/tags/Vue/"}]},{"title":"Mavenå­¦ä¹ ï¼šä½¿ç”¨maven-shade-pluginè§£å†³ä¾èµ–åŒ…å†²çª","date":"2019-10-25T06:23:20.000Z","path":"2019/10/25/apache-maven:study-maven-shade-resolve-jar-conflicts/","text":"java ä¾èµ–åŒ…å†²çªï¼Œä½¿ç”¨maven-shade-pluginè§£å†³ é”™è¯¯åœºæ™¯è¯¦æƒ…1java.lang.NoSuchMethodError: com.google.common.util.concurrent.MoreExecutors.directExecutor()Ljava/util/concurrent/Executor; é”™è¯¯åŸå› å‡ºç°è¿™æ ·çš„é”™è¯¯è¯¦æƒ…ä¸€èˆ¬æ˜¯ç”±äºæœ‰ä¸‹é¢è¿™æ ·çš„åŒ…ä¾èµ–æƒ…å†µ 12A - B - C(guava version 18) \\ D - C(guava version 23.6-jre) Aï¼šä»£è¡¨æˆ‘ä»¬æ‰€å¼€å‘çš„å½“å‰é¡¹ç›®Bå’ŒDï¼šä»£è¡¨å½“å‰é¡¹ç›®æ‰€ä¾èµ–çš„é¡¹ç›®Cï¼šä»£è¡¨å½“å‰é¡¹ç›®ä¾èµ–çš„é¡¹ç›®æ‰€ä¾èµ–çš„é¡¹ç›® ç”±äºæˆ‘ä»¬å½“å‰æ‰€å¼€å‘çš„é¡¹ç›®Aä¾èµ–äº†Bå’ŒDï¼ŒBå’ŒDåˆä¾èµ–äº†é¡¹ç›®Cæˆ‘ä»¬æ‰“åŒ…è¿è¡Œé¡¹ç›®æ—¶ï¼Œmavenåªä¼šå°†ä¸€ä¸ªç‰ˆæœ¬C(guava)æ‰“è¿›åŒ…å†…ï¼ˆmavenæ‰“åŒ…é‡åˆ°ç›¸åŒä¾èµ–ï¼Œæœ€çŸ­è·¯å¾„ä¼˜å…ˆï¼Œåœ¨è·¯å¾„ç›¸åŒæ—¶å…ˆåœ¨pomä¸­å£°æ˜ä¼˜å…ˆï¼‰æ¯”å¦‚æ­¤æ—¶æ‰“è¿›åŒ…çš„ç‰ˆæœ¬æ˜¯C(guava version 23.6-jre)ï¼Œé‚£ä¹ˆå¾ˆæœ‰å¯èƒ½åœ¨è¿è¡ŒBä¸­çš„ä¸€ä¸ªæ–¹æ³•æ—¶ï¼Œè°ƒç”¨Cçš„ä¸€ä¸ªæ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯C(guava version 18)ä¸­çš„ä¸€ä¸ªæ–¹æ³•ï¼Œåœ¨C(guava version 23.6-jre)ä¸­å¹¶ä¸å­˜åœ¨ï¼Œè¿™æ—¶å€™å°±ä¼šæŠ¥å‡ºjava.lang.NoSuchMethodError è§£å†³æ–¹æ¡ˆä½¿ç”¨maven-shade-pluginå°†æ‰€æœ‰Bé¡¹ç›®ä¾èµ–çš„åŒ…å…¨éƒ¨æ‰“è¿›B.jarä¸­ï¼Œå¹¶ä¸”ç»™guavaåŒ…çš„è·¯å¾„é‡å‘½åä¸ºæˆ‘ä»¬çš„è‡ªå®šä¹‰è·¯å¾„\\ maven-shade-pluginåŸºæœ¬åŠŸèƒ½maven-shade-pluginæä¾›äº†ä¸¤å¤§åŸºæœ¬åŠŸèƒ½ï¼š 1ã€å°†ä¾èµ–çš„jaråŒ…æ‰“åŒ…åˆ°å½“å‰jaråŒ…ï¼ˆå¸¸è§„æ‰“åŒ…æ˜¯ä¸ä¼šå°†æ‰€ä¾èµ–jaråŒ…æ‰“è¿›æ¥çš„ï¼‰2ã€å¯¹ä¾èµ–çš„jaråŒ…è¿›è¡Œé‡å‘½åï¼ˆç”¨äºç±»çš„éš”ç¦»ï¼Œè§£å†³åŒ…å†²çªå°±æ˜¯ä½¿ç”¨äº†è¿™ä¸ªåŠŸèƒ½ï¼‰ è§£å†³ç¤ºä¾‹å¦‚ä¸‹ä¾‹ï¼Œå°±å¯ä»¥åœ¨Bé¡¹ç›®ä¸­ä½¿ç”¨C(guava version 18)ï¼Œåªä¸è¿‡importè·¯å¾„å˜æˆäº†æˆ‘ä»¬è‡ªå®šçš„è·¯å¾„ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;RpcModule&lt;/groupId&gt; &lt;artifactId&gt;RpcModule&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;RpcModule&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;guava.version&gt;18&lt;/guava.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;$&#123;guava.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;8&lt;/source&gt; &lt;target&gt;8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;!-- ç»™guavaåŒ…çš„è·¯å¾„é‡å‘½åä¸ºæˆ‘ä»¬çš„è‡ªå®šä¹‰è·¯å¾„ --&gt; &lt;configuration&gt; &lt;relocations&gt; &lt;relocation&gt; &lt;pattern&gt;com.google.guava&lt;/pattern&gt; &lt;shadedPattern&gt;shade.com.google.guava&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;relocation&gt; &lt;pattern&gt;org.joda&lt;/pattern&gt; &lt;shadedPattern&gt;shade.com.google.joda&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;relocation&gt; &lt;pattern&gt;com.google.common&lt;/pattern&gt; &lt;shadedPattern&gt;shade.com.google.common&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;/relocations&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"/&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; ä½¿ç”¨maven-shade-pluginä¹‹å‰ 12345678910import Entity.Request;import Entity.Response;import java.io.*;import java.net.Socket;import com.google.common.collect.ImmutableMap;public class SocketClient &#123;&#125; ä½¿ç”¨maven-shade-pluginä¹‹åç¼–è¯‘ååç¼–è¯‘ç»“æœ 12345678910import Entity.Request;import Entity.Response;import java.io.*;import java.net.Socket;import shade.com.google.common.collect.ImmutableMap;public class SocketClient &#123;&#125; æœ€åå°†æ‰“å¥½çš„åŒ…ä¸Šä¼ è‡³æˆ‘ä»¬çš„mavenä»“åº“ï¼Œç„¶åå†åœ¨å½“å‰é¡¹ç›®Aä¸­ä¾èµ–ï¼Œå°±æ²¡æœ‰ä¾èµ–å†²çªäº† 12A - B - C(guava version 18, shade.com.google.common.collect.ImmutableMap) \\ D - C(guava version 23.6-jre, com.google.common.collect.ImmutableMap) è¿™æ ·å°±å¯ä»¥åšåˆ°å°†ä¸¤ä¸ªä¸åŒç‰ˆæœ¬çš„åŒ…éƒ½å¼•å…¥ä½¿ç”¨ï¼Œç”±äºå¼•å…¥åŒ…è·¯å¾„ä¸åŒï¼Œå› æ­¤ä¹Ÿæ²¡æœ‰å†²çª","tags":[{"name":"Apache Maven","slug":"Apache-Maven","permalink":"https://yangyichao-mango.github.io/tags/Apache-Maven/"}]},{"title":"Apache Zookeeper å­¦ä¹ ï¼šZookeeperå®ç°ç»Ÿä¸€é…ç½®ç®¡ç†ä¸­å¿ƒ","date":"2019-10-24T10:40:24.000Z","path":"2019/10/24/apache-zookeeper:study-zookeeper-implement-unified-configuration-management-center/","text":"Apache Zookeeper å­¦ä¹ ï¼šæ¨¡æ‹Ÿä¸‰å°èŠ‚ç‚¹ç»„æˆçš„Zookeeperé›†ç¾¤å®ç°çš„ç»Ÿä¸€é…ç½®ç®¡ç†ä¸­å¿ƒ æ¨¡æ‹ŸZookeeperé›†ç¾¤æ¶æ„å›¾ Zookeeperé›†ç¾¤æ¶æ„ åˆ›å»ºzookeeperé›†ç¾¤èŠ‚ç‚¹æ¨¡æ‹Ÿä¸‰å°èŠ‚ç‚¹ç»„æˆçš„zookeeperé›†ç¾¤ï¼Œéœ€è¦åœ¨æœ¬æœºzookeeperç›®å½•ä¸‹åˆ›å»ºä¸‰ä¸ªzookeeperé›†ç¾¤èŠ‚ç‚¹é…ç½®æ–‡ä»¶ 1234$ cd conf/$ cp zoo_sample.cfg zoo1.cfg$ cp zoo_sample.cfg zoo2.cfg$ cp zoo_sample.cfg zoo3.cfg åˆ›å»ºæ‰€é…ç½®çš„å„ä¸ªæ–‡ä»¶å¤¹123456789$ mkdir /tmp/zookeeper1$ mkdir /tmp/zookeeper1/data$ mkdir /tmp/zookeeper1/dataLog$ mkdir /tmp/zookeeper2$ mkdir /tmp/zookeeper2/data$ mkdir /tmp/zookeeper2/dataLog$ mkdir /tmp/zookeeper3$ mkdir /tmp/zookeeper3/data$ mkdir /tmp/zookeeper3/dataLog /tmp/zookeeperX/dataæ–‡ä»¶å¤¹ä¸‹åˆ›å»ºmyidæ–‡ä»¶123$ echo 1 &gt; /tmp/zookeeper1/data/myid$ echo 2 &gt; /tmp/zookeeper2/data/myid$ echo 3 &gt; /tmp/zookeeper3/data/myid é…ç½®zookeeperèŠ‚ç‚¹ä¿¡æ¯zoo1.cfg 1234567891011121314151617181920212223242526272829303132333435# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/tmp/zookeeper1/datadataLogDir=/tmp/zookeeper1/dataLog# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to \"0\" to disable auto purge feature#autopurge.purgeInterval=1# æ ¼å¼:server.num=xxxx:port1:port2# numå¯¹åº”myidä¸­çš„å†…å®¹ï¼Œport1æ˜¯zookeeperé›†ç¾¤ä¸­å„æœåŠ¡é—´çš„é€šä¿¡ç«¯å£ï¼Œport2æ˜¯zookeeperé›†ç¾¤é€‰ä¸¾leaderçš„ç«¯å£server.1=localhost:2888:3888server.2=localhost:2899:3899server.3=localhost:2877:3877 zoo2.cfg 1234567891011# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/tmp/zookeeper2/datadataLogDir=/tmp/zookeeper2/dataLog# the port at which the clients will connectclientPort=2182...server.1=localhost:2888:3888server.2=localhost:2899:3899server.3=localhost:2877:3877 zoo3.cfg 1234567891011# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.dataDir=/tmp/zookeeper3/datadataLogDir=/tmp/zookeeper3/dataLog# the port at which the clients will connectclientPort=2183...server.1=localhost:2888:3888server.2=localhost:2899:3899server.3=localhost:2877:3877 é…ç½®æ–‡ä»¶ä¸­dataDirï¼ŒdataLogDirï¼ŒclientPortï¼Œä¸‰ä¸ªzookeeperèŠ‚ç‚¹é…ç½®ä¿¡æ¯éƒ½ä¸åŒæ­å»ºzookeeperé›†ç¾¤ï¼Œéœ€è¦åœ¨æ¯ä¸ªzookeeperå®‰è£…ç›®å½•ä¸‹çš„dataæ–‡ä»¶ä¸­åˆ›å»ºåä¸ºmyidçš„æ–‡ä»¶ï¼Œä¿®æ”¹zooX.cfgå†…å®¹å¦‚ä¸‹ï¼š 123server.1=xxx:2888:3888server.2=xxx:2899:3899server.3=xxx:2877:3877 æ ¼å¼:server.num=xxxx:port1:port2numå¯¹åº”myidä¸­çš„å†…å®¹ï¼Œport1æ˜¯zookeeperé›†ç¾¤ä¸­å„æœåŠ¡é—´çš„é€šä¿¡ç«¯å£ï¼Œport2æ˜¯zookeeperé›†ç¾¤é€‰ä¸¾leaderçš„ç«¯å£ å¯åŠ¨æ¨¡æ‹Ÿé›†ç¾¤èŠ‚ç‚¹123456789101112$ ./zkServer.sh start ../conf/zoo1.cfgZooKeeper JMX enabled by defaultUsing config: ../conf/zoo1.cfgStarting zookeeper ... STARTED$ ./zkServer.sh start ../conf/zoo2.cfgZooKeeper JMX enabled by defaultUsing config: ../conf/zoo2.cfgStarting zookeeper ... STARTED$ ./zkServer.sh start ../conf/zoo3.cfgZooKeeper JMX enabled by defaultUsing config: ../conf/zoo3.cfgStarting zookeeper ... STARTED æŸ¥çœ‹é›†ç¾¤çŠ¶æ€ 123456789101112$ ./zkServer.sh status ../conf/zoo1.cfgZooKeeper JMX enabled by defaultUsing config: ../conf/zoo1.cfgMode: follower$ ./zkServer.sh status ../conf/zoo2.cfgZooKeeper JMX enabled by defaultUsing config: ../conf/zoo2.cfgMode: leader$ ./zkServer.sh status ../conf/zoo3.cfgZooKeeper JMX enabled by defaultUsing config: ../conf/zoo3.cfgMode: follower åˆ›å»ºzookeeperé›†ç¾¤clientåˆ›å»ºç›‘å¬èŠ‚ç‚¹å˜åŒ–çš„serverï¼ˆzookeeperé›†ç¾¤clientï¼‰æ¨¡æ‹Ÿç›‘å¬èŠ‚ç‚¹å˜åŒ–serverï¼Œå¯åŠ¨ä¸¤ä¸ªBaseWatcherç¨‹åºä½œä¸ºç›‘å¬serverï¼ˆå¯¹zookeeperé›†ç¾¤æ¥è¯´æ˜¯clientï¼‰ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class BaseWatcher implements Watcher &#123; private static ZooKeeper zookeeper; /** * è¶…æ—¶æ—¶é—´ */ private static final int SESSION_TIME_OUT = 2000; private static CountDownLatch defaultCountDownLatch = new CountDownLatch(1); private static CountDownLatch childrenCountDownLatch = new CountDownLatch(1); private static CountDownLatch dataCountDownLatch = new CountDownLatch(1); @Override public void process(WatchedEvent event) &#123; if (event.getState() == KeeperState.SyncConnected) &#123; LOGGER.info(\"Watch received event\"); defaultCountDownLatch.countDown(); &#125; if (event.getType() == EventType.NodeCreated) &#123; LOGGER.info(\"åˆ›å»ºèŠ‚ç‚¹\"); &#125; if (event.getType() == EventType.NodeDataChanged) &#123; LOGGER.info(\"èŠ‚ç‚¹æ”¹å˜\"); &#125; if (event.getType() == EventType.NodeChildrenChanged) &#123; LOGGER.info(\"å­èŠ‚ç‚¹èŠ‚ç‚¹æ”¹å˜\"); &#125; if (event.getType() == EventType.NodeDeleted) &#123; LOGGER.info(\"èŠ‚ç‚¹åˆ é™¤\"); &#125; &#125; /** * è¿æ¥zookeeper * @param host * @throws Exception */ public static void connectZookeeper(String host, Watcher defaultWatcher) throws Exception &#123; zookeeper = new ZooKeeper(host, SESSION_TIME_OUT, defaultWatcher); defaultCountDownLatch.await(); LOGGER.info(\"zookeeper connection success\"); &#125; /** * è·å–è·¯å¾„ä¸‹æ‰€æœ‰å­èŠ‚ç‚¹ * @param path * @return * @throws KeeperException * @throws InterruptedException */ public static List&lt;String&gt; getChildren(String path, Watcher childrenWatcher) throws KeeperException, InterruptedException &#123; return zookeeper.getChildren(path, childrenWatcher); &#125; /** * è·å–èŠ‚ç‚¹ä¸Šé¢çš„æ•°æ® * @param path è·¯å¾„ * @return * @throws KeeperException * @throws InterruptedException */ public static String getData(String path, Watcher dataWatcher) throws KeeperException, InterruptedException &#123; byte[] data = zookeeper.getData(path, dataWatcher, null); if (data == null) &#123; return \"\"; &#125; return new String(data); &#125; /** * å…³é—­è¿æ¥ * @throws InterruptedException */ public static void closeConnection() throws InterruptedException &#123; if (zookeeper != null) &#123; zookeeper.close(); &#125; &#125; private static final String HOST = \"localhost:2181,localhost:2182,localhost:2183\"; private static final Logger LOGGER = LoggerFactory.getLogger(BaseWatcher.class); public static void main(String[] args) throws Exception &#123; /** * è¿è¡Œç¨‹åºä¹‹å‰éœ€è¦å¯åŠ¨zookeeperæœåŠ¡ç«¯ï¼Œ&#123;@link BaseWatcher.HOST&#125; æ ¹æ®zookeeperæœåŠ¡ç«¯å…·ä½“é…ç½®å»ä¿®æ”¹ * * é™¤äº†é»˜è®¤watcherå¤–å…¶ä»–watcherä¸€æ—¦è§¦å‘å°±ä¼šå¤±æ•ˆï¼Œéœ€è¦å……æ–°æ³¨å†Œï¼Œæœ¬ç¤ºä¾‹ä¸­å› ä¸º * è¿˜æœªæƒ³åˆ°æ¯”è¾ƒå¥½çš„é‡æ–°æ³¨å†Œwatcheræ–¹å¼(è€ƒè™‘åˆ°å¦‚æœåœ¨Watcherä¸­æŒæœ‰ä¸€ä¸ªzkå®¢æˆ·ç«¯çš„ * å®ä¾‹å¯èƒ½å­˜åœ¨å¾ªç¯å¼•ç”¨çš„é—®é¢˜)ï¼Œå› æ­¤æš‚ä¸å®ç°watcherå¤±æ•ˆåé‡æ–°æ³¨å†Œwatcherçš„é—®é¢˜ï¼Œ * åç»­å¯ä»¥æŸ¥é˜…curatoré‡æ–°æ³¨å†Œwatcherçš„å®ç°æ–¹æ³•ã€‚ */ BaseWatcher defaultWatcher = new BaseWatcher(); // è¿æ¥zookeeperå¹¶è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„watcherç›‘å¬zookeeperæ–‡ä»¶èŠ‚ç‚¹çš„å˜åŒ– connectZookeeper(HOST, defaultWatcher); TimeUnit.SECONDS.sleep(1000000); &#125;&#125; åˆ›å»ºæ”¹å˜èŠ‚ç‚¹æ•°æ®çš„serverï¼ˆzookeeperé›†ç¾¤clientï¼‰å¦‚æœä¸€ä¸ªèŠ‚ç‚¹å‘è¢«ç›‘å¬èŠ‚ç‚¹ä¸­å†™æ•°æ®ï¼Œå…¶ä»–èŠ‚ç‚¹å°±ä¼šæ¥å—åˆ°zookeeperçš„ NodeDataChanged event æ¨¡æ‹Ÿæ”¹å˜æ•°æ®serverï¼Œå¯åŠ¨ä¸€ä¸ªBaseWatcherç¨‹åºä½œä¸ºæ”¹å˜æ•°æ®serverï¼ˆå¯¹zookeeperé›†ç¾¤æ¥è¯´æ˜¯clientï¼‰ 1234567891011121314151617181920public static void main(String[] args) throws Exception &#123; /** * è¿è¡Œç¨‹åºä¹‹å‰éœ€è¦å¯åŠ¨zookeeperæœåŠ¡ç«¯ï¼Œ&#123;@link BaseWatcher.HOST&#125; æ ¹æ®zookeeperæœåŠ¡ç«¯å…·ä½“é…ç½®å»ä¿®æ”¹ * * é™¤äº†é»˜è®¤watcherå¤–å…¶ä»–watcherä¸€æ—¦è§¦å‘å°±ä¼šå¤±æ•ˆï¼Œéœ€è¦å……æ–°æ³¨å†Œï¼Œæœ¬ç¤ºä¾‹ä¸­å› ä¸º * è¿˜æœªæƒ³åˆ°æ¯”è¾ƒå¥½çš„é‡æ–°æ³¨å†Œwatcheræ–¹å¼(è€ƒè™‘åˆ°å¦‚æœåœ¨Watcherä¸­æŒæœ‰ä¸€ä¸ªzkå®¢æˆ·ç«¯çš„ * å®ä¾‹å¯èƒ½å­˜åœ¨å¾ªç¯å¼•ç”¨çš„é—®é¢˜)ï¼Œå› æ­¤æš‚ä¸å®ç°watcherå¤±æ•ˆåé‡æ–°æ³¨å†Œwatcherçš„é—®é¢˜ï¼Œ * åç»­å¯ä»¥æŸ¥é˜…curatoré‡æ–°æ³¨å†Œwatcherçš„å®ç°æ–¹æ³•ã€‚ */ BaseWatcher defaultWatcher = new BaseWatcher(); // è¿æ¥zookeeperå¹¶è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„watcherç›‘å¬zookeeperæ–‡ä»¶èŠ‚ç‚¹çš„å˜åŒ– connectZookeeper(HOST, defaultWatcher); // å‘/GetChildrenèŠ‚ç‚¹å†™æ•°æ®ä¹‹å‰éœ€è¦å…ˆåˆ›å»ºæ­¤æ–‡ä»¶å¤¹ // å‘/GetChildrenèŠ‚ç‚¹å†™æ•°æ®ï¼Œåˆ™ç›‘å¬ç¨‹åºå°±ä¼šæ”¶åˆ°zookeeperçš„ [NodeDataChanged] event setData(\"/GetChildren\", \"8\"); TimeUnit.SECONDS.sleep(1000000);&#125; è¿è¡Œç»“æœä¸¤ä¸ªç›‘å¬ç¨‹åºæ”¶åˆ°zookeeperçš„ NodeDataChanged eventï¼Œlogå¦‚ä¸‹ 123411:24:27.295 [main-SendThread(localhost:2183)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x300001251b5000311:24:27.297 [main-SendThread(localhost:2183)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeDataChanged path:/GetChildren for sessionid 0x300001251b5000311:24:27.297 [main-EventThread] INFO com.github.xxx.bigdata.demo.zookeeper.BaseWatcher - Watch received event11:24:27.297 [main-EventThread] INFO com.github.xxx.bigdata.demo.zookeeper.BaseWatcher - èŠ‚ç‚¹æ”¹å˜","tags":[{"name":"Apache Zookeeper","slug":"Apache-Zookeeper","permalink":"https://yangyichao-mango.github.io/tags/Apache-Zookeeper/"}]},{"title":"Apache Druid å­¦ä¹ ï¼šç»„ä»¶ä»¥åŠæŸ¥è¯¢ç±»å‹","date":"2019-10-22T02:40:12.000Z","path":"2019/10/22/apache-druid:study-components-and-query-types/","text":"Apache Druid å­¦ä¹ ï¼šç»„ä»¶ä»¥åŠæŸ¥è¯¢ç±»å‹ OLAPåŸºæœ¬æ¦‚å¿µç»´åº¦(Dimension): æŒ‡çš„æ˜¯è§‚å¯Ÿæ•°æ®çš„ä¸€ä¸ªè§’åº¦ï¼Œæ˜¯è€ƒè™‘é—®é¢˜çš„ä¸€ç±»å±æ€§ï¼Œè¿™äº›å±æ€§çš„é›†åˆç»Ÿç§°ä¸ºä¸€ä¸ªç»´ã€‚ç»´çš„çº§åˆ«(Level): å¯¹æ•°æ®çš„è§‚å¯Ÿè¿˜å­˜åœ¨ç»†èŠ‚ç¨‹åº¦çš„ä¸åŒï¼Œåœ¨druidä¸­ä¸€èˆ¬è¡¨ç¤ºä¸ºæ—¶é—´çš„ç²’åº¦(granularity)ï¼Œæ¯”å¦‚ä¸€ç§’ï¼Œä¸€åˆ†é’Ÿï¼Œä¸€å°æ—¶ï¼Œä¸€å¤©â€¦â€¦ åº¦é‡(Measure): åº¦é‡æ˜¯ç”¨æ¥èšåˆåˆ†æè®¡ç®—çš„æ•°å­—ä¿¡æ¯ï¼Œåœ¨druidä¸­ç§°ä¸ºâ€metricsâ€ï¼Œå®ƒå¯ä»¥æ˜¯å­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œä¹Ÿå¯ä»¥æ˜¯é€šè¿‡ç­–ç•¥è®¡ç®—å¾—å‡ºçš„ã€‚æ¯”å¦‚ä¸€ç¯‡æ–‡ç« çš„ç‚¹å‡»æ•°ã€æˆ–è€…æ˜¯æ ¹æ®è¯„è®ºæ•°ã€ç‚¹å‡»æ•°ã€è½¬å‘æ•°è®¡ç®—å‡ºçš„çƒ­ç‚¹å€¼ å¯¹äºæ•°æ®å¤„ç†å‘ä¸‹é’»å–(Drill-down)/ä¸Šå·(Roll-up): æ”¹å˜ç»´çš„å±‚æ¬¡å’Œçº§åˆ«ï¼Œå˜æ¢åˆ†æçš„ç²’åº¦ã€‚Roll-upåœ¨äºæå‡ç»´çš„çº§åˆ«ï¼ˆæˆ–è€…ç§°ç²’åº¦ï¼‰æˆ–è€…å‡å°‘ç»´åº¦æ¥èšåˆæ•°æ®ï¼Œå±•ç°æ€»è§ˆï¼ŒDrill-downåä¹‹ï¼Œé™ä½ç»´çš„çº§åˆ«(æˆ–è€…ç§°ç²’åº¦)æˆ–å¢åŠ ç»´åº¦æ¥æŸ¥çœ‹ç»†èŠ‚åˆ‡ç‰‡(slice)å’Œåˆ‡å—(dice): å½“ç»´åº¦ä¸ºä¸¤ä¸ªæ—¶ï¼Œæˆ‘ä»¬å¯¹è·å–æ•°æ®(æŸ¥è¯¢)çš„æ“ä½œç§°ä¹‹ä¸ºåˆ‡ç‰‡ï¼Œå½“ç»´åº¦çš„æ•°é‡å¤§äºä¸¤ä¸ªæ—¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºåˆ‡å—æ—‹è½¬(Pivoting): å˜æ¢ç»´çš„æ–¹å‘ï¼Œä¾‹å¦‚è¡¨æ ¼ä¸­çš„è¡Œåˆ—äº’æ¢ æŸ¥è¯¢æ¡ä»¶å‚æ•° å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¯¹åº”èšåˆæŸ¥è¯¢ä¸‹çš„ç±»å‹å€¼ï¼štimeseriesã€topNã€groupByç­‰ æ˜¯ dataSource æ•°æ®æºï¼Œç±»ä¼¼å…³ç³»æ•°æ®åº“ä¸­è¡¨çš„æ¦‚å¿µï¼Œå¯¹åº”æ•°æ®å¯¼å…¥æ—¶Jsoné…ç½®å±æ€§dataSourceå€¼ æ˜¯ descending è¿”å›ç»“æœæ˜¯å¦é€†åºï¼Œé»˜è®¤å€¼ä¸ºå¦ï¼ˆæ­£åºï¼‰ å¦ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ filter å¯¹Dimensionè¿›è¡Œè¿‡æ»¤ï¼Œå¯ä»¥æ ¹æ®æƒ…å†µå¯¹å‡ ä¸ªç»´åº¦ç»„åˆä¸åŒçš„filterç±»å‹(andã€orã€notã€bound)ï¼Œè¿˜å¯ä»¥æ ¹æ®éœ€è¦å®šä¹‰javascript functionè¿›è¡Œè¿‡æ»¤ å¦ aggregations æŒ‡å®šåº¦é‡åœ¨èšåˆæ—¶å€™çš„è®¡ç®—ç­–ç•¥ï¼Œä¾‹å¦‚ç›¸åŠ ã€æˆ–è€…æ±‚å¹³å‡å€¼ã€åˆæˆ–è€…å–æœ€åä¸€ä¸ªå€¼ï¼Œåœ¨å†…ç½®ç±»å‹ä¸æ»¡è¶³çš„æƒ…å†µä¸‹å¯ä»¥ä½¿ç”¨javascriptã€‚æ¯”å¦‚æŸæ‰‹æ¸¸ä¸­æˆ‘ç»Ÿè®¡äº†æˆ‘æ¯ä¸€å±€å‡»æ€å°æ€ªæ•°é‡ï¼Œä»¥åŠé‡æ€ªçš„æ•°é‡ï¼Œé€šè¿‡èšåˆç­–ç•¥sumï¼Œæˆ‘èƒ½çŸ¥é“æˆ‘ä»å¼€å·ä»¥æ¥å‡»æ€äº†å¤šå°‘å°æ€ªå’Œé‡æ€ªã€‚ å¦ postAggregations åèšåˆç­–ç•¥ï¼Œæä¾›äº†å¤šä¸ªåº¦é‡ç»„åˆç”Ÿæˆæ–°åº¦é‡çš„èƒ½åŠ›ï¼Œä¸»è¦æœ‰åˆ©äºèšåˆè®¡ç®—çš„æŠ½è±¡ï¼Œé¿å…å¯¹ä¸€äº›æŒ‡æ ‡çš„é‡å¤è®¡ç®—ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡å¦‚æˆ‘éœ€è¦ä¸€ä¸ªåº¦é‡ï¼Œæ˜¯æˆ‘å‡»æ€å°æ€ªå’Œé‡æ€ªçš„æ€»å’Œï¼Œé‚£ä¹ˆï¼Œæˆ‘åªéœ€è¦åœ¨åèšåˆé˜¶æ®µè®¡ç®—ï¼Œåªéœ€è¦æ‹¿å°æ€ªå’Œé‡æ€ªçš„æ•°é‡ç›¸åŠ ä¸€æ¬¡ï¼Œå¤§å¤§åœ°æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚ å¦ granularity æŸ¥è¯¢çš„æ—¶é—´ç²’åº¦ï¼Œæœ€ç»†ç²’åº¦ä¸ºç§’ï¼Œæœ€å¤§ç²’åº¦ä¸ºallï¼Œæä¾›äº†æ—¶é—´ç»´åº¦çº§åˆ«çš„è°ƒæ•´å¹¶å¯¹æ•°æ®è¿›è¡Œä¸Šå·å’Œå‘ä¸‹é’»å–çš„èƒ½åŠ› æ˜¯ dimensionSpec æä¾›äº†ç»´åº¦åœ¨èšåˆå‰è¾“å‡ºå±•ç¤ºå€¼å®šåˆ¶çš„èƒ½åŠ›ï¼Œæ¯”å¦‚åœ¨Dimension ageä¸€åˆ—ä¸­ï¼Œæ‹¿åˆ°çš„æ˜¯å­—ç¬¦ä¸²ç±»å‹çš„æ•°å­—ï¼Œæˆ‘å¸Œæœ›è½¬æˆæ•°å­—ç±»å‹ï¼Œåˆæˆ–è€…å®šåˆ¶ä¸€ä¸ªjavascript functionï¼Œç»Ÿä¸€ä»¥ ${age} year oldçš„å½¢å¼å±•ç° å¦ limit è¿”å›ç»“æœæ•°é‡é™åˆ¶ å¦ context è¡¨ç¤ºå¯¹å½“å‰æŸ¥è¯¢æœ¬èº«çš„ä¸€äº›é…ç½®ï¼Œæ¯”å¦‚è®¾ç½®æŸ¥è¯¢è¶…æ—¶çš„æ—¶é—´ï¼Œåˆæ¯”å¦‚æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œåœ¨é€šç”¨çš„é…ç½®åŸºç¡€ä¸Šï¼Œæ¯ç§æŸ¥è¯¢ç±»å‹è¿˜æœ‰ç‰¹å®šçš„é…ç½®ï¼Œè¯¦è§æ–‡æ¡£ å¦ åŸºæœ¬ç»„ä»¶filterè¿‡æ»¤å™¨ï¼Œåœ¨æŸ¥è¯¢è¯­å¥ä¸­æ˜¯ä¸€ä¸ªjsonå¯¹è±¡ï¼Œç”¨æ¥å¯¹ç»´åº¦è¿›è¡Œç­›é€‰ï¼Œè¡¨ç¤ºæ»¡è¶³filterçš„æ˜¯æˆ‘ä»¬éœ€è¦çš„æ•°æ®ã€‚ç±»ä¼¼äºSQLä¸­çš„whereã€‚ ç±»å‹ åŠŸèƒ½ SelectorFilter åŠŸèƒ½ç±»ä¼¼äºSQLä¸­çš„where key=value AndFilter, OrFilter, NotFilter åŠŸèƒ½ç±»ä¼¼äºSQLä¸­andã€orã€notä¸‰ç§è¿‡æ»¤å™¨ã€‚æ”¯æŒé€’å½’åµŒå¥—ï¼Œå¯ä»¥æ„é€ å‡ºä¸°å¯Œçš„é€»è¾‘è¡¨è¾¾å¼ RegexFilter æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ”¯æŒä»»æ„ç»´åº¦å€¼çš„javaæ­£åˆ™ SearchFilter é€šè¿‡å­—ç¬¦ä¸²åŒ¹é…ç»´åº¦ï¼Œæ”¯æŒå¤šç§è¡¨è¾¾å¼ InFilter åŠŸèƒ½ç±»ä¼¼äºSQLä¸­where key in (value1, value2) IntervalFilter é’ˆå¯¹äºæ—¶é—´ç»´åº¦è¿‡æ»¤ BoundFilter åŠŸèƒ½ç±»ä¼¼äºSQLä¸­çš„å¤§äºã€å°äºã€ç­‰äºä¸‰ç§ç®—å­ JavaScriptFilter ä¸Šè¿°filterå‡ä¸èƒ½æ»¡è¶³å¯ä»¥è‡ªå·±å†™JavaScriptæ¥è¿‡æ»¤ç»´åº¦ aggregatorèšåˆå¯ä»¥åœ¨é‡‡é›†æ•°æ®æ—¶è§„æ ¼éƒ¨åˆ†çš„ä¸€ç§æ–¹å¼ï¼Œæ±‡æ€»æ•°æ®è¿›å…¥Druidä¹‹å‰æä¾›ã€‚èšåˆä¹Ÿå¯ä»¥è¢«æŒ‡å®šä¸ºåœ¨æŸ¥è¯¢æ—¶å¤šæŸ¥è¯¢çš„éƒ¨åˆ†ï¼Œèšåˆç±»å‹å¦‚ä¸‹ï¼š ç±»å‹ åŠŸèƒ½ CountAggregator SQL count(key) SumAggregator SQL sum(key) MaxAggregator, MinAggregator SQL max(key), min(key) DistinctCountAggregator SQL count(distinct key) JavaScriptAggregator ä¸Šè¿°aggregatorå‡ä¸èƒ½æ»¡è¶³å¯ä»¥è‡ªå·±å†™JavaScriptæ¥å®šä¹‰è®¡ç®— post-aggregator ç±»å‹ åŠŸèƒ½ ArithmeticPostAggregator æ”¯æŒå¯¹èšåˆåæŒ‡æ ‡è¿›è¡Œâ€+ - * / quotientâ€è®¡ç®— FieldAccessPostAggregator ç›´æ¥è·å–èšåˆçš„å­—æ®µï¼ˆç»´åº¦ï¼ŒæŒ‡æ ‡ï¼‰ ConstantPostAggregator è¿”å›å¸¸æ•° JavaScriptPostAggregator ä¸Šè¿°postAggregatorå‡ä¸èƒ½æ»¡è¶³å¯ä»¥è‡ªå·±å†™JavaScriptæ¥å®šä¹‰è®¡ç®— æŸ¥è¯¢ç±»å‹èšåˆæŸ¥è¯¢timeseriesæ—¶åºæŸ¥è¯¢ï¼Œå®é™…ä¸Šå³æ˜¯å¯¹æ•°æ®åŸºäºæ—¶é—´ç‚¹(timestamp)çš„ä¸€æ¬¡ä¸Šå·ã€‚é€‚åˆç”¨æ¥çœ‹æŸå‡ ä¸ªåº¦é‡åœ¨ä¸€ä¸ªæ—¶é—´æ®µå†…çš„è¶‹åŠ¿ã€‚æ’åºå¯æŒ‰æ—¶é—´é™åºæˆ–å‡åº å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¿…é¡»ä¸º â€œtimeseriesâ€ æ˜¯ dataSource æ•°æ®æºï¼Œæ¯”å¦‚ â€œwikipediaâ€ æ˜¯ descending è¿”å›ç»“æœæ˜¯å¦é€†åºï¼Œé»˜è®¤å€¼ä¸ºå¦ï¼ˆæ­£åºï¼‰ å¦ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ granularity èšåˆç²’åº¦ï¼Œç²’åº¦å†³å®šå¦‚ä½•åœ¨è·¨æ—¶é—´ç»´åº¦å¾—åˆ°æ•°æ®å— æ˜¯ filter å¦ aggregations å¦ postAggregations å¦ limit å¦ context å¦ contextï¼š 1.grandTotal 2.é›¶å¡«å……å¦‚æœæ—¶é—´èŒƒå›´å†…æ²¡æœ‰å€¼ï¼Œåˆ™ä¼šå¡«å……0æ—¶é—´åºåˆ—æŸ¥è¯¢é€šå¸¸ç”¨é›¶å¡«å……ç©ºçš„å†…éƒ¨æ—¶é—´æ®µã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å¯¹é—´éš”2012-01-01 / 2012-01-04å‘å‡ºâ€œå¤©â€ç²’åº¦æ—¶é—´åºåˆ—æŸ¥è¯¢ï¼Œè€Œ2012-01-02æ²¡æœ‰æ•°æ®å­˜åœ¨ï¼Œæ‚¨å°†æ”¶åˆ°ï¼š 1234567891011121314[ &#123; \"timestamp\": \"2012-01-01T00:00:00.000Z\", \"result\": &#123; \"sample_name1\": &lt;some_value&gt; &#125; &#125;, &#123; \"timestamp\": \"2012-01-02T00:00:00.000Z\", \"result\": &#123; \"sample_name1\": 0 &#125; &#125;, &#123; \"timestamp\": \"2012-01-03T00:00:00.000Z\", \"result\": &#123; \"sample_name1\": &lt;some_value&gt; &#125; &#125;] topNåœ¨æ—¶é—´ç‚¹çš„åŸºç¡€ä¸Šï¼Œåˆå¢åŠ äº†ä¸€ä¸ªç»´åº¦(OLAPçš„æ¦‚å¿µç®—ä¸¤ä¸ªç»´åº¦)ï¼Œè¿›è€Œå¯¹æºæ•°æ®è¿›è¡Œåˆ‡ç‰‡ï¼Œåˆ‡ç‰‡ä¹‹ååˆ†åˆ«ä¸Šå·ï¼Œæœ€åè¿”å›ä¸€ä¸ªèšåˆé›†ï¼Œä½ å¯ä»¥æŒ‡å®šæŸä¸ªæŒ‡æ ‡ä½œä¸ºæ’åºçš„ä¾æ®ã€‚å®˜æ–¹æ–‡æ¡£ç§°è¿™å¯¹æ¯”å•ä¸ªdruid dimension çš„groupBy æ›´é«˜æ•ˆã€‚é€‚åˆçœ‹æŸä¸ªç»´åº¦ä¸‹çš„æ—¶é—´è¶‹åŠ¿ï¼Œï¼ˆæ¯”å¦‚ç¾å›½å’Œä¸­å›½åå¹´å†…GDPçš„å¢é•¿è¶‹åŠ¿æ¯”å¯¹ï¼Œåœ¨è¿™é‡Œé™¤äº†æ—¶é—´å¤–å›½å®¶å°±æ˜¯å¦å¤–ä¸€ä¸ªç»´åº¦ï¼‰ å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¿…é¡»ä¸º â€œtopNâ€ æ˜¯ dataSource æ•°æ®æºï¼Œæ¯”å¦‚ â€œwikipediaâ€ æ˜¯ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ granularity èšåˆç²’åº¦ï¼Œç²’åº¦å†³å®šå¦‚ä½•åœ¨è·¨æ—¶é—´ç»´åº¦å¾—åˆ°æ•°æ®å— æ˜¯ filter å¦ aggregations å¦ postAggregations å¦ dimension é™¤äº†æ—¶é—´ä¹‹å¤–èšåˆçš„ç»´åº¦ï¼Œåªèƒ½å®šä¹‰ä¸€ä¸ªç»´åº¦ æ˜¯ threshold topNä¸­çš„Nï¼Œä¾‹å¦‚ï¼šå¸Œæœ›æŸ¥è¯¢åˆ°top2ï¼Œåˆ™å€¼ä¸º2 æ˜¯ metric topNä¸­ç”¨æ¥æ’åºçš„æŒ‡æ ‡ æ˜¯ context å¦ groupByé€‚ç”¨äºä¸¤ä¸ªç»´åº¦ä»¥ä¸Šçš„æŸ¥è¯¢ï¼Œdruidä¼šæ ¹æ®ç»´åº¦åˆ‡å—ï¼Œå¹¶ä¸”åˆ†åˆ«ä¸Šå·ï¼Œæœ€åè¿”å›èšåˆé›†ã€‚ç›¸å¯¹äºtopNè€Œè¨€ï¼Œè¿™æ˜¯ä¸€ä¸ªå‘ä¸‹é’»å–çš„æ“ä½œï¼Œæ¯å¤šä¸€ä¸ªç»´åº¦æ„å‘³ç€ä¿ç•™æ›´å¤šçš„ç»†èŠ‚ã€‚(æ¯”å¦‚å¢åŠ ä¸€ä¸ªè¡Œä¸šçš„ç»´åº¦ï¼Œå°±å¯ä»¥çŸ¥é“ç¾å›½å’Œä¸­å›½åå¹´å†…ï¼Œæ¯ä¸€å¹´ä¸åŒè¡Œä¸šè´¡çŒ®GDPçš„å æ¯”)æ³¨æ„ï¼šå¦‚æœè¦ä½¿ç”¨æ—¶é—´ä½œä¸ºå”¯ä¸€åˆ†ç»„è¿›è¡Œèšåˆï¼Œæˆ–è€…åœ¨å•ä¸ªç»´åº¦ä¸Šä½¿ç”¨æœ‰åºgroupByè¿›è¡Œèšåˆï¼Œè¯·ä¼˜å…ˆè€ƒè™‘ä½¿ç”¨Timeserieså’ŒTopNæŸ¥è¯¢ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå®ƒä»¬çš„æ€§èƒ½å¯èƒ½ä¼šæ›´å¥½ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ä¸‹é¢çš„æ›¿ä»£æ–¹æ³•ã€‚ å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¿…é¡»ä¸º â€œgroupByâ€ æ˜¯ dataSource æ•°æ®æºï¼Œæ¯”å¦‚ â€œwikipediaâ€ æ˜¯ dimensions éœ€è¦èšåˆçš„æ‰€æœ‰ç»´åº¦ æ˜¯ limitSpec åŒå…³ç³»å‹æ•°æ®åº“ä¸­çš„limit å¦ having åŒå…³ç³»å‹æ•°æ®åº“ä¸­çš„having å¦ granularity èšåˆç²’åº¦ï¼Œç²’åº¦å†³å®šå¦‚ä½•åœ¨è·¨æ—¶é—´ç»´åº¦å¾—åˆ°æ•°æ®å— æ˜¯ filter å¦ aggregations å¦ postAggregations å¦ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ subtotalsSpec ç±»ä¼¼äºçš„grouping sets å¦ context å¦ æ™®é€šæŸ¥è¯¢selectç±»ä¼¼SQLä¸­çš„selectæ“ä½œï¼Œselectç”¨æ¥æŸ¥çœ‹Druidä¸­å­˜å‚¨çš„æ•°æ®ï¼Œå¹¶æ”¯æŒæŒ‰ç…§æŒ‡å®šè¿‡æ»¤å™¨å’Œæ—¶é—´æŸ¥çœ‹æŒ‡å®šç»´åº¦å’ŒæŒ‡æ ‡ã€‚ä¸æ”¯æŒaggregationså’Œpost aggregations æ³¨æ„ï¼šå»ºè®®æ‚¨å°½å¯èƒ½ä½¿ç”¨scanæŸ¥è¯¢ç±»å‹è€Œä¸æ˜¯selectã€‚åœ¨æ¶‰åŠå¤§é‡segmentçš„æƒ…å†µä¸‹ï¼ŒselectæŸ¥è¯¢å¯èƒ½å…·æœ‰å¾ˆé«˜çš„å†…å­˜å’Œæ€§èƒ½å¼€é”€ï¼Œä½†æ˜¯scanæŸ¥è¯¢æ²¡æœ‰æ­¤é—®é¢˜ã€‚ä¸¤è€…ä¹‹é—´çš„ä¸»è¦åŒºåˆ«æ˜¯â€œæ‰«æâ€æŸ¥è¯¢ä¸æ”¯æŒåˆ†é¡µã€‚ä½†æ˜¯ï¼Œå³ä½¿æ²¡æœ‰åˆ†é¡µï¼ŒscanæŸ¥è¯¢ç±»å‹ä¹Ÿèƒ½å¤Ÿè¿”å›å‡ ä¹æ— é™æ•°é‡çš„ç»“æœï¼Œä½¿å¾—åˆ†é¡µåœ¨è®¸å¤šæƒ…å†µä¸‹æ˜¯ä¸å¿…è¦çš„ã€‚ å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¿…é¡»ä¸º â€œselectâ€ æ˜¯ dataSource æ•°æ®æºï¼Œæ¯”å¦‚ â€œwikipediaâ€ æ˜¯ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ descending è¿”å›ç»“æœæ˜¯å¦é€†åºï¼Œé»˜è®¤å€¼ä¸ºå¦ï¼ˆæ­£åºï¼‰ å¦ filter å¦ dimensions éœ€è¦æŸ¥è¯¢çš„ç»´åº¦åˆ—è¡¨ å¦ metrics éœ€è¦æŸ¥è¯¢çš„æŒ‡æ ‡åˆ—è¡¨ å¦ granularity èšåˆç²’åº¦ï¼Œç²’åº¦å†³å®šå¦‚ä½•åœ¨è·¨æ—¶é—´ç»´åº¦å¾—åˆ°æ•°æ®å—ï¼Œé»˜è®¤æ˜¯Granularity.ALL å¦ pagingSpec åˆ†é¡µ æ˜¯ context å¦ scanæ‰«ææŸ¥è¯¢ä»¥æµæ¨¡å¼è¿”å›è¡Œï¼ŒSelectæŸ¥è¯¢å’ŒScanæŸ¥è¯¢ä¹‹é—´çš„æœ€å¤§åŒºåˆ«æ˜¯ï¼ŒScanæŸ¥è¯¢å­è¿”å›ç»™å®¢æˆ·ç«¯æ•°æ®ä¹‹å‰ä¸ä¼šå°†æ‰€æœ‰è¡Œæ•°æ®ä¿ç•™åœ¨å†…å­˜ä¸­è€ŒselectæŸ¥è¯¢å°†æŠŠè¡Œä¿ç•™åœ¨å†…å­˜ä¸­ï¼Œå¦‚æœè¿”å›å¤ªå¤šè¡Œï¼Œåˆ™ä¼šå¯¼è‡´å†…å­˜å‹åŠ›ã€‚æ‰«ææŸ¥è¯¢å¯ä»¥è¿”å›æ‰€æœ‰è¡Œï¼Œè€Œæ— éœ€å‘å‡ºå¦ä¸€ä¸ªåˆ†é¡µæŸ¥è¯¢ã€‚ é™¤äº†å°†scanæŸ¥è¯¢å‘é€ç»™serverçš„ç”¨æ³•å¤–ï¼Œè¿˜å¯ä»¥ç›´æ¥å‘historicalå†å²è®°å½•è¿›ç¨‹æˆ–streaming ingestionæµå¼æå–ä»»åŠ¡å‘å‡ºæ‰«ææŸ¥è¯¢ã€‚å¦‚æœè¦å¹¶è¡Œæ£€ç´¢å¤§é‡æ•°æ®ï¼Œè¿™å°†å¾ˆæœ‰ç”¨ã€‚ å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¿…é¡»ä¸º â€œscanâ€ æ˜¯ dataSource æ•°æ®æºï¼Œæ¯”å¦‚ â€œwikipediaâ€ æ˜¯ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ resultFormat è¿”å›ç»“æœç±»å‹ï¼šlistï¼ŒcompactedListæˆ–valueVectorã€‚ç›®å‰ä»…listå’ŒcompactedListå—æ”¯æŒã€‚é»˜è®¤æ˜¯list å¦ filter å¦ columns éœ€è¦scançš„ç»´åº¦å’ŒæŒ‡æ ‡ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰ å¦ batchSize è¿”å›æ•°æ®ä¹‹å‰é»˜è®¤ç¼“å­˜æœ€å¤šå¤šå°‘è¡Œ å¦ limit æŸ¥è¯¢è¿”å›æœ€å¤§çš„æ•°æ®æ¡ç›®ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œåˆ™è¿”å›æ‰€æœ‰çš„æ•°æ® å¦ order è¿”å›æ•°æ®çš„orderï¼ŒåŸºäºtimestampï¼Œå¹¶ä¸”åªæœ‰__timeè¢«åŒ…å«åœ¨columnsä¸­æ‰ç”Ÿæ•ˆ å¦ legacy å¦ context å¦ searchç±»ä¼¼SQLä¸­çš„Likeæ“ä½œï¼Œä½†æ˜¯æ”¯æŒæ›´å¤šçš„åŒ¹é…æ“ä½œ å­—æ®µå æè¿° æ˜¯å¦å¿…é¡» queryType æŸ¥è¯¢ç±»å‹ï¼Œå¿…é¡»ä¸º â€œsearchâ€ æ˜¯ dataSource æ•°æ®æºï¼Œæ¯”å¦‚ â€œwikipediaâ€ æ˜¯ granularity èšåˆç²’åº¦ï¼Œç²’åº¦å†³å®šå¦‚ä½•åœ¨è·¨æ—¶é—´ç»´åº¦å¾—åˆ°æ•°æ®å— æ˜¯ filter å¦ limit æ¯ä¸ªå†å²è¿›ç¨‹çš„æœ€å¤§æŸ¥è¯¢è¿”å›æ•°æ®æ¡ç›®ï¼ˆé»˜è®¤æ˜¯1000ï¼‰ å¦ intervals æŸ¥è¯¢æ—¶é—´åŒºé—´ æ˜¯ searchDimensions éœ€è¦searchçš„ç»´åº¦ï¼ˆé»˜è®¤æ˜¯æ‰€æœ‰ç»´åº¦ï¼‰ï¼Œkey like valueä¸­çš„key å¦ query searchç»´åº¦éœ€è¦åŒ¹é…çš„valueï¼Œkey like valueä¸­çš„value æ˜¯ sort æŒ‡å®šåº”å¦‚ä½•å¯¹æœç´¢ç»“æœè¿›è¡Œæ’åºï¼ŒåŒ…æ‹¬å­—å…¸ç¼–æ’ï¼ˆé»˜è®¤æ’åºï¼‰ï¼Œå­—æ¯æ•°å­—ï¼Œstrlenå’Œæ•°å­—æ’åº å¦ context å¦ å…ƒæ•°æ®æŸ¥è¯¢time boundingsegment metadatadataSource metadata","tags":[{"name":"Apache Druid","slug":"Apache-Druid","permalink":"https://yangyichao-mango.github.io/tags/Apache-Druid/"}]},{"title":"Apache Druid å­¦ä¹ ï¼škafka to druid","date":"2019-10-21T07:08:45.000Z","path":"2019/10/21/apache-druid:study-kafka-to-druid/","text":"Apache Druid å­¦ä¹ ï¼škafka to druid demo Druid Webæ“ä½œå®˜ç½‘æ•™ç¨‹ Java Demo","tags":[{"name":"Apache Druid","slug":"Apache-Druid","permalink":"https://yangyichao-mango.github.io/tags/Apache-Druid/"},{"name":"Apache Kafka","slug":"Apache-Kafka","permalink":"https://yangyichao-mango.github.io/tags/Apache-Kafka/"}]},{"title":"Macå®‰è£…Apache Druid-0.16.0-incubating","date":"2019-10-21T06:21:53.000Z","path":"2019/10/21/apache-druid:0.16.0-incubating-mac-install/","text":"Macå®‰è£…Apache Druid-0.16.0-incubatingæ•™ç¨‹ å®‰è£…å‚è€ƒå®˜ç½‘æ•™ç¨‹ brewå®‰è£…1brew install druid quer ä¸‹è½½å®‰è£…123$ curl https://www-us.apache.org/dist/incubator/druid/0.16.0-incubating/apache-druid-0.16.0-incubating-bin.tar.gz$ tar -xzf apache-druid-0.16.0-incubating-bin.tar.gz$ cd apache-druid-0.16.0-incubating é…ç½®å¯åŠ¨å¯åŠ¨druidæœåŠ¡ä¹‹å‰éœ€è¦å…ˆå¯åŠ¨zookeeperï¼Œä¸‹é¢æœ‰ä¸¤ç§æ–¹å¼å¯åŠ¨å’Œä½¿ç”¨zookeeper ä½¿ç”¨é›†æˆzookeeper1234$ cd $DRUID_HOME // éœ€è¦åœ¨~/.bash_profileä¸­è¿›è¡Œé…ç½®$ curl https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz -o zookeeper-3.4.14.tar.gz$ tar -xzf zookeeper-3.4.14.tar.gz$ mv zookeeper-3.4.14 zk ä½¿ç”¨å¤–éƒ¨zookeeperä¿®æ”¹ $DRUID_HOME/conf/supervise/single-server/micro-quickstart.conf ä¸­çš„é…ç½®å°† !p10 zk bin/run-zk conf æ³¨é‡Šæ‰ 123456789101112131415$ vi $DRUID_HOME/conf/supervise/single-server/micro-quickstart.conf:verify bin/verify-java:verify bin/verify-default-ports:kill-timeout 10# !p10 zk bin/run-zk conf // è¿™é‡Œæ˜¯è¿è¡Œé›†æˆzookeeperçš„ä»£ç ï¼Œæ‰€ä»¥è¦æ³¨é‡Šæ‰coordinator-overlord bin/run-druid coordinator-overlord conf/druid/single-server/micro-quickstartbroker bin/run-druid broker conf/druid/single-server/micro-quickstartrouter bin/run-druid router conf/druid/single-server/micro-quickstarthistorical bin/run-druid historical conf/druid/single-server/micro-quickstart!p90 middleManager bin/run-druid middleManager conf/druid/single-server/micro-quickstart# Uncomment to use Tranquility Server#!p95 tranquility-server tranquility/bin/tranquility server -configFile conf/tranquility/wikipedia-server.json -Ddruid.extensions.loadList=[] ä¿®æ”¹ $DRUID_HOME/conf/druid/single-server/micro-quickstart/_common/common.runtime.properties ä¸­çš„é…ç½®ä¿®æ”¹zookeeperçš„clienté…ç½® 1234567$ vim $DRUID_HOME/conf/druid/single-server/micro-quickstart/_common/common.runtime.properties# é…ç½®å¤–éƒ¨zookeeperçš„ä¿¡æ¯# zookeeperï¼Œå¤§æ¦‚åœ¨46~55è¡Œä¸­é—´ï¼Œå¯¹zkè¿›è¡Œé…ç½®# zookeeperçš„serverè¿è¡Œåœ¨2181ç«¯å£ä¸Šdruid.zk.service.host=127.0.0.1:2181druid.zk.paths.base=/druid ä¿®æ”¹ $DRUID_HOME/bin/verify-default-ports ä¸­çš„é…ç½®å› ä¸ºä½¿ç”¨äº†å¤–éƒ¨zookeeperï¼Œå¹¶ä¸”å¤–éƒ¨zookeeperçš„ip:portä¸º127.0.0.1:2181æ‰€ä»¥éœ€è¦å°†zookeeperçš„2181ç«¯å£åˆ é™¤ï¼Œå¦åˆ™ä¼šæ ¡éªŒæœ¬æœº2181ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼Œå› ä¸ºæœ¬æœºzookeeperå·²ç»å°†å…¶å ç”¨ï¼Œåˆ™ä¼šæŠ¥é”™ï¼ŒæœåŠ¡ä¸èƒ½å¯åŠ¨å¦‚æœä½¿ç”¨çš„zookeeperçš„ä¸åœ¨æœ¬æœºéƒ¨ç½²ï¼Œåˆ™å¯ä»¥ä¸æ³¨é‡Š2181 12345$ vi $DRUID_HOME/bin/verify-default-ports# my @ports = (1527, 2181, 8081, 8082, 8083, 8090, 8091, 8200, 9095);my @ports = (1527, 8081, 8082, 8083, 8090, 8091, 8200, 9095); å¯åŠ¨æœåŠ¡1$ ./bin/start-micro-quickstart å¯ä»¥åˆ°http://localhost:8888æŸ¥çœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸ","tags":[{"name":"Apache Druid","slug":"Apache-Druid","permalink":"https://yangyichao-mango.github.io/tags/Apache-Druid/"},{"name":"Apache Zookeeper","slug":"Apache-Zookeeper","permalink":"https://yangyichao-mango.github.io/tags/Apache-Zookeeper/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šhbaseä½œä¸ºsink","date":"2019-10-20T06:27:49.000Z","path":"2019/10/20/apache-flink:study-hbase-sink/","text":"Apache Flink å­¦ä¹ ï¼šhbaseä½œä¸ºsinkçš„demo ä¾èµ–é¡¹1234567891011&lt;properties&gt; &lt;hbase.version&gt;2.0.5&lt;/hbase.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;$&#123;hbase.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; demoä»£ç ä½¿ç”¨äº†hbaseä½œä¸ºsourceï¼Œhbaseä½œä¸ºsink è¿è¡Œä¹‹å‰éœ€è¦è¿è¡Œhadoopé›†ç¾¤ï¼ˆzookeeperé›†ç¾¤ï¼‰ï¼Œhbaseé›†ç¾¤flinkæ ¹æ®éƒ¨ç½²çš„é›†ç¾¤ä¿¡æ¯ï¼ˆæ¯”å¦‚zookeeperçš„ip:portä¸º127.0.0.1:2181ç­‰çš„ä¿¡æ¯ï¼‰å»è¿æ¥hbase hbase-site.xml12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--Autogenerated by Cloudera Manager--&gt;&lt;configuration&gt; &lt;!-- zk configuration --&gt; &lt;property&gt; &lt;name&gt;zookeeper.session.timeout&lt;/name&gt; &lt;value&gt;60000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;zookeeper.znode.parent&lt;/name&gt; &lt;value&gt;/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; HBaseReaderHBaseä½œä¸ºsource 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static class HBaseReader extends RichSourceFunction&lt;String&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(HBaseReader.class); private transient HBaseClient hBaseClient; private static final String DEFAULT_HBASE_SOURCE_TABLE_NAME = \"student\"; private static final String DEFAULT_HBASE_SOURCE_START_ROW = \"row1\"; private static final String DEFAULT_HBASE_SOURCE_STOP_ROW = \"row1\"; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); if (Objects.isNull(hBaseClient)) &#123; synchronized (this) &#123; if (Objects.isNull(hBaseClient)) &#123; hBaseClient = new HBaseClient(); hBaseClient.initialize(); &#125; &#125; &#125; &#125; @Override public void run(SourceContext&lt;String&gt; ctx) throws Exception &#123; List&lt;byte[]&gt; results = hBaseClient.scan( DEFAULT_HBASE_SOURCE_TABLE_NAME , DEFAULT_HBASE_SOURCE_START_ROW , DEFAULT_HBASE_SOURCE_STOP_ROW); results.forEach(result -&gt; ctx.collect(new String(result))); &#125; @Override public void cancel() &#123; if (Objects.isNull(hBaseClient)) &#123; synchronized (this) &#123; if (Objects.isNull(hBaseClient)) &#123; try &#123; hBaseClient.destroy(); &#125; catch (IOException e) &#123; LOGGER.error(\"\", e); &#125; &#125; &#125; &#125; &#125;&#125; HBaseWriterHBaseä½œä¸ºsink 12345678910111213141516171819202122232425262728293031323334353637383940414243public static class HBaseWriter extends RichSinkFunction&lt;Tuple2&lt;String, Integer&gt;&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(HBaseWriter.class); private transient HBaseClient hBaseClient; @Override public void open(Configuration parameters) throws Exception &#123; super.open(parameters); if (Objects.isNull(hBaseClient)) &#123; synchronized (this) &#123; if (Objects.isNull(hBaseClient)) &#123; hBaseClient = new HBaseClient(); hBaseClient.initialize(); &#125; &#125; &#125; &#125; @Override public void invoke(Tuple2&lt;String, Integer&gt; value, Context context) throws IOException &#123; String result = value.toString(); Put put = hBaseClient.createPut(\"row2\"); hBaseClient.addValueOnPut(put, \"description\", \"age\", \"19\"); hBaseClient.put(\"student\", put); &#125; @Override public void close() throws Exception &#123; super.close(); if (Objects.isNull(hBaseClient)) &#123; synchronized (this) &#123; if (Objects.isNull(hBaseClient)) &#123; try &#123; hBaseClient.destroy(); &#125; catch (IOException e) &#123; LOGGER.error(\"\", e); &#125; &#125; &#125; &#125; &#125;&#125; å®šä¹‰dag12345678910111213141516171819202122232425public static void main(String[] args) throws Exception &#123; final SourceFunction&lt;String&gt; source; final ParameterTool params = ParameterTool.fromArgs(args); /******************************* hbase source *******************************/ source = new HBaseReader(); /******************************* define dag *******************************/ // create the environment to create streams and configure execution final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); DataStream&lt;String&gt; sentenceStream = env.addSource(source); DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCountStream = sentenceStream .flatMap(new LineSplitter()) .keyBy(0) .sum(1); /******************************* hbase sink *******************************/ wordCountStream.addSink(new HBaseWriter()); wordCountStream.print(); env.execute(\"Java hbase Word Count\");&#125; æŸ¥çœ‹hbaseæ–‡ä»¶12345678910hbase(main):001:0&gt; scan 'student'ROW COLUMN+CELL row1 column=description:age, timestamp=1571460125600, value=18 row1 column=description:name, timestamp=1571460129987, value=li u # è®°å½•ä»¥åŠè¢«å†™å…¥hbase row2 column=description:age, timestamp=1571576517072, value=192 row(s) in 0.2010 secondshbase(main):002:0&gt; å‘ç°columnFamilyNameä¸ºdescriptionï¼ŒcolumnNameä¸ºageï¼Œrowkeyä¸ºrow2ï¼Œvalueä¸º19çš„è®°å½•å·²ç»è¢«å†™å…¥hbase","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"},{"name":"Apache HBase","slug":"Apache-HBase","permalink":"https://yangyichao-mango.github.io/tags/Apache-HBase/"}]},{"title":"Macå®‰è£…Apache Zookeeper-3.4.12","date":"2019-10-20T03:23:17.000Z","path":"2019/10/20/apache-zookeeper:3.4.12-mac-install/","text":"Macå®‰è£…Apache Zookeeper-3.4.12æ•™ç¨‹ å®‰è£…å®‰è£…æ–¹å¼1-brewå®‰è£…1$ brew install zookeeper å®‰è£…æ–¹å¼2-ä¸‹è½½å‹ç¼©åŒ…ä»æ­¤åœ°å€ä¸‹è½½http://mirrors.hust.edu.cn/apache/zookeeper/stable/ è§£å‹é…ç½®æ–‡ä»¶ 1234$ tar -zxvf zookeeper-3.4.12.tar.gz // è§£å‹$ cd zookeeper-3.4.12/conf // åˆ‡æ¢åˆ°é…ç½®ç›®å½•ä¸‹$ mv zoo_sample.cfg zoo.cfg // æ›´æ”¹é»˜è®¤é…ç½®æ–‡ä»¶åç§°$ vi zoo.cfg // ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œè‡ªå®šä¹‰dataDir å¯åŠ¨å¯åŠ¨severç«¯åˆ‡æ¢åˆ°binç›®å½• 1234567891011$ pwd/user/local/Celler/zookeeper/3.4.12/bin$ lsREADME.txt zkCli.cmd zkEnv.cmd zkServer.cmd zookeeper.outzkCleanup.sh zkCli.sh zkEnv.sh zkServer.sh$ ./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /user/local/Celler/zookeeper/3.4.12/bin/../conf/zoo.cfgStarting zookeeper ... STARTED å¯åŠ¨clientç«¯12345678910111213141516171819./zkCli.sh -server 127.0.0.1:2181Connecting to 127.0.0.1:21812019-10-20 12:17:25,861 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.12-e5259e437540f349646870ea94dc2658c4e44b3b, built on 03/27/2018 03:55 GMT2019-10-20 12:17:25,864 [myid:] - INFO [main:Environment@100] - Client environment:host.name=localhost2019-10-20 12:17:25,864 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_1912019-10-20 12:17:25,866 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation2019-10-20 12:17:25,866 [myid:] - INFO [main:Environment@100] - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home/jre2019-10-20 12:17:25,868 [myid:] - INFO [main:ZooKeeper@441] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@799f7e29Welcome to ZooKeeper!2019-10-20 12:17:25,896 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1028] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)JLine support is enabled2019-10-20 12:17:25,959 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@878] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session2019-10-20 12:17:25,966 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1302] - Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x10000112e160008, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: 127.0.0.1:2181(CONNECTED) 0] ls /[zookeeper, hbase] åœæ­¢serverç«¯1234&gt; ./zkServer.sh stop //åœæ­¢åï¼Œå¦‚æœCLiæ²¡æœ‰å…³é—­ï¼Œå°†æŠ¥é”™ZooKeeper JMX enabled by defaultUsing config: zookeeper-3.4.12/bin/../conf/zoo.cfgStopping zookeeper ... STOPPED é…ç½®æ–‡ä»¶123456789101112131415161718192021222324252627282930# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes. # å†…å­˜æ•°æ®å¿«ç…§çš„ä¿å­˜ç›®å½•ï¼›å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰Logä¹Ÿä½¿ç”¨è¯¥ç›®å½•dataDir=/tmp/zookeeper# the port at which the clients will connect# zookeeperæœåŠ¡ç«¯çš„ç«¯å£ï¼Œå®¢æˆ·ç«¯å¯åŠ¨æ—¶éœ€è¦è¿æ¥çš„ç«¯å£clientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to \"0\" to disable auto purge feature#autopurge.purgeInterval=1","tags":[{"name":"Apache Zookeeper","slug":"Apache-Zookeeper","permalink":"https://yangyichao-mango.github.io/tags/Apache-Zookeeper/"}]},{"title":"Apache Flink å­¦ä¹ ï¼šhdfsä½œä¸ºsink","date":"2019-10-19T11:33:38.000Z","path":"2019/10/19/apache-flink:study-hdfs-sink/","text":"Apache Flink å­¦ä¹ ï¼šhdfsä½œä¸ºsourceå’Œsinkçš„demo ä¾èµ–é¡¹1234567891011&lt;properties&gt; &lt;flink.version&gt;1.9.0&lt;/flink.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-filesystem_2.12&lt;/artifactId&gt; &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;dependencies&gt; demoä»£ç ä½¿ç”¨äº†kafkaä½œä¸ºsourceï¼Œhdfsä½œä¸ºsinkè¿è¡Œä¹‹å‰éœ€è¦è¿è¡Œkafkaé›†ç¾¤ï¼Œhadoopé›†ç¾¤ï¼ˆzookeeperé›†ç¾¤ï¼‰ 123456789101112131415161718192021222324/******************************* define dag *******************************/// create the environment to create streams and configure executionfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();// make parameters available in the web interfaceenv.getConfig().setGlobalJobParameters(params);DataStream&lt;String&gt; sentenceStream = env.addSource(source);DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCountStream = sentenceStream .flatMap(new LineSplitter()) .keyBy(0) .sum(1);wordCountStream.print();DataStream&lt;String&gt; kafkaSinkStream = wordCountStream .map(new WordBuilder());/******************************* hdfs sink *******************************/BucketingSink&lt;String&gt; bucketingSink = new BucketingSink&lt;&gt;(\"/user/xxx/flink/from-kafka\"); //hdfsä¸Šçš„è·¯å¾„bucketingSink.setWriter(new StringWriter&lt;&gt;()) .setBatchSize(1024 * 1024L) .setBatchRolloverInterval(2000) .setInactiveBucketThreshold(1000);kafkaSinkStream.addSink(bucketingSink); ä¸Šé¢ä¾‹å­å°†åˆ›å»ºä¸€ä¸ª Sinkï¼Œå†™å…¥éµå¾ªä¸‹é¢æ ¼å¼çš„åˆ†æ¡¶æ–‡ä»¶ä¸­ï¼š 1/base/path/&#123;date-time&#125;/_part-&#123;parallel-task&#125;-&#123;count&#125; date-timeï¼šæ˜¯ä»setBucketer()è‡ªå®šä¹‰çš„æ—¥æœŸ/æ—¶é—´æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸è¿›è¡Œè®¾ç½®ï¼Œé»˜è®¤Bucketeræ˜¯DateTimeBucketerï¼Œé»˜è®¤å€¼æ˜¯yyyy-MM-ddâ€“HHï¼ˆDateTimeBucketer.DEFAULT_FORMAT_STRINGï¼‰ _part-{parallel-task}-{count}ï¼š 1234567891011121314151617private static final String DEFAULT_VALID_PREFIX = \"_\";private static final String DEFAULT_PART_PREFIX = \"part\";private static final String DEFAULT_PENDING_SUFFIX = \".pending\";private void openNewPartFile(Path bucketPath, BucketState&lt;T&gt; bucketState) throws Exception &#123; Path partPath = assemblePartPath(bucketPath, subtaskIndex, bucketState.partCounter); Path inProgressPath = getInProgressPathFor(partPath);&#125;private Path assemblePartPath(Path bucket, int subtaskIndex, int partIndex) &#123; String localPartSuffix = partSuffix != null ? partSuffix : \"\"; return new Path(bucket, String.format(\"%s-%s-%s%s\", partPrefix, subtaskIndex, partIndex, localPartSuffix));&#125;private Path getInProgressPathFor(Path path) &#123; return new Path(path.getParent(), inProgressPrefix + path.getName()).suffix(inProgressSuffix);&#125; æŸ¥çœ‹hdfsæ–‡ä»¶1234567891011$ ./hdfs dfs -ls /user/xxx/flink/from-kafka/2019-10-19--192019-10-19 20:08:31,244 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableFound 15 items-rw-r--r-- 1 xxx supergroup 4 2019-10-19 19:45 /user/xxx/flink/from-kafka/2019-10-19--19/_part-0-0.pending-rw-r--r-- 1 xxx supergroup 2 2019-10-19 19:45 /user/xxx/flink/from-kafka/2019-10-19--19/_part-1-0.pending-rw-r--r-- 1 xxx supergroup 5 2019-10-19 19:44 /user/xxx/flink/from-kafka/2019-10-19--19/_part-2-0.pending-rw-r--r-- 1 xxx supergroup 11 2019-10-19 19:45 /user/xxx/flink/from-kafka/2019-10-19--19/_part-2-1.pending-rw-r--r-- 1 xxx supergroup 10 2019-10-19 19:44 /user/xxx/flink/from-kafka/2019-10-19--19/_part-3-0.pending-rw-r--r-- 1 xxx supergroup 13 2019-10-19 19:45 /user/xxx/flink/from-kafka/2019-10-19--19/_part-3-1.pending-rw-r--r-- 1 xxx supergroup 9 2019-10-19 19:45 /user/xxx/flink/from-kafka/2019-10-19--19/_part-4-0.pending-rw-r--r-- 1 xxx supergroup 10 2019-10-19 19:44 /user/xxx/flink/from-kafka/2019-10-19--19/_part-5-0.pending","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"},{"name":"Apache Hadoop","slug":"Apache-Hadoop","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hadoop/"}]},{"title":"Macå®‰è£…Apache HBase-1.3.5","date":"2019-10-18T15:14:59.000Z","path":"2019/10/18/apache-hbase:1.3.5-mac-install/","text":"Macå®‰è£…Apache HBase-1.3.5æ•™ç¨‹ HBaseå®‰è£…1$ brew install hbase å®‰è£…åœ¨/usr/local/Cellar/hbase/1.3.5 HBaseé…ç½®hbase-env.shåœ¨conf/hbase-env.shè®¾ç½®JAVA_HOME 1234$ cd /usr/local/Cellar/hbase/1.3.5/libexec/conf$ vim hbase-env.shexport JAVA_HOME=\"$(/usr/libexec/java_home --version 1.8)\" Apache HBase-1.3.5ä¸­JAVA_HOMEå·²ç»é»˜è®¤è¢«é…ç½®å¥½äº†å¦‚æœJAVA_HOMEæ²¡æœ‰é…ç½®å¥½ï¼Œåˆ™éœ€è¦è®¾ç½®JAVA_HOMEï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹JAVA_HOME 12$ /usr/libexec/java_home/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home hbase-site.xmlåœ¨conf/hbase-site.xmlè®¾ç½®HBaseçš„æ ¸å¿ƒé…ç½® 1234567891011121314$ vim hbase-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; // è¿™é‡Œè®¾ç½®è®©HBaseå­˜å‚¨æ–‡ä»¶çš„åœ°æ–¹ &lt;value&gt;file:///usr/local/Cellar/hbase/tmp/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; // è¿™é‡Œè®¾ç½®è®©HBaseå­˜å‚¨å†…å»ºzookeeperæ–‡ä»¶çš„åœ°æ–¹ &lt;value&gt;/usr/local/Cellar/hbase/tmp/zookeeper&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; å¯åŠ¨HBase/usr/local/Cellar/hbase/1.3.5/bin/start-hbase.shæä¾›HBaseçš„å¯åŠ¨ 12$ ./start-hbase.shstarting master, logging to /usr/local/var/log/hbase/hbase-xxx-master-xxx.local.out éªŒè¯æ˜¯å¦å®‰è£…æˆåŠŸ12345$ jps722 Launcher1142 HMaster726 Launcher1256 Jps å¯åŠ¨HBase Shell1234567$ ./hbase shell2019-10-19 11:58:34,879 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableHBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.Type \"exit&lt;RETURN&gt;\" to leave the HBase ShellVersion 1.3.5, rb59afe7b1dc650ff3a86034477b563734e8799a9, Wed Jun 5 15:57:14 PDT 2019hbase(main):001:0&gt; åœæ­¢HBaseè¿è¡Œ12$ ./stop-hbase.shstopping hbase............... ä¼ªåˆ†å¸ƒå¼æ¨¡å¼å¿…é¡»å…ˆå…³é—­HBase ä¿®æ”¹hbase-env.sh1HBASE_MANAGE_ZK = true ä¿®æ”¹hbase-site.xmlè®¾ç½®HBaseä½¿ç”¨åˆ†å¸ƒå¼æ¨¡å¼è¿è¡Œ 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; // Here you have to set the path where you want HBase to store its files. &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hbase.rootdirè·¯å¾„ä¸€å®šè¦è·Ÿhadoopä¸­core-site.xmlä¸­fs.default.nameç›¸åŒ change the hbase.rootdir from the local filesystem to the address of your HDFS instance â€”offical quick start å¦‚ä½•ä¸¤å¤„è®¾ç½®ä¸åŒä¼šå¼•èµ·ERROR: Canâ€™t get master address from ZooKeeper; znode data == nullé”™è¯¯é”™è¯¯ åœ¨å¯åŠ¨HBaseä¹‹å‰, è¯·å…ˆå¯åŠ¨Hadoop, ä½¿ä¹‹è¿è¡Œ 123456789101112131415161718$ ./start-hbase.shlocalhost: starting zookeeper, logging to /usr/local/var/log/hbase/hbase-xxx-zookeeper-xxx.local.outstarting master, logging to /usr/local/var/log/hbase/hbase-xxx-master-xxx.local.outstarting regionserver, logging to /usr/local/var/log/hbase/hbase-xxx-1-regionserver-xxx.local.out$ jps #éªŒè¯æ˜¯å¦å¯åŠ¨æˆåŠŸ, åŒ…å«HMasterå’ŒHRegionServerè¯´æ˜å¯åŠ¨æˆåŠŸ5614 HRegionServer2222 NameNode722 Launcher2323 DataNode5461 HMaster726 Launcher2650 ResourceManager2747 NodeManager2459 SecondaryNameNode5405 HQuorumPeer2855726 Jps æŸ¥çœ‹hdfsä¸­æ–‡ä»¶å¤¹ 123456$ ./hdfs dfs -ls /2019-10-19 12:39:03,895 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableFound 3 itemsdrwxr-xr-x - xxx supergroup 0 2019-10-19 12:38 /hbasedrwxrwxr-x - xxx supergroup 0 2019-10-17 14:41 /tmpdrwxr-xr-x - xxx supergroup 0 2019-10-17 11:44 /user HBase Shell123456789101112131415161718192021222324252627$ hbase shell #å¯åŠ¨HBase Shell# åˆ›å»ºè¡¨&gt; create 'student', 'description', 'course' #åˆ›å»ºè¡¨åä¸ºstudentçš„è¡¨, æŒ‡æ˜ä¸¤ä¸ªåˆ—å, åˆ†åˆ«ä¸ºdescriptionå’Œcourse# ä¿¡æ¯æ˜ç»†&gt; list 'student' #åˆ—å‡ºlistè¡¨ä¿¡æ¯# æ’å…¥æ•°æ®# æ„æ€ä¸ºåœ¨studentè¡¨row1å¤„æ’å…¥description:ageçš„æ•°æ®ä¸º18# rowKeyä¸ºrow1ï¼ŒcolumnFamilyNameä¸ºdescriptionï¼ŒcolumnNameä¸ºage&gt; put 'student', 'row1', 'description:age', '18'&gt; put 'student', 'row1', 'description:name', 'liu'&gt; put 'student', 'row1', 'course:chinese', '100'# ä¸€æ¬¡æ‰«ææ‰€æœ‰æ•°æ®&gt; scan 'student'# ä½¿è¡¨å¤±æ•ˆ / æœ‰æ•ˆ&gt; disable 'student'&gt; enable 'student'# åˆ é™¤è¡¨(è¦å…ˆdisable)&gt; drop 'student'# é€€å‡ºshell&gt; quit","tags":[{"name":"Apache HBase","slug":"Apache-HBase","permalink":"https://yangyichao-mango.github.io/tags/Apache-HBase/"},{"name":"Macå®‰è£…","slug":"Macå®‰è£…","permalink":"https://yangyichao-mango.github.io/tags/Macå®‰è£…/"}]},{"title":"IntelliJ IDEA ä¸­å¦‚ä½•æŸ¥çœ‹ä¸€ä¸ªç±»çš„æ‰€æœ‰ç»§æ‰¿å…³ç³»","date":"2019-10-18T06:09:17.000Z","path":"2019/10/18/idea-mac:show-class-hierarchy/","text":"IntelliJ IDEA ä¸­å¦‚ä½•æŸ¥çœ‹ä¸€ä¸ªç±»çš„æ‰€æœ‰ç»§æ‰¿å…³ç³»ï¼ŒåŒ…æ‹¬çˆ¶ç±»ä¸å­ç±» æŸ¥çœ‹æ–¹å¼IntelliJ IDEA ä¸­æœ€ä¸Šç«¯çš„Navigateï¼Œä¸‹æ‹‰é€‰æ‹©Type Hierarchyï¼Œå°±ä¼šå‡ºç°å±‚çº§å…³ç³»åˆ—è¡¨ å…³äºè¯¥ç±»çš„çˆ¶ç±»å’Œå­ç±»ç»§æ‰¿å…³ç³» çˆ¶ç±»å’Œå­ç±»ç»§æ‰¿å…³ç³» å…³äºè¯¥ç±»çš„çˆ¶ç±»ç»§æ‰¿å…³ç³» çˆ¶ç±»ç»§æ‰¿å…³ç³» å…³äºè¯¥ç±»çš„å­ç±»ç»§æ‰¿å…³ç³» å­ç±»ç»§æ‰¿å…³ç³»","tags":[{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","permalink":"https://yangyichao-mango.github.io/tags/IntelliJ-IDEA/"}]},{"title":"Apache Hiveç¯å¢ƒæ­å»ºé”™è¯¯ï¼šjava.lang.IllegalArgumentException: java.net.URISyntaxException:...","date":"2019-10-17T07:44:01.000Z","path":"2019/10/17/apache-hive:error-URISyntaxException:Relative-path-in-absolute-URI:{system:java.io.tmpdir}{system-user-name}/","text":"å‡ºç°é”™è¯¯ï¼šException in thread â€œmainâ€ java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: ${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D é”™è¯¯åœºæ™¯è¯¦æƒ…1234567891011121314151617181920212223$ $HIVE_HOME/bin/hiveHive Session ID = 41e2ad09-81b3-4700-9b87-f42b25a29731Logging initialized using configuration in jar:file:/usr/local/Cellar/hive/3.1.2/libexec/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: trueException in thread \"main\" java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: $&#123;system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D at org.apache.hadoop.fs.Path.initialize(Path.java:263) at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:221) at org.apache.hadoop.hive.ql.session.SessionState.createSessionDirs(SessionState.java:710) at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:627) at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:591) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:747) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:323) at org.apache.hadoop.util.RunJar.main(RunJar.java:236)Caused by: java.net.URISyntaxException: Relative path in absolute URI: $&#123;system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D at java.net.URI.checkPath(URI.java:1823) at java.net.URI.&lt;init&gt;(URI.java:745) at org.apache.hadoop.fs.Path.initialize(Path.java:260) ... 12 more é”™è¯¯åŸå› hive-site.xmlé‡Œçš„ä¸´æ—¶ç›®å½•æ²¡æœ‰è®¾ç½®å¥½ï¼Œä¸€å…±æœ‰ä¸‰ä¸ª 1234567891011121314151617&lt;property&gt; &lt;name&gt;Hive.exec.local.scratchdir&lt;/name&gt; &lt;value&gt;$&#123;system:Java.io.tmpdir&#125;/$&#123;system:user.name&#125;&lt;/value&gt; &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;value&gt;$&#123;system:java.io.tmpdir&#125;/$&#123;hive.session.id&#125;_resources&lt;/value&gt; &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt; &lt;value&gt;$&#123;system:Java.io.tmpdir&#125;/$&#123;system:user.name&#125;/operation_logs&lt;/value&gt; &lt;description&gt;Top level directory where operation logs are stored if logging functionality is enabled&lt;/description&gt;&lt;/property&gt; è§£å†³æ–¹æ¡ˆå°†hive-site.xmlæ–‡ä»¶ä¸­çš„${system:java.io.tmpdir}æ›¿æ¢ä¸ºhiveçš„ä¸´æ—¶ç›®å½•ä¾‹å¦‚æˆ‘æ›¿æ¢ä¸º/usr/local/Cellar/hive/tmpï¼Œè¯¥ç›®å½•å¦‚æœä¸å­˜åœ¨åˆ™è¦è‡ªå·±æ‰‹å·¥åˆ›å»ºï¼Œå¹¶ä¸”èµ‹äºˆè¯»å†™æƒé™ 1234567891011121314151617&lt;property&gt; &lt;name&gt;Hive.exec.local.scratchdir&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hive/tmp&lt;/value&gt; &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hive/tmp/$&#123;hive.session.id&#125;_resources&lt;/value&gt; &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hive/tmp/root/operation_logs&lt;/value&gt; &lt;description&gt;Top level directory where operation logs are stored if logging functionality is enabled&lt;/description&gt;&lt;/property&gt;","tags":[{"name":"Apache Hive","slug":"Apache-Hive","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hive/"}]},{"title":"Macå®‰è£…Apache Hive-3.2.1","date":"2019-10-17T06:58:34.000Z","path":"2019/10/17/apache-hive:3.1.2-mac-install/","text":"Macå®‰è£…Apache Hive-3.2.1æ•™ç¨‹ å®‰è£…Hadoopä¸‹è½½åŒ…è¿›è¡Œå®‰è£…ï¼Œåˆ™hadoopéœ€è¦ç‹¬ç«‹å®‰è£… å®‰è£…Hivebrewå®‰è£…1$ brew install hive æ­¤å‘½ä»¤ä¼šæŠŠhiveä¾èµ–çš„hadoopå®‰è£…ï¼Œæ‰€ä»¥å°±ä¸éœ€è¦å•ç‹¬è¿›è¡Œå®‰è£…hadoopè¯¥å‘½ä»¤é»˜è®¤å®‰è£…çš„ç‰ˆæœ¬è¾ƒæ–°ï¼Œæˆ‘çš„hiveæ˜¯3.1.2ï¼Œhadoopæ˜¯3.2.1ï¼Œå®‰è£…ä½ç½®ï¼š/usr/local/Cellar/hive/ ç¯å¢ƒå˜é‡ä¿®æ”¹12345$ vim ~/.bash_profileexport HIVE_HOME=/usr/local/Cellar/hive/3.1.2export PATH=\"$HIVE_HOME/bin:$PATH\"$ source ~/.bash_profile ä½¿ç”¨mysqlä½œä¸ºhiveå…ƒæ•°æ®å­˜å‚¨åœ¨mysqlä¸­ä¸ºhive åˆ›å»ºç”¨æˆ·ï¼ŒåŠåˆå§‹åŒ–æ•°æ®åº“ä»¥ä¸‹åœ¨mysql ä¸­æ“ä½œï¼Œæ³¨æ„ï¼šè¿™é‡Œåˆ›å»ºçš„ç”¨æˆ·åæ˜¯ hadoopï¼Œ å¯†ç  mysqlç¬¬ä¸€è¡Œï¼šåˆ›å»ºæ•°æ®åº“ç¬¬äºŒã€ä¸‰è¡Œ åˆ›å»ºç”¨æˆ·ï¼Œèµ‹äºˆæƒé™ç¬¬å››è¡Œ æƒé™ç”Ÿæ•ˆ 1234create database hive;CREATE USER 'hadoop'@'%' IDENTIFIED BY 'mysql';GRANT ALL PRIVILEGES ON *.* TO 'hadoop'@'%' WITH GRANT OPTION;flush privileges; æŸ¥çœ‹æƒé™æ˜¯å¦å·²ç»å­˜å‚¨ 1SELECT * FROM mysql.user; ä¿®æ”¹é…ç½®æ–‡ä»¶hive-site.xmlä¿®æ”¹hiveé…ç½®æ–‡ä»¶ï¼Œæˆ‘çš„é…ç½®æ–‡ä»¶ä½ç½®åœ¨ /usr/local/Cellar/hive/3.1.2/libexec/confå¦‚æœä¸å­˜åœ¨hive-site.xmlæ–‡ä»¶ï¼Œåˆ™ä½¿ç”¨ä¸‹é¢è¿™ä¸ªå‘½ä»¤åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„hive-site.xml 1$ cp hive-default.xml.template hive-site.xml ä¿®æ”¹é…ç½®æ–‡ä»¶ 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;mysql&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;mysql &lt;value&gt;jdbc:mysql://localhost:3306/hive&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; javax.jdo.option.ConnectionUserName â€“ è¿æ¥mysqlçš„è´¦å·ï¼Œhadoopjavax.jdo.option.ConnectionPassword â€“ è¿æ¥mysqlçš„å¯†ç ï¼Œmysqljavax.jdo.option.ConnectionURL â€“ å¯¹åº”ä¸Šä¸€æ­¥åˆ›å»ºçš„æ•°æ®åº“ï¼Œlocalhost:3306/hive hadoopä¸­åˆ›å»ºhiveæ‰€éœ€ä»“åº“1234$ $HADOOP_HOME/bin/hadoop fs -mkdir /tmp$ $HADOOP_HOME/bin/hadoop fs -mkdir -p /user/hive/warehouse$ $HADOOP_HOME/bin/hadoop fs -chmod g+w /tmp$ $HADOOP_HOME/bin/hadoop fs -chmod g+w /user/hive/warehouse $HADOOP_HOME â€“ ä»£è¡¨æ‚¨çš„hadoopå·¥ä½œç›®å½• hiveåˆå§‹åŒ–mysqlä¸­çš„æ•°æ®åº“hiveå‘½ä»¤1$ $HIVE_HOME/bin/schematool -dbType msyql -initSchema å¯èƒ½å‡ºç°é”™è¯¯1ï¼šjava.lang.NoSuchMethodError: com.google.commonâ€¦è§£å†³æ–¹æ¡ˆï¼šjava.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument å¯èƒ½å‡ºç°é”™è¯¯2ï¼šjava.lang.ClassNotFoundException: com.mysqlâ€¦è§£å†³æ–¹æ¡ˆï¼šjava.lang.ClassNotFoundException: com.mysql.jdbc.Driver å¯åŠ¨Hiveçš„Metastore ServeræœåŠ¡è¿›ç¨‹1$ $HIVE_HOME/bin/hive --service metastore &amp; ç™»å½•hiveå®¢æˆ·ç«¯å‘½ä»¤1$ $HIVE_HOME/bin/ hive å¯èƒ½å‡ºç°çš„é”™è¯¯1ï¼šjava.lang.IllegalArgumentException: java.net.URISyntaxException:â€¦è§£å†³æ–¹æ¡ˆï¼šException in thread â€œmainâ€ java.lang.IllegalArgumentException: java.net.URISyntaxException:","tags":[{"name":"Macå®‰è£…","slug":"Macå®‰è£…","permalink":"https://yangyichao-mango.github.io/tags/Macå®‰è£…/"},{"name":"Apache Hive","slug":"Apache-Hive","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hive/"}]},{"title":"Apache Hiveç¯å¢ƒæ­å»ºé”™è¯¯ï¼šcom.mysql.jdbc.Driver was not found in the CLASSPATH","date":"2019-10-17T06:35:11.000Z","path":"2019/10/17/apache-hive:error-ClassNotFoundException:com.mysql.jdbc.driver/","text":"Apache Hiveç¯å¢ƒæ­å»ºé”™è¯¯ï¼šcom.mysql.jdbc.Driver was not found in the CLASSPATH é”™è¯¯åœºæ™¯è¯¦æƒ…12345678910111213$ $HIVE_HOME/bin/schematool -dbType mysql -initSchemaSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/Cellar/hive/3.1.2/libexec/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/Cellar/hadoop/3.2.1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Metastore connection URL: jdbc:mysql://localhost:3306/hive?characterEncoding=UTF-8Metastore Connection Driver : com.mysql.jdbc.DriverMetastore connection User: hadooporg.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driverUnderlying cause: java.lang.ClassNotFoundException : com.mysql.jdbc.DriverUse --verbose for detailed stacktrace.*** schemaTool failed *** é”™è¯¯åŸå› åœ¨é…ç½®hive-site.xmlæ–‡ä»¶æ—¶é…ç½®äº†mysqlé©±åŠ¨ï¼Œè€Œhive/libç›®å½•ä¸‹æ²¡æœ‰mysqlé©±åŠ¨åŒ…ã€‚ è§£å†³æ–¹æ¡ˆå®˜ç½‘ä¸‹è½½mysqlé©±åŠ¨ä¸‹è½½åœ°å€ (https://dev.mysql.com/downloads/connector/j/)æŠŠä¸‹è½½å¥½çš„å‹ç¼©åŒ…ï¼ˆmysql-connector-java-8.0.18.zipï¼‰è¿›è¡Œè§£å‹unzip mysql-connector-java-8.0.18.zipå¤åˆ¶åˆ°hive/libä¸‹cp mysql-connector-java-8.0.18/mysql-connector-java-8.0.18.jar hive/lib","tags":[{"name":"Apache Hive","slug":"Apache-Hive","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hive/"}]},{"title":"Apache Hiveç¯å¢ƒæ­å»ºé”™è¯¯ï¼šjava.lang.NoSuchMethodError: com.google.common...","date":"2019-10-17T06:14:27.000Z","path":"2019/10/17/apache-hive:error-NoSuchMethodError:com.google.common.base.Preconditions.checkArgument/","text":"Apache Hiveç¯å¢ƒæ­å»ºé”™è¯¯ï¼šjava.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument é”™è¯¯åœºæ™¯è¯¦æƒ…12345678910111213141516171819202122$ $HIVE_HOME/bin/schematool -dbType mysql -initSchemaSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/Cellar/hive/3.1.2/libexec/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/Cellar/hadoop/3.2.1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Exception in thread \"main\" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357) at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338) at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:536) at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:554) at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:448) at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5141) at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:5104) at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:96) at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:323) at org.apache.hadoop.util.RunJar.main(RunJar.java:236) é”™è¯¯åŸå› è¿™æ˜¯å› ä¸ºhiveå†…ä¾èµ–çš„guava.jarå’Œhadoopå†…çš„ç‰ˆæœ¬ä¸ä¸€è‡´é€ æˆçš„ã€‚ è§£å†³æ–¹æ¡ˆæŸ¥çœ‹hadoopå®‰è£…ç›®å½•ä¸‹share/hadoop/common/libå†…guava.jarç‰ˆæœ¬æŸ¥çœ‹hiveå®‰è£…ç›®å½•ä¸‹libå†…guava.jarçš„ç‰ˆæœ¬ï¼Œå¦‚æœä¸¤è€…ä¸ä¸€è‡´ï¼Œåˆ é™¤ç‰ˆæœ¬ä½çš„ï¼Œå¹¶æ‹·è´é«˜ç‰ˆæœ¬çš„ï¼Œé—®é¢˜è§£å†³ï¼","tags":[{"name":"Apache Hive","slug":"Apache-Hive","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hive/"}]},{"title":"Apache Hadoopé”™è¯¯ï¼šUnable to load native-hadoop library for your platform","date":"2019-10-17T03:34:57.000Z","path":"2019/10/17/apache-hadoop:error-unable-to-load-native-hadoop-library-from-you-platform/","text":"Apache Hadoopé”™è¯¯ï¼šUnable to load native-hadoop library for your platform é”™è¯¯åœºæ™¯è¯¦æƒ…12$ hadoop fs -ls /WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable é”™è¯¯åŸå› Hadoopæ˜¯ä½¿ç”¨Javaè¯­è¨€å¼€å‘çš„,ä½†æ˜¯æœ‰ä¸€äº›éœ€æ±‚å’Œæ“ä½œå¹¶ä¸é€‚åˆä½¿ç”¨javaæ‰€ä»¥ä¼šå¼•å…¥äº†æœ¬åœ°åº“ï¼ˆNative Librariesï¼‰çš„æ¦‚å¿µï¼Œé€šè¿‡æœ¬åœ°åº“ï¼ŒHadoopå¯ä»¥æ›´åŠ é«˜æ•ˆåœ°æ‰§è¡ŒæŸä¸€äº›æ“ä½œ.å½“æˆ‘ä»¬åœ¨linux è¾“å…¥ hdoop fs -ls / å»æŸ¥çœ‹ hdfs æ–‡ä»¶ç³»ç»Ÿä¸Šçš„èµ„æºæ—¶ä¼šå‡ºç°ä¸‹é¢é”™è¯¯ è§£å†³æ–¹æ¡ˆè§£å†³æ–¹æ¡ˆ1åœ¨Hadoopçš„é…ç½®æ–‡ä»¶core-site.xmlä¸­å¯ä»¥è®¾ç½®æ˜¯å¦ä½¿ç”¨æœ¬åœ°åº“ï¼šï¼ˆHadoopé»˜è®¤çš„é…ç½®ä¸ºå¯ç”¨æœ¬åœ°åº“ï¼‰ 12345&lt;property&gt; &lt;name&gt;hadoop.native.lib&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;Should native hadoop libraries, if present, be used.&lt;/description&gt;&lt;/property&gt; è§£å†³æ–¹æ¡ˆ2æœ‰åšå®¢è¯´å¯ä»¥ç›´æ¥ä¸‹è½½ç¼–è¯‘å¥½çš„ä½åŒ…ï¼Œæ›¿æ¢åŸæ¥çš„nativeåŒ…ç”±äºåœ¨æˆ‘æœ¬åœ°å®‰è£…çš„Apache Hadoop 3.2.1ç‰ˆæœ¬ä¸­æ²¡æœ‰æ‰¾åˆ°libæ–‡ä»¶å¤¹ï¼Œæ‰€ä»¥åœ¨3.2.1ç‰ˆæœ¬ä¸­æš‚æ—¶ä¸èƒ½ä½¿ç”¨æ­¤ç§æ–¹æ³• æ‰§è¡ŒæŸ¥çœ‹æ–‡ä»¶å‘½ä»¤ 1234$ hadoop fs -ls /2019-10-17 11:33:09,369 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableFound 1 itemsdrwxr-xr-x - xxx supergroup 0 2019-10-17 11:23 /tmp","tags":[{"name":"Apache Hadoop","slug":"Apache-Hadoop","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hadoop/"}]},{"title":"Macå®‰è£…Apache Hadoop-3.2.1","date":"2019-10-17T02:12:31.000Z","path":"2019/10/17/apache-hadoop:3.2.1-mac-install/","text":"Macå®‰è£…Apache hadoop-3.2.1æ•™ç¨‹ Javaç¯å¢ƒé…ç½®å®‰è£…Javaï¼ŒæŸ¥çœ‹Javaç‰ˆæœ¬ä»¥æµ‹è¯•æ˜¯å¦å®‰è£…æˆåŠŸ1234$ java -versionjava version \"1.8.0_191\"Java(TM) SE Runtime Environment (build 1.8.0_191-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) æŸ¥çœ‹Javaå®‰è£…ä½ç½®ä¿¡æ¯ï¼Œä¹‹åé…ç½®Hadoopè¿è¡Œç¯å¢ƒéœ€è¦ä½¿ç”¨12$ /usr/libexec/java_home/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home sshé…ç½®é…ç½®ssh12$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys$ chmod 0600 ~/.ssh/authorized_keys åˆ›å»ºsshå…¬é’¥å¦‚æœæ²¡æœ‰sshå…¬é’¥ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»º 1$ ssh-keygen -t rsa å¼€å¯è¿œç¨‹ç™»å½• ç³»ç»Ÿåå¥½è®¾ç½®->å…±äº« æµ‹è¯•è¿œç¨‹ç™»å½•æ˜¯å¦å¼€å¯1$ ssh localhost å®‰è£…hadoopbrewå®‰è£…hadoopbrewå®‰è£…çš„ä¸€èˆ¬éƒ½æ˜¯æœ€æ–°çš„hadoopï¼Œæˆ‘è¿™é‡Œæ˜¯hadoop 3.2.1 å¦‚æœéœ€è¦å®‰è£…å…¶ä»–ç‰ˆæœ¬çš„hadoopï¼Œé€šè¿‡brewå®‰è£…æŒ‡å®šç‰ˆæœ¬çš„è½¯ä»¶è¿›è¡Œå®‰è£… 123456$ brew install hadoopUpdating Homebrew...==&gt; Downloading https://www.apache.org/dyn/closer.cgi?path=hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz==&gt; Downloading from http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz######################################################################## 100.0%ğŸº /usr/local/Cellar/hadoop/3.2.1: 21,686 files, 774.1MB, built in 10 minutes 1 second æ³¨æ„ä¸Šé¢çš„ä¸‹è½½ä¿¡æ¯ä¸­ é»˜è®¤brewæ˜¯ä¼šä»apacheå®˜æ–¹çš„é•œåƒä¸­ä¸‹è½½ 1==&gt; Downloading https://www.apache.org/dyn/closer.cgi?path=hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz å¦‚æœä¸‹è½½å¾ˆæ…¢ï¼Œå¯ä»¥é…ç½®å›½å†…é•œåƒè¿›è¡Œä¸‹è½½(æ¸…åå¤§å­¦å¼€æºè½¯ä»¶é•œåƒç«™) 1==&gt; Downloading from http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz å®‰è£…å®Œä¹‹åæŸ¥çœ‹hadoopå®‰è£…ä½ç½® 1234567891011121314151617$ brew info hadoophadoop: stable 3.2.1Framework for distributed processing of large data setshttps://hadoop.apache.org/Conflicts with: yarn (because both install `yarn` binaries)/usr/local/Cellar/hadoop/hdfs (20 files, 1MB) Built from source/usr/local/Cellar/hadoop/3.2.1 (22,408 files, 815.8MB) Built from source on 2019-10-17 at 09:46:37From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/hadoop.rb==&gt; RequirementsRequired: java &gt;= 1.8 âœ”==&gt; Analyticsinstall: 4,572 (30 days), 10,774 (90 days), 44,762 (365 days)install_on_request: 3,822 (30 days), 9,128 (90 days), 38,206 (365 days)build_error: 0 (30 days) é…ç½®hadoopéœ€è¦ä¿®æ”¹çš„é…ç½®æ–‡ä»¶éƒ½åœ¨/usr/local/Cellar/hadoop/3.2.1/libexec/etc/hadoopè¿™ä¸ªç›®å½•ä¸‹ hadoop-env.shé…ç½® export JAVA_HOME å°†/usr/libexec/java_homeæŸ¥åˆ°çš„ Java è·¯å¾„é…ç½®è¿›å»ï¼Œè®°å¾—å»æ‰æ³¨é‡Š #ã€‚ 1export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_191.jdk/Contents/Home core-site.xmlä¿®æ”¹core-site.xml æ–‡ä»¶å‚æ•°,é…ç½®NameNodeçš„ä¸»æœºåå’Œç«¯å£å· 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xmlå˜é‡dfs.replicationæŒ‡å®šäº†æ¯ä¸ªHDFSæ•°æ®åº“çš„å¤åˆ¶æ¬¡æ•°ã€‚ é€šå¸¸ä¸º3, ç”±äºæˆ‘ä»¬åªæœ‰ä¸€å°ä¸»æœºå’Œä¸€ä¸ªä¼ªåˆ†å¸ƒå¼æ¨¡å¼çš„DataNodeï¼Œå°†æ­¤å€¼ä¿®æ”¹ä¸º1 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; æ ¼å¼åŒ–æ ¼å¼åŒ–hdfsæ“ä½œåªè¦ç¬¬ä¸€æ¬¡æ‰ä½¿ç”¨ï¼Œå¦åˆ™ä¼šé€ æˆæ•°æ®å…¨éƒ¨ä¸¢å¤± 1$ hdfs namenode -format å¯åŠ¨æœåŠ¡å¯åŠ¨æœåŠ¡ 1$ ./start-all.sh å¯åŠ¨æˆåŠŸåï¼Œå¯ä»¥åœ¨http://localhost:9870/http://localhost:8088/clusterè¿›è¡ŒæŸ¥çœ‹ å…³é—­æœåŠ¡ 1$ ./stop-all.sh","tags":[{"name":"Apache Hadoop","slug":"Apache-Hadoop","permalink":"https://yangyichao-mango.github.io/tags/Apache-Hadoop/"},{"name":"Macå®‰è£…","slug":"Macå®‰è£…","permalink":"https://yangyichao-mango.github.io/tags/Macå®‰è£…/"}]},{"title":"useful-api-for-java","date":"2019-10-16T02:16:10.000Z","path":"2019/10/16/java-api:useful-api/","text":"API Retrofitï¼ˆhttpè¯·æ±‚å·¥å…·åŒ…ï¼‰ Resilience4jï¼ˆæ¥å£é‡è¯•ï¼Œé™æµï¼Œç†”æ–­å™¨å·¥å…·ï¼‰","tags":[{"name":"Java Api","slug":"Java-Api","permalink":"https://yangyichao-mango.github.io/tags/Java-Api/"}]},{"title":"Apache Flink é›¶åŸºç¡€å…¥é—¨ï¼ˆå››ï¼‰ï¼šDataStream API ç¼–ç¨‹ å­¦ä¹ å¿ƒå¾—","date":"2019-10-15T07:57:16.000Z","path":"2019/10/15/apache-flink:study-4-datastream-api/","text":"å­¦ä¹ å¿ƒå¾— DataStreamRichParallelSourceFunctionç”¨æˆ·é€šè¿‡å®ç°SourceFunctionè‡ªå®šä¹‰DataSource å¦‚æœè®¾ç½®äº†å¹¶è¡Œåº¦ï¼Œåˆ™ä¼šäº§ç”ŸæŒ‡å®šå¹¶è¡Œåº¦ä¸ªæ•°çš„DataSourceæ¶ˆè´¹å®¢æˆ·ç«¯å»æ¶ˆè´¹DataSource 1StreamExecutionEnvironment.setParallelism(int) ä¸¾ä¾‹ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class GroupedProcessingTimeWindow &#123; private static final Logger LOGGER = LoggerFactory.getLogger(GroupedProcessingTimeWindow.class); private static class DataSource extends RichParallelSourceFunction&lt;Tuple2&lt;String, Integer&gt;&gt; &#123; private volatile boolean isRunning = true; @Override public void run(SourceContext&lt;Tuple2&lt;String, Integer&gt;&gt; ctx) throws Exception &#123; Random random = new Random(); while (isRunning) &#123; TimeUnit.MILLISECONDS.sleep((getRuntimeContext().getIndexOfThisSubtask() + 1) * 1000 * 5); String key = \"ç±»åˆ«\" + (char) ('A' + random.nextInt(3)); int value = random.nextInt(10) + 1; LOGGER.info(\"Thread: &#123;&#125;, key: &#123;&#125;, value: &#123;&#125;, dataSource object: &#123;&#125;)\" , Thread.currentThread().getName() , key , value , this); ctx.collect(new Tuple2&lt;&gt;(key, value)); &#125; &#125; @Override public void cancel() &#123; isRunning = false; &#125; &#125; public static void main(String[] args) throws Exception &#123; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(2); DataSource dataSource = new DataSource(); LOGGER.info(\"dataSource object: &#123;&#125;\", dataSource); DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; ds = env.addSource(dataSource); KeyedStream&lt;Tuple2&lt;String, Integer&gt;, Tuple&gt; keyedStream = ds.keyBy(0); // KeyedStream&lt;Tuple2&lt;String, Integer&gt;, Tuple&gt; keyedStream = ds.keyBy(\"f0\"); é€šè¿‡æŒ‡å®šå­—æ®µå f0 keyedStream .sum(1) // .sum(\"f1\") é€šè¿‡åˆ¶å®šå­—æ®µå f1 .keyBy((KeySelector&lt;Tuple2&lt;String, Integer&gt;, Object&gt;) stringIntegerTuple2 -&gt; StringUtils.EMPTY) .fold(new HashMap&lt;String, Integer&gt;(), new FoldFunction&lt;Tuple2&lt;String, Integer&gt;, HashMap&lt;String, Integer&gt;&gt;() &#123; @Override public HashMap&lt;String, Integer&gt; fold(HashMap&lt;String, Integer&gt; accumulator, Tuple2&lt;String, Integer&gt; value) throws Exception &#123; accumulator.put(value.f0, value.f1); return accumulator; &#125; &#125;) .addSink(new SinkFunction&lt;HashMap&lt;String, Integer&gt;&gt;() &#123; @Override public void invoke(HashMap&lt;String, Integer&gt; value, Context context) throws Exception &#123; // æ¯ä¸ªç±»å‹çš„å•†å“æˆäº¤é‡ LOGGER.info(\"&#123;&#125;\" , value); // å•†å“æˆäº¤æ€»é‡ LOGGER.info(\"&#123;&#125;\" , value.values().stream().mapToInt(v -&gt; v).sum()); &#125; &#125;); env.execute(); &#125;&#125; é€šè¿‡æŸ¥çœ‹dataSource object:çš„logå°±ä¼šå‘ç°ä¸Šé¢è¿™ä¸ªä¾‹å­ä¸­å›½äº§ç”Ÿäº†3ä¸ªDataSourceå®ä¾‹ã€‚ EvictorCountEvictorï¼šä¿æŒçª—å£å†…å…ƒç´ æ•°é‡ç¬¦åˆç”¨æˆ·æŒ‡å®šæ•°é‡ï¼Œå¦‚æœå¤šäºç”¨æˆ·æŒ‡å®šçš„æ•°é‡ï¼Œä»çª—å£ç¼“å†²åŒºçš„å¼€å¤´ä¸¢å¼ƒå‰©ä½™çš„å…ƒç´ ã€‚DeltaEvictorï¼šä½¿ç”¨ DeltaFunctionå’Œ ä¸€ä¸ªé˜ˆå€¼ï¼Œè®¡ç®—çª—å£ç¼“å†²åŒºä¸­çš„æœ€åä¸€ä¸ªå…ƒç´ ä¸å…¶ä½™æ¯ä¸ªå…ƒç´ ä¹‹é—´çš„ delta å€¼ï¼Œå¹¶åˆ é™¤ delta å€¼å¤§äºæˆ–ç­‰äºé˜ˆå€¼çš„å…ƒç´ ã€‚TimeEvictorï¼šä»¥æ¯«ç§’ä¸ºå•ä½çš„æ—¶é—´é—´éš”ä½œä¸ºå‚æ•°ï¼Œå¯¹äºç»™å®šçš„çª—å£ï¼Œæ‰¾åˆ°å…ƒç´ ä¸­çš„æœ€å¤§çš„æ—¶é—´æˆ³max_tsï¼Œå¹¶åˆ é™¤æ—¶é—´æˆ³å°äºmax_ts - intervalçš„æ‰€æœ‰å…ƒç´ ã€‚ keyedStreamKeyedStream.fold(R initialValue, FoldFunction&lt;T, R&gt; folder)æ·»åŠ ä¸€ä¸ªåˆå¹¶keyåˆ†ç»„çš„ç®—å­ï¼ŒFoldFunctionä¼šæ¥æ”¶åˆ°åŒä¸€keyçš„valueï¼Œåªæœ‰keyç›¸åŒçš„å€¼æ‰ä¼šè¢«åˆ†å‘åˆ°åŒä¸€ä¸ªfolderã€‚ å¯èƒ½å‡ºç°çš„é—®é¢˜Apache Flink: Return type of function could not be determined automatically due to type erasureé”™è¯¯åœºæ™¯ï¼šåœ¨ç”¨æˆ·å®šä¹‰DAGå›¾ç®—å­çš„æ—¶å€™ï¼Œå¯èƒ½ä¼šå‡ºç°ä¸æ”¯æŒlambdaè¡¨è¾¾å¼çš„æƒ…å†µ åŸå› ï¼šä¸ºäº†æ‰§è¡Œç¨‹åºï¼ŒFlinkéœ€è¦çŸ¥é“è¦å¤„ç†çš„å€¼çš„ç±»å‹ï¼Œå› ä¸ºå®ƒéœ€è¦åºåˆ—åŒ–å’Œååºåˆ—åŒ–æ•°æ®ã€‚Flinkçš„ç±»å‹ç³»ç»ŸåŸºäºæè¿°æ•°æ®ç±»å‹çš„TypeInformationè¿›è¡Œåºåˆ—åŒ–å’Œååºåˆ—åŒ–ï¼Œä¼šå°†Javaä¸­çš„åŸºæœ¬ç±»å‹ä»¥åŠObjectç±»å‹ä¸TypeInformationè¿›è¡Œæ˜ å°„ã€‚å½“æ‚¨æŒ‡å®šä¸€ä¸ªå‡½æ•°æ—¶ï¼ŒFlinkä¼šå°è¯•æ¨æ–­è¯¥å‡½æ•°çš„è¿”å›ç±»å‹ã€‚ä½†æ˜¯æŸäº›Lambdaå‡½æ•°ç”±äºç±»å‹æ“¦é™¤è€Œä¸¢å¤±äº†æ­¤ä¿¡æ¯ï¼ˆå¯ä»¥è‡ªå·±ç¼–è¯‘åå†å¯¹ç¼–è¯‘æˆçš„.classæ–‡ä»¶è¿›è¡Œåç¼–è¯‘ï¼Œç„¶åæŸ¥çœ‹å‡½æ•°ç­¾åï¼Œå‘ç°å‡½æ•°ç­¾åå…·ä½“ç±»å‹è¢«æ“¦é™¤ï¼‰ï¼Œå› æ­¤Flinkæ— æ³•é€šè¿‡æ­¤è‡ªåŠ¨æ¨æ–­ç±»å‹ã€‚Flink Java Lambdaè¡¨è¾¾å¼ å› æ­¤ï¼Œå¿…é¡»æ˜¾å¼å£°æ˜è¿”å›ç±»å‹ã€‚ è§£å†³æ–¹æ¡ˆ1ï¼šç”¨æˆ·è‡ªå·±å®šä¹‰è¿”å›ç±»å‹ 1234567DataStream&lt;String&gt; wordDataStream = dataStream.flatMap( (String sentence, Collector&lt;String&gt; out) -&gt; &#123; for(String word: sentence.split(\"\\\\W+\")) &#123; out.collect(word); // collect objects of type String &#125; &#125;).returns(Types.STRING); è§£å†³æ–¹æ¡ˆ2ï¼šæ˜¾ç¤ºå£°æ˜è¿”å›ç±»å‹ 12345678910111213141516DataStream&lt;String&gt; wordDataStream = dataStream.flatMap( new FlatMapFunction&lt;String, String&gt;() &#123; @Override public void flatMap(String sentence, Collector&lt;String&gt; out) &#123; // normalize and split the line String[] words = sentence.toLowerCase().split(\"\\\\W+\"); // emit the pairs for (String word : words) &#123; if (word.length() &gt; 0) &#123; out.collect(word); &#125; &#125; &#125; &#125;)","tags":[{"name":"Apache Flink","slug":"Apache-Flink","permalink":"https://yangyichao-mango.github.io/tags/Apache-Flink/"}]},{"title":"Hello World","date":"2019-10-14T12:54:25.000Z","path":"2019/10/14/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]