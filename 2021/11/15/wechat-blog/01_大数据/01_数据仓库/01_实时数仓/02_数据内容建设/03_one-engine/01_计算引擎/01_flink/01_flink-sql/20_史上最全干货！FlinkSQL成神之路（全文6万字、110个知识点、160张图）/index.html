<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Apache Flink," />





  <link rel="alternate" href="/atom.xml" title="antigeneral's blog" type="application/atom+xml" />






<meta name="description" content="本系列每篇文章都是从实际生产出发，深度解析 flink 中的全局一致性快照流程以及具体实现，抛砖引玉，提高小伙伴的姿♂势水平。阅读时长大概 20 分钟，话不多说，直接进入正文！">
<meta property="og:type" content="article">
<meta property="og:title" content="史上最全干货！Flink SQL 成神之路（全文 18 万字、138 个案例、42 张图）">
<meta property="og:url" content="https://yangyichao-mango.github.io/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%B9%B2%E8%B4%A7%EF%BC%81FlinkSQL%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%85%A8%E6%96%876%E4%B8%87%E5%AD%97%E3%80%81110%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9%E3%80%81160%E5%BC%A0%E5%9B%BE%EF%BC%89/index.html">
<meta property="og:site_name" content="antigeneral&#39;s blog">
<meta property="og:description" content="本系列每篇文章都是从实际生产出发，深度解析 flink 中的全局一致性快照流程以及具体实现，抛砖引玉，提高小伙伴的姿♂势水平。阅读时长大概 20 分钟，话不多说，直接进入正文！">
<meta property="og:locale">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/FlinkSQLnb.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/9.jpg">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/9.jpg">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/4.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/30.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/4.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/12.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/5.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/11.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/6.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/7.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/8.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/1.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/10.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/6.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/35.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/36.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/14.jpg">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/15.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/16.jpg">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/17.jpg">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/12_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%EF%BC%89%EF%BC%9A1.13cumulatewindow/1.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/13.jpg">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/34.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/19.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/20.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/2.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/3.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/4.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/5.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/21.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/22.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/23.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/24.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/25.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/27.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/26.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/28.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/29.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/32.png">
<meta property="og:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/31.png">
<meta property="article:published_time" content="2021-11-15T08:26:59.000Z">
<meta property="article:modified_time" content="2022-02-04T03:37:40.240Z">
<meta property="article:author" content="yangyichao-mango">
<meta property="article:tag" content="Apache Flink">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yangyichao-mango.github.io/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/FlinkSQLnb.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://yangyichao-mango.github.io/2021/11/15/wechat-blog/01_大数据/01_数据仓库/01_实时数仓/02_数据内容建设/03_one-engine/01_计算引擎/01_flink/01_flink-sql/20_史上最全干货！FlinkSQL成神之路（全文6万字、110个知识点、160张图）/"/>





  <title>史上最全干货！Flink SQL 成神之路（全文 18 万字、138 个案例、42 张图） | antigeneral's blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-150061865-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?c013b4f82e10e4f302d6f461f20bdf63";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">antigeneral's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-links">
          <a href="/links" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-link"></i> <br />
            
            links
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yangyichao-mango.github.io/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%B9%B2%E8%B4%A7%EF%BC%81FlinkSQL%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%85%A8%E6%96%876%E4%B8%87%E5%AD%97%E3%80%81110%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9%E3%80%81160%E5%BC%A0%E5%9B%BE%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/blog-img/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="antigeneral's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">史上最全干货！Flink SQL 成神之路（全文 18 万字、138 个案例、42 张图）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-11-15T16:26:59+08:00">
                2021-11-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Apache-Flink/" itemprop="url" rel="index">
                    <span itemprop="name">Apache Flink</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%B9%B2%E8%B4%A7%EF%BC%81FlinkSQL%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%85%A8%E6%96%876%E4%B8%87%E5%AD%97%E3%80%81110%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9%E3%80%81160%E5%BC%A0%E5%9B%BE%EF%BC%89/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2021/11/15/wechat-blog/01_大数据/01_数据仓库/01_实时数仓/02_数据内容建设/03_one-engine/01_计算引擎/01_flink/01_flink-sql/20_史上最全干货！FlinkSQL成神之路（全文6万字、110个知识点、160张图）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  63k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  273
                </span>
              
            </div>
          

          
              <div class="post-description">
                  本系列每篇文章都是从实际生产出发，深度解析 flink 中的全局一致性快照流程以及具体实现，抛砖引玉，提高小伙伴的姿♂势水平。阅读时长大概 20 分钟，话不多说，直接进入正文！
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h1><p>提前说明，如有抄袭，版权必究。</p>
<p>呕心沥血，Flink SQL 成神之路出品。小伙伴萌可以先体验一下下图大纲。由于微信公众号限制上传图片像素，所以博主分隔成了 5 张图片。。。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/FlinkSQLnb.png" alt="NB"></p>
<h1 id="2-基础概念篇"><a href="#2-基础概念篇" class="headerlink" title="2.基础概念篇"></a>2.基础概念篇</h1><h2 id="2-1-SQL-amp-Table-简介及运行环境"><a href="#2-1-SQL-amp-Table-简介及运行环境" class="headerlink" title="2.1.SQL &amp; Table 简介及运行环境"></a>2.1.SQL &amp; Table 简介及运行环境</h2><h3 id="2-1-1-简介"><a href="#2-1-1-简介" class="headerlink" title="2.1.1.简介"></a>2.1.1.简介</h3><p>Apache Flink 提供了两种关系型 API 用于统一流和批处理，Table 和 SQL API。</p>
<ol>
<li>⭐ Table API 是一种集成在 Java、Scala 和 Python 语言中的查询 API，简单理解就是用 Java、Scala、Python 按照 SQL 的查询接口封装了一层 lambda 表达式的查询 API，它允许以强类型接口的方式组合各种关系运算符（如选择、筛选和联接）的查询操作，然后生成一个 Flink 任务运行。如下案例所示：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">    .newInstance()</span><br><span class="line">    .inStreamingMode()</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">TableEnvironment tEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下面就是 Table API 的案例，其语义等同于</span></span><br><span class="line"><span class="comment">// select a, count(b) as cnt </span></span><br><span class="line"><span class="comment">// from Orders</span></span><br><span class="line"><span class="comment">// group by a</span></span><br><span class="line">DataSet&lt;Row&gt; result = tEnv</span><br><span class="line">        .from(<span class="string">&quot;Orders&quot;</span>)</span><br><span class="line">        .groupBy($(<span class="string">&quot;a&quot;</span>))</span><br><span class="line">        .select($(<span class="string">&quot;a&quot;</span>), $(<span class="string">&quot;b&quot;</span>).count().as(<span class="string">&quot;cnt&quot;</span>))</span><br><span class="line">        .toDataSet(counts, Row.class);</span><br><span class="line"></span><br><span class="line">result.print();</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ SQL API 是基于 SQL 标准的 Apache Calcite 框架实现的，我们可以使用纯 SQL 来开发和运行一个 Flink 任务。如下案例所示：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> target</span><br><span class="line"><span class="keyword">select</span> a, <span class="built_in">count</span>(b) <span class="keyword">as</span> cnt</span><br><span class="line"><span class="keyword">from</span> Orders</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> a</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>无论输入是连续（流处理）还是有界（批处理），在 Table 和 SQL 任一 API 中同一条查询语句是具有相同的语义并且会产出相同的结果的。<br>这就是说为什么 Flink SQL 和 Table API 可以做到在用户接口层面的流批统一。xdm，用一套 SQL 既能跑流任务，也能跑批任务，它不香嘛？</p>
</blockquote>
<p>Table API 和 SQL API 也与 DataStream API 做到了无缝集成。可以轻松地在三种 API 之间灵活切换。例如，可以使用 SQL 的 MATCH_RECOGNIZE 子句匹配出异常的数据，然后使用再转为 DataStream API 去灵活的构建针对于异常数据的自定义报警机制。</p>
<p>在 xdm 大体了解了这两个 API 是干啥的之后，我们就可以直接来看看，怎么使用这两个 API 了。</p>
<h3 id="2-1-2-SQL-和-Table-API-运行环境依赖"><a href="#2-1-2-SQL-和-Table-API-运行环境依赖" class="headerlink" title="2.1.2.SQL 和 Table API 运行环境依赖"></a>2.1.2.SQL 和 Table API 运行环境依赖</h3><p>根据小伙伴们使用的编程语言的不同（Java 或 Scala），需要将对应的依赖包添加到项目中。</p>
<ol>
<li>⭐ Java 依赖如下</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-java-bridge_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner-blink_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ Scala 依赖如下</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-scala-bridge_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner-blink_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-scala_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>引入上述依赖之后，小伙伴萌就可以开始使用 Table\SQL API 了。具体案例如下文所示。</p>
<h2 id="2-2-SQL-amp-Table-的基本概念及常用-API"><a href="#2-2-SQL-amp-Table-的基本概念及常用-API" class="headerlink" title="2.2.SQL &amp; Table 的基本概念及常用 API"></a>2.2.SQL &amp; Table 的基本概念及常用 API</h2><p>在小伙伴萌看下文之前，先看一下 2.2 节整体的思路，跟着博主思路走，会更清晰：</p>
<ol>
<li>⭐ 先通过一个 SQL\Table API 任务看一下我们在实际开发时的代码结构应该长啥样，让大家能有直观的感受</li>
<li>⭐ 重点介绍 SQL\Table API 中核心 API - TableEnvironment。SQL\Table 所有能用的接口都在 TableEnvironment 中</li>
<li>⭐ 通过两个角度（外部表\视图、临时\非临时）认识 Flink SQL 体系中的表的概念</li>
<li>⭐ 举几个创建外部表、视图的实际应用案例</li>
</ol>
<h3 id="2-2-1-一个-SQL-Table-API-任务的代码结构"><a href="#2-2-1-一个-SQL-Table-API-任务的代码结构" class="headerlink" title="2.2.1.一个 SQL\Table API 任务的代码结构"></a>2.2.1.一个 SQL\Table API 任务的代码结构</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个 TableEnvironment，为后续使用 SQL 或者 Table API 提供上线</span></span><br><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">    .newInstance()</span><br><span class="line">    .inStreamingMode() <span class="comment">// 声明为流任务</span></span><br><span class="line">    <span class="comment">//.inBatchMode() // 声明为批任务</span></span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">TableEnvironment tEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个输入表</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;CREATE TEMPORARY TABLE table1 ... WITH ( &#x27;connector&#x27; = ... )&quot;</span>);</span><br><span class="line"><span class="comment">// 创建一个输出表</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;CREATE TEMPORARY TABLE outputTable ... WITH ( &#x27;connector&#x27; = ... )&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 使用 Table API 做一个查询并返回 Table</span></span><br><span class="line">Table table2 = tableEnv.from(<span class="string">&quot;table1&quot;</span>).select(...);</span><br><span class="line"><span class="comment">// 2. 使用 SQl API 做一个查询并返回 Table</span></span><br><span class="line">Table table3 = tableEnv.sqlQuery(<span class="string">&quot;SELECT ... FROM table1 ... &quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 table2 的结果使用 Table API 写入 outputTable 中，并返回结果</span></span><br><span class="line">TableResult tableResult = table2.executeInsert(<span class="string">&quot;outputTable&quot;</span>);</span><br><span class="line">tableResult...</span><br></pre></td></tr></table></figure>

<p>总结一下上面案例使用到的一些 API，让大家先对 Table\SQL API 的能力有一个大概了解：</p>
<ol>
<li>⭐ TableEnvironment：Table API 和 SQL API 的都集成在一个统一上下文（即 TableEnvironment）中，其地位等同于 DataStream API 中的 StreamExecutionEnvironment 的地位</li>
<li>⭐ TableEnvironment::executeSql：用于 SQL API 中，可以执行一段完整 DDL，DML SQL。举例，方法入参可以是 <code>CREATE TABLE xxx</code>，<code>INSERT INTO xxx SELECT xxx FROM xxx</code>。</li>
<li>⭐ TableEnvironment::from(xxx)：用于 Table API 中，可以以强类型接口的方式运行。方法入参是一个表名称。</li>
<li>⭐ TableEnvironment::sqlQuery：用于 SQL API 中，可以执行一段查询 SQL，并把结果以 Table 的形式返回。举例，方法的入参是 <code>SELECT xxx FROM xxx</code> </li>
<li>⭐ Table::executeInsert：用于将 Table 的结果插入到结果表中。方法入参是写入的目标表。</li>
</ol>
<p><strong>无论是对于 SQL API 来说还是对于 Table API 来说，都是使用 TableEnvironment 接口承载我们的业务查询逻辑的。只是在用户的使用接口的方式上有区别，以上述的 Java 代码为例，Table API 其实就是模拟 SQL 的查询方式封装了 Java 语言的 lambda 强类型 API，SQL 就是纯 SQL 查询。Table 和 SQL 很多时候都是掺杂在一起的，大家理解的时候就可以直接将 Table 和 SQL API 直接按照 SQL 进行理解，不用强行做特殊的区分。</strong></p>
<p><strong>而且博主推荐的话，直接上 SQL API 就行，其实 Table API 在企业实战中用的不是特别多。你说 Table API 方便吧，它确实比 DataStream API 方便，但是又比 SQL 复杂。一般生产使用不多。</strong></p>
<p><code>注意：由于 Table 和 SQL API 基本上属于一回事，后续如果没有特别介绍的话，博主就直接按照 SQL API 进行介绍了。</code></p>
<p>如果 xdm 想直接上手运行一段 Flink SQL 的代码。</p>
<p>可以直接在公众号后台回复<strong>1.13.2 最全 flink sql</strong>获取源代码。所有的源码都开源到 github 上面了。里面包含了非常多的案例。可以直接拿来在本地运行的！！！肥肠的方便。</p>
<h3 id="2-2-2-SQL-上下文：TableEnvironment"><a href="#2-2-2-SQL-上下文：TableEnvironment" class="headerlink" title="2.2.2.SQL 上下文：TableEnvironment"></a>2.2.2.SQL 上下文：TableEnvironment</h3><p>TableEnvironment 是使用 SQL API 永远都离不开的一个接口。其是 SQL API 使用的入口（上下文），就像是你要使用 Java DataStream API 去写一个 Flink 任务需要使用到 StreamExecutionEnvironment 一样。</p>
<p>可以认为 TableEnvironment 在 SQL API 中的地位和 StreamExecutionEnvironment 在 DataStream 中的地位是一样的，都是包含了一个 Flink 任务运行时的所有上下文环境信息。大家这样对比学习会比较好理解。</p>
<p>TableEnvironment 包含的功能如下：</p>
<ol>
<li><p>⭐ ️Catalog 管理：Catalog 可以理解为 Flink 的 MetaStore，类似 Hive MetaStore 对在 Hive 中的地位，关于 Flink Catalog 的详细内容后续进行介绍</p>
</li>
<li><p>⭐ ️表管理：在 Catalog 中注册表</p>
</li>
<li><p>⭐️ SQL 查询：（这 TMD 还用说，最基本的功能啊），就像 DataStream 中提供了 addSource、map、flatmap 等接口</p>
</li>
<li><p>⭐ UDF 管理：注册用户定义（标量函数：一进一出、表函数：一进多出、聚合函数：多进一出）函数</p>
</li>
<li><p>⭐️ UDF 扩展：加载可插拔 Module（Module 可以理解为 Flink 管理 UDF 的模块，是可插拔的，可以让小伙伴萌自定义 Module，去支持奇奇怪怪的 UDF 功能）</p>
</li>
<li><p>⭐ DataStream 和 Table（Table\SQL API 的查询结果）之间进行转换：目前 1.13 版本的只有流任务支持，批任务不支持。1.14 支持批任务。</p>
</li>
</ol>
<p>接下来介绍如何创建一个 TableEnvironment。案例为 Java。easy game。</p>
<ol>
<li>⭐ 方法 1：通过 EnvironmentSettings 创建 TableEnvironment</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.TableEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 就是设置一些环境信息</span></span><br><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">    .newInstance()</span><br><span class="line">    .inStreamingMode() <span class="comment">// 声明为流任务</span></span><br><span class="line">    <span class="comment">//.inBatchMode() // 声明为批任务</span></span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 创建 TableEnvironment</span></span><br><span class="line">TableEnvironment tEnv = TableEnvironment.create(settings);</span><br></pre></td></tr></table></figure>

<p>在 1.13 版本中。</p>
<p>如果你是 <code>inStreamingMode</code>，则最终创建出来的 <code>TableEnvironment</code> 实例为 <code>StreamTableEnvironmentImpl</code>。</p>
<p>如果你是 <code>inBatchMode</code>，则最终创建出来的 <code>TableEnvironment</code> 实例为 <code>TableEnvironmentImpl</code>。</p>
<p>它两虽然都继承了 <code>TableEnvironment</code> 接口，但是 <code>StreamTableEnvironmentImpl</code> 支持的功能更多一些。大家可以直接去看看接口实验一下，这里就不进行详细介绍。</p>
<ol start="2">
<li>⭐ 方法 2：通过已有的 StreamExecutionEnvironment 创建 TableEnvironment</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;</span><br><span class="line"></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-SQL-中表的概念"><a href="#2-2-3-SQL-中表的概念" class="headerlink" title="2.2.3.SQL 中表的概念"></a>2.2.3.SQL 中表的概念</h3><p>一个表的全名（标识）会由三个部分组成：<code>Catalog 名称.数据库名称.表名称</code>。如果 <code>Catalog 名称</code>或者<code>数据库名称</code>没有指明，就会使用当前默认值 default。</p>
<p>举个例子，下面这个 SQL 创建的 Table 的全名为 <code>default.default.table1</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.executeSql(<span class="string">&quot;CREATE TEMPORARY TABLE table1 ... WITH ( &#x27;connector&#x27; = ... )&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>下面这个 SQL 创建的 Table 的全名为 <code>default.mydatabase.table1</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tableEnv.executeSql(<span class="string">&quot;CREATE TEMPORARY TABLE mydatabase.table1 ... WITH ( &#x27;connector&#x27; = ... )&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>表可以是常规的（外部表 TABLE），也可以是虚拟的（视图 VIEW）。</p>
<ol>
<li>⭐ 外部表 TABLE：描述的是外部数据，例如文件（HDFS）、消息队列（Kafka）等。依然拿离线 Hive SQL 举个例子，离线中一个表指的是 Hive 表，也就是所说的外部数据。</li>
<li>⭐ 视图 VIEW：从已经存在的表中创建，视图一般是一个 SQL 逻辑的查询结果。对比到离线的 Hive SQL 中，在离线的场景（Hive 表）中 VIEW 也都是从已有的表中去创建的。其实 Flink 也是一样的。</li>
</ol>
<blockquote>
<p>注意：</p>
<p>这里有不同的地方就是，离线 Hive MetaStore 中不会有 Catalog 这个概念，其标识都是 <code>数据库.数据表</code>。</p>
</blockquote>
<h3 id="2-2-4-SQL-临时表、永久表"><a href="#2-2-4-SQL-临时表、永久表" class="headerlink" title="2.2.4.SQL 临时表、永久表"></a>2.2.4.SQL 临时表、永久表</h3><p>表（视图、外部表）可以是临时的，并与单个 Flink session（可以理解为 Flink 任务运行一次就是一个 session）的生命周期绑定。</p>
<p>表（视图、外部表）也可以是永久的，并且对多个 Flink session 都生效。</p>
<ol>
<li>⭐ 临时表：通常保存于内存中并且仅在创建它们的 Flink session（可以理解为一次 Flink 任务的运行）持续期间存在。这些表对于其它 session（即其他 Flink 任务或非此次运行的 Flink 任务）是不可见的。因为这个表的元数据没有被持久化。如下案例：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 临时外部表</span></span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    `name` STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;user_defined&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;class.name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;flink.examples.sql._03.source_sink.table.user_defined.UserDefinedSource&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 临时视图</span></span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">VIEW</span> query_view <span class="keyword">as</span></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 永久表：需要外部 Catalog（例如 Hive Metastore）来持久化表的元数据。一旦永久表被创建，它将对任何连接到这个 Catalog 的 Flink session 可见且持续存在，直至从 Catalog 中被明确删除。如下案例：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 永久外部表。需要外部 Catalog 持久化！！！</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    `name` STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;user_defined&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;class.name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;flink.examples.sql._03.source_sink.table.user_defined.UserDefinedSource&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 永久视图。需要外部 Catalog 持久化！！！</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> query_view <span class="keyword">as</span></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 如果临时表和永久表使用了相同的名称（Catalog名.数据库名.表名）。那么在这个 Flink session 中，你的任务访问到这个表时，访问到的永远是临时表（即相同名称的表，临时表会屏蔽永久表）。</li>
</ol>
<h3 id="2-2-5-SQL-外部数据表"><a href="#2-2-5-SQL-外部数据表" class="headerlink" title="2.2.5.SQL 外部数据表"></a>2.2.5.SQL 外部数据表</h3><p>由于目前在实时数据的场景中多以消息队列作为数据表。此处就以 Kafka 为例创建一个外部数据表。</p>
<ol>
<li>⭐ Table API 创建外部数据表</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    StreamExecutionEnvironment env =</span><br><span class="line">            StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="keyword">new</span> Configuration());</span><br><span class="line">    </span><br><span class="line">    EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">            .newInstance()</span><br><span class="line">            .useBlinkPlanner()</span><br><span class="line">            .inStreamingMode()</span><br><span class="line">            .build();</span><br><span class="line"></span><br><span class="line">    StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// kafka 数据源</span></span><br><span class="line">    DataStream&lt;Row&gt; r = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer&lt;Row&gt;(xxx));</span><br><span class="line">    <span class="comment">// 将 DataStream 转为一个 Table API 中的 Table 对象进行使用</span></span><br><span class="line">    Table sourceTable = tEnv.fromDataStream(r</span><br><span class="line">            , Schema</span><br><span class="line">                    .newBuilder()</span><br><span class="line">                    .column(<span class="string">&quot;f0&quot;</span>, <span class="string">&quot;string&quot;</span>)</span><br><span class="line">                    .column(<span class="string">&quot;f1&quot;</span>, <span class="string">&quot;string&quot;</span>)</span><br><span class="line">                    .column(<span class="string">&quot;f2&quot;</span>, <span class="string">&quot;bigint&quot;</span>)</span><br><span class="line">                    .columnByExpression(<span class="string">&quot;proctime&quot;</span>, <span class="string">&quot;PROCTIME()&quot;</span>)</span><br><span class="line">                    .build());</span><br><span class="line"></span><br><span class="line">    tEnv.createTemporaryView(<span class="string">&quot;source_table&quot;</span>, sourceTable);</span><br><span class="line"></span><br><span class="line">    String selectWhereSql = <span class="string">&quot;select f0 from source_table where f1 = &#x27;b&#x27;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    Table resultTable = tEnv.sqlQuery(selectWhereSql);</span><br><span class="line"></span><br><span class="line">    tEnv.toRetractStream(resultTable, Row.class).print();</span><br><span class="line"></span><br><span class="line">    env.execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述案例中，Table API 将一个 DataStream 的结果集通过 <code>StreamTableEnvironment::fromDataStream</code> 转为一个 Table 对象来使用。</p>
<ol start="2">
<li>⭐ SQL API 创建外部数据表</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">        .newInstance()</span><br><span class="line">        .useBlinkPlanner()</span><br><span class="line">        .inStreamingMode()</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL API 执行 create table 创建表</span></span><br><span class="line">tEnv.executeSql(</span><br><span class="line">        <span class="string">&quot;CREATE TABLE KafkaSourceTable (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  `f0` STRING,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  `f1` STRING\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;kafka&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;topic&#x27; = &#x27;topic&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;properties.bootstrap.servers&#x27; = &#x27;localhost:9092&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;properties.group.id&#x27; = &#x27;testGroup&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;format&#x27; = &#x27;json&#x27;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;)&quot;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">Table t = tEnv.sqlQuery(<span class="string">&quot;SELECT * FROM KafkaSourceTable&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>具体的创建方式就是使用 <code>Create Table xxx</code> DDL 定义一个 Kafka 数据源（输入）表（也可以是 Kafka 数据汇（输出）表）。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/9.jpg" alt="9"></p>
<p>xdm，是不是又和 Hive 一样？惊不惊喜意不意外。对比学习 +1。</p>
<h3 id="2-2-6-SQL-视图-VIEW"><a href="#2-2-6-SQL-视图-VIEW" class="headerlink" title="2.2.6.SQL 视图 VIEW"></a>2.2.6.SQL 视图 VIEW</h3><p>上文已经说了，一个 VIEW 其实就是一段 SQL 逻辑的查询结果。</p>
<p>视图 VIEW 在 Table API 中的体现就是：一个 Table 的 Java 对象，其封装了一段查询逻辑。如下案例所示：</p>
<ol>
<li>⭐ Table API 创建 VIEW</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.TableEnvironment;</span><br><span class="line"></span><br><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">    .newInstance()</span><br><span class="line">    .inStreamingMode() <span class="comment">// 声明为流任务</span></span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">TableEnvironment tEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API 中的一个 Table 对象</span></span><br><span class="line">Table projTable = tEnv.from(<span class="string">&quot;X&quot;</span>).select(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 projTable 创建为一个叫做 projectedTable 的 VIEW</span></span><br><span class="line">tEnv.createTemporaryView(<span class="string">&quot;projectedTable&quot;</span>, projTable);</span><br></pre></td></tr></table></figure>

<p>Table API 是使用了 <code>TableEnvironment::createTemporaryView</code> 接口将一个 Table 对象创建为一个 VIEW。</p>
<ol start="2">
<li>⭐ SQL API 创建 VIEW</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.TableEnvironment;</span><br><span class="line"></span><br><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">    .newInstance()</span><br><span class="line">    .inStreamingMode() <span class="comment">// 声明为流任务</span></span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">TableEnvironment tEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">&quot;CREATE TABLE source_table (\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;    user_id BIGINT,\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;    `name` STRING\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;user_defined&#x27;,\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;  &#x27;format&#x27; = &#x27;json&#x27;,\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;  &#x27;class.name&#x27; = &#x27;flink.examples.sql._03.source_sink.table.user_defined.UserDefinedSource&#x27;\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;);\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;CREATE TABLE sink_table (\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;    user_id BIGINT,\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;    name STRING\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;print&#x27;\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;);\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;CREATE VIEW query_view as\n&quot;</span> <span class="comment">// 创建 VIEW</span></span><br><span class="line">    + <span class="string">&quot;SELECT\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;    *\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;FROM source_table\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;;\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;INSERT INTO sink_table\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;SELECT\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;    *\n&quot;</span></span><br><span class="line">    + <span class="string">&quot;FROM query_view;&quot;</span>;</span><br><span class="line"></span><br><span class="line">Arrays.stream(sql.split(<span class="string">&quot;;&quot;</span>))</span><br><span class="line">      .forEach(tEnv::executeSql);</span><br></pre></td></tr></table></figure>

<p>SQL API 是直接通过一段 <code>CREATE VIEW query_view as select * from source_table</code> 来创建的 VIEW，是纯 SQL 写法。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/9.jpg" alt="9"></p>
<p>这种创建方式是不是贼熟悉，和离线 Hive 一样 +1~</p>
<blockquote>
<p>注意：</p>
<p>在 Table API 中的一个 Table 对象被后续的多个查询使用的场景下：<br>Table 对象不会真的产生一个中间表供下游多个查询去引用，即多个查询不共享这个 Table 的结果，小伙伴萌可以理解为是一种中间表的简化写法，不会先产出一个中间表结果，然后将这个结果在下游多个查询中复用，后续的多个查询会将这个 Table 的逻辑执行多次。类似于 with tmp as (DML) 的语法</p>
</blockquote>
<h3 id="2-2-7-一个-SQL-查询案例"><a href="#2-2-7-一个-SQL-查询案例" class="headerlink" title="2.2.7.一个 SQL 查询案例"></a>2.2.7.一个 SQL 查询案例</h3><p>首先，如果 xdm 想直接上手运行一段 Flink SQL 的代码。</p>
<p>可以直接在公众号后台回复<strong>1.13.2 最全 flink sql</strong>获取源代码。所有的源码都开源到 github 上面了。里面包含了非常多的案例。可以直接拿来在本地运行的！！！肥肠的方便。</p>
<p>来看看一个 SQL 查询案例。</p>
<ol>
<li><p>⭐ 案例场景：计算每一种商品（sku_id 唯一标识）的售出个数、总销售额、平均销售额、最低价、最高价</p>
</li>
<li><p>⭐ 数据准备：数据源为商品的销售流水（sku_id：商品，price：销售价格），然后写入到 Kafka 的指定 topic（sku_id：商品，count_result：售出个数、sum_result：总销售额、avg_result：平均销售额、min_result：最低价、max_result：最高价）当中</p>
</li>
<li><p>⭐ 任务代码：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">    .newInstance()</span><br><span class="line">    .inStreamingMode() <span class="comment">// 声明为流任务</span></span><br><span class="line">    <span class="comment">//.inBatchMode() // 声明为批任务</span></span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">TableEnvironment tEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 创建一个数据源（输入）表，这里的数据源是 flink 自带的一个随机 mock 数据的数据源。</span></span><br><span class="line">String sourceSql = <span class="string">&quot;CREATE TABLE source_table (\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    sku_id STRING,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    price BIGINT\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;datagen&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;rows-per-second&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;fields.sku_id.length&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;fields.price.min&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;fields.price.max&#x27; = &#x27;1000000&#x27;\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;)&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 创建一个数据汇（输出）表，输出到 kafka 中</span></span><br><span class="line">String sinkSql = <span class="string">&quot;CREATE TABLE sink_table (\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    sku_id STRING,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    count_result BIGINT,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    sum_result BIGINT,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    avg_result DOUBLE,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    min_result BIGINT,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    max_result BIGINT,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;    PRIMARY KEY (`sku_id`) NOT ENFORCED\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;upsert-kafka&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;topic&#x27; = &#x27;tuzisir&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;properties.bootstrap.servers&#x27; = &#x27;localhost:9092&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;key.format&#x27; = &#x27;json&#x27;,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;  &#x27;value.format&#x27; = &#x27;json&#x27;\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;)&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 执行一段 group by 的聚合 SQL 查询</span></span><br><span class="line">String selectWhereSql = <span class="string">&quot;insert into sink_table\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;select sku_id,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;       count(*) as count_result,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;       sum(price) as sum_result,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;       avg(price) as avg_result,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;       min(price) as min_result,\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;       max(price) as max_result\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;from source_table\n&quot;</span></span><br><span class="line">        + <span class="string">&quot;group by sku_id&quot;</span>;</span><br><span class="line"></span><br><span class="line">tEnv.executeSql(sourceSql);</span><br><span class="line">tEnv.executeSql(sinkSql);</span><br><span class="line">tEnv.executeSql(selectWhereSql);</span><br></pre></td></tr></table></figure>

<h3 id="2-2-8-SQL-与-DataStream-API-的转换"><a href="#2-2-8-SQL-与-DataStream-API-的转换" class="headerlink" title="2.2.8.SQL 与 DataStream API 的转换"></a>2.2.8.SQL 与 DataStream API 的转换</h3><p>大家会比较好奇，要写 SQL 就纯 SQL 呗，要写 DataStream 就纯 DataStream 呗，为啥还要把这两类接口做集成呢？</p>
<p>博主举一个案例：在 pdd 这种发补贴券的场景下，希望可以在发的补贴券总金额超过 1w 元时，及时报警出来，来帮助控制预算，防止发的太多。</p>
<p>对应的解决方案，我们可以想到使用 SQL 计算补贴券发放的结果，但是 SQL 的问题在于无法做到报警。所以我们可以将 SQL 的查询的结果（即 Table 对象）转为 DataStream，然后就可以在 DataStream 后自定义报警逻辑的算子。</p>
<p>我们直接上 SQL 和 DataStream API 互相转化的案例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    FlinkEnv flinkEnv = FlinkEnvUtils.getStreamTableEnv(args);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. pdd 发补贴券流水数据</span></span><br><span class="line">    String createTableSql = <span class="string">&quot;CREATE TABLE source_table (\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;    id BIGINT,\n&quot;</span> -- 补贴券的流水 id</span><br><span class="line">            + <span class="string">&quot;    money BIGINT,\n&quot;</span> -- 补贴券的金额</span><br><span class="line">            + <span class="string">&quot;    row_time AS cast(CURRENT_TIMESTAMP as timestamp_LTZ(3)),\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;    WATERMARK FOR row_time AS row_time - INTERVAL &#x27;5&#x27; SECOND\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;datagen&#x27;,\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;  &#x27;rows-per-second&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;  &#x27;fields.id.min&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;  &#x27;fields.id.max&#x27; = &#x27;100000&#x27;,\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;  &#x27;fields.money.min&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;  &#x27;fields.money.max&#x27; = &#x27;100000&#x27;\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;)\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 计算总计发放补贴券的金额</span></span><br><span class="line">    String querySql = <span class="string">&quot;SELECT UNIX_TIMESTAMP(CAST(window_end AS STRING)) * 1000 as window_end, \n&quot;</span></span><br><span class="line">            + <span class="string">&quot;      window_start, \n&quot;</span></span><br><span class="line">            + <span class="string">&quot;      sum(money) as sum_money,\n&quot;</span> -- 补贴券的发放总金额</span><br><span class="line">            + <span class="string">&quot;      count(distinct id) as count_distinct_id\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;FROM TABLE(CUMULATE(\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;         TABLE source_table\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;         , DESCRIPTOR(row_time)\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;         , INTERVAL &#x27;5&#x27; SECOND\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;         , INTERVAL &#x27;1&#x27; DAY))\n&quot;</span></span><br><span class="line">            + <span class="string">&quot;GROUP BY window_start, \n&quot;</span></span><br><span class="line">            + <span class="string">&quot;        window_end&quot;</span>;</span><br><span class="line"></span><br><span class="line">    flinkEnv.streamTEnv().executeSql(createTableSql);</span><br><span class="line"></span><br><span class="line">    Table resultTable = flinkEnv.streamTEnv().sqlQuery(querySql);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 将金额结果转为 DataStream，然后自定义超过 1w 的报警逻辑</span></span><br><span class="line">    flinkEnv.streamTEnv()</span><br><span class="line">            .toDataStream(resultTable, Row.class)</span><br><span class="line">            .flatMap(<span class="keyword">new</span> FlatMapFunction&lt;Row, Object&gt;() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(Row value, Collector&lt;Object&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                    <span class="keyword">long</span> l = Long.parseLong(String.valueOf(value.getField(<span class="string">&quot;sum_money&quot;</span>)));</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (l &gt; <span class="number">10000L</span>) &#123;</span><br><span class="line">                        log.info(<span class="string">&quot;报警，超过 1w&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">    flinkEnv.env().execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<p>目前在 1.13 版本中，Flink 对于 Table 和 DataStream 的转化是有一些限制的：<br>上面的案例可以看到，Table 和 DataStream 之间的转换目前只有 <code>StreamTableEnvironment::toDataStream</code>、<code>StreamTableEnvironment::fromDataStream</code> 接口支持。</p>
<p>所以其实小伙伴萌可以理解为只有流任务才支持 Table 和 DataStream 之间的转换，批任务是不支持的（虽然可以使用流执行模式处理有界流 - 批数据，也就是模拟按照批执行，但效率较低，这种骚操作不建议大家搞）。</p>
<p>那什么时候才能支持批任务的 Table 和 DataStream 之间的转换呢？<br>1.14 版本支持。1.14 版本中，流和批的都统一到了 StreamTableEnvironment 中，因此就可以做 Table 和 DataStream 的互相转换了。</p>
</blockquote>
<h2 id="2-3-SQL-数据类型"><a href="#2-3-SQL-数据类型" class="headerlink" title="2.3.SQL 数据类型"></a>2.3.SQL 数据类型</h2><p>在介绍完一些基本概念之后，我们来认识一下，Flink SQL 中的数据类型。</p>
<p>Flink SQL 内置了很多常见的数据类型，并且也为用户提供了自定义数据类型的能力。</p>
<p>总共包含 3 部分：</p>
<ol>
<li>⭐ 原子数据类型</li>
<li>⭐ 复合数据类型</li>
<li>⭐ 用户自定义数据类型</li>
</ol>
<h3 id="2-3-1-原子数据类型"><a href="#2-3-1-原子数据类型" class="headerlink" title="2.3.1.原子数据类型"></a>2.3.1.原子数据类型</h3><ol>
<li>⭐ 字符串类型：</li>
</ol>
<ul>
<li>⭐ CHAR、CHAR(n)：定长字符串，就和 Java 中的 Char 一样，n 代表字符的定长，取值范围 [1, 2,147,483,647]。如果不指定 n，则默认为 1。</li>
<li>⭐ VARCHAR、VARCHAR(n)、STRING：可变长字符串，就和 Java 中的 String 一样，n 代表字符的最大长度，取值范围 [1, 2,147,483,647]。如果不指定 n，则默认为 1。STRING 等同于 VARCHAR(2147483647)。</li>
</ul>
<ol start="2">
<li>⭐ 二进制字符串类型：</li>
</ol>
<ul>
<li>⭐ BINARY、BINARY(n)：定长二进制字符串，n 代表定长，取值范围 [1, 2,147,483,647]。如果不指定 n，则默认为 1。</li>
<li>⭐ VARBINARY、VARBINARY(n)、BYTES：可变长二进制字符串，n 代表字符的最大长度，取值范围 [1, 2,147,483,647]。如果不指定 n，则默认为 1。BYTES 等同于 VARBINARY(2147483647)。</li>
</ul>
<ol start="3">
<li>⭐ 精确数值类型：</li>
</ol>
<ul>
<li>⭐ DECIMAL、DECIMAL(p)、DECIMAL(p, s)、DEC、DEC(p)、DEC(p, s)、NUMERIC、NUMERIC(p)、NUMERIC(p, s)：固定长度和精度的数值类型，就和 Java 中的 BigDecimal 一样，p 代表数值位数（长度），取值范围 [1, 38]；s 代表小数点后的位数（精度），取值范围 [0, p]。如果不指定，p 默认为 10，s 默认为 0。</li>
<li>⭐ TINYINT：-128 到 127 的 1 字节大小的有符号整数，就和 Java 中的 byte 一样。</li>
<li>⭐ SMALLINT：-32,768 to 32,767 的 2 字节大小的有符号整数，就和 Java 中的 short 一样。</li>
<li>⭐ INT、INTEGER：-2,147,483,648 to 2,147,483,647 的 4 字节大小的有符号整数，就和 Java 中的 int 一样。</li>
<li>⭐ BIGINT：-9,223,372,036,854,775,808 to 9,223,372,036,854,775,807 的 8 字节大小的有符号整数，就和 Java 中的 long 一样。</li>
</ul>
<ol start="4">
<li>⭐ 有损精度数值类型：</li>
</ol>
<ul>
<li>⭐ FLOAT：4 字节大小的单精度浮点数值，就和 Java 中的 float 一样。</li>
<li>⭐ DOUBLE、DOUBLE PRECISION：8 字节大小的双精度浮点数值，就和 Java 中的 double 一样。</li>
<li>⭐ 关于 FLOAT 和 DOUBLE 的区别可见 <a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/float-and-double-different.html">https://www.runoob.com/w3cnote/float-and-double-different.html</a></li>
</ul>
<ol start="5">
<li><p>⭐ 布尔类型：BOOLEAN</p>
</li>
<li><p>⭐ NULL 类型：NULL</p>
</li>
<li><p>⭐ Raw 类型：RAW(‘class’, ‘snapshot’) 。只会在数据发生网络传输时进行序列化，反序列化操作，可以保留其原始数据。以 Java 举例，<code>class</code> 参数代表具体对应的 Java 类型，<code>snapshot</code> 代表类型在发生网络传输时的序列化器</p>
</li>
<li><p>⭐ 日期、时间类型：</p>
</li>
</ol>
<ul>
<li>⭐ DATE：由 <code>年-月-日</code> 组成的 <code>不带时区含义</code> 的日期类型，取值范围 [0000-01-01, 9999-12-31]</li>
<li>⭐ TIME、TIME(p)：由 <code>小时：分钟：秒[.小数秒]</code> 组成的 <code>不带时区含义</code> 的的时间的数据类型，精度高达纳秒，取值范围 [00:00:00.000000000到23:59:59.9999999]。其中 p 代表小数秒的位数，取值范围 [0, 9]，如果不指定 p，默认为 0。</li>
<li>⭐ TIMESTAMP、TIMESTAMP(p)、TIMESTAMP WITHOUT TIME ZONE、TIMESTAMP(p) WITHOUT TIME ZONE：由 <code>年-月-日 小时：分钟：秒[.小数秒]</code> 组成的 <code>不带时区含义</code> 的时间类型，取值范围 [0000-01-01 00:00:00.000000000, 9999-12-31 23:59:59.999999999]。其中 p 代表小数秒的位数，取值范围 [0, 9]，如果不指定 p，默认为 6。</li>
<li>⭐ TIMESTAMP WITH TIME ZONE、TIMESTAMP(p) WITH TIME ZONE：由 <code>年-月-日 小时：分钟：秒[.小数秒] 时区</code> 组成的 <code>带时区含义</code> 的时间类型，取值范围 [0000-01-01 00:00:00.000000000 +14:59, 9999-12-31 23:59:59.999999999 -14:59]。其中 p 代表小数秒的位数，取值范围 [0, 9]，如果不指定 p，默认为 6。</li>
<li>⭐ TIMESTAMP_LTZ、TIMESTAMP_LTZ(p)：由 <code>年-月-日 小时：分钟：秒[.小数秒] 时区</code> 组成的 <code>带时区含义</code> 的时间类型，取值范围 [0000-01-01 00:00:00.000000000 +14:59, 9999-12-31 23:59:59.999999999 -14:59]。其中 p 代表小数秒的位数，取值范围 [0, 9]，如果不指定 p，默认为 6。</li>
<li>⭐ TIMESTAMP_LTZ 与 TIMESTAMP WITH TIME ZONE 的区别在于：TIMESTAMP WITH TIME ZONE 的时区信息是携带在数据中的，举例：其输入数据应该是 2022-01-01 00:00:00.000000000 +08:00；TIMESTAMP_LTZ 的时区信息不是携带在数据中的，而是由 Flink SQL 任务的全局配置决定的，我们可以由 <code>table.local-time-zone</code> 参数来设置时区。</li>
<li>⭐ INTERVAL YEAR TO MONTH、 INTERVAL DAY TO SECOND：interval 的涉及到的种类比较多。INTERVAL 主要是用于给 TIMESTAMP、TIMESTAMP_LTZ 添加偏移量的。举例，比如给 TIMESTAMP 加、减几天、几个月、几年。INTERVAL 子句总共涉及到的语法种类如下 Flink SQL 案例所示。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    result_interval_year <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_year_p <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_year_p_to_month <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_month <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_day <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_day_p1 <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_day_p1_to_hour <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_day_p1_to_minute <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_day_p1_to_second_p2 <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_hour <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_hour_to_minute <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_hour_to_second <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_minute <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_minute_to_second_p2 <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_second <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    result_interval_second_p2 <span class="type">TIMESTAMP</span>(<span class="number">3</span>)</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="comment">-- Flink SQL 支持的所有 INTERVAL 子句如下，总体可以分为 `年-月`、`日-小时-秒` 两种</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">-- 1. 年-月。取值范围为 [-9999-11, +9999-11]，其中 p 是指有效位数，取值范围 [1, 4]，默认值为 2。比如如果值为 1000，但是 p = 2，则会直接报错。</span></span><br><span class="line">    <span class="comment">-- INTERVAL YEAR</span></span><br><span class="line">    f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">YEAR</span> <span class="keyword">as</span> result_interval_year</span><br><span class="line">    <span class="comment">-- INTERVAL YEAR(p)</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;100&#x27;</span> <span class="keyword">YEAR</span>(<span class="number">3</span>) <span class="keyword">as</span> result_interval_year_p</span><br><span class="line">    <span class="comment">-- INTERVAL YEAR(p) TO MONTH</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10-03&#x27;</span> <span class="keyword">YEAR</span>(<span class="number">3</span>) <span class="keyword">TO</span> <span class="keyword">MONTH</span> <span class="keyword">as</span> result_interval_year_p_to_month</span><br><span class="line">    <span class="comment">-- INTERVAL MONTH</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;13&#x27;</span> <span class="keyword">MONTH</span> <span class="keyword">as</span> result_interval_month</span><br><span class="line"></span><br><span class="line">    <span class="comment">-- 2. 日-小时-秒。取值范围为 [-999999 23:59:59.999999999, +999999 23:59:59.999999999]，其中 p1\p2 都是有效位数，p1 取值范围 [1, 6]，默认值为 2；p2 取值范围 [0, 9]，默认值为 6</span></span><br><span class="line">    <span class="comment">-- INTERVAL DAY</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">DAY</span> <span class="keyword">as</span> result_interval_day</span><br><span class="line">    <span class="comment">-- INTERVAL DAY(p1)</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;100&#x27;</span> <span class="keyword">DAY</span>(<span class="number">3</span>) <span class="keyword">as</span> result_interval_day_p1</span><br><span class="line">    <span class="comment">-- INTERVAL DAY(p1) TO HOUR</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10 03&#x27;</span> <span class="keyword">DAY</span>(<span class="number">3</span>) <span class="keyword">TO</span> <span class="keyword">HOUR</span> <span class="keyword">as</span> result_interval_day_p1_to_hour</span><br><span class="line">    <span class="comment">-- INTERVAL DAY(p1) TO MINUTE</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10 03:12&#x27;</span> <span class="keyword">DAY</span>(<span class="number">3</span>) <span class="keyword">TO</span> <span class="keyword">MINUTE</span> <span class="keyword">as</span> result_interval_day_p1_to_minute</span><br><span class="line">    <span class="comment">-- INTERVAL DAY(p1) TO SECOND(p2)</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10 00:00:00.004&#x27;</span> <span class="keyword">DAY</span> <span class="keyword">TO</span> <span class="keyword">SECOND</span>(<span class="number">3</span>) <span class="keyword">as</span> result_interval_day_p1_to_second_p2</span><br><span class="line">    <span class="comment">-- INTERVAL HOUR</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">HOUR</span> <span class="keyword">as</span> result_interval_hour</span><br><span class="line">    <span class="comment">-- INTERVAL HOUR TO MINUTE</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10:03&#x27;</span> <span class="keyword">HOUR</span> <span class="keyword">TO</span> <span class="keyword">MINUTE</span> <span class="keyword">as</span> result_interval_hour_to_minute</span><br><span class="line">    <span class="comment">-- INTERVAL HOUR TO SECOND(p2)</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;00:00:00.004&#x27;</span> <span class="keyword">HOUR</span> <span class="keyword">TO</span> <span class="keyword">SECOND</span>(<span class="number">3</span>) <span class="keyword">as</span> result_interval_hour_to_second</span><br><span class="line">    <span class="comment">-- INTERVAL MINUTE</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span> <span class="keyword">as</span> result_interval_minute</span><br><span class="line">    <span class="comment">-- INTERVAL MINUTE TO SECOND(p2)</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;05:05.006&#x27;</span> <span class="keyword">MINUTE</span> <span class="keyword">TO</span> <span class="keyword">SECOND</span>(<span class="number">3</span>) <span class="keyword">as</span> result_interval_minute_to_second_p2</span><br><span class="line">    <span class="comment">-- INTERVAL SECOND</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;3&#x27;</span> <span class="keyword">SECOND</span> <span class="keyword">as</span> result_interval_second</span><br><span class="line">    <span class="comment">-- INTERVAL SECOND(p2)</span></span><br><span class="line">    , f1 <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;300&#x27;</span> <span class="keyword">SECOND</span>(<span class="number">3</span>) <span class="keyword">as</span> result_interval_second_p2</span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">SELECT</span> TO_TIMESTAMP_LTZ(<span class="number">1640966476500</span>, <span class="number">3</span>) <span class="keyword">as</span> f1)</span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-复合数据类型"><a href="#2-3-2-复合数据类型" class="headerlink" title="2.3.2.复合数据类型"></a>2.3.2.复合数据类型</h3><ol>
<li>⭐ 数组类型：ARRAY<t>、t ARRAY。数组最大长度为 2,147,483,647。t 代表数组内的数据类型。举例 ARRAY<INT>、ARRAY<STRING>，其等同于 INT ARRAY、STRING ARRAY</li>
<li>⭐ Map 类型：MAP&lt;kt, vt&gt;。Map 类型就和 Java 中的 Map 类型一样，key 是没有重复的。举例 Map&lt;STRING, INT&gt;、Map&lt;BIGINT, STRING&gt;</li>
<li>⭐ 集合类型：MULTISET<t>、t MULTISET。就和 Java 中的 List 类型，一样，运行重复的数据。举例 MULTISET<INT>，其等同于 INT MULTISET</li>
<li>⭐ 对象类型：ROW&lt;n0 t0, n1 t1, …&gt;、ROW&lt;n0 t0 ‘d0’, n1 t1 ‘d1’, …&gt;、ROW(n0 t0, n1 t1, …&gt;、ROW(n0 t0 ‘d0’, n1 t1 ‘d1’, …)。就和 Java 中的自定义对象一样。举例：ROW(myField INT, myOtherField BOOLEAN)，其等同于 ROW&lt;myField INT, myOtherField BOOLEAN&gt;</li>
</ol>
<h3 id="2-3-3-用户自定义数据类型"><a href="#2-3-3-用户自定义数据类型" class="headerlink" title="2.3.3.用户自定义数据类型"></a>2.3.3.用户自定义数据类型</h3><p>用户自定义类型就是运行用户使用 Java 等语言自定义一个数据类型出来。但是目前数据类型不支持使用 CREATE TABLE 的 DDL 进行定义，只支持作为函数的输入输出参数。如下案例：</p>
<ol>
<li>⭐ 第一步，自定义数据类型</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 基础类型，Flink 可以通过反射类型信息自动把数据类型获取到</span></span><br><span class="line">    <span class="comment">// 关于 SQL 类型和 Java 类型之间的映射见：https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/types/#data-type-extraction</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">public</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 复杂类型，用户可以通过 @DataTypeHint(&quot;DECIMAL(10, 2)&quot;) 注解标注此字段的数据类型</span></span><br><span class="line">    <span class="keyword">public</span> <span class="meta">@DataTypeHint(&quot;DECIMAL(10, 2)&quot;)</span> BigDecimal totalBalance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 第二步，在 UDF 中使用此数据类型</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserScalarFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 自定义数据类型作为输出参数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">eval</span><span class="params">(<span class="keyword">long</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (i &gt; <span class="number">0</span> &amp;&amp; i &lt;= <span class="number">5</span>) &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = (<span class="keyword">int</span>) i;</span><br><span class="line">            u.name = <span class="string">&quot;name1&quot;</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">1.1d</span>);</span><br><span class="line">            <span class="keyword">return</span> u;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = (<span class="keyword">int</span>) i;</span><br><span class="line">            u.name = <span class="string">&quot;name2&quot;</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">2.2d</span>);</span><br><span class="line">            <span class="keyword">return</span> u;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. 自定义数据类型作为输入参数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">eval</span><span class="params">(User i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (i.age &gt; <span class="number">0</span> &amp;&amp; i.age &lt;= <span class="number">5</span>) &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = <span class="number">1</span>;</span><br><span class="line">            u.name = <span class="string">&quot;name1&quot;</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">1.1d</span>);</span><br><span class="line">            <span class="keyword">return</span> u.name;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = <span class="number">2</span>;</span><br><span class="line">            u.name = <span class="string">&quot;name2&quot;</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">2.2d</span>);</span><br><span class="line">            <span class="keyword">return</span> u.name;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 第三步，在 Flink SQL 中使用</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1. 创建 UDF</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> user_scalar_func <span class="keyword">AS</span> <span class="string">&#x27;flink.examples.sql._12_data_type._02_user_defined.UserScalarFunction&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2. 创建数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;用户 id&#x27;</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3. 创建数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    result_row_1 <span class="type">ROW</span><span class="operator">&lt;</span>age <span class="type">INT</span>, name STRING, totalBalance <span class="type">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>)<span class="operator">&gt;</span>,</span><br><span class="line">    result_row_2 STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 4. SQL 查询语句</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="comment">-- 4.a. 用户自定义类型作为输出</span></span><br><span class="line">    user_scalar_func(user_id) <span class="keyword">as</span> result_row_1,</span><br><span class="line">    <span class="comment">-- 4.b. 用户自定义类型作为输出及输入</span></span><br><span class="line">    user_scalar_func(user_scalar_func(user_id)) <span class="keyword">as</span> result_row_2</span><br><span class="line"><span class="keyword">from</span> source_table;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 5. 查询结果</span></span><br><span class="line"><span class="operator">+</span>I[<span class="operator">+</span>I[<span class="number">9</span>, name2, <span class="number">2.20</span>], name2]</span><br><span class="line"><span class="operator">+</span>I[<span class="operator">+</span>I[<span class="number">1</span>, name1, <span class="number">1.10</span>], name1]</span><br><span class="line"><span class="operator">+</span>I[<span class="operator">+</span>I[<span class="number">5</span>, name1, <span class="number">1.10</span>], name1]</span><br></pre></td></tr></table></figure>

<h2 id="2-4-SQL-动态表-amp-连续查询"><a href="#2-4-SQL-动态表-amp-连续查询" class="headerlink" title="2.4.SQL 动态表 &amp; 连续查询"></a>2.4.SQL 动态表 &amp; 连续查询</h2><p>在小伙伴萌看下文之前，先看一下 2.4 节整体的思路，跟着博主思路走，会更清晰：</p>
<ol>
<li>⭐ 先分析一下将 SQL 应用到流处理的思路</li>
<li>⭐ SQL 应用于批处理已经很成熟了，通过对比流批处理在输入、数据处理、输出的异同点来分析出将 SQL 应用于流处理的核心要解决的问题点</li>
<li>⭐ 分析如何使用 <code>SQL 动态输入表</code> 技术来将 <code>输入数据流</code> 映射到 <code>SQL 中的输入表</code></li>
<li>⭐ 分析如何使用 <code>SQL 连续查询</code> 技术来将 <code>计算逻辑</code> 映射到 <code>SQL 中的运算语义</code></li>
<li>⭐ 使用 <code>SQL 动态表 &amp; 连续查询技术</code> 两种技术方案来将 <code>流式 SQL</code> 实际应用到两个常见案例中</li>
<li>⭐ 分析 <code>SQL 连续查询</code> 的两种类型：更新（Update）查询 &amp; 追加（Append）查询</li>
<li>⭐ 分析如何使用 <code>SQL 动态输出表</code> 技术来将 <code>输出数据流</code> 映射到 <code>SQL 中的输出表</code></li>
</ol>
<p>博主认为读完本节你应该掌握：</p>
<ol>
<li>⭐ <code>SQL 动态输入表</code>、<code>SQL 动态输出表</code></li>
<li>⭐ <code>SQL 连续查询</code> 的两种类型分别对应的查询场景及 SQL 语义</li>
</ol>
<h3 id="2-4-1-SQL-应用于流处理的思路"><a href="#2-4-1-SQL-应用于流处理的思路" class="headerlink" title="2.4.1.SQL 应用于流处理的思路"></a>2.4.1.SQL 应用于流处理的思路</h3><p>在流式 SQL 诞生之前，所有的基于 SQL 的数据查询都是基于批数据的，没有将 SQL 应用到流数据处理这一说法。</p>
<p>那么如果我们想将 SQL 应用到流处理中，必然要站在巨人的肩膀（批数据处理的流程）上面进行，那么具体的分析思路如下：</p>
<ol>
<li>⭐ 步骤一：先比较 <code>批处理</code> 与 <code>流处理</code> 的异同之处：如果有相同的部分，那么可以直接复用；不同之处才是我们需要重点克服和关注的。</li>
<li>⭐ 步骤二：摘出 1 中说到的不同之处，分析如果要满足这个不同之处，目前有哪些技术是类似的</li>
<li>⭐ 步骤三：再从这些类似的技术上进一步发展，以满足将 SQL 应用于流任务中</li>
</ol>
<p>博主下文就会根据上述三个步骤来一步一步介绍 <code>动态表</code> 诞生的背景以及这个概念是如何诞生的。</p>
<h3 id="2-4-2-流批处理的异同点及将-SQL-应用于流处理核心解决的问题"><a href="#2-4-2-流批处理的异同点及将-SQL-应用于流处理核心解决的问题" class="headerlink" title="2.4.2.流批处理的异同点及将 SQL 应用于流处理核心解决的问题"></a>2.4.2.流批处理的异同点及将 SQL 应用于流处理核心解决的问题</h3><p>首先对比一下常见的 <code>批处理</code> 和 <code>流处理</code> 中 <code>数据源（输入表）</code>、<code>处理逻辑</code>、<code>数据汇（结果表）</code> 的异同点。</p>
<table>
<thead>
<tr>
<th>-</th>
<th>输入表</th>
<th>处理逻辑</th>
<th>结果表</th>
</tr>
</thead>
<tbody><tr>
<td>批处理</td>
<td>静态表：输入数据有限、是有界集合</td>
<td>批式计算：每次执行查询能够访问到完整的输入数据，然后计算，输出完整的结果数据</td>
<td>静态表：数据有限</td>
</tr>
<tr>
<td>流处理</td>
<td>动态表：输入数据无限，数据实时增加，并且源源不断</td>
<td>流式计算：执行时不能够访问到完整的输入数据，每次计算的结果都是一个中间结果</td>
<td>动态表：数据无限</td>
</tr>
</tbody></table>
<p>对比上述流批处理之后，我们得到了要将 SQL 应用于流式任务的三个要解决的核心点：</p>
<ol>
<li>⭐ SQL 输入表：分析如何将一个实时的，源源不断的输入流数据表示为 SQL 中的输入表。</li>
<li>⭐ SQL 处理计算：分析将 SQL 查询逻辑翻译成什么样的底层处理技术才能够实时的处理流式输入数据，然后产出流式输出数据。</li>
<li>⭐ SQL 输出表：分析如何将 SQL 查询输出的源源不断的流数据表示为一个 SQL 中的输出表。</li>
</ol>
<p>将上面 3 个点总结一下，也就引出了本节的 <code>动态表</code> 和 <code>连续查询</code> 两种技术方案：</p>
<ol>
<li>⭐ <code>动态表</code>：源源不断的输入、输出流数据映射到 <code>动态表</code></li>
<li>⭐ <code>连续查询</code>：实时处理输入数据，产出输出数据的实时处理技术</li>
</ol>
<h3 id="2-4-3-SQL-流处理的输入：输入流映射为-SQL-动态输入表"><a href="#2-4-3-SQL-流处理的输入：输入流映射为-SQL-动态输入表" class="headerlink" title="2.4.3.SQL 流处理的输入：输入流映射为 SQL 动态输入表"></a>2.4.3.SQL 流处理的输入：输入流映射为 SQL 动态输入表</h3><p><code>动态表</code>。这里的动态其实是相比于批处理的静态（有界）来说的。</p>
<ol>
<li>⭐ 静态表：应用于批处理数据中，静态表可以理解为是不随着时间<code>实时</code>进行变化的。一般都是一天、一小时的粒度新生成一个分区。</li>
<li>⭐ 动态表：动态表是随时间实时进行变化的。是将 SQL 体系中表的概念应用到 Flink 上面的的核心点。</li>
</ol>
<p>来看一个具体的案例，下图显示了<code>点击事件流</code>（左侧）如何转换为<code>动态表</code>（右侧）。当数据源生成更多的点击事件记录时，映射出来的动态表也会不断增长，这就是动态表的概念：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/4.png" alt="Dynamic Table"></p>
<h3 id="2-4-4-SQL-流处理的计算：实时处理底层技术-SQL-连续查询"><a href="#2-4-4-SQL-流处理的计算：实时处理底层技术-SQL-连续查询" class="headerlink" title="2.4.4.SQL 流处理的计算：实时处理底层技术 - SQL 连续查询"></a>2.4.4.SQL 流处理的计算：实时处理底层技术 - SQL 连续查询</h3><p><code>连续查询</code>。</p>
<p>部分高级关系数据库系统提供了一个称为<strong>物化视图</strong>（Materialized Views) 的特性。</p>
<p>物化视图其实就是一条 SQL 查询，就像常规的虚拟视图 VIEW 一样。但与虚拟视图不同的是，物化视图会缓存查询的结果，因此在请求访问视图时不需要对查询进行重新计算，可以直接获取物化视图的结果，小伙伴萌可以认为物化视图其实就是把结果缓存了下来。</p>
<p>举个例子：批处理中，如果以 Hive 天级别的物化视图来说，其实就是每天等数据源 ready 之后，调度物化视图的 SQL 执行然后产生新的结果提供服务。<code>那么就可以认为一条表示了输入、处理、输出的 SQL 就是一个构建物化视图的过程。</code></p>
<p>映射到我们的流任务中，输入、处理逻辑、输出这一套流程也是一个物化视图的概念。相比批处理来说，流处理中，我们的数据源表的数据是源源不断的。那么从输入、处理、输出的整个物化视图的维护流程也必须是实时的。</p>
<p>因此我们就需要引入一种<code>实时视图维护（Eager View Maintenance）</code>的技术去做到：一旦更新了物化视图的数据源表就立即更新视图的结果，从而保证输出的结果也是最新的。</p>
<p>这种 <code>实时视图维护（Eager View Maintenance）</code>的技术就叫做 <code>连续查询</code>。</p>
<blockquote>
<p>注意：</p>
<ol>
<li>⭐ <strong>连续查询（Continuous Query）</strong> 不断的消费动态输入表的的数据，不断的更新动态结果表的数据。</li>
<li>⭐ <strong>连续查询（Continuous Query）</strong> 的产出的结果 = 批处理模式在输入表的上执行的相同查询的结果。相同的 SQL，对应于同一个输入数据，虽然执行方式不同，但是流处理和批处理的结果是永远都会相同的。</li>
</ol>
</blockquote>
<h3 id="2-4-5-SQL-流处理实际应用：动态表-amp-连续查询技术的两个实战案例"><a href="#2-4-5-SQL-流处理实际应用：动态表-amp-连续查询技术的两个实战案例" class="headerlink" title="2.4.5.SQL 流处理实际应用：动态表 &amp; 连续查询技术的两个实战案例"></a>2.4.5.SQL 流处理实际应用：动态表 &amp; 连续查询技术的两个实战案例</h3><p>总结前两节，<code>动态表</code> &amp; <code>连续查询</code> 两项技术在一条流 SQL 中的执行流程总共包含了三个步骤，如下图及总结所示：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/30.png" alt="Query"></p>
<ol>
<li>⭐ 第一步：将数据输入流转换为 SQL 中的动态输入表。这里的转化其实就是指将输入流映射（绑定）为一个动态输入表。上图虽然分开画了，但是可以理解为一个东西。</li>
<li>⭐ 第二步：在动态输入表上执行一个连续查询，然后生成一个新的动态结果表。</li>
<li>⭐ 第三步：生成的动态结果表被转换回数据输出流。</li>
</ol>
<p>我们实际介绍一个案例来看看其运行方式，以上文介绍到的<strong>点击事件流</strong>为例，点击事件流数据的字段如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  user:  VARCHAR,   &#x2F;&#x2F; 用户名</span><br><span class="line">  cTime: TIMESTAMP, &#x2F;&#x2F; 访问 URL 的时间</span><br><span class="line">  url:   VARCHAR    &#x2F;&#x2F; 用户访问的 URL</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<ol>
<li>⭐ 第一步，将输入数据流映射为一个动态输入表。以下图为例，我们将点击事件流（图左）转换为动态表 (图右)。当点击数据源源不断的来到时，动态表的数据也会不断的增加。</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/4.png" alt="Dynamic Table"></p>
<ol start="2">
<li>⭐ 第二步，在点击事件流映射的动态输入表上执行一个<strong>连续查询（Continuous Query）</strong>，并生成一个新的动态输出表。</li>
</ol>
<p>下面介绍两个查询的案例：</p>
<p>第一个查询：一个简单的 GROUP-BY COUNT 聚合查询，写过 SQL 的都不会陌生吧，这种应该都是最基础，最常用的对数据按照类别分组的方法。</p>
<p>如下图所示 group by 聚合的常用案例。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/12.png" alt="time"></p>
<p>那么本案例中呢，是基于 clicks 表中 user 字段对 clicks 表（点击事件流）进行分组，来统计每一个 user 的访问的 URL 的数量。下面的图展示了当 clicks 输入表来了新数据（即表更新时），<strong>连续查询（Continuous Query）</strong> 的计算逻辑。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/5.png" alt="group agg"></p>
<p>当查询开始，clicks 表(左侧)是空的。</p>
<ol>
<li>⭐ 当第一行数据被插入到 clicks 表时，连续查询（Continuous Query）开始计算结果数据。数据源表第一行数据 [Mary,./home] 输入后，会计算结果 [Mary, 1] <code>插入（insert）结果表</code>。</li>
<li>⭐ 当第二行 [Bob, ./cart] 插入到 clicks 表时，连续查询（Continuous Query）会计算结果 [Bob, 1]，并<code>插入（insert）到结果表</code>。</li>
<li>⭐ 第三行 [Mary, ./prod?id=1] 输出时，会计算出[Mary, 2]（user 为 Mary 的数据总共来过两条，所以为 2），并<code>更新（update）结果表</code>，[Mary, 1] 更新成 [Mary, 2]。</li>
<li>⭐ 最后，当第四行数据加入 clicks 表时，查询将第三行 [Liz, 1] <code>插入（insert）结果表</code>中。</li>
</ol>
<p>注意上述特殊标记出来的字体，可以看到连续查询对于结果的数据输出方式有两种：</p>
<ol>
<li>⭐ 插入（insert）结果表</li>
<li>⭐ 更新（update）结果表</li>
</ol>
<p>大家对于 <code>插入（insert）结果表</code> 这件事都比较好理解，因为离线数据都只有插入这个概念。</p>
<p>但是 <code>更新（update）结果表</code> 就是离线处理中没有概念了。这就是连续查询中中比较重要一个概念。后文会介绍。</p>
<p>接下来介绍第二条查询语句。</p>
<p><code>第二条查询与第一条类似</code>，但是 group by 中除了 user 字段之外，还 group by 了 tumble，其代表开了个滚动窗口（后面会详细说明滚动窗口的作用），然后计算 url 数量。</p>
<p>group by user，是按照类别（横向）给数据分组，group by tumble 滚动窗口是按时间粒度（纵向）给数据进行分组。如下图所示。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/11.png" alt="time"></p>
<p>图形化一解释就很好理解了，两种都是对数据进行分组，一个是按照 <code>类别</code> 分组，另一种是按照 <code>时间</code> 分组。</p>
<p>与前面一样，左边显示了输入表 clicks。查询每小时持续计算结果并更新结果表。clicks 表有三列，user，cTime，url。其中 cTime 代表数据的时间戳，用于给数据按照时间粒度分组。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/6.png" alt="tumble window"></p>
<p>我们的滚动窗口的步长为 1 小时，即时间粒度上面的分组为 1 小时。其中时间戳在 12:00:00 - 12:59:59 之间有四条数据。13:00:00 - 13:59:59 有三条数据。14:00:00 - 14:59:59 之间有四条数据。</p>
<ol>
<li>⭐ 当 12:00:00 - 12:59:59 数据输入之后，1 小时的窗口，连续查询（Continuous Query）计算的结果如右图所示，将 [Mary, 3]，[Bob, 1] <code>插入（insert）结果表</code>。</li>
<li>⭐ 当 13:00:00 - 13:59:59 数据输入之后，1 小时的窗口，连续查询（Continuous Query）计算的结果如右图所示，将 [Bob, 1]，[Liz, 2] <code>插入（insert）结果表</code>。</li>
<li>⭐ 当 14:00:00 - 14:59:59 数据输入之后，1 小时的窗口，连续查询（Continuous Query）计算的结果如右图所示，将 [Mary, 1]，[Bob, 2]，[Liz, 1] <code>插入（insert）结果表</code>。</li>
</ol>
<p>而这个查询只有 <code>插入（insert）结果表</code> 这个行为。</p>
<h3 id="2-4-6-SQL-连续查询的两种类型：更新（Update）查询-amp-追加（Append）查询"><a href="#2-4-6-SQL-连续查询的两种类型：更新（Update）查询-amp-追加（Append）查询" class="headerlink" title="2.4.6.SQL 连续查询的两种类型：更新（Update）查询 &amp; 追加（Append）查询"></a>2.4.6.SQL 连续查询的两种类型：更新（Update）查询 &amp; 追加（Append）查询</h3><p>虽然前一节的两个查询看起来非常相似（都计算分组进行计数聚合），但它们在一个重要方面不同：</p>
<ol>
<li><p>⭐ 第一个查询（group by user），即（Update）查询：会更新先前输出的结果，即结果表流数据中包含 INSERT 和 UPDATE 数据。<br>小伙伴萌可以理解为 group by user 这条语句当中，输入源的数据是一直有的，源源不断的，同一个 user 的数据之后可能还是会有的，因此可以认为此 SQL 的每次的输出结果都是一个中间结果，<br>当同一个 user 下一条数据到来的时候，就要用新结果把上一次的产出中间结果（旧结果）给 UPDATE 了。所以这就是 UPDATE 查询的由来（其中 INSERT 就是第一条数据到来的时候，没有之前的中间结果，所以是 INSERT）。</p>
</li>
<li><p>⭐ 第二个查询（group by user, tumble(xxx)），即（Append）查询：只追加到结果表，即结果表流数据中只包含 INSERT 的数据。<br>小伙伴萌可以理解为虽然 group by user, tumble(xxx) 上游也是一个源源不断的数据，但是这个查询本质上是对时间上的划分，而时间都是越变越大的，当前这个滚动窗口结束之后，后面来的数据的时间都会比这个滚动窗口的结束时间大，都归属于之后的窗口了，当前这个滚动窗口的结果数据就不会再改变了，因此这条查询只有 INSERT 数据，即一个 Append 查询。</p>
</li>
</ol>
<p>上面是 Flink SQL 连续查询处理机制上面的两类查询方式。我们可以发现连续查询的处理机制不一样，产出到结果表中的结果数据也是不一样的。针对上面两种结果表的更新方式，Flink SQL 提出了 changelog 表的概念来进行兼容。</p>
<p>changelog 表这个概念其实就和 MySQL binlog 是一样的。会包含 <code>INSERT</code>、<code>UPDATE</code>、<code>DELETE</code> 三种数据，通过这三种数据的处理来描述实时处理技术对于动态表的变更：</p>
<ol>
<li>⭐ changelog 表：即第一个查询的输出表，输出结果数据不但会追加，还会发生更新</li>
<li>⭐ changelog insert-only 表：即第二个查询的输出表，输出结果数据只会追加，不会发生更新</li>
</ol>
<h3 id="2-4-7-SQL-流处理的输出：动态输出表转化为输出数据"><a href="#2-4-7-SQL-流处理的输出：动态输出表转化为输出数据" class="headerlink" title="2.4.7.SQL 流处理的输出：动态输出表转化为输出数据"></a>2.4.7.SQL 流处理的输出：动态输出表转化为输出数据</h3><p>可以看到我们的标题都是随着一个 SQL 的生命周期的。从 <code>输入流映射为 SQL 动态输入表</code>、<code>实时处理底层技术 - SQL 连续查询</code> 到本小节的 <code>SQL 动态输出表转化为输出数据</code>。都是有逻辑关系的。</p>
<p>我们上面介绍到了 <strong>连续查询（Continuous Query）</strong> 的输出结果表是一个 changelog。其可以像普通数据库表一样通过 INSERT、UPDATE 和 DELETE 来不断修改。</p>
<p>它可能是一个只有一行、不断更新 changelog 表，也可能是一个 insert-only 的 changelog 表，没有 UPDATE 和 DELETE 修改，或者介于两者之间的其他表。</p>
<p>在将动态表转换为流或将其写入外部系统时，需要对这些不同状态的数据进行编码。Flink 的 Table API 和 SQL API 支持三种方式来编码一个动态表的变化:</p>
<ol>
<li><p>⭐ Append-only 流： 输出的结果只有 <code>INSERT</code> 操作的数据。</p>
</li>
<li><p>⭐ Retract 流： </p>
</li>
</ol>
<ul>
<li>⭐ Retract 流包含两种类型的 message： add messages 和 retract messages 。其将 <code>INSERT</code> 操作编码为 add message、将 <code>DELETE</code> 操作编码为 retract message、将 <code>UPDATE</code> 操作编码为更新先前行的 retract message 和更新（新）行的 add message，从而将动态表转换为 retract 流。</li>
<li>⭐ Retract 流写入到输出结果表的数据如下图所示，有 <code>-</code>，<code>+</code> 两种，分别 <code>-</code> 代表撤回旧数据，<code>+</code> 代表输出最新的数据。这两种数据最终都会写入到输出的数据引擎中。</li>
<li>⭐ 如果下游还有任务去消费这条流的话，要注意需要正确处理 <code>-</code>，<code>+</code> 两种数据，防止数据计算重复或者错误。</li>
</ul>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/7.png" alt="retract"></p>
<ol start="3">
<li>⭐ Upsert 流：</li>
</ol>
<ul>
<li>⭐ Upsert 流包含两种类型的 message： upsert messages 和 delete messages。转换为 upsert 流的动态表需要唯一键（唯一键可以由多个字段组合而成）。其会将 <code>INSERT</code> 和 <code>UPDATE</code> 操作编码为 upsert message，将 <code>DELETE</code> 操作编码为 delete message。</li>
<li>⭐ Upsert 流写入到输出结果表的数据如下图所示，每次输出的结果都是当前每一个 user 的最新结果数据，不会有 Retract 中的 <code>-</code> 回撤数据。</li>
<li>⭐ 如果下游还有一个任务去消费这条流的话，消费流的算子需要知道唯一键（即 user），以便正确地根据唯一键（user）去拿到每一个 user 当前最新的状态。其与 retract 流的主要区别在于 UPDATE 操作是用单个 message 编码的，因此效率更高。下图显示了将动态表转换为 upsert 流的过程。</li>
</ul>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/8.png" alt="upsert"></p>
<h3 id="2-4-8-补充知识：SQL-与关系代数"><a href="#2-4-8-补充知识：SQL-与关系代数" class="headerlink" title="2.4.8.补充知识：SQL 与关系代数"></a>2.4.8.补充知识：SQL 与关系代数</h3><p>小伙伴萌会问到，关系代数是啥东西？</p>
<p>其实关系代数就是对于数据集（即表）的一系列的 <code>操作</code>（即查询语句）。常见关系代数有：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/1.png" alt="Relational Algebra"></p>
<p>⭐ 那么 SQL 和关系代数是啥关系呢？</p>
<p><strong>SQL 就是能够表示关系代数一种面向用户的接口：即用户能使用 SQL 表达关系代数的处理逻辑，也就是我们可以用 SQL 去在表（数据集）上执行我们的业务逻辑操作（关系代数操作）。</strong></p>
<h2 id="2-5-SQL-的时间属性"><a href="#2-5-SQL-的时间属性" class="headerlink" title="2.5.SQL 的时间属性"></a>2.5.SQL 的时间属性</h2><p>在小伙伴萌看下文之前，先看一下 2.5 节整体的思路，跟着博主思路走：</p>
<ol>
<li>⭐ 与离线处理中常见的时间分区字段一样，在实时处理中，时间属性也是一个核心概念。Flink 支持 <code>处理时间</code>、<code>事件时间</code>、<code>摄入时间</code> 三种时间语义。</li>
<li>⭐ 分别介绍三种时间语义的应用场景及案例。三种时间在生产环境的使用频次 <code>事件时间（SQL 常用）</code> &gt; <code>处理时间（SQL 几乎不用，DataStream 少用）</code> &gt; <code>摄入时间（不用）</code></li>
</ol>
<h3 id="2-5-1-Flink-三种时间属性简介"><a href="#2-5-1-Flink-三种时间属性简介" class="headerlink" title="2.5.1.Flink 三种时间属性简介"></a>2.5.1.Flink 三种时间属性简介</h3><p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/10.png" alt="time"></p>
<ol>
<li>⭐ 事件时间：指的是数据本身携带的时间，这个时间是在事件产生时的时间，而且在 Flink SQL 触发计算时，也使用数据本身携带的时间。这就叫做 <code>事件时间</code>。<code>目前生产环境中用的最多</code>。</li>
<li>⭐ 处理时间：指的是具体算子计算数据执行时的机器时间（例如在算子中 Java 取 System.currentTimeMillis()) ），<code>在生产环境中用的次多</code>。</li>
<li>⭐ 摄入时间：指的是数据从数据源进入 Flink 的时间。<code>摄入时间用的最少，可以说基本不使用</code>。</li>
</ol>
<p>小伙伴萌要注意到：</p>
<ol>
<li>⭐ 上述的三种时间概念不是由于有了数据而诞生的，而是有了 Flink 之后根据实际的应用场景而诞生的。以事件时间举个例子，如果只是数据携带了时间，Flink 也消费了这个数据，但是在 Flink 中没有使用数据的这个时间作为计算的触发条件，也不能把这个 Flink 任务叫做事件时间的任务。</li>
<li>⭐ 其次，要认识到，一般一个 Flink 任务只会有一个时间属性，所以时间属性通常认为是一个任务粒度的。举例：我们可以说 A 任务是事件时间语义的任务，B 任务是处理时间语义的任务。当然了，一个任务也可以存在多个时间属性。</li>
</ol>
<h3 id="2-5-2-Flink-三种时间属性的应用场景"><a href="#2-5-2-Flink-三种时间属性的应用场景" class="headerlink" title="2.5.2.Flink 三种时间属性的应用场景"></a>2.5.2.Flink 三种时间属性的应用场景</h3><p>讲到这里，xdm 会问，博主上面写的 3 种时间属性到底对我们的任务有啥影响呢？3 种时间属性的应用场景是啥？</p>
<p>先说结论，在 Flink 中时间的作用：</p>
<ol>
<li>⭐ <code>主要体现在包含时间窗口的计算中</code>：用于标识任务的时间进度，来判断是否需要触发窗口的计算。比如常用的<code>滚动窗口</code>、<code>滑动窗口</code>等都需要时间推动触发。这些窗口的应用场景后续会详细介绍。</li>
<li>⭐ <code>次要体现在自定义时间语义的计算中</code>：举个例子，比如用户可以自定义每隔 10s 的本地时间，或者消费到的数据的时间戳每增大 10s，就把计算结果输出一次，时间在此类应用中也是一种标识任务进度的作用。</li>
</ol>
<p>博主以 <code>滚动窗口</code> 的聚合任务为例来介绍一下事件时间和处理时间的对比区别。</p>
<ol>
<li>⭐ 事件时间案例：还是以之前的 clicks 表拿来举例。</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/6.png" alt="tumble window"></p>
<p>上面这个案例的窗口大小是 1 小时，需求方需要按照用户点击时间戳 <code>cTime</code> 划分数据（划分滚动窗口），然后计算出 count 聚合结果（这样计算能反映出事件的真实发生时间），那么就需要把 <code>cTime</code> 设置为窗口的划分时间戳，即代码中 <code>tumble(cTime, interval &#39;1&#39; hour)</code>。</p>
<p>上面这种就叫做事件时间。即用数据中自带的时间戳进行窗口的划分（点击操作真实的发生时间）。</p>
<p>后续 Flink SQL 任务在运行的过程中也会实际按照 <code>cTime</code> 的当前时间作为一小时窗口结束触发条件并计算一个小时窗口内的数据。</p>
<ol start="2">
<li>⭐ 处理时间案例：还是以之前的 clicks 表拿来举例。</li>
</ol>
<p>还是上面那个案例，但是这次需求方不需要按照数据上的时间戳划分数据（划分滚动窗口），只需要数据来了之后， 在 Flink 机器上的时间作为一小时窗口结束的书法条件并计算。</p>
<p>那么这种触发机制就是处理时间。</p>
<ol start="3">
<li>⭐ 摄入时间案例：在 Flink 从外部数据源读取到数据时，给这条数据带上的当前数据源算子的本地时间戳。下游可以用这个时间戳进行窗口聚合，不过这种几乎不使用。</li>
</ol>
<h3 id="2-5-3-SQL-指定时间属性的两种方式"><a href="#2-5-3-SQL-指定时间属性的两种方式" class="headerlink" title="2.5.3.SQL 指定时间属性的两种方式"></a>2.5.3.SQL 指定时间属性的两种方式</h3><p>如果要满足 Flink SQL 时间窗口类的聚合操作，SQL 或 Table API 中的 <code>数据源表</code> 就需要提供时间属性（相当于我们把这个时间属性在 <code>数据源表</code> 上面进行声明），以及支持时间相关的操作。</p>
<p>那么来看看 Flink SQL 为我们提供的两种指定时间戳的方式：</p>
<ol>
<li>⭐ <code>CREATE TABLE DDL</code> 创建表的时候指定</li>
<li>⭐ <code>可以在 DataStream 中指定</code>，在后续的 DataStream 转的 Table 中使用</li>
</ol>
<p>一旦时间属性定义好，它就可以像普通列一样使用，也可以在时间相关的操作中使用。</p>
<h3 id="2-5-4-SQL-事件时间案例"><a href="#2-5-4-SQL-事件时间案例" class="headerlink" title="2.5.4.SQL 事件时间案例"></a>2.5.4.SQL 事件时间案例</h3><p>来看看 Flink 中如何指定事件时间。</p>
<ol>
<li>⭐ <code>CREATE TABLE DDL</code> 指定时间戳的方式。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_actions (</span><br><span class="line">  user_name STRING,</span><br><span class="line">  data STRING,</span><br><span class="line">  user_action_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">  <span class="comment">-- 使用下面这句来将 user_action_time 声明为事件时间，并且声明 watermark 的生成规则，即 user_action_time 减 5 秒</span></span><br><span class="line">  <span class="comment">-- 事件时间列的字段类型必须是 TIMESTAMP 或者 TIMESTAMP_LTZ 类型</span></span><br><span class="line">  WATERMARK <span class="keyword">FOR</span> user_action_time <span class="keyword">AS</span> user_action_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> TUMBLE_START(user_action_time, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>), <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_name)</span><br><span class="line"><span class="keyword">FROM</span> user_actions</span><br><span class="line"><span class="comment">-- 然后就可以在窗口算子中使用 user_action_time</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(user_action_time, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>);</span><br></pre></td></tr></table></figure>

<p>从上面这条语句可以看到，如果想使用事件时间，那么我们的时间戳类型必须是 TIMESTAMP 或者 TIMESTAMP_LTZ 类型。很多小伙伴会想到，我们的时间戳一般不都是秒或者是毫秒（BIGINT 类型）嘛，那这种情况怎么办？</p>
<p>解决方案必须要有啊。如下。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_actions (</span><br><span class="line">  user_name STRING,</span><br><span class="line">  data STRING,</span><br><span class="line">  <span class="comment">-- 1. 这个 ts 就是常见的毫秒级别时间戳</span></span><br><span class="line">  ts <span class="type">BIGINT</span>,</span><br><span class="line">  <span class="comment">-- 2. 将毫秒时间戳转换成 TIMESTAMP_LTZ 类型</span></span><br><span class="line">  time_ltz <span class="keyword">AS</span> TO_TIMESTAMP_LTZ(ts, <span class="number">3</span>),</span><br><span class="line">  <span class="comment">-- 3. 使用下面这句来将 user_action_time 声明为事件时间，并且声明 watermark 的生成规则，即 user_action_time 减 5 秒</span></span><br><span class="line">  <span class="comment">-- 事件时间列的字段类型必须是 TIMESTAMP 或者 TIMESTAMP_LTZ 类型</span></span><br><span class="line">  WATERMARK <span class="keyword">FOR</span> time_ltz <span class="keyword">AS</span> time_ltz <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> TUMBLE_START(time_ltz, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>), <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_name)</span><br><span class="line"><span class="keyword">FROM</span> user_actions</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(time_ltz, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ <code>DataStream</code> 中指定事件时间。</li>
</ol>
<p>之前介绍了 <code>Table</code> 和 <code>DataStream</code> 可以互转，那么 Flink 也提供了一个能力，就是在 Table 转为 DataStream 时，指定时间戳字段。如下案例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataStreamSourceEventTimeTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        StreamExecutionEnvironment env =</span><br><span class="line">                StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line">        EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">                .newInstance()</span><br><span class="line">                .useBlinkPlanner()</span><br><span class="line">                .inStreamingMode()</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 分配 watermark</span></span><br><span class="line">        DataStream&lt;Row&gt; r = env.addSource(<span class="keyword">new</span> UserDefinedSource())</span><br><span class="line">                .assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Row&gt;(Time.minutes(<span class="number">0L</span>)) &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Row element)</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">return</span> (<span class="keyword">long</span>) element.getField(<span class="string">&quot;f2&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">        <span class="comment">// 2. 使用 f2.rowtime 的方式将 f2 字段指为事件时间时间戳</span></span><br><span class="line">        Table sourceTable = tEnv.fromDataStream(r, <span class="string">&quot;f0, f1, f2.rowtime&quot;</span>);</span><br><span class="line"></span><br><span class="line">        tEnv.createTemporaryView(<span class="string">&quot;source_table&quot;</span>, sourceTable);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 在 tumble window 中使用 f2</span></span><br><span class="line">        String tumbleWindowSql =</span><br><span class="line">                <span class="string">&quot;SELECT TUMBLE_START(f2, INTERVAL &#x27;5&#x27; SECOND), COUNT(DISTINCT f0)\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;FROM source_table\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;GROUP BY TUMBLE(f2, INTERVAL &#x27;5&#x27; SECOND)&quot;</span></span><br><span class="line">                ;</span><br><span class="line"></span><br><span class="line">        Table resultTable = tEnv.sqlQuery(tumbleWindowSql);</span><br><span class="line"></span><br><span class="line">        tEnv.toDataStream(resultTable, Row.class).print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDefinedSource</span> <span class="keyword">implements</span> <span class="title">SourceFunction</span>&lt;<span class="title">Row</span>&gt;, <span class="title">ResultTypeQueryable</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> isCancel;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Row&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (!<span class="keyword">this</span>.isCancel) &#123;</span><br><span class="line"></span><br><span class="line">                sourceContext.collect(Row.of(<span class="string">&quot;a&quot;</span> + i, <span class="string">&quot;b&quot;</span>, System.currentTimeMillis()));</span><br><span class="line"></span><br><span class="line">                Thread.sleep(<span class="number">10L</span>);</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.isCancel = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> TypeInformation&lt;Row&gt; <span class="title">getProducedType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RowTypeInfo(TypeInformation.of(String.class), TypeInformation.of(String.class),</span><br><span class="line">                    TypeInformation.of(Long.class));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-5-5-SQL-处理时间案例"><a href="#2-5-5-SQL-处理时间案例" class="headerlink" title="2.5.5.SQL 处理时间案例"></a>2.5.5.SQL 处理时间案例</h3><p>来看看 Flink SQL 中如何指定处理时间。</p>
<ol>
<li>⭐ <code>CREATE TABLE DDL</code> 指定时间戳的方式。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_actions (</span><br><span class="line">  user_name STRING,</span><br><span class="line">  data STRING,</span><br><span class="line">  <span class="comment">-- 使用下面这句来将 user_action_time 声明为处理时间</span></span><br><span class="line">  user_action_time <span class="keyword">AS</span> PROCTIME()</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> TUMBLE_START(user_action_time, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>), <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_name)</span><br><span class="line"><span class="keyword">FROM</span> user_actions</span><br><span class="line"><span class="comment">-- 然后就可以在窗口算子中使用 user_action_time</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(user_action_time, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">MINUTE</span>);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ <code>DataStream</code> 中指定处理时间。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataStreamSourceProcessingTimeTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        StreamExecutionEnvironment env =</span><br><span class="line">                StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line">        EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">                .newInstance()</span><br><span class="line">                .useBlinkPlanner()</span><br><span class="line">                .inStreamingMode()</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 分配 watermark</span></span><br><span class="line">        DataStream&lt;Row&gt; r = env.addSource(<span class="keyword">new</span> UserDefinedSource());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 使用 proctime.proctime 的方式将 f2 字段指为处理时间时间戳</span></span><br><span class="line">        Table sourceTable = tEnv.fromDataStream(r, <span class="string">&quot;f0, f1, f2, proctime.proctime&quot;</span>);</span><br><span class="line"></span><br><span class="line">        tEnv.createTemporaryView(<span class="string">&quot;source_table&quot;</span>, sourceTable);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 在 tumble window 中使用 f2</span></span><br><span class="line">        String tumbleWindowSql =</span><br><span class="line">                <span class="string">&quot;SELECT TUMBLE_START(proctime, INTERVAL &#x27;5&#x27; SECOND), COUNT(DISTINCT f0)\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;FROM source_table\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;GROUP BY TUMBLE(proctime, INTERVAL &#x27;5&#x27; SECOND)&quot;</span></span><br><span class="line">                ;</span><br><span class="line"></span><br><span class="line">        Table resultTable = tEnv.sqlQuery(tumbleWindowSql);</span><br><span class="line"></span><br><span class="line">        tEnv.toDataStream(resultTable, Row.class).print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDefinedSource</span> <span class="keyword">implements</span> <span class="title">SourceFunction</span>&lt;<span class="title">Row</span>&gt;, <span class="title">ResultTypeQueryable</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> isCancel;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Row&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (!<span class="keyword">this</span>.isCancel) &#123;</span><br><span class="line"></span><br><span class="line">                sourceContext.collect(Row.of(<span class="string">&quot;a&quot;</span> + i, <span class="string">&quot;b&quot;</span>, System.currentTimeMillis()));</span><br><span class="line"></span><br><span class="line">                Thread.sleep(<span class="number">10L</span>);</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.isCancel = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> TypeInformation&lt;Row&gt; <span class="title">getProducedType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RowTypeInfo(TypeInformation.of(String.class), TypeInformation.of(String.class),</span><br><span class="line">                    TypeInformation.of(Long.class));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-6-SQL-时区问题"><a href="#2-6-SQL-时区问题" class="headerlink" title="2.6.SQL 时区问题"></a>2.6.SQL 时区问题</h2><h3 id="2-6-1-SQL-时区解决的问题"><a href="#2-6-1-SQL-时区解决的问题" class="headerlink" title="2.6.1.SQL 时区解决的问题"></a>2.6.1.SQL 时区解决的问题</h3><p>首先说一下这个问题的背景：</p>
<p>大家想一下离线 Hive 环境中，有遇到过时区时区相关的问题吗？</p>
<p>至少博主目前没有碰到过，因为这个问题在底层的数据集成系统都已经给解决了，小伙伴萌拿到手的 ODS 层表都是已经按照所在地区的时区给格式化好的了。</p>
<p>举个例子：小伙伴萌看到日期分区为 2022-01-01 的 Hive 表时，可以默认认为该分区中的数据就对应到你所在地区的时区的 2022-01-01 日的数据。</p>
<p>但是 Flink 中时区问题要特别引起关注，不加小心就会误用。</p>
<p>而本节 SQL 时区旨在帮助大家了解到以下两个场景的问题：</p>
<ol>
<li>⭐ 在 1.13 之前，DDL create table 中使用 <code>PROCTIME()</code> 指定处理时间列时，返回值类型为 TIMESTAMP(3) 类型，而 TIMESTAMP(3) 是不带任何时区信息的，默认为 UTC 时间（0 时区）。</li>
<li>⭐ 使用 <code>StreamTableEnvironment::createTemporaryView</code> 将 DataStream 转为 Table 时，注册处理时间（<code>proctime.proctime</code>）、事件时间列（<code>rowtime.rowtime</code>）时，两列时间类型也为 TIMESTAMP(3) 类型，不带时区信息。</li>
</ol>
<p>而以上两个场景就会导致：</p>
<ol>
<li>⭐ 在北京时区的用户使用 TIMESTAMP(3) 类型的时间列开最常用的 1 天的窗口时，划分出来的窗口范围是北京时间的 [2022-01-01 08:00:00, 2022-01-02 08:00:00]，而不是北京时间的 [2022-01-01 00:00:00, 2022-01-02 00:00:00]。因为 TIMESTAMP(3) 是默认的 UTC 时间，即 0 时区。</li>
<li>⭐ 北京时区的用户将 TIMESTAMP(3) 类型时间属性列转为 STRING 类型的数据展示时，也是 UTC 时区的，而不是北京时间的。</li>
</ol>
<p>因此充分了解本节的知识内容可以很好的帮你避免时区问题错误。</p>
<h3 id="2-6-1-SQL-时间类型"><a href="#2-6-1-SQL-时间类型" class="headerlink" title="2.6.1.SQL 时间类型"></a>2.6.1.SQL 时间类型</h3><ol>
<li>⭐ Flink SQL 支持 TIMESTAMP（不带时区信息的时间）、TIMESTAMP_LTZ（带时区信息的时间）</li>
<li>⭐ TIMESTAMP（不带时区信息的时间）：是通过一个 <code>年， 月， 日， 小时， 分钟， 秒 和 小数秒</code> 的字符串来指定。举例：1970-01-01 00:00:04.001。</li>
</ol>
<ul>
<li>⭐ 为什么要使用字符串来指定呢？因为此种类型不带时区信息，所以直接用一个字符串指定就好了</li>
<li>⭐ 那 TIMESTAMP 字符串的时间代表的是什么时区的时间呢？UTC 时区，也就是默认 0 时区，对应中国北京是东八区</li>
</ul>
<ol start="3">
<li>⭐ TIMESTAMP_LTZ（带时区信息的时间）：没有字符串来指定，而是通过 java 标准 epoch 时间 1970-01-01T00:00:00Z 开始计算的毫秒数。举例：1640966400000</li>
</ol>
<ul>
<li>⭐ 其时区信息是怎么指定的呢？是通过本次任务中的时区配置参数 <code>table.local-time-zone</code> 设置的</li>
<li>⭐ 时间戳本身也不带有时区信息，为什么要使用时间戳来指定呢？就是因为时间戳不带有时区信息，所以我们通过配置 <code>table.local-time-zone</code> 时区参数之后，就能将一个不带有时区信息的时间戳转换为带有时区信息的字符串了。举例：<code>table.local-time-zone</code> 为 <code>Asia/Shanghai</code> 时，4001 时间戳转化为字符串的效果是 <code>1970-01-01 08:00:04.001</code>。</li>
</ul>
<p>如果你还对时区问题有疑惑，可以参考博主写的一篇时区相关的文章。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/PSwHs18ZhKsBUaTsppkp9Q">https://mp.weixin.qq.com/s/PSwHs18ZhKsBUaTsppkp9Q</a></p>
<h3 id="2-6-2-时区参数生效的-SQL-时间函数"><a href="#2-6-2-时区参数生效的-SQL-时间函数" class="headerlink" title="2.6.2.时区参数生效的 SQL 时间函数"></a>2.6.2.时区参数生效的 SQL 时间函数</h3><p>以下 SQL 中的时间函数都会受到时区参数的影响，从而做到最后显示给用户的时间、窗口的划分都按照用户设置时区之内的时间。</p>
<ol>
<li>⭐ LOCALTIME</li>
<li>⭐ LOCALTIMESTAMP</li>
<li>⭐ CURRENT_DATE</li>
<li>⭐ CURRENT_TIME</li>
<li>⭐ CURRENT_TIMESTAMP</li>
<li>⭐ CURRENT_ROW_TIMESTAMP()</li>
<li>⭐ NOW()</li>
<li>⭐ PROCTIME()：其中 PROCTIME() 在 1.13 版本及之后版本，返回值类型是 TIMESTAMP_LTZ(3)</li>
</ol>
<p>在 Flink SQL client 中执行结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> <span class="keyword">sql</span><span class="operator">-</span>client.execution.result<span class="operator">-</span>mode<span class="operator">=</span>tableau;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> MyView1 <span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="built_in">LOCALTIME</span>, <span class="built_in">LOCALTIMESTAMP</span>, <span class="built_in">CURRENT_DATE</span>, <span class="built_in">CURRENT_TIME</span>, <span class="built_in">CURRENT_TIMESTAMP</span>, CURRENT_ROW_TIMESTAMP(), NOW(), PROCTIME();</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">DESC</span> MyView1;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------+-----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>                   name <span class="operator">|</span>                        type <span class="operator">|</span>  <span class="keyword">null</span> <span class="operator">|</span> key <span class="operator">|</span> extras <span class="operator">|</span> watermark <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------+-----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>              <span class="built_in">LOCALTIME</span> <span class="operator">|</span>                     <span class="type">TIME</span>(<span class="number">0</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         <span class="built_in">LOCALTIMESTAMP</span> <span class="operator">|</span>                <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           <span class="built_in">CURRENT_DATE</span> <span class="operator">|</span>                        <span class="type">DATE</span> <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           <span class="built_in">CURRENT_TIME</span> <span class="operator">|</span>                     <span class="type">TIME</span>(<span class="number">0</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>      <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">|</span>            TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>CURRENT_ROW_TIMESTAMP() <span class="operator">|</span>            TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                  NOW() <span class="operator">|</span>            TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             PROCTIME() <span class="operator">|</span> TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">*</span>PROCTIME<span class="operator">*</span> <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------+-----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>UTC;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView1;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-------------------------+--------------+--------------+-------------------------+-------------------------+-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">LOCALTIME</span> <span class="operator">|</span>          <span class="built_in">LOCALTIMESTAMP</span> <span class="operator">|</span> <span class="built_in">CURRENT_DATE</span> <span class="operator">|</span> <span class="built_in">CURRENT_TIME</span> <span class="operator">|</span>       <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">|</span> CURRENT_ROW_TIMESTAMP() <span class="operator">|</span>                   NOW() <span class="operator">|</span>              PROCTIME() <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-------------------------+--------------+--------------+-------------------------+-------------------------+-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">15</span>:<span class="number">18</span>:<span class="number">36</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">15</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span>   <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="operator">|</span>     <span class="number">15</span>:<span class="number">18</span>:<span class="number">36</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">15</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">15</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">15</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">15</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-------------------------+--------------+--------------+-------------------------+-------------------------+-------------------------+-------------------------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>Asia<span class="operator">/</span>Shanghai;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView1;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-------------------------+--------------+--------------+-------------------------+-------------------------+-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">LOCALTIME</span> <span class="operator">|</span>          <span class="built_in">LOCALTIMESTAMP</span> <span class="operator">|</span> <span class="built_in">CURRENT_DATE</span> <span class="operator">|</span> <span class="built_in">CURRENT_TIME</span> <span class="operator">|</span>       <span class="built_in">CURRENT_TIMESTAMP</span> <span class="operator">|</span> CURRENT_ROW_TIMESTAMP() <span class="operator">|</span>                   NOW() <span class="operator">|</span>              PROCTIME() <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-------------------------+--------------+--------------+-------------------------+-------------------------+-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">23</span>:<span class="number">18</span>:<span class="number">36</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">23</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span>   <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="operator">|</span>     <span class="number">23</span>:<span class="number">18</span>:<span class="number">36</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">23</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">23</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">23</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">23</span>:<span class="number">18</span>:<span class="number">36.384</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+-------------------------+--------------+--------------+-------------------------+-------------------------+-------------------------+-------------------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> MyView2 <span class="keyword">AS</span> <span class="keyword">SELECT</span> TO_TIMESTAMP_LTZ(<span class="number">4001</span>, <span class="number">3</span>) <span class="keyword">AS</span> ltz, <span class="type">TIMESTAMP</span> <span class="string">&#x27;1970-01-01 00:00:01.001&#x27;</span>  <span class="keyword">AS</span> ntz;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">DESC</span> MyView2;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------+------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span> name <span class="operator">|</span>             type <span class="operator">|</span>  <span class="keyword">null</span> <span class="operator">|</span> key <span class="operator">|</span> extras <span class="operator">|</span> watermark <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>  ltz <span class="operator">|</span> TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  ntz <span class="operator">|</span>     <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+------------------+-------+-----+--------+-----------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>UTC;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView2;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     ltz <span class="operator">|</span>                     ntz <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">04.001</span> <span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">01.001</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>Asia<span class="operator">/</span>Shanghai;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView2;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     ltz <span class="operator">|</span>                     ntz <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">04.001</span> <span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">01.001</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> MyView3 <span class="keyword">AS</span> <span class="keyword">SELECT</span> ltz, <span class="built_in">CAST</span>(ltz <span class="keyword">AS</span> <span class="type">TIMESTAMP</span>(<span class="number">3</span>)), <span class="built_in">CAST</span>(ltz <span class="keyword">AS</span> STRING), ntz, <span class="built_in">CAST</span>(ntz <span class="keyword">AS</span> TIMESTAMP_LTZ(<span class="number">3</span>)) <span class="keyword">FROM</span> MyView2;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">DESC</span> MyView3;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>                          name <span class="operator">|</span>             type <span class="operator">|</span>  <span class="keyword">null</span> <span class="operator">|</span> key <span class="operator">|</span> extras <span class="operator">|</span> watermark <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>                           ltz <span class="operator">|</span> TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     <span class="built_in">CAST</span>(ltz <span class="keyword">AS</span> <span class="type">TIMESTAMP</span>(<span class="number">3</span>)) <span class="operator">|</span>     <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           <span class="built_in">CAST</span>(ltz <span class="keyword">AS</span> STRING) <span class="operator">|</span>           STRING <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                           ntz <span class="operator">|</span>     <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">CAST</span>(ntz <span class="keyword">AS</span> TIMESTAMP_LTZ(<span class="number">3</span>)) <span class="operator">|</span> TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+------------------+-------+-----+--------+-----------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView3;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+---------------------------+-------------------------+-------------------------+-------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     ltz <span class="operator">|</span> <span class="built_in">CAST</span>(ltz <span class="keyword">AS</span> <span class="type">TIMESTAMP</span>(<span class="number">3</span>)) <span class="operator">|</span>     <span class="built_in">CAST</span>(ltz <span class="keyword">AS</span> STRING) <span class="operator">|</span>                     ntz <span class="operator">|</span> <span class="built_in">CAST</span>(ntz <span class="keyword">AS</span> TIMESTAMP_LTZ(<span class="number">3</span>)) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+---------------------------+-------------------------+-------------------------+-------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">04.001</span> <span class="operator">|</span>   <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">04.001</span> <span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">04.001</span> <span class="operator">|</span> <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">01.001</span> <span class="operator">|</span>       <span class="number">1970</span><span class="number">-01</span><span class="number">-01</span> <span class="number">00</span>:<span class="number">00</span>:<span class="number">01.001</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+---------------------------+-------------------------+-------------------------+-------------------------------+</span></span><br></pre></td></tr></table></figure>

<h3 id="2-6-3-事件时间和时区应用案例"><a href="#2-6-3-事件时间和时区应用案例" class="headerlink" title="2.6.3.事件时间和时区应用案例"></a>2.6.3.事件时间和时区应用案例</h3><p>这里分两类，分别是 TIMESTAMP（不带时区信息的时间）、TIMESTAMP_LTZ（带时区信息的时间） 的事件时间 Flink SQL 任务</p>
<ol>
<li>⭐ TIMESTAMP（不带时区信息的时间）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable2 (</span><br><span class="line">                  item STRING,</span><br><span class="line">                  price <span class="keyword">DOUBLE</span>,</span><br><span class="line">                  ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>), <span class="comment">-- TIMESTAMP 类型的时间戳</span></span><br><span class="line">                  WATERMARK <span class="keyword">FOR</span> ts <span class="keyword">AS</span> ts <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">            ) <span class="keyword">WITH</span> (</span><br><span class="line">                <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;socket&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;hostname&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;port&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;9999&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">           );</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> MyView4 <span class="keyword">AS</span></span><br><span class="line">            <span class="keyword">SELECT</span></span><br><span class="line">                TUMBLE_START(ts, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">AS</span> window_start,</span><br><span class="line">                TUMBLE_END(ts, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">AS</span> window_end,</span><br><span class="line">                TUMBLE_ROWTIME(ts, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">as</span> window_rowtime,</span><br><span class="line">                item,</span><br><span class="line">                <span class="built_in">MAX</span>(price) <span class="keyword">as</span> max_price</span><br><span class="line">            <span class="keyword">FROM</span> MyTable2</span><br><span class="line">                <span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(ts, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES), item;</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">DESC</span> MyView4;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+------------------------+------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>           name <span class="operator">|</span>                   type <span class="operator">|</span> <span class="keyword">null</span> <span class="operator">|</span> key <span class="operator">|</span> extras <span class="operator">|</span> watermark <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+------------------------+------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>   window_start <span class="operator">|</span>           <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     window_end <span class="operator">|</span>           <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> window_rowtime <span class="operator">|</span> <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">*</span>ROWTIME<span class="operator">*</span> <span class="operator">|</span> <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           item <span class="operator">|</span>                 STRING <span class="operator">|</span> <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>      max_price <span class="operator">|</span>                 <span class="keyword">DOUBLE</span> <span class="operator">|</span> <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+------------------------+------+-----+--------+-----------+</span></span><br></pre></td></tr></table></figure>

<p>将数据写入到 MyTable2 中：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> nc -lk 9999</span></span><br><span class="line">A,1.1,2021-04-15 14:01:00</span><br><span class="line">B,1.2,2021-04-15 14:02:00</span><br><span class="line">A,1.8,2021-04-15 14:03:00 </span><br><span class="line">B,2.5,2021-04-15 14:04:00</span><br><span class="line">C,3.8,2021-04-15 14:05:00       </span><br><span class="line">C,3.8,2021-04-15 14:11:00</span><br></pre></td></tr></table></figure>

<p>最终结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>UTC; </span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView4;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span>            window_start <span class="operator">|</span>              window_end <span class="operator">|</span>          window_rowtime <span class="operator">|</span> item <span class="operator">|</span> max_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    A <span class="operator">|</span>       <span class="number">1.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    B <span class="operator">|</span>       <span class="number">2.5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    C <span class="operator">|</span>       <span class="number">3.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>Asia<span class="operator">/</span>Shanghai; </span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView4;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span>            window_start <span class="operator">|</span>              window_end <span class="operator">|</span>          window_rowtime <span class="operator">|</span> item <span class="operator">|</span> max_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    A <span class="operator">|</span>       <span class="number">1.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    B <span class="operator">|</span>       <span class="number">2.5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    C <span class="operator">|</span>       <span class="number">3.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br></pre></td></tr></table></figure>

<p>通过上述结果可见，使用 TIMESTAMP（不带时区信息的时间） 进开窗，在 UTC 时区下的计算结果与在 Asia/Shanghai 时区下计算的窗口开始时间，窗口结束时间和窗口的时间是相同的。</p>
<ol start="2">
<li>⭐ TIMESTAMP_LTZ（带时区信息的时间）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable3 (</span><br><span class="line">                  item STRING,</span><br><span class="line">                  price <span class="keyword">DOUBLE</span>,</span><br><span class="line">                  ts <span class="type">BIGINT</span>, <span class="comment">-- long 类型的时间戳</span></span><br><span class="line">                  ts_ltz <span class="keyword">AS</span> TO_TIMESTAMP_LTZ(ts, <span class="number">3</span>), <span class="comment">-- 转为 TIMESTAMP_LTZ 类型的时间戳</span></span><br><span class="line">                  WATERMARK <span class="keyword">FOR</span> ts_ltz <span class="keyword">AS</span> ts_ltz <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">            ) <span class="keyword">WITH</span> (</span><br><span class="line">                <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;socket&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;hostname&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;port&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;9999&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">           );</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> MyView5 <span class="keyword">AS</span> </span><br><span class="line">            <span class="keyword">SELECT</span> </span><br><span class="line">                TUMBLE_START(ts_ltz, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">AS</span> window_start,        </span><br><span class="line">                TUMBLE_END(ts_ltz, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">AS</span> window_end,</span><br><span class="line">                TUMBLE_ROWTIME(ts_ltz, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">as</span> window_rowtime,</span><br><span class="line">                item,</span><br><span class="line">                <span class="built_in">MAX</span>(price) <span class="keyword">as</span> max_price</span><br><span class="line">            <span class="keyword">FROM</span> MyTable3</span><br><span class="line">                <span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(ts_ltz, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES), item;</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">DESC</span> MyView5;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>           name <span class="operator">|</span>                       type <span class="operator">|</span>  <span class="keyword">null</span> <span class="operator">|</span> key <span class="operator">|</span> extras <span class="operator">|</span> watermark <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>   window_start <span class="operator">|</span>               <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     window_end <span class="operator">|</span>               <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> window_rowtime <span class="operator">|</span> TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">*</span>ROWTIME<span class="operator">*</span> <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           item <span class="operator">|</span>                     STRING <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>      max_price <span class="operator">|</span>                     <span class="keyword">DOUBLE</span> <span class="operator">|</span>  <span class="literal">true</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+----------------------------+-------+-----+--------+-----------+</span></span><br></pre></td></tr></table></figure>

<p>将数据写入 MyTable3：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">A,1.1,1618495260000  # 对应到 UTC 时区的时间为 2021-04-15 14:01:00</span><br><span class="line">B,1.2,1618495320000  # 对应到 UTC 时区的时间为 2021-04-15 14:02:00</span><br><span class="line">A,1.8,1618495380000  # 对应到 UTC 时区的时间为 2021-04-15 14:03:00</span><br><span class="line">B,2.5,1618495440000  # 对应到 UTC 时区的时间为 2021-04-15 14:04:00</span><br><span class="line">C,3.8,1618495500000  # 对应到 UTC 时区的时间为 2021-04-15 14:05:00       </span><br><span class="line">C,3.8,1618495860000  # 对应到 UTC 时区的时间为 2021-04-15 14:11:00</span><br></pre></td></tr></table></figure>

<p>最终结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>UTC; </span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView5;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span>            window_start <span class="operator">|</span>              window_end <span class="operator">|</span>          window_rowtime <span class="operator">|</span> item <span class="operator">|</span> max_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    A <span class="operator">|</span>       <span class="number">1.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    B <span class="operator">|</span>       <span class="number">2.5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    C <span class="operator">|</span>       <span class="number">3.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>Asia<span class="operator">/</span>Shanghai; </span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView5;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span>            window_start <span class="operator">|</span>              window_end <span class="operator">|</span>          window_rowtime <span class="operator">|</span> item <span class="operator">|</span> max_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    A <span class="operator">|</span>       <span class="number">1.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    B <span class="operator">|</span>       <span class="number">2.5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">09</span>:<span class="number">59.999</span> <span class="operator">|</span>    C <span class="operator">|</span>       <span class="number">3.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br></pre></td></tr></table></figure>

<p>通过上述结果可见，使用 TIMESTAMP_LTZ（带时区信息的时间） 进开窗，在 UTC 时区下的计算结果与在 Asia/Shanghai 时区下计算的窗口开始时间，窗口结束时间和窗口的时间是不同的，都是按照时区进行格式化的。</p>
<h3 id="2-6-4-处理时间和时区应用案例"><a href="#2-6-4-处理时间和时区应用案例" class="headerlink" title="2.6.4.处理时间和时区应用案例"></a>2.6.4.处理时间和时区应用案例</h3><p>Flink SQL 定义处理时间属性列是通过 <code>PROCTIME()</code> 函数来指定的，其返回值类型是 TIMESTAMP_LTZ。</p>
<blockquote>
<p>注意：</p>
<p>在 Flink 1.13 之前，<code>PROCTIME()</code> 函数返回类型是 TIMESTAMP，返回值是 UTC 时区的时间戳，例如，上海时间显示为 2021-03-01 12:00:00 时，PROCTIME() 返回值显示 2021-03-01 04:00:00，我们进行使用是错误的。Flink 1.13 修复了这个问题，使用 TIMESTAMP_LTZ 作为 PROCTIME() 的返回类型，这样 Flink 就会自动获取当前时区信息，然后进行处理，不需要用户再进行时区的格式化处理了。</p>
</blockquote>
<p>如下案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>UTC;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> PROCTIME();</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span>              PROCTIME() <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">48</span>:<span class="number">31.387</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>Asia<span class="operator">/</span>Shanghai;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> PROCTIME();</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span>              PROCTIME() <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">48</span>:<span class="number">31.387</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable1 (</span><br><span class="line">                  item STRING,</span><br><span class="line">                  price <span class="keyword">DOUBLE</span>,</span><br><span class="line">                  proctime <span class="keyword">as</span> PROCTIME()</span><br><span class="line">            ) <span class="keyword">WITH</span> (</span><br><span class="line">                <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;socket&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;hostname&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;port&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;9999&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">           );</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> MyView3 <span class="keyword">AS</span></span><br><span class="line">            <span class="keyword">SELECT</span></span><br><span class="line">                TUMBLE_START(proctime, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">AS</span> window_start,</span><br><span class="line">                TUMBLE_END(proctime, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">AS</span> window_end,</span><br><span class="line">                TUMBLE_PROCTIME(proctime, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES) <span class="keyword">as</span> window_proctime,</span><br><span class="line">                item,</span><br><span class="line">                <span class="built_in">MAX</span>(price) <span class="keyword">as</span> max_price</span><br><span class="line">            <span class="keyword">FROM</span> MyTable1</span><br><span class="line">                <span class="keyword">GROUP</span> <span class="keyword">BY</span> TUMBLE(proctime, <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> MINUTES), item;</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">DESC</span> MyView3;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+-----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>           name  <span class="operator">|</span>                        type <span class="operator">|</span>  <span class="keyword">null</span> <span class="operator">|</span> key <span class="operator">|</span> extras <span class="operator">|</span> watermark <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+-----------------------------+-------+-----+--------+-----------+</span></span><br><span class="line"><span class="operator">|</span>    window_start <span class="operator">|</span>                <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>      window_end <span class="operator">|</span>                <span class="type">TIMESTAMP</span>(<span class="number">3</span>) <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> window_proctime <span class="operator">|</span> TIMESTAMP_LTZ(<span class="number">3</span>) <span class="operator">*</span>PROCTIME<span class="operator">*</span> <span class="operator">|</span> <span class="literal">false</span> <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            item <span class="operator">|</span>                      STRING <span class="operator">|</span> <span class="literal">true</span>  <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       max_price <span class="operator">|</span>                      <span class="keyword">DOUBLE</span> <span class="operator">|</span> <span class="literal">true</span>  <span class="operator">|</span>     <span class="operator">|</span>        <span class="operator">|</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+-----------------------------+-------+-----+--------+-----------+</span></span><br></pre></td></tr></table></figure>

<p>将数据写入到 MyTable1 中：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> nc -lk 9999</span></span><br><span class="line">A,1.1</span><br><span class="line">B,1.2</span><br><span class="line">A,1.8</span><br><span class="line">B,2.5</span><br><span class="line">C,3.8</span><br></pre></td></tr></table></figure>

<p>其输出结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>UTC;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView3;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span>            window_start <span class="operator">|</span>              window_end <span class="operator">|</span>          window_procime <span class="operator">|</span> item <span class="operator">|</span> max_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.005</span> <span class="operator">|</span>    A <span class="operator">|</span>       <span class="number">1.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.007</span> <span class="operator">|</span>    B <span class="operator">|</span>       <span class="number">2.5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">00.007</span> <span class="operator">|</span>    C <span class="operator">|</span>       <span class="number">3.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.local<span class="operator">-</span><span class="type">time</span><span class="operator">-</span>zone<span class="operator">=</span>Asia<span class="operator">/</span>Shanghai;</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> MyView3;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span>            window_start <span class="operator">|</span>              window_end <span class="operator">|</span>          window_procime <span class="operator">|</span> item <span class="operator">|</span> max_price <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.005</span> <span class="operator">|</span>    A <span class="operator">|</span>       <span class="number">1.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.007</span> <span class="operator">|</span>    B <span class="operator">|</span>       <span class="number">2.5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">00</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.000</span> <span class="operator">|</span> <span class="number">2021</span><span class="number">-04</span><span class="number">-15</span> <span class="number">22</span>:<span class="number">10</span>:<span class="number">00.007</span> <span class="operator">|</span>    C <span class="operator">|</span>       <span class="number">3.8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+-------------------------+-------------------------+------+-----------+</span></span><br></pre></td></tr></table></figure>

<p>通过上述结果可见，使用处理时间进行开窗，在 UTC 时区下的计算结果与在 Asia/Shanghai 时区下计算的窗口开始时间，窗口结束时间和窗口的时间是不同的，都是按照时区进行格式化的。</p>
<h3 id="2-6-5-SQL-时间函数返回在流批任务中的异同"><a href="#2-6-5-SQL-时间函数返回在流批任务中的异同" class="headerlink" title="2.6.5.SQL 时间函数返回在流批任务中的异同"></a>2.6.5.SQL 时间函数返回在流批任务中的异同</h3><p>以下函数：</p>
<ol>
<li>⭐ LOCALTIME</li>
<li>⭐ LOCALTIMESTAMP</li>
<li>⭐ CURRENT_DATE</li>
<li>⭐ CURRENT_TIME</li>
<li>⭐ CURRENT_TIMESTAMP</li>
<li>⭐ NOW()</li>
</ol>
<p>在 Streaming 模式下这些函数是每条记录都会计算一次，但在 Batch 模式下，只会在 query 开始时计算一次，所有记录都使用相同的时间结果。</p>
<p>以下时间函数无论是在 Streaming 模式还是 Batch 模式下，都会为每条记录计算一次结果：</p>
<ol>
<li>⭐ CURRENT_ROW_TIMESTAMP()</li>
<li>⭐ PROCTIME()</li>
</ol>
<h1 id="3-SQL-语法篇"><a href="#3-SQL-语法篇" class="headerlink" title="3.SQL 语法篇"></a>3.SQL 语法篇</h1><h2 id="3-1-DDL：Create-子句"><a href="#3-1-DDL：Create-子句" class="headerlink" title="3.1.DDL：Create 子句"></a>3.1.DDL：Create 子句</h2><p>CREATE 语句用于向当前或指定的 Catalog 中注册库、表、视图或函数。注册后的库、表、视图和函数可以在 SQL 查询中使用。</p>
<p>目前 Flink SQL 支持下列 CREATE 语句：</p>
<ol>
<li>⭐ CREATE TABLE</li>
<li>⭐ CREATE DATABASE</li>
<li>⭐ CREATE VIEW</li>
<li>⭐ CREATE FUNCTION</li>
</ol>
<p>此节重点介绍建表，建数据库、视图和 UDF 会在后面的扩展章节进行介绍。</p>
<h3 id="3-1-1-建表语句"><a href="#3-1-1-建表语句" class="headerlink" title="3.1.1.建表语句"></a>3.1.1.建表语句</h3><p>下面的 SQL 语句就是建表语句的定义，根据指定的表名创建一个表，如果同名表已经在 catalog 中存在了，则无法注册。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [catalog_name.][db_name.]table_name</span><br><span class="line">  (</span><br><span class="line">    &#123; &lt;physical_column_definition&gt; | &lt;metadata_column_definition&gt; | &lt;computed_column_definition&gt; &#125;[ , ...n]</span><br><span class="line">    [ <span class="operator">&lt;</span>watermark_definition<span class="operator">&gt;</span> ]</span><br><span class="line">    [ <span class="operator">&lt;</span>table_constraint<span class="operator">&gt;</span> ][ , ...n]</span><br><span class="line">  )</span><br><span class="line">  [COMMENT table_comment]</span><br><span class="line">  [PARTITIONED <span class="keyword">BY</span> (partition_column_name1, partition_column_name2, ...)]</span><br><span class="line">  <span class="keyword">WITH</span> (key1<span class="operator">=</span>val1, key2<span class="operator">=</span>val2, ...)</span><br><span class="line">  [ <span class="keyword">LIKE</span> source_table [( <span class="operator">&lt;</span>like_options<span class="operator">&gt;</span> )] ]</span><br><span class="line">   </span><br><span class="line"><span class="operator">&lt;</span>physical_column_definition<span class="operator">&gt;</span>:</span><br><span class="line">  column_name column_type [ <span class="operator">&lt;</span>column_constraint<span class="operator">&gt;</span> ] [COMMENT column_comment]</span><br><span class="line">  </span><br><span class="line"><span class="operator">&lt;</span>column_constraint<span class="operator">&gt;</span>:</span><br><span class="line">  [<span class="keyword">CONSTRAINT</span> constraint_name] <span class="keyword">PRIMARY</span> KEY <span class="keyword">NOT</span> ENFORCED</span><br><span class="line"></span><br><span class="line"><span class="operator">&lt;</span>table_constraint<span class="operator">&gt;</span>:</span><br><span class="line">  [<span class="keyword">CONSTRAINT</span> constraint_name] <span class="keyword">PRIMARY</span> KEY (column_name, ...) <span class="keyword">NOT</span> ENFORCED</span><br><span class="line"></span><br><span class="line"><span class="operator">&lt;</span>metadata_column_definition<span class="operator">&gt;</span>:</span><br><span class="line">  column_name column_type METADATA [ <span class="keyword">FROM</span> metadata_key ] [ VIRTUAL ]</span><br><span class="line"></span><br><span class="line"><span class="operator">&lt;</span>computed_column_definition<span class="operator">&gt;</span>:</span><br><span class="line">  column_name <span class="keyword">AS</span> computed_column_expression [COMMENT column_comment]</span><br><span class="line"></span><br><span class="line"><span class="operator">&lt;</span>watermark_definition<span class="operator">&gt;</span>:</span><br><span class="line">  WATERMARK <span class="keyword">FOR</span> rowtime_column_name <span class="keyword">AS</span> watermark_strategy_expression</span><br><span class="line"></span><br><span class="line"><span class="operator">&lt;</span>source_table<span class="operator">&gt;</span>:</span><br><span class="line">  [catalog_name.][db_name.]table_name</span><br><span class="line"></span><br><span class="line"><span class="operator">&lt;</span>like_options<span class="operator">&gt;</span>:</span><br><span class="line">&#123;</span><br><span class="line">   &#123; INCLUDING | EXCLUDING &#125; &#123; ALL | CONSTRAINTS | PARTITIONS &#125;</span><br><span class="line"> | &#123; INCLUDING | EXCLUDING | OVERWRITING &#125; &#123; GENERATED | OPTIONS | WATERMARKS &#125; </span><br><span class="line">&#125;[, ...]</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-表中的列"><a href="#3-1-2-表中的列" class="headerlink" title="3.1.2.表中的列"></a>3.1.2.表中的列</h3><ol>
<li>⭐ 常规列（即物理列）</li>
</ol>
<p>物理列是数据库中所说的常规列。其定义了物理介质中存储的数据中字段的名称、类型和顺序。</p>
<p>其他类型的列可以在物理列之间声明，但不会影响最终的物理列的读取。</p>
<p>举一个仅包含常规列的表的案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `name` STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 元数据列</li>
</ol>
<p>元数据列是 SQL 标准的扩展，允许访问数据源本身具有的一些元数据。元数据列由 <code>METADATA</code> 关键字标识。</p>
<p>例如，我们可以使用元数据列从 Kafka 数据中读取 Kafka 数据自带的时间戳（这个时间戳不是数据中的某个时间戳字段，而是数据写入 Kafka 时，Kafka 引擎给这条数据打上的时间戳标记），然后我们可以在 Flink SQL 中使用这个时间戳，比如进行基于时间的窗口操作。</p>
<p>举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `name` STRING,</span><br><span class="line">  <span class="comment">-- 读取 kafka 本身自带的时间戳</span></span><br><span class="line">  `record_time` TIMESTAMP_LTZ(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> <span class="string">&#x27;timestamp&#x27;</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span></span><br><span class="line">  ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>元数据列可以用于后续数据的处理，或者写入到目标表中。</p>
<p>举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> MyTable </span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    user_id</span><br><span class="line">    , name</span><br><span class="line">    , record_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">SECOND</span> </span><br><span class="line"><span class="keyword">FROM</span> MyTable;</span><br></pre></td></tr></table></figure>

<p>如果自定义的列名称和 Connector 中定义 metadata 字段的名称一样的话，<code>FROM xxx</code> 子句是可以被省略的。</p>
<p>举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `name` STRING,</span><br><span class="line">  <span class="comment">-- 读取 kafka 本身自带的时间戳</span></span><br><span class="line">  `<span class="type">timestamp</span>` TIMESTAMP_LTZ(<span class="number">3</span>) METADATA</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span></span><br><span class="line">  ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>关于 Flink SQL 的每种 Connector 都提供了哪些 metadata 字段，详细可见官网文档 <a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/overview/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/overview/</a></p>
<p>如果自定义列的数据类型和 Connector 中定义的 metadata 字段的数据类型不一致的话，程序运行时会自动 cast 强转。但是这要求两种数据类型是可以强转的。举例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `name` STRING,</span><br><span class="line">  <span class="comment">-- 将时间戳强转为 BIGINT</span></span><br><span class="line">  `<span class="type">timestamp</span>` <span class="type">BIGINT</span> METADATA</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span></span><br><span class="line">  ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>默认情况下，Flink SQL planner 认为 metadata 列是可以 <code>读取</code> 也可以 <code>写入</code> 的。但是有些外部存储系统的元数据信息是只能用于读取，不能写入的。</p>
<p>那么在往一个表写入的场景下，我们就可以使用 <code>VIRTUAL</code> 关键字来标识某个元数据列不写入到外部存储中（不持久化）。</p>
<p>以 Kafka 举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable (</span><br><span class="line">  <span class="comment">-- sink 时会写入</span></span><br><span class="line">  `<span class="type">timestamp</span>` <span class="type">BIGINT</span> METADATA,</span><br><span class="line">  <span class="comment">-- sink 时不写入</span></span><br><span class="line">  `<span class="keyword">offset</span>` <span class="type">BIGINT</span> METADATA VIRTUAL,</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `name` STRING,</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span></span><br><span class="line">  ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>在上面这个案例中，Kafka 引擎的 <code>offset</code> 是只读的。所以我们在把 <code>MyTable</code> 作为数据源（输入）表时，schema 中是包含 <code>offset</code> 的。在把 <code>MyTable</code> 作为数据汇（输出）表时，schema 中是不包含 <code>offset</code> 的。如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 当做数据源（输入）的 schema</span><br><span class="line">MyTable(&#96;timestamp&#96; BIGINT, &#96;offset&#96; BIGINT, &#96;user_id&#96; BIGINT, &#96;name&#96; STRING)</span><br><span class="line"></span><br><span class="line">-- 当做数据汇（输出）的 schema</span><br><span class="line">MyTable(&#96;timestamp&#96; BIGINT, &#96;user_id&#96; BIGINT, &#96;name&#96; STRING)</span><br></pre></td></tr></table></figure>

<p>所以这里在写入时需要注意，不要在 SQL 的 INSERT INTO 语句中写入 <code>offset</code> 列，否则 Flink SQL 任务会直接报错。</p>
<ol start="3">
<li>⭐ 计算列</li>
</ol>
<p>计算列其实就是在写建表的 DDL 时，可以拿已有的一些列经过一些自定义的运算生成的新列。这些列本身是没有以物理形式存储到数据源中的。</p>
<p>举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> MyTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `price` <span class="keyword">DOUBLE</span>,</span><br><span class="line">  `quantity` <span class="keyword">DOUBLE</span>,</span><br><span class="line">  <span class="comment">-- cost 就是使用 price 和 quanitity 生成的计算列，计算方式为 price * quanitity</span></span><br><span class="line">  `cost` <span class="keyword">AS</span> price <span class="operator">*</span> quanitity,</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span></span><br><span class="line">  ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意！！！</p>
<p>计算列可以包含其他列、常量或者函数，但是不能写一个子查询进去。</p>
</blockquote>
<p>小伙伴萌这时会问到一个问题，既然只能包含列、常量或者函数计算，我就直接在 DML query 代码中写就完事了呗，为啥还要专门在 DDL 中定义呢？</p>
<p>结论：没错，如果只是简单的四则运算的话直接写在 DML 中就可以，但是计算列一般是用于定义时间属性的（因为在 SQL 任务中时间属性只能在 DDL 中定义，不能在 DML 语句中定义）。比如要把输入数据的时间格式标准化。处理时间、事件时间分别举例如下：</p>
<ul>
<li><p>⭐ 处理时间：使用 <code>PROCTIME()</code> 函数来定义处理时间列</p>
</li>
<li><p>⭐ 事件时间：事件时间的时间戳可以在声明 Watermark 之前进行预处理。比如如果字段不是 TIMESTAMP(3) 类型或者时间戳是嵌套在 JSON 字符串中的，则可以使用计算列进行预处理。</p>
</li>
</ul>
<p>注意！！!和虚拟 metadata 列是类似的，计算列也是只能读不能写的。</p>
<p>也就是说，我们在把 <code>MyTable</code> 作为数据源（输入）表时，schema 中是包含 <code>cost</code> 的。</p>
<p>在把 <code>MyTable</code> 作为数据汇（输出）表时，schema 中是不包含 <code>cost</code> 的。举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 当做数据源（输入）的 schema</span></span><br><span class="line">MyTable(`user_id` <span class="type">BIGINT</span>, `price` <span class="keyword">DOUBLE</span>, `quantity` <span class="keyword">DOUBLE</span>, `cost` <span class="keyword">DOUBLE</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 当做数据汇（输出）的 schema</span></span><br><span class="line">MyTable(`user_id` <span class="type">BIGINT</span>, `price` <span class="keyword">DOUBLE</span>, `quantity` <span class="keyword">DOUBLE</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3-定义-Watermark"><a href="#3-1-3-定义-Watermark" class="headerlink" title="3.1.3.定义 Watermark"></a>3.1.3.定义 Watermark</h3><p>Watermark 是在 <code>Create Table</code> 中进行定义的。具体 SQL 语法标准是 <code>WATERMARK FOR rowtime_column_name AS watermark_strategy_expression</code>。</p>
<p>其中：</p>
<ol>
<li>⭐ <code>rowtime_column_name</code>：表的事件时间属性字段。该列必须是 <code>TIMESTAMP(3)</code>、<code>TIMESTAMP_LTZ(3)</code> 类，这个时间可以是一个计算列。</li>
<li>⭐ <code>watermark_strategy_expression</code>：定义 Watermark 的生成策略。Watermark 的一般都是由 <code>rowtime_column_name</code> 列减掉一段固定时间间隔。SQL 中 Watermark 的生产策略是：当前 Watermark 大于上次发出的 Watermark 时发出当前 Watermark。</li>
</ol>
<blockquote>
<p>注意：</p>
<ol>
<li>如果你使用的是事件时间语义，那么必须要设设置事件时间属性和 WATERMARK 生成策略。</li>
<li>Watermark 的发出频率：Watermark 发出一般是间隔一定时间的，Watermark 的发出间隔时间可以由 <code>pipeline.auto-watermark-interval</code> 进行配置，如果设置为 200ms 则每 200ms 会计算一次 Watermark，然如果比之前发出的 Watermark 大，则发出。如果间隔设为 0ms，则 Watermark 只要满足触发条件就会发出，不会受到间隔时间控制。</li>
</ol>
</blockquote>
<p>Flink SQL 提供了几种 WATERMARK 生产策略：</p>
<ol>
<li>⭐ 有界无序：设置方式为 <code>WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &#39;string&#39; timeUnit</code>。此类策略就可以用于设置最大乱序时间，假如设置为 <code>WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &#39;5&#39; SECOND</code>，则生成的是运行 5s 延迟的 Watermark。。<code>一般都用这种 Watermark 生成策略</code>，此类 Watermark 生成策略通常用于有数据乱序的场景中，而对应到实际的场景中，数据都是会存在乱序的，所以基本都使用此类策略。</li>
<li>⭐ 严格升序：设置方式为 <code>WATERMARK FOR rowtime_column AS rowtime_column</code>。<code>一般基本不用这种方式</code>。如果你能保证你的数据源的时间戳是严格升序的，那就可以使用这种方式。严格升序代表 Flink 任务认为时间戳只会越来越大，也不存在相等的情况，只要相等或者小于之前的，就认为是迟到的数据。</li>
<li>⭐ 递增：设置方式为 <code>WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &#39;0.001&#39; SECOND</code>。<code>一般基本不用这种方式</code>。如果设置此类，则允许有相同的时间戳出现。</li>
</ol>
<h3 id="3-1-4-Create-Table-With-子句"><a href="#3-1-4-Create-Table-With-子句" class="headerlink" title="3.1.4.Create Table With 子句"></a>3.1.4.Create Table With 子句</h3><p>先看一个案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> KafkaTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `item_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `behavior` STRING,</span><br><span class="line">  `ts` <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> <span class="string">&#x27;timestamp&#x27;</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;user_behavior&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;localhost:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>可以看到 DDL 中 With 子句就是在建表时，描述数据源、数据汇的具体外部存储的元数据信息的。</p>
<p>一般 With 中的配置项由 Flink SQL 的 Connector（链接外部存储的连接器） 来定义，每种 Connector 提供的 With 配置项都是不同的。</p>
<blockquote>
<p>注意：</p>
<ol>
<li>Flink SQL 中 Connector 其实就是 Flink 用于链接外部数据源的接口。举一个类似的例子，在 Java 中想连接到 MySQL，需要使用 mysql-connector-java 包提供的 Java API 去链接。映射到 Flink SQL 中，在 Flink SQL 中要连接到 Kafka，需要使用 kafka connector</li>
<li>Flink SQL 已经提供了一系列的内置 Connector，具体可见 <a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/overview/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/overview/</a></li>
</ol>
</blockquote>
<p>回到上述案例中，With 声明了以下几项信息：</p>
<ol>
<li>⭐ <code>&#39;connector&#39; = &#39;kafka&#39;</code>：声明外部存储是 Kafka</li>
<li>⭐ <code>&#39;topic&#39; = &#39;user_behavior&#39;</code>：声明 Flink SQL 任务要连接的 Kafka 表的 topic 是 user_behavior</li>
<li>⭐ <code>&#39;properties.bootstrap.servers&#39; = &#39;localhost:9092&#39;</code>：声明 Kafka 的 server ip 是 localhost:9092</li>
<li>⭐ <code>&#39;properties.group.id&#39; = &#39;testGroup&#39;</code>：声明 Flink SQL 任务消费这个 Kafka topic，会使用 testGroup 的 group id 去消费</li>
<li>⭐ <code>&#39;scan.startup.mode&#39; = &#39;earliest-offset&#39;</code>：声明 Flink SQL 任务消费这个 Kafka topic 会从最早位点开始消费</li>
<li>⭐ <code>&#39;format&#39; = &#39;csv&#39;</code>：声明 Flink SQL 任务读入或者写出时对于 Kafka 消息的序列化方式是 csv 格式</li>
</ol>
<p>从这里也可以看出来 With 中具体要配置哪些配置项都是和每种 Connector 决定的。</p>
<h3 id="3-1-4-Create-Table-Like-子句"><a href="#3-1-4-Create-Table-Like-子句" class="headerlink" title="3.1.4.Create Table Like 子句"></a>3.1.4.Create Table Like 子句</h3><p>Like 子句是 Create Table 子句的一个延伸。举例：</p>
<p>下面定义了一张 <code>Orders</code> 表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Orders (</span><br><span class="line">    `<span class="keyword">user</span>` <span class="type">BIGINT</span>,</span><br><span class="line">    product STRING,</span><br><span class="line">    order_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>)</span><br><span class="line">) <span class="keyword">WITH</span> ( </span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>但是忘记定义 Watermark 了，那如果想加上 Watermark，就可以用 <code>Like</code> 子句定义一张带 Watermark 的新表：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Orders_with_watermark (</span><br><span class="line">    <span class="comment">-- 1. 添加了 WATERMARK 定义</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span> </span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="comment">-- 2. 覆盖了原 Orders 表中 scan.startup.mode 参数</span></span><br><span class="line">    <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 3. Like 子句声明是在原来的 Orders 表的基础上定义 Orders_with_watermark 表</span></span><br><span class="line"><span class="keyword">LIKE</span> Orders;</span><br></pre></td></tr></table></figure>

<p>上面这个语句的效果就等同于：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Orders_with_watermark (</span><br><span class="line">    `<span class="keyword">user</span>` <span class="type">BIGINT</span>,</span><br><span class="line">    product STRING,</span><br><span class="line">    order_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span> </span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>不过这种不常使用。就不过多介绍了。如果小伙伴萌感兴趣，直接去官网参考具体注意事项：</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/sql/create/#like">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/sql/create/#like</a></p>
<h2 id="3-2-DML：With-子句"><a href="#3-2-DML：With-子句" class="headerlink" title="3.2.DML：With 子句"></a>3.2.DML：With 子句</h2><ol>
<li><p>⭐ 应用场景（支持 Batch\Streaming）：With 语句和离线 Hive SQL With 语句一样的，xdm，语法糖 +1，使用它可以让你的代码逻辑更加清晰。</p>
</li>
<li><p>⭐ 直接上案例：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 语法糖+1</span></span><br><span class="line"><span class="keyword">WITH</span> orders_with_total <span class="keyword">AS</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> </span><br><span class="line">        order_id</span><br><span class="line">        , price <span class="operator">+</span> tax <span class="keyword">AS</span> total</span><br><span class="line">    <span class="keyword">FROM</span> Orders</span><br><span class="line">)</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    order_id</span><br><span class="line">    , <span class="built_in">SUM</span>(total)</span><br><span class="line"><span class="keyword">FROM</span> orders_with_total</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> </span><br><span class="line">    order_id;</span><br></pre></td></tr></table></figure>

<h2 id="3-3-DML：SELECT-amp-WHERE-子句"><a href="#3-3-DML：SELECT-amp-WHERE-子句" class="headerlink" title="3.3.DML：SELECT &amp; WHERE 子句"></a>3.3.DML：SELECT &amp; WHERE 子句</h2><ol>
<li><p>⭐ 应用场景（支持 Batch\Streaming）：SELECT &amp; WHERE 语句和离线 Hive SQL 语句一样的，xdm，常用作 ETL，过滤，字段清洗标准化</p>
</li>
<li><p>⭐ 直接上案例：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> target_table</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Orders</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> target_table</span><br><span class="line"><span class="keyword">SELECT</span> order_id, price <span class="operator">+</span> tax <span class="keyword">FROM</span> Orders</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> target_table</span><br><span class="line"><span class="comment">-- 自定义 Source 的数据</span></span><br><span class="line"><span class="keyword">SELECT</span> order_id, price <span class="keyword">FROM</span> (<span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="number">2.0</span>), (<span class="number">2</span>, <span class="number">3.1</span>))  <span class="keyword">AS</span> t (order_id, price)</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> target_table</span><br><span class="line"><span class="keyword">SELECT</span> price <span class="operator">+</span> tax <span class="keyword">FROM</span> Orders <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 使用 UDF 做字段标准化处理</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> target_table</span><br><span class="line"><span class="keyword">SELECT</span> PRETTY_PRINT(order_id) <span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="comment">-- 过滤条件</span></span><br><span class="line"><span class="keyword">Where</span> id <span class="operator">&gt;</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>其实理解一个 SQL 最后生成的任务是怎样执行的，最好的方式就是理解其语义。</p>
<p>以下面的 SQL 为例，我们来介绍下其在离线中和在实时中执行的区别，对比学习一下，大家就比较清楚了</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> target_table</span><br><span class="line"><span class="keyword">SELECT</span> PRETTY_PRINT(order_id) <span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="keyword">Where</span> id <span class="operator">&gt;</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>这个 SQL 对应的实时任务，假设 Orders 为 kafka，target_table 也为 Kafka，在执行时，会生成三个算子：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：连接到 Kafka topic，数据源算子一直运行，实时的从 Order Kafka 中一条一条的读取数据，然后一条一条发送给下游的 <code>过滤和字段标准化算子</code></li>
<li>⭐ <code>过滤和字段标准化算子</code>（Where id &gt; 3 和 PRETTY_PRINT(order_id)）：接收到上游算子发的一条一条的数据，然后判断 id &gt; 3？将判断结果为 true 的数据执行 PRETTY_PRINT UDF 后，一条一条将计算结果数据发给下游 <code>数据汇算子</code></li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游发的一条一条的数据，写入到 target_table Kafka 中</li>
</ul>
<p>可以看到这个实时任务的所有算子是以一种 pipeline 模式运行的，所有的算子在同一时刻都是处于 running 状态的，24 小时一直在运行，实时任务中也没有离线中常见的分区概念。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/35.png" alt="select &amp; where"></p>
<blockquote>
<p>关于看如何看一段 Flink SQL 最终的执行计划：</p>
<p>最好的方法就如上图，看 Flink web ui 的算子图，算子图上详细的标记清楚了每一个算子做的事情。以上图来说，我们可以看到主要有三个算子：</p>
<ol>
<li>⭐ Source 算子：Source: TableSourceScan(table=[[default_catalog, default_database, Orders]], fields=[order_id, name]) -&gt; Calc(select=[order_id, name, CAST(CURRENT_TIMESTAMP()) AS row_time]) -&gt; WatermarkAssigner(rowtime=[row_time], watermark=[(row_time - 5000:INTERVAL SECOND)]) ，其中 Source 表名称为 <code>table=[[default_catalog, default_database, Orders]</code>，字段为 <code>select=[order_id, name, CAST(CURRENT_TIMESTAMP()) AS row_time]</code>，Watermark 策略为 <code>rowtime=[row_time], watermark=[(row_time - 5000:INTERVAL SECOND)]</code>。</li>
<li>⭐ 过滤算子：Calc(select=[order_id, name, row_time], where=[(order_id &gt; 3)]) -&gt; NotNullEnforcer(fields=[order_id])，其中过滤条件为 <code>where=[(order_id &gt; 3)]</code>，结果字段为 <code>select=[order_id, name, row_time]</code></li>
<li>⭐ Sink 算子：Sink: Sink(table=[default_catalog.default_database.target_table], fields=[order_id, name, row_time])，其中最终产出的表名称为 <code>table=[default_catalog.default_database.target_table]</code>，表字段为 <code>fields=[order_id, name, row_time]</code></li>
</ol>
<p>可以看到 Flink SQL 具体执行了哪些操作是非常详细的标记在算子图上。所以小伙伴萌一定要学会看算子图，这是掌握 debug、调优前最基础的一个技巧。</p>
</blockquote>
<p>那么如果这个 SQL 放在 Hive 中执行时，假设其中 Orders 为 Hive 表，target_table 也为 Hive 表，其也会生成三个类似的算子（虽然实际可能会被优化为一个算子，这里为了方便对比，划分为三个进行介绍），离线和实时任务的执行方式完全不同：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：数据源从 Order Hive 表（通常都是读一天、一小时的分区数据）中一次性读取所有的数据，然后将读到的数据全部发给下游 <code>过滤和字段标准化算子</code>，然后 <code>数据源算子</code> 就运行结束了，释放资源了</li>
<li>⭐ <code>过滤和字段标准化算子</code>（Where id &gt; 3 和 PRETTY_PRINT(order_id)）：接收到上游算子的所有数据，然后遍历所有数据判断 id &gt; 3？将判断结果为 true 的数据执行 PRETTY_PRINT UDF 后，将所有数据发给下游 <code>数据汇算子</code>，然后 <code>过滤和字段标准化算子</code> 就运行结束了，释放资源了</li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游的所有数据，将所有数据都写到 target_table Hive 表中，然后整个任务就运行结束了，整个任务的资源也就都释放了</li>
</ul>
<p>可以看到离线任务的算子是分阶段（stage）进行运行的，每一个 stage 运行结束之后，然后下一个 stage 开始运行，全部的 stage 运行完成之后，这个离线任务就跑结束了。</p>
<blockquote>
<p>注意：</p>
<p>很多小伙伴都是之前做过离线数仓的，熟悉了离线的分区、计算任务定时调度运行这两个概念，所以在最初接触 Flink SQL 时，会以为 Flink SQL 实时任务也会存在这两个概念，这里博主做一下解释</p>
<ol>
<li>分区概念：离线由于能力限制问题，通常都是进行一批一批的数据计算，每一批数据的数据量都是有限的集合，这一批一批的数据自然的划分方式就是时间，比如按小时、天进行划分分区。但是 <code>在实时任务中，是没有分区的概念的</code>，实时任务的上游、下游都是无限的数据流。</li>
<li>计算任务定时调度概念：同上，离线就是由于计算能力限制，数据要一批一批算，一批一批输入、产出，所以要按照小时、天定时的调度和计算。但是 <code>在实时任务中，是没有定时调度的概念的</code>，实时任务一旦运行起来就是 24 小时不间断，不间断的处理上游无限的数据，不简单的产出数据给到下游。</li>
</ol>
</blockquote>
<p>详细可参考：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/VAhodnMetqFEXB33zH8lCg">https://mp.weixin.qq.com/s/VAhodnMetqFEXB33zH8lCg</a></p>
<h2 id="3-4-DML：SELECT-DISTINCT-子句"><a href="#3-4-DML：SELECT-DISTINCT-子句" class="headerlink" title="3.4.DML：SELECT DISTINCT 子句"></a>3.4.DML：SELECT DISTINCT 子句</h2><ol>
<li><p>⭐ 应用场景（支持 Batch\Streaming）：语句和离线 Hive SQL SELECT DISTINCT 语句一样的，xdm，用作根据 key 进行数据去重</p>
</li>
<li><p>⭐ 直接上案例：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">into</span> target_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="keyword">DISTINCT</span> id </span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>也是拿离线和实时做对比。</p>
<p>这个 SQL 对应的实时任务，假设 Orders 为 kafka，target_table 也为 Kafka，在执行时，会生成三个算子：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：连接到 Kafka topic，数据源算子一直运行，实时的从 Order Kafka 中一条一条的读取数据，然后一条一条发送给下游的 <code>去重算子</code></li>
<li>⭐ <code>去重算子</code>（DISTINCT id）：接收到上游算子发的一条一条的数据，然后判断这个 id 之前是否已经来过了，判断方式就是使用 Flink 中的 state 状态，如果状态中已经有这个 id 了，则说明已经来过了，不往下游算子发，如果状态中没有这个 id，则说明没来过，则往下游算子发，也是一条一条发给下游 <code>数据汇算子</code></li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游发的一条一条的数据，写入到 target_table Kafka 中</li>
</ul>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/36.png" alt="select distinct"></p>
<blockquote>
<p>注意：</p>
<p>对于实时任务，计算时的状态可能会无限增长。</p>
<p>状态大小取决于不同 key（上述案例为 id 字段）的数量。为了防止状态无限变大，我们可以设置状态的 TTL。但是这可能会影响查询结果的正确性，比如某个 key 的数据过期从状态中删除了，那么下次再来这么一个 key，由于在状态中找不到，就又会输出一遍。</p>
</blockquote>
<p>那么如果这个 SQL 放在 Hive 中执行时，假设其中 Orders 为 Hive 表，target_table 也为 Hive 表，其也会生成三个相同的算子（虽然可能会被优化为一个算子，这里为了方便对比，划分为三个进行介绍），但是其和实时任务的执行方式完全不同：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：数据源从 Order Hive 表（通常都有天、小时分区限制）中一次性读取所有的数据，然后将读到的数据全部发给下游 <code>去重算子</code>，然后 <code>数据源算子</code> 就运行结束了，释放资源了</li>
<li>⭐ <code>去重算子</code>（DISTINCT id）：接收到上游算子的所有数据，然后遍历所有数据进行去重，将去重完的所有结果数据发给下游 <code>数据汇算子</code>，然后 <code>去重算子</code> 就运行结束了，释放资源了</li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游的所有数据，将所有数据都写到 target_table Hive 中，然后整个任务就运行结束了，整个任务的资源也就都释放了</li>
</ul>
<h2 id="3-5-DML：窗口聚合"><a href="#3-5-DML：窗口聚合" class="headerlink" title="3.5.DML：窗口聚合"></a>3.5.DML：窗口聚合</h2><p>由于窗口涉及到的知识内容比较多，所以博主先为大家说明介绍下面内容时的思路，大家跟着思路走。思路如下：</p>
<ol>
<li>⭐ 先介绍 Flink SQL 支持的 4 种时间窗口</li>
<li>⭐ 分别详细介绍上述的 4 种时间窗口的功能及 SQL 语法</li>
<li>⭐ 结合实际案例介绍 4 种时间窗口</li>
</ol>
<p>首先来看看 Flink SQL 中支持的 4 种窗口的运算。</p>
<ol>
<li>⭐ 滚动窗口（TUMBLE）</li>
<li>⭐ 滑动窗口（HOP）</li>
<li>⭐ Session 窗口（SESSION）</li>
<li>⭐ 渐进式窗口（CUMULATE）</li>
</ol>
<h3 id="3-5-1-滚动窗口（TUMBLE）"><a href="#3-5-1-滚动窗口（TUMBLE）" class="headerlink" title="3.5.1.滚动窗口（TUMBLE）"></a>3.5.1.滚动窗口（TUMBLE）</h3><ol>
<li>⭐ 滚动窗口定义：滚动窗口将每个元素指定给指定窗口大小的窗口。滚动窗口具有固定大小，且不重叠。例如，指定一个大小为 5 分钟的滚动窗口。在这种情况下，Flink 将每隔 5 分钟开启一个新的窗口，其中每一条数都会划分到唯一一个 5 分钟的窗口中，如下图所示。</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/14.jpg" alt="tumble window"></p>
<ol start="2">
<li><p>⭐ 应用场景：常见的按照一分钟对数据进行聚合，计算一分钟内 PV，UV 数据。</p>
</li>
<li><p>⭐ 实际案例：简单且常见的分维度分钟级别同时在线用户数、总销售额</p>
</li>
</ol>
<p>那么上面这个案例的 SQL 要咋写呢？</p>
<p>关于滚动窗口，在 1.13 版本之前和 1.13 及之后版本有两种 Flink SQL 实现方式，分别是：</p>
<ul>
<li>⭐ Group Window Aggregation（1.13 之前只有此类方案，此方案在 1.13 及之后版本已经标记为废弃，不推荐小伙伴萌使用）</li>
<li>⭐ Windowing TVF（1.13 及之后建议使用 Windowing TVF）</li>
</ul>
<p>博主这里两种方法都会介绍：</p>
<ul>
<li>⭐ Group Window Aggregation 方案（支持 Batch\Streaming 任务）：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    pv <span class="type">BIGINT</span>,</span><br><span class="line">    sum_price <span class="type">BIGINT</span>,</span><br><span class="line">    max_price <span class="type">BIGINT</span>,</span><br><span class="line">    min_price <span class="type">BIGINT</span>,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    dim,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> pv,</span><br><span class="line">    <span class="built_in">sum</span>(price) <span class="keyword">as</span> sum_price,</span><br><span class="line">    <span class="built_in">max</span>(price) <span class="keyword">as</span> max_price,</span><br><span class="line">    <span class="built_in">min</span>(price) <span class="keyword">as</span> min_price,</span><br><span class="line">    <span class="comment">-- 计算 uv 数</span></span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv,</span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(tumble_start(row_time, <span class="type">interval</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span>  <span class="keyword">as</span> window_start</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    dim,</span><br><span class="line">    tumble(row_time, <span class="type">interval</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到 Group Window Aggregation 滚动窗口的 SQL 语法就是把 tumble window 的声明写在了 group by 子句中，即 <code>tumble(row_time, interval &#39;1&#39; minute)</code>，第一个参数为事件时间的时间戳；第二个参数为滚动窗口大小。</p>
<ul>
<li>⭐ Window TVF 方案（1.13 只支持 Streaming 任务）：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    pv <span class="type">BIGINT</span>,</span><br><span class="line">    sum_price <span class="type">BIGINT</span>,</span><br><span class="line">    max_price <span class="type">BIGINT</span>,</span><br><span class="line">    min_price <span class="type">BIGINT</span>,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    dim,</span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(window_start <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_start,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> pv,</span><br><span class="line">    <span class="built_in">sum</span>(price) <span class="keyword">as</span> sum_price,</span><br><span class="line">    <span class="built_in">max</span>(price) <span class="keyword">as</span> max_price,</span><br><span class="line">    <span class="built_in">min</span>(price) <span class="keyword">as</span> min_price,</span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">TABLE</span>(TUMBLE(</span><br><span class="line">        <span class="keyword">TABLE</span> source_table</span><br><span class="line">        , DESCRIPTOR(row_time)</span><br><span class="line">        , <span class="type">INTERVAL</span> <span class="string">&#x27;60&#x27;</span> <span class="keyword">SECOND</span>))</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> window_start, </span><br><span class="line">      window_end,</span><br><span class="line">      dim</span><br></pre></td></tr></table></figure>

<p>可以看到 Windowing TVF 滚动窗口的写法就是把 tumble window 的声明写在了数据源的 Table 子句中，即 <code>TABLE(TUMBLE(TABLE source_table, DESCRIPTOR(row_time), INTERVAL &#39;60&#39; SECOND))</code>，包含三部分参数。</p>
<p>第一个参数 <code>TABLE source_table</code> 声明数据源表；<br>第二个参数 <code>DESCRIPTOR(row_time)</code> 声明数据源的时间戳；<br>第三个参数 <code>INTERVAL &#39;60&#39; SECOND</code> 声明滚动窗口大小为 1 min。</p>
<p>可以直接在公众号后台回复<strong>1.13.2 最全 flink sql</strong>获取源代码。所有的源码都开源到 github 上面了。里面包含了非常多的案例。可以直接拿来在本地运行的！！！肥肠的方便。</p>
<ol start="4">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>由于离线没有相同的时间窗口聚合概念，这里就直接说实时场景 SQL 语义，假设 Orders 为 kafka，target_table 也为 Kafka，这个 SQL 生成的实时任务，在执行时，会生成三个算子：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：连接到 Kafka topic，数据源算子一直运行，实时的从 Order Kafka 中一条一条的读取数据，然后一条一条发送给下游的 <code>窗口聚合算子</code></li>
<li>⭐ <code>窗口聚合算子</code>（TUMBLE 算子）：接收到上游算子发的一条一条的数据，然后将每一条数据按照时间戳划分到对应的窗口中（根据事件时间、处理时间的不同语义进行划分），上述案例为事件时间，事件时间中，滚动窗口算子接收到上游的 Watermark 大于窗口的结束时间时，则说明当前这一分钟的滚动窗口已经结束了，将窗口计算完的结果发往下游算子（一条一条发给下游 <code>数据汇算子</code>）</li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游发的一条一条的数据，写入到 target_table Kafka 中</li>
</ul>
<p>这个实时任务也是 24 小时一直在运行的，所有的算子在同一时刻都是处于 running 状态的。</p>
<blockquote>
<p>注意：</p>
<p>事件时间中滚动窗口的窗口计算触发是由 Watermark 推动的。</p>
</blockquote>
<h3 id="3-5-2-滑动窗口（HOP）"><a href="#3-5-2-滑动窗口（HOP）" class="headerlink" title="3.5.2.滑动窗口（HOP）"></a>3.5.2.滑动窗口（HOP）</h3><ol>
<li>⭐ 滑动窗口定义：滑动窗口也是将元素指定给固定长度的窗口。与滚动窗口功能一样，也有窗口大小的概念。不一样的地方在于，滑动窗口有另一个参数控制窗口计算的频率（滑动窗口滑动的步长）。因此，如果滑动的步长小于窗口大小，则滑动窗口之间每个窗口是可以重叠。在这种情况下，一条数据就会分配到多个窗口当中。举例，有 10 分钟大小的窗口，滑动步长为 5 分钟。这样，每 5 分钟会划分一次窗口，这个窗口包含的数据是过去 10 分钟内的数据，如下图所示。</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/15.png" alt="hop window"></p>
<ol start="2">
<li><p>⭐ 应用场景：比如计算同时在线的数据，要求结果的输出频率是 1 分钟一次，每次计算的数据是过去 5 分钟的数据（有的场景下用户可能在线，但是可能会 2 分钟不活跃，但是这也要算在同时在线数据中，所以取最近 5 分钟的数据就能计算进去了）</p>
</li>
<li><p>⭐ 实际案例：简单且常见的分维度分钟级别同时在线用户数，1 分钟输出一次，计算最近 5 分钟的数据</p>
</li>
</ol>
<p>依然是 Group Window Aggregation、Windowing TVF 两种方案：</p>
<ul>
<li>⭐ Group Window Aggregation 方案（支持 Batch\Streaming 任务）：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> dim,</span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(hop_start(row_time, <span class="type">interval</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>, <span class="type">interval</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_start, </span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> dim</span><br><span class="line">    , hop(row_time, <span class="type">interval</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>, <span class="type">interval</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">minute</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以看到 Group Window Aggregation 滚动窗口的写法就是把 hop window 的声明写在了 group by 子句中，即 <code>hop(row_time, interval &#39;1&#39; minute, interval &#39;5&#39; minute)</code>。其中：</p>
<p>第一个参数为事件时间的时间戳；<br>第二个参数为滑动窗口的滑动步长；<br>第三个参数为滑动窗口大小。</p>
<ul>
<li>⭐ Windowing TVF 方案（1.13 只支持 Streaming 任务）：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    dim,</span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(window_start <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_start, </span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> bucket_uv</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">TABLE</span>(HOP(</span><br><span class="line">        <span class="keyword">TABLE</span> source_table</span><br><span class="line">        , DESCRIPTOR(row_time)</span><br><span class="line">        , <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> MINUTES, <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> MINUTES))</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> window_start, </span><br><span class="line">      window_end,</span><br><span class="line">      dim</span><br></pre></td></tr></table></figure>

<p>可以看到 Windowing TVF 滚动窗口的写法就是把 hop window 的声明写在了数据源的 Table 子句中，即 <code>TABLE(HOP(TABLE source_table, DESCRIPTOR(row_time), INTERVAL &#39;1&#39; MINUTES, INTERVAL &#39;5&#39; MINUTES))</code>，包含四部分参数：</p>
<p>第一个参数 <code>TABLE source_table</code> 声明数据源表；<br>第二个参数 <code>DESCRIPTOR(row_time)</code> 声明数据源的时间戳；<br>第三个参数 <code>INTERVAL &#39;1&#39; MINUTES</code> 声明滚动窗口滑动步长大小为 1 min。<br>第四个参数 <code>INTERVAL &#39;5&#39; MINUTES</code> 声明滚动窗口大小为 5 min。</p>
<ol start="4">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>滑动窗口语义和滚动窗口类似，这里不再赘述。</p>
<h3 id="3-5-3-Session-窗口（SESSION）"><a href="#3-5-3-Session-窗口（SESSION）" class="headerlink" title="3.5.3.Session 窗口（SESSION）"></a>3.5.3.Session 窗口（SESSION）</h3><ol>
<li>⭐ Session 窗口定义：Session 时间窗口和滚动、滑动窗口不一样，其没有固定的持续时间，如果在定义的间隔期（Session Gap）内没有新的数据出现，则 Session 就会窗口关闭。如下图对比所示：</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/16.jpg" alt="session window"></p>
<ol start="2">
<li>⭐ 实际案例：计算每个用户在活跃期间（一个 Session）总共购买的商品数量，如果用户 5 分钟没有活动则视为 Session 断开</li>
</ol>
<p>目前 1.13 版本中 Flink SQL 不支持 Session 窗口的 Window TVF，所以这里就只介绍 Group Window Aggregation 方案：</p>
<ul>
<li>⭐ Group Window Aggregation 方案（支持 Batch\Streaming 任务）：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表，用户购买行为记录表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    pv <span class="type">BIGINT</span>, <span class="comment">-- 购买商品数量</span></span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    dim,</span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(session_start(row_time, <span class="type">interval</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_start, </span><br><span class="line">    <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> pv</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> dim</span><br><span class="line">      , session(row_time, <span class="type">interval</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">minute</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<p>上述 SQL 任务是在整个 Session 窗口结束之后才会把数据输出。Session 窗口即支持 <code>处理时间</code> 也支持 <code>事件时间</code>。但是处理时间只支持在 Streaming 任务中运行，Batch 任务不支持。</p>
</blockquote>
<p>可以看到 Group Window Aggregation 中 Session 窗口的写法就是把 session window 的声明写在了 group by 子句中，即 <code>session(row_time, interval &#39;5&#39; minute)</code>。其中：</p>
<p>第一个参数为事件时间的时间戳；<br>第二个参数为 Session gap 间隔。</p>
<ol start="4">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>Session 窗口语义和滚动窗口类似，这里不再赘述。</p>
<p>可以直接在公众号后台回复<strong>1.13.2 最全 flink sql</strong>获取源代码。所有的源码都开源到 github 上面了。里面包含了非常多的案例。可以直接拿来在本地运行的！！！肥肠的方便。</p>
<h3 id="3-5-4-渐进式窗口（CUMULATE）"><a href="#3-5-4-渐进式窗口（CUMULATE）" class="headerlink" title="3.5.4.渐进式窗口（CUMULATE）"></a>3.5.4.渐进式窗口（CUMULATE）</h3><ol>
<li>⭐ 渐进式窗口定义（1.13 只支持 Streaming 任务）：渐进式窗口在其实就是 <code>固定窗口间隔内提前触发的的滚动窗口</code>，其实就是 <code>Tumble Window + early-fire</code> 的一个事件时间的版本。例如，从每日零点到当前这一分钟绘制累积 UV，其中 10:00 时的 UV 表示从 00:00 到 10:00 的 UV 总数。<br>渐进式窗口可以认为是首先开一个最大窗口大小的滚动窗口，然后根据用户设置的触发的时间间隔将这个滚动窗口拆分为多个窗口，这些窗口具有相同的窗口起点和不同的窗口终点。如下图所示：</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/17.jpg" alt="cumulate window"></p>
<ol start="2">
<li><p>⭐ 应用场景：周期内累计 PV，UV 指标（如每天累计到当前这一分钟的 PV，UV）。这类指标是一段周期内的累计状态，对分析师来说更具统计分析价值，而且几乎所有的复合指标都是基于此类指标的统计（不然离线为啥都要累计一天的数据，而不要一分钟累计的数据呢）。</p>
</li>
<li><p>⭐ 实际案例：每天的截止当前分钟的累计 money（sum(money)），去重 id 数（count(distinct id)）。每天代表渐进式窗口大小为 1 天，分钟代表渐进式窗口移动步长为分钟级别。举例如下：</p>
</li>
</ol>
<p>明细输入数据：</p>
<table>
<thead>
<tr>
<th>time</th>
<th>id</th>
<th>money</th>
</tr>
</thead>
<tbody><tr>
<td>2021-11-01 00:01:00</td>
<td>A</td>
<td>3</td>
</tr>
<tr>
<td>2021-11-01 00:01:00</td>
<td>B</td>
<td>5</td>
</tr>
<tr>
<td>2021-11-01 00:01:00</td>
<td>A</td>
<td>7</td>
</tr>
<tr>
<td>2021-11-01 00:02:00</td>
<td>C</td>
<td>3</td>
</tr>
<tr>
<td>2021-11-01 00:03:00</td>
<td>C</td>
<td>10</td>
</tr>
</tbody></table>
<p>预期经过渐进式窗口计算的输出数据：</p>
<table>
<thead>
<tr>
<th>time</th>
<th>count distinct id</th>
<th>sum money</th>
</tr>
</thead>
<tbody><tr>
<td>2021-11-01 00:01:00</td>
<td>2</td>
<td>15</td>
</tr>
<tr>
<td>2021-11-01 00:02:00</td>
<td>3</td>
<td>18</td>
</tr>
<tr>
<td>2021-11-01 00:03:00</td>
<td>3</td>
<td>28</td>
</tr>
</tbody></table>
<p>转化为折线图长这样：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/12_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%EF%BC%89%EF%BC%9A1.13cumulatewindow/1.png" alt="当日累计"></p>
<p>可以看到，其特点就在于，每一分钟的输出结果都是当天零点累计到当前的结果。</p>
<p>渐进式窗口目前只有 Windowing TVF 方案支持：</p>
<ul>
<li>⭐ Windowing TVF 方案（1.13 只支持 Streaming 任务）：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    money <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    window_end <span class="type">bigint</span>,</span><br><span class="line">    window_start <span class="type">bigint</span>,</span><br><span class="line">    sum_money <span class="type">BIGINT</span>,</span><br><span class="line">    count_distinct_id <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(window_end <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_end, </span><br><span class="line">    window_start, </span><br><span class="line">    <span class="built_in">sum</span>(money) <span class="keyword">as</span> sum_money,</span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> id) <span class="keyword">as</span> count_distinct_id</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">TABLE</span>(CUMULATE(</span><br><span class="line">       <span class="keyword">TABLE</span> source_table</span><br><span class="line">       , DESCRIPTOR(row_time)</span><br><span class="line">       , <span class="type">INTERVAL</span> <span class="string">&#x27;60&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">       , <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">DAY</span>))</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">    window_start, </span><br><span class="line">    window_end</span><br></pre></td></tr></table></figure>

<p>可以看到 Windowing TVF 滚动窗口的写法就是把 cumulate window 的声明写在了数据源的 Table 子句中，即 <code>TABLE(CUMULATE(TABLE source_table, DESCRIPTOR(row_time), INTERVAL &#39;60&#39; SECOND, INTERVAL &#39;1&#39; DAY))</code>，其中包含四部分参数：</p>
<p>第一个参数 <code>TABLE source_table</code> 声明数据源表；<br>第二个参数 <code>DESCRIPTOR(row_time)</code> 声明数据源的时间戳；<br>第三个参数 <code>INTERVAL &#39;60&#39; SECOND</code> 声明渐进式窗口触发的渐进步长为 1 min。<br>第四个参数 <code>INTERVAL &#39;1&#39; DAY</code> 声明整个渐进式窗口的大小为 1 天，到了第二天新开一个窗口重新累计。</p>
<ol start="4">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>渐进式窗口语义和滚动窗口类似，这里不再赘述。</p>
<h3 id="3-5-5-Window-TVF-支持-Grouping-Sets、Rollup、Cube"><a href="#3-5-5-Window-TVF-支持-Grouping-Sets、Rollup、Cube" class="headerlink" title="3.5.5.Window TVF 支持 Grouping Sets、Rollup、Cube"></a>3.5.5.Window TVF 支持 Grouping Sets、Rollup、Cube</h3><p>具体应用场景：实际的案例场景中，经常会有多个维度进行组合（cube）计算指标的场景。如果把每个维度组合的代码写一遍，然后 union all 起来，这样写起来非常麻烦，而且会导致一个数据源读取多遍。</p>
<p>这时，有离线 Hive SQL 使用经验的小伙伴萌就会想到，如果有了 Grouping Sets，我们就可以直接用 Grouping Sets 将维度组合写在一条 SQL 中，写起来方便并且执行效率也高。当然，Flink 支持这个功能。</p>
<p><code>但是目前 Grouping Sets 只在 Window TVF 中支持，不支持 Group Window Aggregation。</code></p>
<p>来一个实际案例感受一下，计算每日零点累计到当前这一分钟的分汇总、age、sex、age+sex 维度的用户数。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 用户访问明细表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    age STRING,</span><br><span class="line">    sex STRING,</span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.age.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.sex.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    age STRING,</span><br><span class="line">    sex STRING,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_end <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(window_end <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_end, </span><br><span class="line">    if (age <span class="keyword">is</span> <span class="keyword">null</span>, <span class="string">&#x27;ALL&#x27;</span>, age) <span class="keyword">as</span> age,</span><br><span class="line">    if (sex <span class="keyword">is</span> <span class="keyword">null</span>, <span class="string">&#x27;ALL&#x27;</span>, sex) <span class="keyword">as</span> sex,</span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> bucket_uv</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">TABLE</span>(CUMULATE(</span><br><span class="line">       <span class="keyword">TABLE</span> source_table</span><br><span class="line">       , DESCRIPTOR(row_time)</span><br><span class="line">       , <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">       , <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">DAY</span>))</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> </span><br><span class="line">    window_start, </span><br><span class="line">    window_end,</span><br><span class="line">    <span class="comment">-- grouping sets 写法</span></span><br><span class="line">    <span class="keyword">GROUPING</span> SETS (</span><br><span class="line">        ()</span><br><span class="line">        , (age)</span><br><span class="line">        , (sex)</span><br><span class="line">        , (age, sex)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>小伙伴萌这里需要注意下！！！</p>
<p>Flink SQL 中 Grouping Sets 的语法和 Hive SQL 的语法有一些不同，如果我们使用 Hive SQL 实现上述 SQL 的语义，其实现如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(window_end <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> window_end, </span><br><span class="line">    if (age <span class="keyword">is</span> <span class="keyword">null</span>, <span class="string">&#x27;ALL&#x27;</span>, age) <span class="keyword">as</span> age,</span><br><span class="line">    if (sex <span class="keyword">is</span> <span class="keyword">null</span>, <span class="string">&#x27;ALL&#x27;</span>, sex) <span class="keyword">as</span> sex,</span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> bucket_uv</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">    age</span><br><span class="line">    , sex</span><br><span class="line"><span class="comment">-- hive sql grouping sets 写法</span></span><br><span class="line"><span class="keyword">GROUPING</span> SETS (</span><br><span class="line">    ()</span><br><span class="line">    , (age)</span><br><span class="line">    , (sex)</span><br><span class="line">    , (age, sex)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="3-6-DML：Group-聚合"><a href="#3-6-DML：Group-聚合" class="headerlink" title="3.6.DML：Group 聚合"></a>3.6.DML：Group 聚合</h2><ol>
<li>⭐ Group 聚合定义（支持 Batch\Streaming 任务）：Flink 也支持 Group 聚合。Group 聚合和上面介绍到的窗口聚合的不同之处，就在于 Group 聚合是按照数据的类别进行分组，比如年龄、性别，是横向的；而窗口聚合是在时间粒度上对数据进行分组，是纵向的。如下图所示，就展示出了其区别。其中 <code>按颜色分 key（横向）</code> 就是 Group 聚合，<code>按窗口划分（纵向）</code> 就是窗口聚合。</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/13.jpg" alt="tumble window + key"></p>
<ol start="2">
<li>⭐ 应用场景：一般用于对数据进行分组，然后后续使用聚合函数进行 count、sum 等聚合操作。</li>
</ol>
<p>那么这时候，小伙伴萌就会问到，我其实可以把窗口聚合的写法也转换为 Group 聚合，只需要把 Group 聚合的 Group By key 换成时间就行，那这两个聚合的区别到底在哪？</p>
<p>首先来举一个例子看看怎么将窗口聚合转换为 Group 聚合。假如一个窗口聚合是按照 1 分钟的粒度进行聚合，如下 SQL：</p>
<ul>
<li>⭐ 滚动窗口（TUMBLE）</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    pv <span class="type">BIGINT</span>,</span><br><span class="line">    sum_price <span class="type">BIGINT</span>,</span><br><span class="line">    max_price <span class="type">BIGINT</span>,</span><br><span class="line">    min_price <span class="type">BIGINT</span>,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">select</span> dim,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> pv,</span><br><span class="line">    <span class="built_in">sum</span>(price) <span class="keyword">as</span> sum_price,</span><br><span class="line">    <span class="built_in">max</span>(price) <span class="keyword">as</span> max_price,</span><br><span class="line">    <span class="built_in">min</span>(price) <span class="keyword">as</span> min_price,</span><br><span class="line">    <span class="comment">-- 计算 uv 数</span></span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv,</span><br><span class="line">    UNIX_TIMESTAMP(<span class="built_in">CAST</span>(tumble_start(row_time, <span class="type">interval</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> STRING)) <span class="operator">*</span> <span class="number">1000</span>  <span class="keyword">as</span> window_start</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    dim,</span><br><span class="line">    <span class="comment">-- 按照 Flink SQL tumble 窗口写法划分窗口</span></span><br><span class="line">    tumble(row_time, <span class="type">interval</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>)</span><br></pre></td></tr></table></figure>

<p>转换为 Group 聚合的写法如下：</p>
<ul>
<li>⭐ Group 聚合</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim STRING,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.dim.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.price.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim STRING,</span><br><span class="line">    pv <span class="type">BIGINT</span>,</span><br><span class="line">    sum_price <span class="type">BIGINT</span>,</span><br><span class="line">    max_price <span class="type">BIGINT</span>,</span><br><span class="line">    min_price <span class="type">BIGINT</span>,</span><br><span class="line">    uv <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">select</span> dim,</span><br><span class="line">    <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> pv,</span><br><span class="line">    <span class="built_in">sum</span>(price) <span class="keyword">as</span> sum_price,</span><br><span class="line">    <span class="built_in">max</span>(price) <span class="keyword">as</span> max_price,</span><br><span class="line">    <span class="built_in">min</span>(price) <span class="keyword">as</span> min_price,</span><br><span class="line">    <span class="comment">-- 计算 uv 数</span></span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv,</span><br><span class="line">    <span class="built_in">cast</span>((UNIX_TIMESTAMP(<span class="built_in">CAST</span>(row_time <span class="keyword">AS</span> STRING))) <span class="operator">/</span> <span class="number">60</span> <span class="keyword">as</span> <span class="type">bigint</span>) <span class="keyword">as</span> window_start</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    dim,</span><br><span class="line">    <span class="comment">-- 将秒级别时间戳 / 60 转化为 1min</span></span><br><span class="line">    <span class="built_in">cast</span>((UNIX_TIMESTAMP(<span class="built_in">CAST</span>(row_time <span class="keyword">AS</span> STRING))) <span class="operator">/</span> <span class="number">60</span> <span class="keyword">as</span> <span class="type">bigint</span>)</span><br></pre></td></tr></table></figure>

<p>确实没错，上面这个转换是一点问题都没有的。</p>
<p>但是窗口聚合和 Group by 聚合的差异在于：</p>
<ul>
<li><p>⭐ 本质区别：窗口聚合是具有时间语义的，其本质是想实现窗口结束输出结果之后，后续有迟到的数据也不会对原有的结果发生更改了，即输出结果值是定值（不考虑 allowLateness）。而 Group by 聚合是没有时间语义的，不管数据迟到多长时间，只要数据来了，就把上一次的输出的结果数据撤回，然后把计算好的新的结果数据发出</p>
</li>
<li><p>⭐ 运行层面：窗口聚合是和 <code>时间</code> 绑定的，窗口聚合其中窗口的计算结果触发都是由时间（Watermark）推动的。Group by 聚合完全由数据推动触发计算，新来一条数据去根据这条数据进行计算出结果发出；由此可见两者的实现方式也大为不同。</p>
</li>
</ul>
<ol start="3">
<li>⭐ <code>SQL 语义</code></li>
</ol>
<p>也是拿离线和实时做对比，Orders 为 kafka，target_table 为 Kafka，这个 SQL 生成的实时任务，在执行时，会生成三个算子：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：数据源算子一直运行，实时的从 Order Kafka 中一条一条的读取数据，然后一条一条发送给下游的 <code>Group 聚合算子</code>，向下游发送数据的 shuffle 策略是根据 group by 中的 key 进行发送，相同的 key 发到同一个 SubTask（并发） 中</li>
<li>⭐ <code>Group 聚合算子</code>（group by key + sum\count\max\min）：接收到上游算子发的一条一条的数据，去状态 state 中找这个 key 之前的 sum\count\max\min 结果。如果有结果 <code>oldResult</code>，拿出来和当前的数据进行 <code>sum\count\max\min</code> 计算出这个 key 的新结果 <code>newResult</code>，并将新结果 <code>[key, newResult]</code> 更新到 state 中，在向下游发送新计算的结果之前，先发一条撤回上次结果的消息 <code>-[key, oldResult]</code>，然后再将新结果发往下游 <code>+[key, newResult]</code>；如果 state 中没有当前 key 的结果，则直接使用当前这条数据计算 sum\max\min 结果 <code>newResult</code>，并将新结果 <code>[key, newResult]</code> 更新到 state 中，当前是第一次往下游发，则不需要先发回撤消息，直接发送 <code>+[key, newResult]</code>。</li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游发的一条一条的数据，写入到 target_table Kafka 中</li>
</ul>
<p>这个实时任务也是 24 小时一直在运行的，所有的算子在同一时刻都是处于 running 状态的。</p>
<blockquote>
<p>特别注意：</p>
<ol>
<li>Group by 聚合涉及到了回撤流（也叫 retract 流），会产生回撤流是因为从整个 SQL 的语义来看，上游的 Kafka 数据是源源不断的，无穷无尽的，那么每次这个 SQL 任务产出的结果都是一个中间结果，所以每次结果发生更新时，都需要将上一次发出的中间结果给撤回，然后将最新的结果发下去。</li>
<li>Group by 聚合涉及到了状态：状态大小也取决于不同 key 的数量。为了防止状态无限变大，我们可以设置状态的 TTL。以上面的 SQL 为例，上面 SQL 是按照分钟进行聚合的，理论上到了今天，通常我们就可以不用关心昨天的数据了，那么我们可以设置状态过期时间为一天。关于状态过期时间的设置参数可以参考下文 <code>运行时参数</code> 小节。</li>
</ol>
</blockquote>
<p>如果这个 SQL 放在 Hive 中执行时，其中 Orders 为 Hive，target_table 也为 Hive，其也会生成三个相同的算子，但是其和实时任务的执行方式完全不同：</p>
<ul>
<li>⭐ <code>数据源算子</code>（From Order）：数据源算子从 Order Hive 中读取到所有的数据，然后所有数据发送给下游的 <code>Group 聚合算子</code>，向下游发送数据的 shuffle 策略是根据 group by 中的 key 进行发送，相同的 key 发到同一个算子中，然后这个算子就运行结束了，释放资源了</li>
<li>⭐ <code>Group 聚合算子</code>（group by + sum\count\max\min）：接收到上游算子发的所有数据，然后遍历计算 sum\count\max\min 结果，批量发给下游 <code>数据汇算子</code>，这个算子也就运行结束了，释放资源了</li>
<li>⭐ <code>数据汇算子</code>（INSERT INTO target_table）：接收到上游发的一条一条的数据，写入到 target_table Hive 中，整个任务也就运行结束了，整个任务的资源也就都释放了</li>
</ul>
<h3 id="3-6-1-Group-聚合支持-Grouping-sets、Rollup、Cube"><a href="#3-6-1-Group-聚合支持-Grouping-sets、Rollup、Cube" class="headerlink" title="3.6.1.Group 聚合支持 Grouping sets、Rollup、Cube"></a>3.6.1.Group 聚合支持 Grouping sets、Rollup、Cube</h3><p>Group 聚合也支持 <code>Grouping sets</code>、<code>Rollup</code>、<code>Cube</code></p>
<p>举一个 <code>Grouping sets</code> 的案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    supplier_id</span><br><span class="line">    , rating</span><br><span class="line">    , product_id</span><br><span class="line">    , <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> (<span class="keyword">VALUES</span></span><br><span class="line">    (<span class="string">&#x27;supplier1&#x27;</span>, <span class="string">&#x27;product1&#x27;</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="string">&#x27;supplier1&#x27;</span>, <span class="string">&#x27;product2&#x27;</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="string">&#x27;supplier2&#x27;</span>, <span class="string">&#x27;product3&#x27;</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="string">&#x27;supplier2&#x27;</span>, <span class="string">&#x27;product4&#x27;</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">AS</span> Products(supplier_id, product_id, rating)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">GROUPING</span> <span class="keyword">SET</span> (</span><br><span class="line">    ( supplier_id, product_id, rating ),</span><br><span class="line">    ( supplier_id, product_id         ),</span><br><span class="line">    ( supplier_id,             rating ),</span><br><span class="line">    ( supplier_id                     ),</span><br><span class="line">    (              product_id, rating ),</span><br><span class="line">    (              product_id         ),</span><br><span class="line">    (                          rating ),</span><br><span class="line">    (                                 )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="3-7-DML：Over-聚合"><a href="#3-7-DML：Over-聚合" class="headerlink" title="3.7.DML：Over 聚合"></a>3.7.DML：Over 聚合</h2><ol>
<li>⭐ Over 聚合定义（支持 Batch\Streaming）：可以理解为是一种特殊的滑动窗口聚合函数。</li>
</ol>
<p>那这里我们拿 <code>Over 聚合</code> 与 <code>窗口聚合</code> 做一个对比，其之间的最大不同之处在于：</p>
<ul>
<li>⭐ 窗口聚合：不在 group by 中的字段，不能直接在 select 中拿到</li>
<li>⭐ Over 聚合：能够保留原始字段</li>
</ul>
<blockquote>
<p>注意：</p>
<p>其实在生产环境中，Over 聚合的使用场景还是比较少的。在 Hive 中也有相同的聚合，但是小伙伴萌可以想想你在离线数仓经常使用嘛？</p>
</blockquote>
<ol start="2">
<li><p>⭐ 应用场景：计算最近一段滑动窗口的聚合结果数据。</p>
</li>
<li><p>⭐ 实际案例：查询每个产品最近一小时订单的金额总和：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> order_id, order_time, amount,</span><br><span class="line">  <span class="built_in">SUM</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">    <span class="keyword">PARTITION</span> <span class="keyword">BY</span> product</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_time</span><br><span class="line">    <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">HOUR</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">  ) <span class="keyword">AS</span> one_hour_prod_amount_sum</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br></pre></td></tr></table></figure>

<p>Over 聚合的语法总结如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  agg_func(agg_col) <span class="keyword">OVER</span> (</span><br><span class="line">    [<span class="keyword">PARTITION</span> <span class="keyword">BY</span> col1[, col2, ...]]</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> time_col</span><br><span class="line">    range_definition),</span><br><span class="line">  ...</span><br><span class="line"><span class="keyword">FROM</span> ...</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>⭐ ORDER BY：必须是时间戳列（事件时间、处理时间）</li>
<li>⭐ PARTITION BY：标识了聚合窗口的聚合粒度，如上述案例是按照 product 进行聚合</li>
<li>⭐ range_definition：这个标识聚合窗口的聚合数据范围，在 Flink 中有两种指定数据范围的方式。第一种为 <code>按照行数聚合</code>，第二种为 <code>按照时间区间聚合</code>。如下案例所示：</li>
</ul>
<p>a. ⭐ 时间区间聚合：</p>
<p>按照时间区间聚合就是时间区间的一个滑动窗口，比如下面案例 1 小时的区间，最新输出的一条数据的 sum 聚合结果就是最近一小时数据的 amount 之和。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    order_id <span class="type">BIGINT</span>,</span><br><span class="line">    product <span class="type">BIGINT</span>,</span><br><span class="line">    amount <span class="type">BIGINT</span>,</span><br><span class="line">    order_time <span class="keyword">as</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">TIMESTAMP</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;0.001&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.order_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.order_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.amount.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.amount.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.product.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.product.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    product <span class="type">BIGINT</span>,</span><br><span class="line">    order_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    amount <span class="type">BIGINT</span>,</span><br><span class="line">    one_hour_prod_amount_sum <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> product, order_time, amount,</span><br><span class="line">  <span class="built_in">SUM</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">    <span class="keyword">PARTITION</span> <span class="keyword">BY</span> product</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_time</span><br><span class="line">    <span class="comment">-- 标识统计范围是一个 product 的最近 1 小时的数据</span></span><br><span class="line">    <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">HOUR</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">  ) <span class="keyword">AS</span> one_hour_prod_amount_sum</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+I[2, 2021-12-24T22:08:26.583, 7, 73]</span><br><span class="line">+I[2, 2021-12-24T22:08:27.583, 7, 80]</span><br><span class="line">+I[2, 2021-12-24T22:08:28.583, 4, 84]</span><br><span class="line">+I[2, 2021-12-24T22:08:29.584, 7, 91]</span><br><span class="line">+I[2, 2021-12-24T22:08:30.583, 8, 99]</span><br><span class="line">+I[1, 2021-12-24T22:08:31.583, 9, 138]</span><br><span class="line">+I[2, 2021-12-24T22:08:32.584, 6, 105]</span><br><span class="line">+I[1, 2021-12-24T22:08:33.584, 7, 145]</span><br></pre></td></tr></table></figure>

<p>b. ⭐ 行数聚合：</p>
<p>按照行数聚合就是数据行数的一个滑动窗口，比如下面案例，最新输出的一条数据的 sum 聚合结果就是最近 5 行数据的 amount 之和。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    order_id <span class="type">BIGINT</span>,</span><br><span class="line">    product <span class="type">BIGINT</span>,</span><br><span class="line">    amount <span class="type">BIGINT</span>,</span><br><span class="line">    order_time <span class="keyword">as</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">TIMESTAMP</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;0.001&#x27;</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.order_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.order_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.amount.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.amount.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.product.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.product.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    product <span class="type">BIGINT</span>,</span><br><span class="line">    order_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    amount <span class="type">BIGINT</span>,</span><br><span class="line">    one_hour_prod_amount_sum <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> product, order_time, amount,</span><br><span class="line">  <span class="built_in">SUM</span>(amount) <span class="keyword">OVER</span> (</span><br><span class="line">    <span class="keyword">PARTITION</span> <span class="keyword">BY</span> product</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_time</span><br><span class="line">    <span class="comment">-- 标识统计范围是一个 product 的最近 5 行数据</span></span><br><span class="line">    <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">5</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span></span><br><span class="line">  ) <span class="keyword">AS</span> one_hour_prod_amount_sum</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br></pre></td></tr></table></figure>

<p>预跑结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+I[2, 2021-12-24T22:18:19.147, 1, 9]</span><br><span class="line">+I[1, 2021-12-24T22:18:20.147, 2, 11]</span><br><span class="line">+I[1, 2021-12-24T22:18:21.147, 2, 12]</span><br><span class="line">+I[1, 2021-12-24T22:18:22.147, 2, 12]</span><br><span class="line">+I[1, 2021-12-24T22:18:23.148, 2, 12]</span><br><span class="line">+I[1, 2021-12-24T22:18:24.147, 1, 11]</span><br><span class="line">+I[1, 2021-12-24T22:18:25.146, 1, 10]</span><br><span class="line">+I[1, 2021-12-24T22:18:26.147, 1, 9]</span><br><span class="line">+I[2, 2021-12-24T22:18:27.145, 2, 11]</span><br><span class="line">+I[2, 2021-12-24T22:18:28.148, 1, 10]</span><br><span class="line">+I[2, 2021-12-24T22:18:29.145, 2, 10]</span><br></pre></td></tr></table></figure>

<p>当然，如果你在一个 SELECT 中有多个聚合窗口的聚合方式，Flink SQL 支持了一种简化写法，如下案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> order_id, order_time, amount,</span><br><span class="line">  <span class="built_in">SUM</span>(amount) <span class="keyword">OVER</span> w <span class="keyword">AS</span> sum_amount,</span><br><span class="line">  <span class="built_in">AVG</span>(amount) <span class="keyword">OVER</span> w <span class="keyword">AS</span> avg_amount</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="comment">-- 使用下面子句，定义 Over Window</span></span><br><span class="line"><span class="keyword">WINDOW</span> w <span class="keyword">AS</span> (</span><br><span class="line">  <span class="keyword">PARTITION</span> <span class="keyword">BY</span> product</span><br><span class="line">  <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_time</span><br><span class="line">  <span class="keyword">RANGE</span> <span class="keyword">BETWEEN</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">HOUR</span> PRECEDING <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="type">ROW</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-8-DML：Joins"><a href="#3-8-DML：Joins" class="headerlink" title="3.8.DML：Joins"></a>3.8.DML：Joins</h2><p>Flink 也支持了非常多的数据 Join 方式，主要包括以下三种：</p>
<ol>
<li>⭐ 动态表（流）与动态表（流）的 Join</li>
<li>⭐ 动态表（流）与外部维表（比如 Redis）的 Join</li>
<li>⭐ 动态表字段的列转行（一种特殊的 Join）</li>
</ol>
<p>细分 Flink SQL 支持的 Join：</p>
<ol>
<li>⭐ Regular Join：流与流的 Join，包括 Inner Equal Join、Outer Equal Join</li>
<li>⭐ Interval Join：流与流的 Join，两条流一段时间区间内的 Join</li>
<li>⭐ Temporal Join：流与流的 Join，包括事件时间，处理时间的 Temporal Join，类似于离线中的快照 Join</li>
<li>⭐ Lookup Join：流与外部维表的 Join</li>
<li>⭐ Array Expansion：表字段的列转行，类似于 Hive 的 explode 数据炸开的列转行</li>
<li>⭐ Table Function：自定义函数的表字段的列转行，支持 Inner Join 和 Left Outer Join</li>
</ol>
<h3 id="3-8-1-Regular-Join"><a href="#3-8-1-Regular-Join" class="headerlink" title="3.8.1.Regular Join"></a>3.8.1.Regular Join</h3><ol>
<li><p>⭐ Regular Join 定义（支持 Batch\Streaming）：Regular Join 其实就是和离线 Hive SQL 一样的 Regular Join，通过条件关联两条流数据输出。</p>
</li>
<li><p>⭐ 应用场景：Join 其实在我们的数仓建设过程中应用是非常广泛的。离线数仓可以说基本上是离不开 Join 的。那么实时数仓的建设也必然离不开 Join，比如日志关联扩充维度数据，构建宽表；日志通过 ID 关联计算 CTR。</p>
</li>
<li><p>⭐ Regular Join 包含以下几种（以 <code>L</code> 作为左流中的数据标识，<code>R</code> 作为右流中的数据标识）：</p>
</li>
</ol>
<ul>
<li>⭐ Inner Join（Inner Equal Join）：流任务中，只有两条流 Join 到才输出，输出 <code>+[L, R]</code></li>
<li>⭐ Left Join（Outer Equal Join）：流任务中，左流数据到达之后，无论有没有 Join 到右流的数据，都会输出（Join 到输出 <code>+[L, R]</code>，没 Join 到输出 <code>+[L, null]</code>），如果右流之后数据到达之后，发现左流之前输出过没有 Join 到的数据，则会发起回撤流，先输出 <code>-[L, null]</code>，然后输出 <code>+[L, R]</code></li>
<li>⭐ Right Join（Outer Equal Join）：有 Left Join 一样，左表和右表的执行逻辑完全相反</li>
<li>⭐ Full Join（Outer Equal Join）：流任务中，左流或者右流的数据到达之后，无论有没有 Join 到另外一条流的数据，都会输出（对右流来说：Join 到输出 <code>+[L, R]</code>，没 Join 到输出 <code>+[null, R]</code>；对左流来说：Join 到输出 <code>+[L, R]</code>，没 Join 到输出 <code>+[L, null]</code>）。如果一条流的数据到达之后，发现之前另一条流之前输出过没有 Join 到的数据，则会发起回撤流（左流数据到达为例：回撤 <code>-[null, R]</code>，输出 <code>+[L, R]</code>，右流数据到达为例：回撤 <code>-[L, null]</code>，输出 <code>+[L, R]</code>）。</li>
</ul>
<ol start="4">
<li>⭐ 实际案例：案例为曝光日志关联点击日志筛选既有曝光又有点击的数据，并且补充点击的扩展参数（show inner click）：</li>
</ol>
<p>下面这个案例为 <code>Inner Join 案例</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 曝光日志数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.show_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 点击日志数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> click_log_table (</span><br><span class="line">  log_id <span class="type">BIGINT</span>,</span><br><span class="line">  click_params     STRING</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.click_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    s_id <span class="type">BIGINT</span>,</span><br><span class="line">    s_params STRING,</span><br><span class="line">    c_id <span class="type">BIGINT</span>,</span><br><span class="line">    c_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 流的 INNER JOIN，条件为 log_id</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    show_log_table.log_id <span class="keyword">as</span> s_id,</span><br><span class="line">    show_log_table.show_params <span class="keyword">as</span> s_params,</span><br><span class="line">    click_log_table.log_id <span class="keyword">as</span> c_id,</span><br><span class="line">    click_log_table.click_params <span class="keyword">as</span> c_params</span><br><span class="line"><span class="keyword">FROM</span> show_log_table</span><br><span class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> click_log_table <span class="keyword">ON</span> show_log_table.log_id <span class="operator">=</span> click_log_table.log_id;</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+I[5, d, 5, f]</span><br><span class="line">+I[5, d, 5, 8]</span><br><span class="line">+I[5, d, 5, 2]</span><br><span class="line">+I[3, 4, 3, 0]</span><br><span class="line">+I[3, 4, 3, 3]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>


<p>如果为 <code>Left Join</code> 案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.show_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;3&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> click_log_table (</span><br><span class="line">  log_id <span class="type">BIGINT</span>,</span><br><span class="line">  click_params     STRING</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.click_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;3&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    s_id <span class="type">BIGINT</span>,</span><br><span class="line">    s_params STRING,</span><br><span class="line">    c_id <span class="type">BIGINT</span>,</span><br><span class="line">    c_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    show_log_table.log_id <span class="keyword">as</span> s_id,</span><br><span class="line">    show_log_table.show_params <span class="keyword">as</span> s_params,</span><br><span class="line">    click_log_table.log_id <span class="keyword">as</span> c_id,</span><br><span class="line">    click_log_table.click_params <span class="keyword">as</span> c_params</span><br><span class="line"><span class="keyword">FROM</span> show_log_table</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> click_log_table <span class="keyword">ON</span> show_log_table.log_id <span class="operator">=</span> click_log_table.log_id;</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+I[5, f3c, 5, c05]</span><br><span class="line">+I[5, 6e2, 5, 1f6]</span><br><span class="line">+I[5, 86b, 5, 1f6]</span><br><span class="line">+I[5, f3c, 5, 1f6]</span><br><span class="line">-D[3, 4ab, null, null]</span><br><span class="line">-D[3, 6f2, null, null]</span><br><span class="line">+I[3, 4ab, 3, 765]</span><br><span class="line">+I[3, 6f2, 3, 765]</span><br><span class="line">+I[2, 3c4, null, null]</span><br><span class="line">+I[3, 4ab, 3, a8b]</span><br><span class="line">+I[3, 6f2, 3, a8b]</span><br><span class="line">+I[2, c03, null, null]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果为 <code>Full Join</code> 案例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.show_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> click_log_table (</span><br><span class="line">  log_id <span class="type">BIGINT</span>,</span><br><span class="line">  click_params     STRING</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;2&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.click_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    s_id <span class="type">BIGINT</span>,</span><br><span class="line">    s_params STRING,</span><br><span class="line">    c_id <span class="type">BIGINT</span>,</span><br><span class="line">    c_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    show_log_table.log_id <span class="keyword">as</span> s_id,</span><br><span class="line">    show_log_table.show_params <span class="keyword">as</span> s_params,</span><br><span class="line">    click_log_table.log_id <span class="keyword">as</span> c_id,</span><br><span class="line">    click_log_table.click_params <span class="keyword">as</span> c_params</span><br><span class="line"><span class="keyword">FROM</span> show_log_table</span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">JOIN</span> click_log_table <span class="keyword">ON</span> show_log_table.log_id <span class="operator">=</span> click_log_table.log_id;</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+I[null, null, 7, 6]</span><br><span class="line">+I[6, 5, null, null]</span><br><span class="line">-D[1, c, null, null]</span><br><span class="line">+I[1, c, 1, 2]</span><br><span class="line">+I[3, 1, null, null]</span><br><span class="line">+I[null, null, 7, d]</span><br><span class="line">+I[10, 0, null, null]</span><br><span class="line">+I[null, null, 2, 6]</span><br><span class="line">-D[null, null, 7, 6]</span><br><span class="line">-D[null, null, 7, d]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<blockquote>
<p>关于 Regular Join 的注意事项：</p>
<ul>
<li><p>⭐ 实时 Regular Join 可以不是 <code>等值 join</code>。<code>等值 join</code> 和 <code>非等值 join</code> 区别在于，<code>等值 join</code> 数据 shuffle 策略是 Hash，会按照 Join on 中的等值条件作为 id 发往对应的下游；<code>非等值 join</code> 数据 shuffle 策略是 Global，所有数据发往一个并发，按照非等值条件进行关联</p>
</li>
<li><p>⭐ Join 的流程是左流新来一条数据之后，会和右流中符合条件的所有数据做 Join，然后输出。</p>
</li>
<li><p>⭐ 流的上游是无限的数据，所以要做到关联的话，Flink 会将两条流的所有数据都存储在 State 中，所以 Flink 任务的 State 会无限增大，因此你需要为 State 配置合适的 TTL，以防止 State 过大。</p>
</li>
</ul>
</blockquote>
<ol start="5">
<li>⭐ <code>SQL 语义</code>：</li>
</ol>
<p>详细的 SQL 语义案例可以参考：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Z8QfKfhrX5KEnR-s7gRtsA">https://mp.weixin.qq.com/s/Z8QfKfhrX5KEnR-s7gRtsA</a></p>
<h3 id="3-8-2-Interval-Join（时间区间-Join）"><a href="#3-8-2-Interval-Join（时间区间-Join）" class="headerlink" title="3.8.2.Interval Join（时间区间 Join）"></a>3.8.2.Interval Join（时间区间 Join）</h3><ol>
<li><p>⭐ Interval Join 定义（支持 Batch\Streaming）：Interval Join 在离线的概念中是没有的。Interval Join 可以让一条流去 Join 另一条流中前后一段时间内的数据。</p>
</li>
<li><p>⭐ 应用场景：为什么有 Regular Join 还要 Interval Join 呢？刚刚的案例也讲了，Regular Join 会产生回撤流，但是在实时数仓中一般写入的 sink 都是类似于 Kafka 这样的消息队列，然后后面接 clickhouse 等引擎，这些引擎又不具备处理回撤流的能力。所以博主理解 Interval Join 就是用于消灭回撤流的。</p>
</li>
<li><p>⭐ Interval Join 包含以下几种（以 <code>L</code> 作为左流中的数据标识，<code>R</code> 作为右流中的数据标识）：</p>
</li>
</ol>
<ul>
<li>⭐ Inner Interval Join：流任务中，只有两条流 Join 到（满足 Join on 中的条件：两条流的数据在时间区间 + 满足其他等值条件）才输出，输出 <code>+[L, R]</code></li>
<li>⭐ Left Interval Join：流任务中，左流数据到达之后，如果没有 Join 到右流的数据，就会等待（放在 State 中等），如果之后右流之后数据到达之后，发现能和刚刚那条左流数据 Join 到，则会输出 <code>+[L, R]</code>。事件时间中随着 Watermark 的推进（也支持处理时间）。如果发现发现左流 State 中的数据过期了，就把左流中过期的数据从 State 中删除，然后输出 <code>+[L, null]</code>，如果右流 State 中的数据过期了，就直接从 State 中删除。</li>
<li>⭐ Right Interval Join：和 Left Interval Join 执行逻辑一样，只不过左表和右表的执行逻辑完全相反</li>
<li>⭐ Full Interval Join：流任务中，左流或者右流的数据到达之后，如果没有 Join 到另外一条流的数据，就会等待（左流放在左流对应的 State 中等，右流放在右流对应的 State 中等），如果之后另一条流数据到达之后，发现能和刚刚那条数据 Join 到，则会输出 <code>+[L, R]</code>。事件时间中随着 Watermark 的推进（也支持处理时间），发现 State 中的数据能够过期了，就将这些数据从 State 中删除并且输出（左流过期输出 <code>+[L, null]</code>，右流过期输出 <code>-[null, R]</code>）</li>
</ul>
<p>可以发现 Inner Interval Join 和其他三种 Outer Interval Join 的区别在于，Outer 在随着时间推移的过程中，如果有数据过期了之后，会根据是否是 Outer 将没有 Join 到的数据也给输出。</p>
<ol start="4">
<li>⭐ 实际案例：还是刚刚的案例，曝光日志关联点击日志筛选既有曝光又有点击的数据，条件是曝光关联之后发生 4 小时之内的点击，并且补充点击的扩展参数（show inner interval click）：</li>
</ol>
<p>下面为 <code>Inner Interval Join</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params STRING,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.show_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> click_log_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    click_params STRING,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.click_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    s_id <span class="type">BIGINT</span>,</span><br><span class="line">    s_params STRING,</span><br><span class="line">    c_id <span class="type">BIGINT</span>,</span><br><span class="line">    c_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    show_log_table.log_id <span class="keyword">as</span> s_id,</span><br><span class="line">    show_log_table.show_params <span class="keyword">as</span> s_params,</span><br><span class="line">    click_log_table.log_id <span class="keyword">as</span> c_id,</span><br><span class="line">    click_log_table.click_params <span class="keyword">as</span> c_params</span><br><span class="line"><span class="keyword">FROM</span> show_log_table <span class="keyword">INNER</span> <span class="keyword">JOIN</span> click_log_table <span class="keyword">ON</span> show_log_table.log_id <span class="operator">=</span> click_log_table.log_id</span><br><span class="line"><span class="keyword">AND</span> show_log_table.row_time <span class="keyword">BETWEEN</span> click_log_table.row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;4&#x27;</span> <span class="keyword">HOUR</span> <span class="keyword">AND</span> click_log_table.row_time;</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">6&gt;</span><span class="bash"> +I[2, a, 2, 6]</span></span><br><span class="line"><span class="meta">6&gt;</span><span class="bash"> +I[2, 6, 2, 6]</span></span><br><span class="line"><span class="meta">2&gt;</span><span class="bash"> +I[4, 1, 4, 5]</span></span><br><span class="line"><span class="meta">2&gt;</span><span class="bash"> +I[10, 8, 10, d]</span></span><br><span class="line"><span class="meta">2&gt;</span><span class="bash"> +I[10, 7, 10, d]</span></span><br><span class="line"><span class="meta">2&gt;</span><span class="bash"> +I[10, d, 10, d]</span></span><br><span class="line"><span class="meta">2&gt;</span><span class="bash"> +I[5, b, 5, d]</span></span><br><span class="line"><span class="meta">6&gt;</span><span class="bash"> +I[1, a, 1, 7]</span></span><br></pre></td></tr></table></figure>

<p>如果是 <code>Left Interval Join</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params STRING,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.show_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> click_log (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    click_params STRING,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.click_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    s_id <span class="type">BIGINT</span>,</span><br><span class="line">    s_params STRING,</span><br><span class="line">    c_id <span class="type">BIGINT</span>,</span><br><span class="line">    c_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    show_log.log_id <span class="keyword">as</span> s_id,</span><br><span class="line">    show_log.show_params <span class="keyword">as</span> s_params,</span><br><span class="line">    click_log.log_id <span class="keyword">as</span> c_id,</span><br><span class="line">    click_log.click_params <span class="keyword">as</span> c_params</span><br><span class="line"><span class="keyword">FROM</span> show_log <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> click_log <span class="keyword">ON</span> show_log.log_id <span class="operator">=</span> click_log.log_id</span><br><span class="line"><span class="keyword">AND</span> show_log.row_time <span class="keyword">BETWEEN</span> click_log.row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span> <span class="keyword">AND</span> click_log.row_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>;</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+I[6, e, 6, 7]</span><br><span class="line">+I[11, d, null, null]</span><br><span class="line">+I[7, b, null, null]</span><br><span class="line">+I[8, 0, 8, 3]</span><br><span class="line">+I[13, 6, null, null]</span><br></pre></td></tr></table></figure>

<p>如果是 <code>Full Interval Join</code>：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params STRING,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.show_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;15&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> click_log (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    click_params STRING,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.click_params.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    s_id <span class="type">BIGINT</span>,</span><br><span class="line">    s_params STRING,</span><br><span class="line">    c_id <span class="type">BIGINT</span>,</span><br><span class="line">    c_params STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    show_log.log_id <span class="keyword">as</span> s_id,</span><br><span class="line">    show_log.show_params <span class="keyword">as</span> s_params,</span><br><span class="line">    click_log.log_id <span class="keyword">as</span> c_id,</span><br><span class="line">    click_log.click_params <span class="keyword">as</span> c_params</span><br><span class="line"><span class="keyword">FROM</span> show_log <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> click_log <span class="keyword">ON</span> show_log.log_id <span class="operator">=</span> click_log.log_id</span><br><span class="line"><span class="keyword">AND</span> show_log.row_time <span class="keyword">BETWEEN</span> click_log.row_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span> <span class="keyword">AND</span> click_log.row_time <span class="operator">+</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span>;</span><br></pre></td></tr></table></figure>

<p>输出结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+I[6, 1, null, null]</span><br><span class="line">+I[7, 3, 7, 8]</span><br><span class="line">+I[null, null, 6, 6]</span><br><span class="line">+I[null, null, 4, d]</span><br><span class="line">+I[8, d, null, null]</span><br><span class="line">+I[null, null, 3, b]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>关于 Interval Join 的注意事项：</p>
<p>⭐ 实时 Interval Join 可以不是 <code>等值 join</code>。<code>等值 join</code> 和 <code>非等值 join</code> 区别在于，<code>等值 join</code> 数据 shuffle 策略是 Hash，会按照 Join on 中的等值条件作为 id 发往对应的下游；<code>非等值 join</code> 数据 shuffle 策略是 Global，所有数据发往一个并发，然后将满足条件的数据进行关联输出</p>
</blockquote>
<ol start="5">
<li>⭐ SQL 语义：</li>
</ol>
<p>关于详细的 SQL 语义可以参考。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/p9Y9qzqMgd8DTs9Fw_25kA">https://mp.weixin.qq.com/s/p9Y9qzqMgd8DTs9Fw_25kA</a></p>
<h3 id="3-8-3-Temporal-Join（快照-Join）"><a href="#3-8-3-Temporal-Join（快照-Join）" class="headerlink" title="3.8.3.Temporal Join（快照 Join）"></a>3.8.3.Temporal Join（快照 Join）</h3><ol>
<li><p>⭐ Temporal Join 定义（支持 Batch\Streaming）：Temporal Join 在离线的概念中其实是没有类似的 Join 概念的，但是离线中常常会维护一种表叫做 <code>拉链快照表</code>，使用一个明细表去 join 这个 <code>拉链快照表</code> 的 join 方式就叫做 Temporal Join。而 Flink SQL 中也有对应的概念，表叫做 <code>Versioned Table</code>，使用一个明细表去 join 这个 <code>Versioned Table</code> 的 join 操作就叫做 Temporal Join。Temporal Join 中，<code>Versioned Table</code> 其实就是对同一条 key（在 DDL 中以 primary key 标记同一个 key）的历史版本（根据时间划分版本）做一个维护，当有明细表 Join 这个表时，可以根据明细表中的时间版本选择 <code>Versioned Table</code> 对应时间区间内的快照数据进行 join。</p>
</li>
<li><p>⭐ 应用场景：比如常见的汇率数据（实时的根据汇率计算总金额），在 12:00 之前（事件时间），人民币和美元汇率是 7:1，在 12:00 之后变为 6:1，那么在 12:00 之前数据就要按照 7:1 进行计算，12:00 之后就要按照 6:1 计算。在事件时间语义的任务中，事件时间 12:00 之前的数据，要按照 7:1 进行计算，12:00 之后的数据，要按照 6:1 进行计算。这其实就是离线中快照的概念，维护具体汇率的表在 Flink SQL 体系中就叫做 <code>Versioned Table</code>。</p>
</li>
<li><p>⭐ Verisoned Table：Verisoned Table 中存储的数据通常是来源于 CDC 或者会发生更新的数据。Flink SQL 会为 Versioned Table 维护 Primary Key 下的所有历史时间版本的数据。举一个汇率的场景的案例来看一下一个 Versioned Table 的两种定义方式。</p>
</li>
</ol>
<ul>
<li>⭐ PRIMARY KEY 定义方式：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 定义一个汇率 versioned 表，其中 versioned 表的概念下文会介绍到</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> currency_rates (</span><br><span class="line">    currency STRING,</span><br><span class="line">    conversion_rate <span class="type">DECIMAL</span>(<span class="number">32</span>, <span class="number">2</span>),</span><br><span class="line">    update_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> `values.source.timestamp` VIRTUAL,</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> update_time <span class="keyword">AS</span> update_time,</span><br><span class="line">    <span class="comment">-- PRIMARY KEY 定义方式</span></span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY(currency) <span class="keyword">NOT</span> ENFORCED</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;debezium-json&#x27;</span>,</span><br><span class="line">   <span class="comment">/* ... */</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ Deduplicate 定义方式：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 定义一个 append-only 的数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> currency_rates (</span><br><span class="line">    currency STRING,</span><br><span class="line">    conversion_rate <span class="type">DECIMAL</span>(<span class="number">32</span>, <span class="number">2</span>),</span><br><span class="line">    update_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> `values.source.timestamp` VIRTUAL,</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> update_time <span class="keyword">AS</span> update_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;debezium-json&#x27;</span>,</span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将数据源表按照 Deduplicate 方式定义为 Versioned Table</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> versioned_rates <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> currency, conversion_rate, update_time   <span class="comment">-- 1. 定义 `update_time` 为时间字段</span></span><br><span class="line">  <span class="keyword">FROM</span> (</span><br><span class="line">      <span class="keyword">SELECT</span> <span class="operator">*</span>,</span><br><span class="line">      <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> currency  <span class="comment">-- 2. 定义 `currency` 为主键</span></span><br><span class="line">         <span class="keyword">ORDER</span> <span class="keyword">BY</span> update_time <span class="keyword">DESC</span>              <span class="comment">-- 3. ORDER BY 中必须是时间戳列</span></span><br><span class="line">      ) <span class="keyword">AS</span> rownum </span><br><span class="line">      <span class="keyword">FROM</span> currency_rates)</span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">=</span> <span class="number">1</span>; </span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>⭐ Temporal Join 支持的时间语义：事件时间、处理时间</p>
</li>
<li><p>⭐ 实际案例：就是上文提到的汇率计算。</p>
</li>
</ol>
<p>以 <code>事件时间</code> 任务举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 1. 定义一个输入订单表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orders (</span><br><span class="line">    order_id    STRING,</span><br><span class="line">    price       <span class="type">DECIMAL</span>(<span class="number">32</span>,<span class="number">2</span>),</span><br><span class="line">    currency    STRING,</span><br><span class="line">    order_time  <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time</span><br><span class="line">) <span class="keyword">WITH</span> (<span class="comment">/* ... */</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2. 定义一个汇率 versioned 表，其中 versioned 表的概念下文会介绍到</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> currency_rates (</span><br><span class="line">    currency STRING,</span><br><span class="line">    conversion_rate <span class="type">DECIMAL</span>(<span class="number">32</span>, <span class="number">2</span>),</span><br><span class="line">    update_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> `values.source.timestamp` VIRTUAL,</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> update_time <span class="keyword">AS</span> update_time,</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY(currency) <span class="keyword">NOT</span> ENFORCED</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;debezium-json&#x27;</span>,</span><br><span class="line">   <span class="comment">/* ... */</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">     order_id,</span><br><span class="line">     price,</span><br><span class="line">     currency,</span><br><span class="line">     conversion_rate,</span><br><span class="line">     order_time,</span><br><span class="line"><span class="keyword">FROM</span> orders</span><br><span class="line"><span class="comment">-- 3. Temporal Join 逻辑</span></span><br><span class="line"><span class="comment">-- SQL 语法为：FOR SYSTEM_TIME AS OF</span></span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> currency_rates <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> orders.order_time</span><br><span class="line"><span class="keyword">ON</span> orders.currency <span class="operator">=</span> currency_rates.currency;</span><br></pre></td></tr></table></figure>

<p>结果如下，可以看到相同的货币汇率会根据具体数据的事件时间不同 Join 到对应时间的汇率：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">order_id  price  货币       汇率             order_time</span><br><span class="line">========  =====  ========  ===============  =========</span><br><span class="line">o_001     11.11  EUR       1.14             12:00:00</span><br><span class="line">o_002     12.51  EUR       1.10             12:06:00</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<ol>
<li>⭐ 事件时间的 Temporal Join 一定要给左右两张表都设置 Watermark。</li>
<li>⭐ 事件时间的 Temporal Join 一定要把 Versioned Table 的主键包含在 Join on 的条件中。</li>
</ol>
</blockquote>
<p>还是相同的案例，如果是 <code>处理时间</code> 语义：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10</span>:<span class="number">15</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> LatestRates;</span><br><span class="line"></span><br><span class="line">currency   rate</span><br><span class="line"><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span></span><br><span class="line">US Dollar   <span class="number">102</span></span><br><span class="line">Euro        <span class="number">114</span></span><br><span class="line">Yen           <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">10</span>:<span class="number">30</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> LatestRates;</span><br><span class="line"></span><br><span class="line">currency   rate</span><br><span class="line"><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span></span><br><span class="line">US Dollar   <span class="number">102</span></span><br><span class="line">Euro        <span class="number">114</span></span><br><span class="line">Yen           <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 10:42 时，Euro 的汇率从 114 变为 116</span></span><br><span class="line"><span class="number">10</span>:<span class="number">52</span><span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> LatestRates;</span><br><span class="line"></span><br><span class="line">currency   rate</span><br><span class="line"><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span></span><br><span class="line">US Dollar   <span class="number">102</span></span><br><span class="line">Euro        <span class="number">116</span>     <span class="operator">&lt;=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> 从 <span class="number">114</span> 变为 <span class="number">116</span></span><br><span class="line">Yen           <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从 Orders 表查询数据</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Orders;</span><br><span class="line"></span><br><span class="line">amount currency</span><br><span class="line"><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span></span><br><span class="line">     <span class="number">2</span> Euro             <span class="operator">&lt;=</span><span class="operator">=</span> 在处理时间 <span class="number">10</span>:<span class="number">15</span> 到达的一条数据</span><br><span class="line">     <span class="number">1</span> US Dollar        <span class="operator">&lt;=</span><span class="operator">=</span> 在处理时间 <span class="number">10</span>:<span class="number">30</span> 到达的一条数据</span><br><span class="line">     <span class="number">2</span> Euro             <span class="operator">&lt;=</span><span class="operator">=</span> 在处理时间 <span class="number">10</span>:<span class="number">52</span> 到达的一条数据</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行关联查询</span></span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  o.amount, o.currency, r.rate, o.amount <span class="operator">*</span> r.rate</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">  Orders <span class="keyword">AS</span> o</span><br><span class="line">  <span class="keyword">JOIN</span> LatestRates <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> o.proctime <span class="keyword">AS</span> r</span><br><span class="line">  <span class="keyword">ON</span> r.currency <span class="operator">=</span> o.currency</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 结果如下：</span></span><br><span class="line">amount currency     rate   amount<span class="operator">*</span>rate</span><br><span class="line"><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span> <span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span><span class="operator">=</span></span><br><span class="line">     <span class="number">2</span> Euro          <span class="number">114</span>          <span class="number">228</span>    <span class="operator">&lt;=</span><span class="operator">=</span> 在处理时间 <span class="number">10</span>:<span class="number">15</span> 到达的一条数据</span><br><span class="line">     <span class="number">1</span> US Dollar     <span class="number">102</span>          <span class="number">102</span>    <span class="operator">&lt;=</span><span class="operator">=</span> 在处理时间 <span class="number">10</span>:<span class="number">30</span> 到达的一条数据</span><br><span class="line">     <span class="number">2</span> Euro          <span class="number">116</span>          <span class="number">232</span>    <span class="operator">&lt;=</span><span class="operator">=</span> 在处理时间 <span class="number">10</span>:<span class="number">52</span> 到达的一条数据</span><br></pre></td></tr></table></figure>

<p>可以发现处理时间就比较好理解了，因为处理时间语义中是根据左流数据到达的时间决定拿到的汇率值。Flink 就只为 LatestRates 维护了最新的状态数据，不需要关心历史版本的数据。</p>
<h3 id="3-8-4-Lookup-Join（维表-Join）"><a href="#3-8-4-Lookup-Join（维表-Join）" class="headerlink" title="3.8.4.Lookup Join（维表 Join）"></a>3.8.4.Lookup Join（维表 Join）</h3><ol>
<li><p>⭐ Lookup Join 定义（支持 Batch\Streaming）：Lookup Join 其实就是维表 Join，比如拿离线数仓来说，常常会有用户画像，设备画像等数据，而对应到实时数仓场景中，这种实时获取外部缓存的 Join 就叫做维表 Join。</p>
</li>
<li><p>⭐ 应用场景：小伙伴萌会问，我们既然已经有了上面介绍的 Regular Join，Interval Join 等，为啥还需要一种 Lookup Join？因为上面说的这几种 Join 都是流与流之间的 Join，而 Lookup Join 是流与 Redis，Mysql，HBase 这种存储介质的 Join。Lookup 的意思就是实时查找，而实时的画像数据一般都是存储在 Redis，Mysql，HBase 中，这就是 Lookup Join 的由来</p>
</li>
<li><p>⭐ 实际案例：使用曝光用户日志流（show_log）关联用户画像维表（user_profile）关联到用户的维度之后，提供给下游计算分性别，年龄段的曝光用户数使用。</p>
</li>
</ol>
<p>来一波输入数据：</p>
<p>曝光用户日志流（show_log）数据（数据存储在 kafka 中）：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">log_id	timestamp	        user_id</span><br><span class="line">1       2021-11-01 00:01:03	a</span><br><span class="line">2       2021-11-01 00:03:00	b</span><br><span class="line">3       2021-11-01 00:05:00	c</span><br><span class="line">4       2021-11-01 00:06:00	b</span><br><span class="line">5       2021-11-01 00:07:00	c</span><br></pre></td></tr></table></figure>

<p>用户画像维表（user_profile）数据（数据存储在 redis 中）：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user_id(主键)	age	    sex</span><br><span class="line">a               12-18   男</span><br><span class="line">b               18-24   女</span><br><span class="line">c               18-24   男</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<p>redis 中的数据结构存储是按照 key，value 去存储的。其中 key 为 user_id，value 为 age，sex 的 json。</p>
</blockquote>
<p>具体 SQL：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    `<span class="type">timestamp</span>` <span class="keyword">as</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    user_id STRING,</span><br><span class="line">    proctime <span class="keyword">AS</span> PROCTIME()</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_profile (</span><br><span class="line">    user_id STRING,</span><br><span class="line">    age STRING,</span><br><span class="line">    sex STRING</span><br><span class="line">    ) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;redis&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;hostname&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;port&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;6379&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;lookup.cache.max-rows&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;500&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;lookup.cache.ttl&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;3600&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;lookup.max-retries&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    `<span class="type">timestamp</span>` <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    user_id STRING,</span><br><span class="line">    proctime <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    age STRING,</span><br><span class="line">    sex STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- lookup join 的 query 逻辑</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    s.log_id <span class="keyword">as</span> log_id</span><br><span class="line">    , s.`<span class="type">timestamp</span>` <span class="keyword">as</span> `<span class="type">timestamp</span>`</span><br><span class="line">    , s.user_id <span class="keyword">as</span> user_id</span><br><span class="line">    , s.proctime <span class="keyword">as</span> proctime</span><br><span class="line">    , u.sex <span class="keyword">as</span> sex</span><br><span class="line">    , u.age <span class="keyword">as</span> age</span><br><span class="line"><span class="keyword">FROM</span> show_log <span class="keyword">AS</span> s</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> user_profile <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> s.proctime <span class="keyword">AS</span> u</span><br><span class="line"><span class="keyword">ON</span> s.user_id <span class="operator">=</span> u.user_id</span><br></pre></td></tr></table></figure>

<p>输出数据如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">log_id  timestamp           user_id age	    sex</span><br><span class="line">1       2021-11-01 00:01:03 a       12-18   男</span><br><span class="line">2       2021-11-01 00:03:00 b       18-24   女</span><br><span class="line">3       2021-11-01 00:05:00 c       18-24   男</span><br><span class="line">4       2021-11-01 00:06:00 b       18-24   女</span><br><span class="line">5       2021-11-01 00:07:00 c       18-24   男</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<p>实时的 lookup 维表关联能使用 <code>处理时间</code> 去做关联。</p>
</blockquote>
<ol start="4">
<li>⭐ SQL 语义：</li>
</ol>
<p>详细 SQL 语义及案例可见：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ku11tCZp7CAFzpkqd4J1cQ">https://mp.weixin.qq.com/s/ku11tCZp7CAFzpkqd4J1cQ</a></p>
<p>其实，Flink 官方并没有提供 redis 的维表 connector 实现。</p>
<p>没错，博主自己实现了一套。关于 redis 维表的 connector 实现，直接参考下面的文章。都是可以从 github 上找到源码拿来用的！</p>
<blockquote>
<p>注意：</p>
<ol>
<li>⭐ 同一条数据关联到的维度数据可能不同：实时数仓中常用的实时维表都是在不断的变化中的，当前流表数据关联完维表数据后，如果同一个 key 的维表的数据发生了变化，已关联到的维表的结果数据不会再同步更新。举个例子，维表中 user_id 为 1 的数据在 08：00 时 age 由 12-18 变为了 18-24，那么当我们的任务在 08：01 failover 之后从 07：59 开始回溯数据时，原本应该关联到 12-18 的数据会关联到 18-24 的 age 数据。这是有可能会影响数据质量的。所以小伙伴萌在评估你们的实时任务时要考虑到这一点。</li>
<li>⭐ 会发生实时的新建及更新的维表博主建议小伙伴萌应该建立起数据延迟的监控机制，防止出现流表数据先于维表数据到达，导致关联不到维表数据</li>
</ol>
</blockquote>
<p>再说说维表常见的性能问题及优化思路。</p>
<p>所有的维表性能问题都可以总结为：<code>高 qps 下访问维表存储引擎产生的任务背压，数据产出延迟问题。</code></p>
<p>举个例子：</p>
<ol>
<li>⭐ 在没有使用维表的情况下：一条数据从输入 Flink 任务到输出 Flink 任务的时延假如为 <code>0.1 ms</code>，那么并行度为 1 的任务的吞吐可以达到 <code>1 query / 0.1 ms = 1w qps</code>。</li>
<li>⭐ 在使用维表之后：每条数据访问维表的外部存储的时长为 <code>2 ms</code>，那么一条数据从输入 Flink 任务到输出 Flink 任务的时延就会变成 <code>2.1 ms</code>，那么同样并行度为 1 的任务的吞吐只能达到<code>1 query / 2.1 ms = 476 qps</code>。两者的吞吐量相差 <code>21 倍</code>。</li>
</ol>
<p>这就是为什么维表 join 的算子会产生背压，任务产出会延迟。</p>
<p>那么当然，解决方案也是有很多的。抛开 Flink SQL 想一下，如果我们使用 DataStream API，甚至是在做一个后端应用，需要访问外部存储时，常用的优化方案有哪些？这里列举一下：</p>
<ol>
<li>⭐ 按照 redis 维表的 key 分桶 + local cache：通过按照 key 分桶的方式，让大多数据的维表关联的数据访问走之前访问过得 local cache 即可。这样就可以把访问外部存储 2.1 ms 处理一个 query 变为访问内存的 0.1 ms 处理一个 query 的时长。</li>
<li>⭐ 异步访问外存：DataStream api 有异步算子，可以利用线程池去同时多次请求维表外部存储。这样就可以把 2.1 ms 处理 1 个 query 变为 2.1 ms 处理 10 个 query。吞吐可变优化到 10 / 2.1 ms = 4761 qps。</li>
<li>⭐ 批量访问外存：除了异步访问之外，我们还可以批量访问外部存储。举一个例子：在访问 redis 维表的 1 query 占用 2.1 ms 时长中，其中可能有 2 ms 都是在网络请求上面的耗时 ，其中只有 0.1 ms 是 redis server 处理请求的时长。那么我们就可以使用 redis 提供的 pipeline 能力，在客户端（也就是 flink 任务 lookup join 算子中），攒一批数据，使用 pipeline 去同时访问 redis sever。这样就可以把 2.1 ms 处理 1 个 query 变为 7ms（2ms + 50 * 0.1ms） 处理 50 个 query。吞吐可变为 50 query / 7 ms = 7143 qps。博主这里测试了下使用 redis pipeline 和未使用的时长消耗对比。如下图所示。</li>
</ol>
<p>博主认为上述优化效果中，最好用的是 1 + 3，2 相比 3 还是一条一条发请求，性能会差一些。</p>
<p>既然 DataStream 可以这样做，Flink SQL 必须必的也可以借鉴上面的这些优化方案。具体怎么操作呢？看下文骚操作</p>
<ol>
<li>⭐ 按照 redis 维表的 key 分桶 + local cache：sql 中如果要做分桶，得先做 group by，但是如果做了 group by 的聚合，就只能在 udaf 中做访问 redis 处理，并且 udaf 产出的结果只能是一条，所以这种实现起来非常复杂。我们选择不做 keyby 分桶。但是我们可以直接使用 local cache 去做本地缓存，虽然【直接缓存】的效果比【先按照 key 分桶再做缓存】的效果差，但是也能一定程度上减少访问 redis 压力。在博主实现的 redis connector 中，内置了 local cache 的实现，小伙伴萌可以参考下面这部篇文章进行配置。</li>
<li>⭐ 异步访问外存：目前博主实现的 redis connector 不支持异步访问，但是官方实现的 hbase connector 支持这个功能，参考下面链接文章的，点开之后搜索 lookup.async。<a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/hbase/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/hbase/</a></li>
<li>⭐ 批量访问外存：这玩意官方必然没有实现啊，但是，但是，但是，经过博主周末两天的疯狂 debug，改了改源码，搞定了基于 redis 的批量访问外存优化的功能。具体可以参考下文。</li>
</ol>
<p>关于批量访问外存可参考：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ku11tCZp7CAFzpkqd4J1cQ">https://mp.weixin.qq.com/s/ku11tCZp7CAFzpkqd4J1cQ</a></p>
<h3 id="3-8-5-Array-Expansion（数组列转行）"><a href="#3-8-5-Array-Expansion（数组列转行）" class="headerlink" title="3.8.5.Array Expansion（数组列转行）"></a>3.8.5.Array Expansion（数组列转行）</h3><ol>
<li><p>⭐ 应用场景（支持 Batch\Streaming）：将表中 ARRAY 类型字段（列）拍平，转为多行</p>
</li>
<li><p>⭐ 实际案例：比如某些场景下，日志是合并、攒批上报的，就可以使用这种方式将一个 Array 转为多行。</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> show_log_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_params <span class="keyword">ARRAY</span><span class="operator">&lt;</span>STRING<span class="operator">&gt;</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.log_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    log_id <span class="type">BIGINT</span>,</span><br><span class="line">    show_param STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    log_id,</span><br><span class="line">    t.show_param <span class="keyword">as</span> show_param</span><br><span class="line"><span class="keyword">FROM</span> show_log_table</span><br><span class="line"><span class="comment">-- array 炸开语法</span></span><br><span class="line"><span class="keyword">CROSS</span> <span class="keyword">JOIN</span> <span class="built_in">UNNEST</span>(show_params) <span class="keyword">AS</span> t (show_param)</span><br></pre></td></tr></table></figure>

<p>show_log_table 原始数据：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">+</span>I[<span class="number">7</span>, [a, b, c]]</span><br><span class="line"><span class="operator">+</span>I[<span class="number">5</span>, [d, e, f]]</span><br></pre></td></tr></table></figure>

<p>输出结果如下所示：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- +I[7, [a, b, c]] 一行转为 3 行</span><br><span class="line">+I[7, a]</span><br><span class="line">+I[7, b]</span><br><span class="line">+I[7, b]</span><br><span class="line">-- +I[5, [d, e, f]] 一行转为 3 行</span><br><span class="line">+I[5, d]</span><br><span class="line">+I[5, e]</span><br><span class="line">+I[5, f]</span><br></pre></td></tr></table></figure>

<h3 id="3-8-6-Table-Function（自定义列转行）"><a href="#3-8-6-Table-Function（自定义列转行）" class="headerlink" title="3.8.6.Table Function（自定义列转行）"></a>3.8.6.Table Function（自定义列转行）</h3><ol>
<li><p>⭐ 应用场景（支持 Batch\Streaming）：这个其实和 Array Expansion 功能类似，但是 Table Function 本质上是个 UDTF 函数，和离线 Hive SQL 一样，我们可以自定义 UDTF 去决定列转行的逻辑</p>
</li>
<li><p>⭐ Table Function 使用分类：</p>
</li>
</ol>
<ul>
<li>⭐ Inner Join Table Function：如果 UDTF 返回结果为空，则相当于 1 行转为 0 行，这行数据直接被丢弃</li>
<li>⭐ Left Join Table Function：如果 UDTF 返回结果为空，折行数据不会被丢弃，只会在结果中填充 null 值</li>
</ul>
<ol start="3">
<li>⭐ 实际案例：直接上 SQL 。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TableFunctionInnerJoin_Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        FlinkEnv flinkEnv = FlinkEnvUtils.getStreamTableEnv(args);</span><br><span class="line"></span><br><span class="line">        String sql = <span class="string">&quot;CREATE FUNCTION user_profile_table_func AS &#x27;flink.examples.sql._07.query._06_joins._06_table_function&quot;</span></span><br><span class="line">                + <span class="string">&quot;._01_inner_join.TableFunctionInnerJoin_Test$UserProfileTableFunction&#x27;;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;CREATE TABLE source_table (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    user_id BIGINT NOT NULL,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    name STRING,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    row_time AS cast(CURRENT_TIMESTAMP as timestamp(3)),\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    WATERMARK FOR row_time AS row_time - INTERVAL &#x27;5&#x27; SECOND\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;datagen&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;rows-per-second&#x27; = &#x27;10&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.name.length&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.user_id.min&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.user_id.max&#x27; = &#x27;10&#x27;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;);\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;CREATE TABLE sink_table (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    user_id BIGINT,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    name STRING,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    age INT,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    row_time TIMESTAMP(3)\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;print&#x27;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;);\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;INSERT INTO sink_table\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;SELECT user_id,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;       name,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;       age,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;       row_time\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;FROM source_table,\n&quot;</span></span><br><span class="line">                <span class="comment">// Table Function Join 语法对应 LATERAL TABLE</span></span><br><span class="line">                + <span class="string">&quot;LATERAL TABLE(user_profile_table_func(user_id)) t(age)&quot;</span>;</span><br><span class="line"></span><br><span class="line">        Arrays.stream(sql.split(<span class="string">&quot;;&quot;</span>))</span><br><span class="line">                .forEach(flinkEnv.streamTEnv()::executeSql);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">UserProfileTableFunction</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Integer</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(<span class="keyword">long</span> userId)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 自定义输出逻辑</span></span><br><span class="line">            <span class="keyword">if</span> (userId &lt;= <span class="number">5</span>) &#123;</span><br><span class="line">                <span class="comment">// 一行转 1 行</span></span><br><span class="line">                collect(<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 一行转 3 行</span></span><br><span class="line">                collect(<span class="number">1</span>);</span><br><span class="line">                collect(<span class="number">2</span>);</span><br><span class="line">                collect(<span class="number">3</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行结果如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- &lt;= 5，则只有 1 行结果</span></span><br><span class="line"><span class="operator">+</span>I[<span class="number">3</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.560</span>]</span><br><span class="line"><span class="comment">-- &gt; 5，则有行 3 结果</span></span><br><span class="line"><span class="operator">+</span>I[<span class="number">8</span>, e, <span class="number">1</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.560</span>]</span><br><span class="line"><span class="operator">+</span>I[<span class="number">8</span>, e, <span class="number">2</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.560</span>]</span><br><span class="line"><span class="operator">+</span>I[<span class="number">8</span>, e, <span class="number">3</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.560</span>]</span><br><span class="line"><span class="comment">-- &lt;= 5，则只有 1 行结果</span></span><br><span class="line"><span class="operator">+</span>I[<span class="number">4</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.561</span>]</span><br><span class="line"><span class="comment">-- &gt; 5，则有行 3 结果</span></span><br><span class="line"><span class="operator">+</span>I[<span class="number">8</span>, c, <span class="number">1</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.561</span>]</span><br><span class="line"><span class="operator">+</span>I[<span class="number">8</span>, c, <span class="number">2</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.561</span>]</span><br><span class="line"><span class="operator">+</span>I[<span class="number">8</span>, c, <span class="number">3</span>, <span class="number">2021</span><span class="number">-05</span><span class="number">-01</span>T18:<span class="number">23</span>:<span class="number">42.561</span>]</span><br></pre></td></tr></table></figure>

<h2 id="3-9-DML：集合操作"><a href="#3-9-DML：集合操作" class="headerlink" title="3.9 DML：集合操作"></a>3.9 DML：集合操作</h2><p>集合操作支持 Batch\Streaming 任务。</p>
<ol>
<li>⭐ UNION：将集合合并并且去重。</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/34.png" alt="union"></p>
<ol start="2">
<li>⭐ UNION ALL：将集合合并，不做去重。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">view</span> t1(s) <span class="keyword">as</span> <span class="keyword">values</span> (<span class="string">&#x27;c&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>);</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">view</span> t2(s) <span class="keyword">as</span> <span class="keyword">values</span> (<span class="string">&#x27;d&#x27;</span>), (<span class="string">&#x27;e&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t1) <span class="keyword">UNION</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t2);</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  s<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  c<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  a<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  d<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  e<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t1) <span class="keyword">UNION</span> <span class="keyword">ALL</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t2);</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  c<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  c<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  a<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  c<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  d<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  e<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  a<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ Intersect：交集并且去重</li>
<li>⭐ Intersect ALL：交集不做去重</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">view</span> t1(s) <span class="keyword">as</span> <span class="keyword">values</span> (<span class="string">&#x27;c&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>);</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">view</span> t2(s) <span class="keyword">as</span> <span class="keyword">values</span> (<span class="string">&#x27;d&#x27;</span>), (<span class="string">&#x27;e&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t1) <span class="keyword">INTERSECT</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t2);</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  s<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  a<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t1) <span class="keyword">INTERSECT</span> <span class="keyword">ALL</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t2);</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  s<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span>  a<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  b<span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>⭐ Except：差集并且去重</li>
<li>⭐ Except ALL：差集不做去重</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t1) <span class="keyword">EXCEPT</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t2);</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span> s <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span> c <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t1) <span class="keyword">EXCEPT</span> <span class="keyword">ALL</span> (<span class="keyword">SELECT</span> s <span class="keyword">FROM</span> t2);</span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span> s <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br><span class="line"><span class="operator">|</span> c <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> c <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---+</span></span><br></pre></td></tr></table></figure>

<p>上述 SQL 在流式任务中，如果一条左流数据先来了，没有从右流集合数据中找到对应的数据时会直接输出，当右流对应数据后续来了之后，会下发回撤流将之前的数据給撤回。这也是一个回撤流。</p>
<ol start="7">
<li>⭐ In 子查询：这个大家比较熟悉了，但是注意，In 子查询的结果集只能有一列</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">user</span>, amount</span><br><span class="line"><span class="keyword">FROM</span> Orders</span><br><span class="line"><span class="keyword">WHERE</span> product <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> product <span class="keyword">FROM</span> NewProducts</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>上述 SQL 的 In 子句其实就和之前介绍到的 Inner Join 类似。并且 In 子查询也会涉及到大状态问题，大家注意设置 State 的 TTL。</p>
<h2 id="3-10-DML：Order-By、Limit-子句"><a href="#3-10-DML：Order-By、Limit-子句" class="headerlink" title="3.10.DML：Order By、Limit 子句"></a>3.10.DML：Order By、Limit 子句</h2><h3 id="3-10-1-Order-By-子句"><a href="#3-10-1-Order-By-子句" class="headerlink" title="3.10.1.Order By 子句"></a>3.10.1.Order By 子句</h3><p>支持 Batch\Streaming，但在实时任务中一般用的非常少。</p>
<p>实时任务中，Order By 子句中必须要有时间属性字段，并且时间属性必须为升序时间属性，即 <code>WATERMARK FOR rowtime_column AS rowtime_column - INTERVAL &#39;0.001&#39; SECOND</code> 或者 <code>WATERMARK FOR rowtime_column AS rowtime_column</code>。</p>
<p>举例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table_1 (</span><br><span class="line">    user_id <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> user_id</span><br><span class="line"><span class="keyword">FROM</span> source_table_1</span><br><span class="line"><span class="keyword">Order</span> <span class="keyword">By</span> row_time, user_id <span class="keyword">desc</span></span><br></pre></td></tr></table></figure>

<h3 id="3-10-2-Limit-子句"><a href="#3-10-2-Limit-子句" class="headerlink" title="3.10.2.Limit 子句"></a>3.10.2.Limit 子句</h3><p>支持 Batch\Streaming，但实时场景一般不使用，但是此处依然举一个例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table_1 (</span><br><span class="line">    user_id <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> user_id</span><br><span class="line"><span class="keyword">FROM</span> source_table_1</span><br><span class="line">Limit <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>结果如下，只有 3 条输出：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">+I[5]</span><br><span class="line">+I[9]</span><br><span class="line">+I[4]</span><br></pre></td></tr></table></figure>

<h2 id="3-11-DML：TopN-子句"><a href="#3-11-DML：TopN-子句" class="headerlink" title="3.11.DML：TopN 子句"></a>3.11.DML：TopN 子句</h2><ol>
<li><p>⭐ TopN 定义（支持 Batch\Streaming）：TopN 其实就是对应到离线数仓中的 row_number()，可以使用 row_number() 对某一个分组的数据进行排序</p>
</li>
<li><p>⭐ 应用场景：根据 <code>某个排序</code> 条件，计算<code>某个分组</code>下的排行榜数据</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [column_list]</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">   <span class="keyword">SELECT</span> [column_list],</span><br><span class="line">     <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> ([<span class="keyword">PARTITION</span> <span class="keyword">BY</span> col1[, col2...]]</span><br><span class="line">       <span class="keyword">ORDER</span> <span class="keyword">BY</span> col1 [<span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>][, col2 [<span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>]...]) <span class="keyword">AS</span> rownum</span><br><span class="line">   <span class="keyword">FROM</span> table_name)</span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">&lt;=</span> N [<span class="keyword">AND</span> conditions]</span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ <code>ROW_NUMBER()</code>：标识 TopN 排序子句</li>
<li>⭐ <code>PARTITION BY col1[, col2...]</code>：标识分区字段，代表按照这个 col 字段作为分区粒度对数据进行排序取 topN，比如下述案例中的 <code>partition by key</code>，就是根据需求中的搜索关键词（key）做为分区</li>
<li>⭐ <code>ORDER BY col1 [asc|desc][, col2 [asc|desc]...]</code>：标识 TopN 的排序规则，是按照哪些字段、顺序或逆序进行排序</li>
<li>⭐ <code>WHERE rownum &lt;= N</code>：这个子句是一定需要的，只有加上了这个子句，Flink 才能将其识别为一个 TopN 的查询，其中 N 代表 TopN 的条目数</li>
<li>⭐ <code>[AND conditions]</code>：其他的限制条件也可以加上</li>
</ul>
<ol start="4">
<li>⭐ 实际案例：取某个搜索关键词下的搜索热度前 10 名的词条数据。</li>
</ol>
<p>输入数据为搜索词条数据的搜索热度数据，当搜索热度发生变化时，会将变化后的数据写入到数据源的 Kafka 中：</p>
<p>数据源 schema：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 字段名	        备注</span></span><br><span class="line"><span class="comment">-- key         	搜索关键词</span></span><br><span class="line"><span class="comment">-- name        	搜索热度名称</span></span><br><span class="line"><span class="comment">-- search_cnt   	热搜消费热度（比如 3000）</span></span><br><span class="line"><span class="comment">-- timestamp       消费词条时间戳</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    name <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    search_cnt <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    key <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇 schema：</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- key         	搜索关键词</span></span><br><span class="line"><span class="comment">-- name        	搜索热度名称</span></span><br><span class="line"><span class="comment">-- search_cnt   	热搜消费热度（比如 3000）</span></span><br><span class="line"><span class="comment">-- timestamp       消费词条时间戳</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    key <span class="type">BIGINT</span>,</span><br><span class="line">    name <span class="type">BIGINT</span>,</span><br><span class="line">    search_cnt <span class="type">BIGINT</span>,</span><br><span class="line">    `<span class="type">timestamp</span>` <span class="type">TIMESTAMP</span>(<span class="number">3</span>)</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- DML 逻辑</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> key, name, search_cnt, row_time <span class="keyword">as</span> `<span class="type">timestamp</span>`</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">   <span class="keyword">SELECT</span> key, name, search_cnt, row_time, </span><br><span class="line">     <span class="comment">-- 根据热搜关键词 key 作为 partition key，然后按照 search_cnt 倒排取前 100 名</span></span><br><span class="line">     <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> key</span><br><span class="line">       <span class="keyword">ORDER</span> <span class="keyword">BY</span> search_cnt <span class="keyword">desc</span>) <span class="keyword">AS</span> rownum</span><br><span class="line">   <span class="keyword">FROM</span> source_table)</span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">&lt;=</span> <span class="number">100</span></span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-D[关键词1, 词条1, 4944]</span><br><span class="line">+I[关键词1, 词条1, 8670]</span><br><span class="line">+I[关键词1, 词条2, 1735]</span><br><span class="line">-D[关键词1, 词条3, 6641]</span><br><span class="line">+I[关键词1, 词条3, 6928]</span><br><span class="line">-D[关键词1, 词条4, 6312]</span><br><span class="line">+I[关键词1, 词条4, 7287]</span><br></pre></td></tr></table></figure>

<p>可以看到输出数据是有回撤数据的，为什么会出现回撤，我们来看看 SQL 语义。</p>
<ol start="5">
<li>⭐ SQL 语义</li>
</ol>
<p>上面的 SQL 会翻译成以下三个算子：</p>
<ul>
<li>⭐ <code>数据源</code>：数据源即最新的词条下面的搜索词的搜索热度数据，消费到 Kafka 中数据后，按照 partition key 将数据进行 hash 分发到下游排序算子，相同的 key 数据将会发送到一个并发中</li>
<li>⭐ <code>排序算子</code>：为每个 Key 维护了一个 TopN 的榜单数据，接受到上游的一条数据后，如果 TopN 榜单还没有到达 N 条，则将这条数据加入 TopN 榜单后，直接下发数据，如果到达 N 条之后，经过 TopN 计算，发现这条数据比原有的数据排序靠前，那么新的 TopN 排名就会有变化，就变化了的这部分数据之前下发的排名数据撤回（即回撤数据），然后下发新的排名数据</li>
<li>⭐ <code>数据汇</code>：接收到上游的数据之后，然后输出到外部存储引擎中</li>
</ul>
<p>上面三个算子也是会 24 小时一直运行的。</p>
<h2 id="3-12-DML：Window-TopN"><a href="#3-12-DML：Window-TopN" class="headerlink" title="3.12.DML：Window TopN"></a>3.12.DML：Window TopN</h2><ol>
<li><p>⭐ Window TopN 定义（支持 Streaming）：Window TopN 是一种特殊的 TopN，它的返回结果是每一个窗口内的 N 个最小值或者最大值。</p>
</li>
<li><p>⭐ 应用场景：小伙伴萌会问了，我有了 TopN 为啥还需要 Window TopN 呢？还记得上文介绍 TopN 说道的 TopN 时会出现中间结果，从而出现回撤数据的嘛？Window TopN 不会出现回撤数据，因为 Window TopN 实现是在窗口结束时输出最终结果，不会产生中间结果。而且注意，因为是窗口上面的操作，Window TopN 在窗口结束时，会自动把 State 给清除。</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [column_list]</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">   <span class="keyword">SELECT</span> [column_list],</span><br><span class="line">     <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> window_start, window_end [, col_key1...]</span><br><span class="line">       <span class="keyword">ORDER</span> <span class="keyword">BY</span> col1 [<span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>][, col2 [<span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>]...]) <span class="keyword">AS</span> rownum</span><br><span class="line">   <span class="keyword">FROM</span> table_name) <span class="comment">-- windowing TVF</span></span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">&lt;=</span> N [<span class="keyword">AND</span> conditions]</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 实际案例：取当前这一分钟的搜索关键词下的搜索热度前 10 名的词条数据</li>
</ol>
<p>输入表字段：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 字段名	        备注</span></span><br><span class="line"><span class="comment">-- key         	    搜索关键词</span></span><br><span class="line"><span class="comment">-- name             搜索热度名称</span></span><br><span class="line"><span class="comment">-- search_cnt       热搜消费热度（比如 3000）</span></span><br><span class="line"><span class="comment">-- timestamp        消费词条时间戳</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    name <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    search_cnt <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    key <span class="type">BIGINT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 输出表字段：</span></span><br><span class="line"><span class="comment">-- 字段名	        备注</span></span><br><span class="line"><span class="comment">-- key              搜索关键词</span></span><br><span class="line"><span class="comment">-- name        	    搜索热度名称</span></span><br><span class="line"><span class="comment">-- search_cnt       热搜消费热度（比如 3000）</span></span><br><span class="line"><span class="comment">-- window_start     窗口开始时间戳</span></span><br><span class="line"><span class="comment">-- window_end       窗口结束时间戳</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    key <span class="type">BIGINT</span>,</span><br><span class="line">    name <span class="type">BIGINT</span>,</span><br><span class="line">    search_cnt <span class="type">BIGINT</span>,</span><br><span class="line">    window_start <span class="type">TIMESTAMP</span>(<span class="number">3</span>),</span><br><span class="line">    window_end <span class="type">TIMESTAMP</span>(<span class="number">3</span>)</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  ...</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 处理 sql：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> key, name, search_cnt, window_start, window_end</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">   <span class="keyword">SELECT</span> key, name, search_cnt, window_start, window_end, </span><br><span class="line">     <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> window_start, window_end, key</span><br><span class="line">       <span class="keyword">ORDER</span> <span class="keyword">BY</span> search_cnt <span class="keyword">desc</span>) <span class="keyword">AS</span> rownum</span><br><span class="line">   <span class="keyword">FROM</span> (</span><br><span class="line">      <span class="keyword">SELECT</span> window_start, window_end, key, name, <span class="built_in">max</span>(search_cnt) <span class="keyword">as</span> search_cnt</span><br><span class="line">      <span class="comment">-- window tvf 写法</span></span><br><span class="line">      <span class="keyword">FROM</span> <span class="keyword">TABLE</span>(TUMBLE(<span class="keyword">TABLE</span> source_table, DESCRIPTOR(row_time), <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> MINUTES))</span><br><span class="line">      <span class="keyword">GROUP</span> <span class="keyword">BY</span> window_start, window_end, key, name</span><br><span class="line">   )</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">&lt;=</span> <span class="number">100</span></span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+I[关键词1, 词条1, 8670, 2021-1-28T22:34, 2021-1-28T22:35]</span><br><span class="line">+I[关键词1, 词条2, 6928, 2021-1-28T22:34, 2021-1-28T22:35]</span><br><span class="line">+I[关键词1, 词条3, 1735, 2021-1-28T22:34, 2021-1-28T22:35]</span><br><span class="line">+I[关键词1, 词条4, 7287, 2021-1-28T22:34, 2021-1-28T22:35]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看到结果是符合预期的，其中没有回撤数据。</p>
<ol start="5">
<li>⭐ SQL 语义</li>
</ol>
<ul>
<li>⭐ <code>数据源</code>：数据源即最新的词条下面的搜索词的搜索热度数据，消费到 Kafka 中数据后，将数据按照窗口聚合的 key 通过 hash 分发策略发送到下游窗口聚合算子</li>
<li>⭐ <code>窗口聚合算子</code>：进行窗口聚合计算，随着时间的推进，将窗口聚合结果计算完成发往下游窗口排序算子</li>
<li>⭐ <code>窗口排序算子</code>：这个算子其实也是一个窗口算子，只不过这个窗口算子为每个 Key 维护了一个 TopN 的榜单数据，接受到上游发送的窗口结果数据进行排序，随着时间的推进，窗口的结束，将排序的结果输出到下游数据汇算子。</li>
<li>⭐ <code>数据汇</code>：接收到上游的数据之后，然后输出到外部存储引擎中</li>
</ul>
<h2 id="3-13-DML：Deduplication"><a href="#3-13-DML：Deduplication" class="headerlink" title="3.13.DML：Deduplication"></a>3.13.DML：Deduplication</h2><ol>
<li><p>⭐ Deduplication 定义（支持 Batch\Streaming）：Deduplication 其实就是去重，也即上文介绍到的 TopN 中 row_number = 1 的场景，但是这里有一点不一样在于其排序字段一定是时间属性列，不能是其他非时间属性的普通列。在 row_number = 1 时，如果排序字段是普通列 planner 会翻译成 TopN 算子，如果是时间属性列 planner 会翻译成 Deduplication，这两者最终的执行算子是不一样的，Deduplication 相比 TopN 算子专门做了对应的优化，性能会有很大提升。</p>
</li>
<li><p>⭐ 应用场景：比如上游数据发重了，或者计算 DAU 明细数据等场景，都可以使用 Deduplication 语法去做去重。</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [column_list]</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">   <span class="keyword">SELECT</span> [column_list],</span><br><span class="line">     <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> ([<span class="keyword">PARTITION</span> <span class="keyword">BY</span> col1[, col2...]]</span><br><span class="line">       <span class="keyword">ORDER</span> <span class="keyword">BY</span> time_attr [<span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>]) <span class="keyword">AS</span> rownum</span><br><span class="line">   <span class="keyword">FROM</span> table_name)</span><br><span class="line"><span class="keyword">WHERE</span> rownum <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li>⭐ <code>ROW_NUMBER()</code>：标识当前数据的排序值</li>
<li>⭐ <code>PARTITION BY col1[, col2...]</code>：标识分区字段，代表按照这个 col 字段作为分区粒度对数据进行排序</li>
<li>⭐ <code>ORDER BY time_attr [asc|desc]</code>：标识排序规则，必须为时间戳列，当前 Flink SQL 支持处理时间、事件时间，ASC 代表保留第一行，DESC 代表保留最后一行</li>
<li>⭐ <code>WHERE rownum = 1</code>：这个子句是一定需要的，而且必须为 rownum = 1</li>
</ul>
<ol start="4">
<li>⭐ 实际案例：</li>
</ol>
<p>博主这里举两个案例：</p>
<ul>
<li>⭐ 案例 1（事件时间）：是腾讯 QQ 用户等级的场景，每一个 QQ 用户都有一个 QQ 用户等级，需要求出当前用户等级在 <code>星星</code>，<code>月亮</code>，<code>太阳</code> 的用户数分别有多少。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源：当每一个用户的等级初始化及后续变化的时候的数据，即用户等级变化明细数据。</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;用户 id&#x27;</span>,</span><br><span class="line">    level STRING COMMENT <span class="string">&#x27;用户等级&#x27;</span>,</span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="type">timestamp</span>(<span class="number">3</span>)) COMMENT <span class="string">&#x27;事件时间戳&#x27;</span>,</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.level.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1000000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇：输出即每一个等级的用户数</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    level STRING COMMENT <span class="string">&#x27;等级&#x27;</span>,</span><br><span class="line">    uv <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;当前等级用户数&#x27;</span>,</span><br><span class="line">    row_time <span class="type">timestamp</span>(<span class="number">3</span>) COMMENT <span class="string">&#x27;时间戳&#x27;</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 处理逻辑：</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    level</span><br><span class="line">    , <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> uv</span><br><span class="line">    , <span class="built_in">max</span>(row_time) <span class="keyword">as</span> row_time</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">      <span class="keyword">SELECT</span></span><br><span class="line">          user_id,</span><br><span class="line">          level,</span><br><span class="line">          row_time,</span><br><span class="line">          <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> user_id <span class="keyword">order</span> <span class="keyword">by</span> row_time) <span class="keyword">as</span> rn</span><br><span class="line">      <span class="keyword">FROM</span> source_table</span><br><span class="line">)</span><br><span class="line"><span class="keyword">where</span> rn <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> </span><br><span class="line">    level</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+I[等级 1, 6928, 2021-1-28T22:34]</span><br><span class="line">-I[等级 1, 6928, 2021-1-28T22:34]</span><br><span class="line">+I[等级 1, 8670, 2021-1-28T22:34]</span><br><span class="line">-I[等级 1, 8670, 2021-1-28T22:34]</span><br><span class="line">+I[等级 1, 77287, 2021-1-28T22:34]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看到其有回撤数据。</p>
<p>其对应的 SQL 语义如下：</p>
<ul>
<li><p>⭐ <code>数据源</code>：消费到 Kafka 中数据后，将数据按照 partition by 的 key 通过 hash 分发策略发送到下游去重算子</p>
</li>
<li><p>⭐ <code>Deduplication 去重算子</code>：接受到上游数据之后，根据 order by 中的条件判断当前的这条数据和之前数据时间戳大小，以上面案例来说，如果当前数据时间戳大于之前数据时间戳，则撤回之前向下游发的中间结果，然后将最新的结果发向下游（发送策略也为 hash，具体的 hash 策略为按照 group by 中 key 进行发送），如果当前数据时间戳小于之前数据时间戳，则不做操作。次算子产出的结果就是每一个用户的对应的最新等级信息。</p>
</li>
<li><p>⭐ <code>Group by 聚合算子</code>：接受到上游数据之后，根据 Group by 聚合粒度对数据进行聚合计算结果（每一个等级的用户数），发往下游数据汇算子</p>
</li>
<li><p>⭐ <code>数据汇</code>：接收到上游的数据之后，然后输出到外部存储引擎中</p>
</li>
<li><p>⭐ 案例 2（处理时间）：最原始的日志是明细数据，需要我们根据用户 id 筛选出这个用户当天的第一条数据，发往下游，下游可以据此计算分各种维度的 DAU</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 数据源：原始日志明细数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;用户 id&#x27;</span>,</span><br><span class="line">    name STRING COMMENT <span class="string">&#x27;用户姓名&#x27;</span>,</span><br><span class="line">    server_timestamp <span class="type">BIGINT</span> COMMENT <span class="string">&#x27;用户访问时间戳&#x27;</span>,</span><br><span class="line">    proctime <span class="keyword">AS</span> PROCTIME()</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.name.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.user_id.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.server_timestamp.min&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;1&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fields.server_timestamp.max&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇：根据 user_id 去重的第一条数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    user_id <span class="type">BIGINT</span>,</span><br><span class="line">    name STRING,</span><br><span class="line">    server_timestamp <span class="type">BIGINT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 处理逻辑：</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">select</span> user_id,</span><br><span class="line">       name,</span><br><span class="line">       server_timestamp</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">      <span class="keyword">SELECT</span></span><br><span class="line">          user_id,</span><br><span class="line">          name,</span><br><span class="line">          server_timestamp,</span><br><span class="line">          <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> user_id <span class="keyword">order</span> <span class="keyword">by</span> proctime) <span class="keyword">as</span> rn</span><br><span class="line">      <span class="keyword">FROM</span> source_table</span><br><span class="line">)</span><br><span class="line"><span class="keyword">where</span> rn <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+I[1, 用户 1, 2021-1-28T22:34]</span><br><span class="line">+I[2, 用户 2, 2021-1-28T22:34]</span><br><span class="line">+I[3, 用户 3, 2021-1-28T22:34]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看到这个处理逻辑是没有回撤数据的。其对应的 SQL 语义如下：</p>
<ul>
<li>⭐ <code>数据源</code>：消费到 Kafka 中数据后，将数据按照 partition by 的 key 通过 hash 分发策略发送到下游去重算子</li>
<li>⭐ <code>Deduplication 去重算子</code>：处理时间语义下，如果是当前 key 的第一条数据，则直接发往下游，如果判断（根据 state 中是否存储过改 key）不是第一条，则直接丢弃</li>
<li>⭐ <code>数据汇</code>：接收到上游的数据之后，然后输出到外部存储引擎中</li>
</ul>
<blockquote>
<p>注意：</p>
<p>在 Deduplication 关于是否会出现回撤流，博主总结如下：</p>
<ol>
<li>⭐ Order by 事件时间 DESC：会出现回撤流，因为当前 key 下 <code>可能会有</code> 比当前事件时间还大的数据</li>
<li>⭐ Order by 事件时间 ASC：会出现回撤流，因为当前 key 下 <code>可能会有</code> 比当前事件时间还小的数据</li>
<li>⭐ Order by 处理时间 DESC：会出现回撤流，因为当前 key 下 <code>可能会有</code> 比当前处理时间还大的数据</li>
<li>⭐ Order by 处理时间 ASC：不会出现回撤流，因为当前 key 下 <code>不可能会有</code> 比当前处理时间还小的数据</li>
</ol>
</blockquote>
<h2 id="3-14-EXPLAIN-子句"><a href="#3-14-EXPLAIN-子句" class="headerlink" title="3.14.EXPLAIN 子句"></a>3.14.EXPLAIN 子句</h2><ol>
<li><p>⭐ 应用场景：EXPLAIN 子句其实就是用于查看当前这个 sql 查询的逻辑计划以及优化的执行计划。</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN PLAN <span class="keyword">FOR</span> <span class="operator">&lt;</span>query_statement_or_insert_statement<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 实际案例：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Explain_Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        FlinkEnv flinkEnv = FlinkEnvUtils.getStreamTableEnv(args);</span><br><span class="line"></span><br><span class="line">        flinkEnv.env().setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        String sql = <span class="string">&quot;CREATE TABLE source_table (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    user_id BIGINT COMMENT &#x27;用户 id&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    name STRING COMMENT &#x27;用户姓名&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    server_timestamp BIGINT COMMENT &#x27;用户访问时间戳&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    proctime AS PROCTIME()\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;datagen&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;rows-per-second&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.name.length&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.user_id.min&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.user_id.max&#x27; = &#x27;10&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.server_timestamp.min&#x27; = &#x27;1&#x27;,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;fields.server_timestamp.max&#x27; = &#x27;100000&#x27;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;);\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;CREATE TABLE sink_table (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    user_id BIGINT,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    name STRING,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;    server_timestamp BIGINT\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;) WITH (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;  &#x27;connector&#x27; = &#x27;print&#x27;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;);\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;EXPLAIN PLAN FOR\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;INSERT INTO sink_table\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;select user_id,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;       name,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;       server_timestamp\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;from (\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;      SELECT\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;          user_id,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;          name,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;          server_timestamp,\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;          row_number() over(partition by user_id order by proctime) as rn\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;      FROM source_table\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;)\n&quot;</span></span><br><span class="line">                + <span class="string">&quot;where rn = 1&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 算子 &#123;<span class="doctag">@link</span> org.apache.flink.streaming.api.operators.KeyedProcessOperator&#125;</span></span><br><span class="line"><span class="comment">         *      -- &#123;<span class="doctag">@link</span> org.apache.flink.table.runtime.operators.deduplicate.ProcTimeDeduplicateKeepFirstRowFunction&#125;</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (String innerSql : sql.split(<span class="string">&quot;;&quot;</span>)) &#123;</span><br><span class="line">            TableResult tableResult = flinkEnv.streamTEnv().executeSql(innerSql);</span><br><span class="line"></span><br><span class="line">            tableResult.print();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码执行结果如下：</p>
<figure class="highlight shell"><figcaption><span>script</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">1. 抽象语法树</span><br><span class="line">== Abstract Syntax Tree ==</span><br><span class="line">LogicalSink(table=[default_catalog.default_database.sink_table], fields=[user_id, name, server_timestamp])</span><br><span class="line">+- LogicalProject(user_id=[$0], name=[$1], server_timestamp=[$2])</span><br><span class="line">   +- LogicalFilter(condition=[=($3, 1)])</span><br><span class="line">      +- LogicalProject(user_id=[$0], name=[$1], server_timestamp=[$2], rn=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY PROCTIME() NULLS FIRST)])</span><br><span class="line">         +- LogicalTableScan(table=[[default_catalog, default_database, source_table]])</span><br><span class="line"></span><br><span class="line">2. 优化后的物理计划</span><br><span class="line">== Optimized Physical Plan ==</span><br><span class="line">Sink(table=[default_catalog.default_database.sink_table], fields=[user_id, name, server_timestamp])</span><br><span class="line">+- Calc(select=[user_id, name, server_timestamp])</span><br><span class="line">   +- Deduplicate(keep=[FirstRow], key=[user_id], order=[PROCTIME])</span><br><span class="line">      +- Exchange(distribution=[hash[user_id]])</span><br><span class="line">         +- Calc(select=[user_id, name, server_timestamp, PROCTIME() AS $3])</span><br><span class="line">            +- TableSourceScan(table=[[default_catalog, default_database, source_table]], fields=[user_id, name, server_timestamp])</span><br><span class="line"></span><br><span class="line">3. 优化后的执行计划</span><br><span class="line">== Optimized Execution Plan ==</span><br><span class="line">Sink(table=[default_catalog.default_database.sink_table], fields=[user_id, name, server_timestamp])</span><br><span class="line">+- Calc(select=[user_id, name, server_timestamp])</span><br><span class="line">   +- Deduplicate(keep=[FirstRow], key=[user_id], order=[PROCTIME])</span><br><span class="line">      +- Exchange(distribution=[hash[user_id]])</span><br><span class="line">         +- Calc(select=[user_id, name, server_timestamp, PROCTIME() AS $3])</span><br><span class="line">            +- TableSourceScan(table=[[default_catalog, default_database, source_table]], fields=[user_id, name, server_timestamp])</span><br></pre></td></tr></table></figure>

<h2 id="3-15-USE-子句"><a href="#3-15-USE-子句" class="headerlink" title="3.15.USE 子句"></a>3.15.USE 子句</h2><ol>
<li><p>⭐ 应用场景：如果熟悉 MySQL 的同学会非常熟悉这个子句，在 MySQL 中，USE 子句通常被用于切换库，那么在 Flink SQL 体系中，它的作用也是和 MySQL 中 USE 子句的功能基本一致，用于切换 Catalog，DataBase，使用 Module</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<ul>
<li>⭐ 切换 Catalog</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USE CATALOG catalog_name</span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ 使用 Module</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USE MODULES module_name1[, module_name2, ...]</span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ 切换 Database</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USE db名称</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 实际案例：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a catalog</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;CREATE CATALOG cat1 WITH (...)&quot;</span>);</span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW CATALOGS&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-----------------+</span></span><br><span class="line"><span class="comment">// |    catalog name |</span></span><br><span class="line"><span class="comment">// +-----------------+</span></span><br><span class="line"><span class="comment">// | default_catalog |</span></span><br><span class="line"><span class="comment">// | cat1            |</span></span><br><span class="line"><span class="comment">// +-----------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// change default catalog</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;USE CATALOG cat1&quot;</span>);</span><br><span class="line"></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW DATABASES&quot;</span>).print();</span><br><span class="line"><span class="comment">// databases are empty</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// | database name |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// create a database</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;CREATE DATABASE db1 WITH (...)&quot;</span>);</span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW DATABASES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// | database name |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// |        db1    |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// change default database</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;USE db1&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// change module resolution order and enabled status</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;USE MODULES hive&quot;</span>);</span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// | module name |  used |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// |        hive |  true |</span></span><br><span class="line"><span class="comment">// |        core | false |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br></pre></td></tr></table></figure>

<h2 id="3-16-SHOW-子句"><a href="#3-16-SHOW-子句" class="headerlink" title="3.16.SHOW 子句"></a>3.16.SHOW 子句</h2><ol>
<li><p>⭐ 应用场景：如果熟悉 MySQL 的同学会非常熟悉这个子句，在 MySQL 中，SHOW 子句常常用于查询库、表、函数等，在 Flink SQL 体系中也类似。Flink SQL 支持 SHOW 以下内容。</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> CATALOGS：展示所有 Catalog</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CURRENT</span> CATALOG：展示当前的 Catalog</span><br><span class="line"><span class="keyword">SHOW</span> DATABASES：展示当前 Catalog 下所有 Database</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CURRENT</span> DATABASE：展示当前的 Database</span><br><span class="line"><span class="keyword">SHOW</span> TABLES：展示当前 Database 下所有表</span><br><span class="line"><span class="keyword">SHOW</span> VIEWS：展示所有视图</span><br><span class="line"><span class="keyword">SHOW</span> FUNCTIONS：展示所有的函数</span><br><span class="line"><span class="keyword">SHOW</span> MODULES：展示所有的 <span class="keyword">Module</span>（<span class="keyword">Module</span> 是用于 UDF 扩展）</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 实际案例：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// show catalogs</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW CATALOGS&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-----------------+</span></span><br><span class="line"><span class="comment">// |    catalog name |</span></span><br><span class="line"><span class="comment">// +-----------------+</span></span><br><span class="line"><span class="comment">// | default_catalog |</span></span><br><span class="line"><span class="comment">// +-----------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// show current catalog</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW CURRENT CATALOG&quot;</span>).print();</span><br><span class="line"><span class="comment">// +----------------------+</span></span><br><span class="line"><span class="comment">// | current catalog name |</span></span><br><span class="line"><span class="comment">// +----------------------+</span></span><br><span class="line"><span class="comment">// |      default_catalog |</span></span><br><span class="line"><span class="comment">// +----------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// show databases</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW DATABASES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +------------------+</span></span><br><span class="line"><span class="comment">// |    database name |</span></span><br><span class="line"><span class="comment">// +------------------+</span></span><br><span class="line"><span class="comment">// | default_database |</span></span><br><span class="line"><span class="comment">// +------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// show current database</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW CURRENT DATABASE&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-----------------------+</span></span><br><span class="line"><span class="comment">// | current database name |</span></span><br><span class="line"><span class="comment">// +-----------------------+</span></span><br><span class="line"><span class="comment">// |      default_database |</span></span><br><span class="line"><span class="comment">// +-----------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// create a table</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;CREATE TABLE my_table (...) WITH (...)&quot;</span>);</span><br><span class="line"><span class="comment">// show tables</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW TABLES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"><span class="comment">// | table name |</span></span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"><span class="comment">// |   my_table |</span></span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// create a view</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;CREATE VIEW my_view AS ...&quot;</span>);</span><br><span class="line"><span class="comment">// show views</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW VIEWS&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-----------+</span></span><br><span class="line"><span class="comment">// | view name |</span></span><br><span class="line"><span class="comment">// +-----------+</span></span><br><span class="line"><span class="comment">// |   my_view |</span></span><br><span class="line"><span class="comment">// +-----------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// show functions</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW FUNCTIONS&quot;</span>).print();</span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// | function name |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// |           mod |</span></span><br><span class="line"><span class="comment">// |        sha256 |</span></span><br><span class="line"><span class="comment">// |           ... |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// create a user defined function</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;CREATE FUNCTION f1 AS ...&quot;</span>);</span><br><span class="line"><span class="comment">// show user defined functions</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW USER FUNCTIONS&quot;</span>).print();</span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// | function name |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"><span class="comment">// |            f1 |</span></span><br><span class="line"><span class="comment">// |           ... |</span></span><br><span class="line"><span class="comment">// +---------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// show modules</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// show full modules</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// | module name |  used |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// |        core |  true |</span></span><br><span class="line"><span class="comment">// |        hive | false |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br></pre></td></tr></table></figure>

<h2 id="3-17-LOAD、UNLOAD-子句"><a href="#3-17-LOAD、UNLOAD-子句" class="headerlink" title="3.17.LOAD、UNLOAD 子句"></a>3.17.LOAD、UNLOAD 子句</h2><ol>
<li><p>⭐ 应用场景：我们可以使用 LOAD 子句去加载 Flink SQL 体系内置的或者用户自定义的 Module，UNLOAD 子句去卸载 Flink SQL 体系内置的或者用户自定义的 Module</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 加载</span></span><br><span class="line">LOAD <span class="keyword">MODULE</span> module_name [<span class="keyword">WITH</span> (<span class="string">&#x27;key1&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;val1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;val2&#x27;</span>, ...)]</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 卸载</span></span><br><span class="line">UNLOAD <span class="keyword">MODULE</span> module_name</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 实际案例：</li>
</ol>
<ul>
<li>⭐ LOAD 案例：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加载 Flink SQL 体系内置的 Hive module</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;LOAD MODULE hive WITH (&#x27;hive-version&#x27; = &#x27;3.1.2&#x27;)&quot;</span>);</span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ UNLOAD 案例：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 卸载唯一的一个 CoreModule</span></span><br><span class="line">tEnv.executeSql(<span class="string">&quot;UNLOAD MODULE core&quot;</span>);</span><br><span class="line">tEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// 结果啥 Moudle 都没有了</span></span><br></pre></td></tr></table></figure>

<h2 id="3-18-SET、RESET-子句"><a href="#3-18-SET、RESET-子句" class="headerlink" title="3.18.SET、RESET 子句"></a>3.18.SET、RESET 子句</h2><ol>
<li><p>⭐ 应用场景：SET 子句可以用于修改一些 Flink SQL 的环境配置，RESET 子句是可以将所有的环境配置恢复成默认配置，但只能在 SQL CLI 中进行使用，主要是为了让用户更纯粹的使用 SQL 而不必使用其他方式或者切换系统环境。</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> (key <span class="operator">=</span> <span class="keyword">value</span>)?</span><br><span class="line"></span><br><span class="line">RESET (key)?</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 实际案例：</li>
</ol>
<p>启动一个 SQL CLI 之后，在 SQL CLI 中可以进行以下 SET 设置：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span> table.planner <span class="operator">=</span> blink;</span><br><span class="line">[INFO] Session property has been set.</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> <span class="keyword">SET</span>;</span><br><span class="line">table.planner<span class="operator">=</span>blink;</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> RESET table.planner;</span><br><span class="line">[INFO] Session property has been reset.</span><br><span class="line"></span><br><span class="line">Flink <span class="keyword">SQL</span><span class="operator">&gt;</span> RESET;</span><br><span class="line">[INFO] <span class="keyword">All</span> session properties have been <span class="keyword">set</span> <span class="keyword">to</span> their <span class="keyword">default</span> values.</span><br></pre></td></tr></table></figure>

<h2 id="3-19-SQL-Hints"><a href="#3-19-SQL-Hints" class="headerlink" title="3.19.SQL Hints"></a>3.19.SQL Hints</h2><ol>
<li><p>⭐ 应用场景：比如有一个 kafka 数据源表 kafka_table1，用户想直接从 <code>latest-offset</code> select 一些数据出来预览，其元数据已经存储在 Hive MetaStore 中，但是 Hive MetaStore 中存储的配置中的 <code>scan.startup.mode</code> 是 <code>earliest-offset</code>，通过 SQL Hints，用户可以在 DML 语句中将 <code>scan.startup.mode</code> 改为 <code>latest-offset</code> 查询，因此可以看出 SQL Hints 常用语这种比较临时的参数修改，比如 Ad-hoc 这种临时查询中，方便用户使用自定义的新的表参数而不是 Catalog 中已有的表参数。</p>
</li>
<li><p>⭐ SQL 语法标准：</p>
</li>
</ol>
<p>以下 DML SQL 中的 <code>/*+ OPTIONS(key=val [, key=val]*) */</code> 就是 SQL Hints。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> table_path <span class="comment">/*+ OPTIONS(key=val [, key=val]*) */</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 实际案例：</li>
</ol>
<p>启动一个 SQL CLI 之后，在 SQL CLI 中可以进行以下 SET 设置：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kafka_table1 (id <span class="type">BIGINT</span>, name STRING, age <span class="type">INT</span>) <span class="keyword">WITH</span> (...);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kafka_table2 (id <span class="type">BIGINT</span>, name STRING, age <span class="type">INT</span>) <span class="keyword">WITH</span> (...);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 1. 使用 &#x27;scan.startup.mode&#x27;=&#x27;earliest-offset&#x27; 覆盖原来的 scan.startup.mode</span></span><br><span class="line"><span class="keyword">select</span> id, name <span class="keyword">from</span> kafka_table1 <span class="comment">/*+ OPTIONS(&#x27;scan.startup.mode&#x27;=&#x27;earliest-offset&#x27;) */</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 2. 使用 &#x27;scan.startup.mode&#x27;=&#x27;earliest-offset&#x27; 覆盖原来的 scan.startup.mode</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span></span><br><span class="line">    kafka_table1 <span class="comment">/*+ OPTIONS(&#x27;scan.startup.mode&#x27;=&#x27;earliest-offset&#x27;) */</span> t1</span><br><span class="line">    <span class="keyword">join</span></span><br><span class="line">    kafka_table2 <span class="comment">/*+ OPTIONS(&#x27;scan.startup.mode&#x27;=&#x27;earliest-offset&#x27;) */</span> t2</span><br><span class="line">    <span class="keyword">on</span> t1.id <span class="operator">=</span> t2.id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 3. 使用 &#x27;sink.partitioner&#x27;=&#x27;round-robin&#x27; 覆盖原来的 Sink 表的 sink.partitioner</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> kafka_table1 <span class="comment">/*+ OPTIONS(&#x27;sink.partitioner&#x27;=&#x27;round-robin&#x27;) */</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> kafka_table2;</span><br></pre></td></tr></table></figure>

<h1 id="4-SQL-UDF-篇"><a href="#4-SQL-UDF-篇" class="headerlink" title="4.SQL UDF 篇"></a>4.SQL UDF 篇</h1><p>Flink Table\SQL API 允许用户使用函数进行数据处理、字段标准化等处理。</p>
<h2 id="4-1-SQL-函数的归类"><a href="#4-1-SQL-函数的归类" class="headerlink" title="4.1.SQL 函数的归类"></a>4.1.SQL 函数的归类</h2><p>Flink 中的函数有两个维度的归类标准。</p>
<ol>
<li><p>⭐ 一个归类标准是：系统（内置）函数和 Catalog 函数。系统函数没有命名空间，只能通过其名称来进行引用。Catalog 函数属于 Catalog 和数据库，因此它们拥有 Catalog 和数据库的命名空间。用户可以通过全/部分限定名（catalog.db.func 或 db.func）或者函数来对 Catalog 函数进行引用。</p>
</li>
<li><p>⭐ 另一个归类标准是：临时函数和持久化函数。临时函数由用户创建，它仅在会话的生命周期（也就是一个 Flink 任务的一次运行生命周期内）内有效。持久化函数不是由系统提供的，是存储在 Catalog 中，它在不同会话的生命周期内都有效。</p>
</li>
</ol>
<p>这两个维度归类标准组合下，Flink SQL 总共提供了 4 种函数：</p>
<ol>
<li>⭐ 临时性系统内置函数</li>
<li>⭐ 系统内置函数</li>
<li>⭐ 临时性 Catalog 函数（例如：Create Temporary Function）</li>
<li>⭐ Catalog 函数（例如：Create Function）</li>
</ol>
<p>请注意，在用户使用函数时，系统函数始终优先于 Catalog 函数解析，临时函数始终优先于持久化函数解析。</p>
<h2 id="4-2-SQL-函数的引用方式"><a href="#4-2-SQL-函数的引用方式" class="headerlink" title="4.2.SQL 函数的引用方式"></a>4.2.SQL 函数的引用方式</h2><p>用户在 Flink 中可以通过精确、模糊两种引用方式引用函数。</p>
<h3 id="4-2-1-精确函数"><a href="#4-2-1-精确函数" class="headerlink" title="4.2.1.精确函数"></a>4.2.1.精确函数</h3><p>精确函数引用是让用户限定 Catalog，数据库名称进行精准定位一个 UDF 然后调用。</p>
<p>例如：select mycatalog.mydb.myfunc(x) from mytable 或者 select mydb.myfunc(x) from mytable。</p>
<h3 id="4-2-2-模糊函数"><a href="#4-2-2-模糊函数" class="headerlink" title="4.2.2.模糊函数"></a>4.2.2.模糊函数</h3><p>在模糊函数引用中，用户只需在 SQL 查询中指定函数名就可以引用 UDF，例如： select myfunc(x) from mytable。</p>
<p>当然小伙伴萌问到，如果系统函数和 Catalog 函数的名称是重复的，Flink 体系是会使用哪一个函数呢？这就是下文要介绍的 UDF 解析顺序</p>
<h2 id="4-3-SQL-函数的解析顺序"><a href="#4-3-SQL-函数的解析顺序" class="headerlink" title="4.3.SQL 函数的解析顺序"></a>4.3.SQL 函数的解析顺序</h2><h3 id="4-3-1-精确函数"><a href="#4-3-1-精确函数" class="headerlink" title="4.3.1.精确函数"></a>4.3.1.精确函数</h3><p>由于精确函数应用一定会带上 Catalog 或者数据库名称，所以 Flink 中的精确函数引用一定是指向临时性 Catalog 函数或 Catalog 函数的。</p>
<p>比如：<code>select mycatalog.mydb.myfunc(x) from mytable</code>。</p>
<p>那么 Flink 对其解析顺序以及使用顺序如下：</p>
<ol>
<li>⭐ 临时性 catalog 函数</li>
<li>⭐ Catalog 函数</li>
</ol>
<h3 id="4-3-2-模糊函数"><a href="#4-3-2-模糊函数" class="headerlink" title="4.3.2.模糊函数"></a>4.3.2.模糊函数</h3><p>比如 <code>select myfunc(x) from mytable</code>。</p>
<p>解析顺序以及使用顺序如下：</p>
<ol>
<li>⭐ 临时性系统内置函数</li>
<li>⭐ 系统内置函数</li>
<li>⭐ 临时性 Catalog 函数, 只会在当前会话的当前 Catalog 和当前数据库中查找函数及解析函数</li>
<li>⭐ Catalog 函数, 在当前 Catalog 和当前数据库中查找函数及解析函数</li>
</ol>
<h2 id="4-4-系统内置函数"><a href="#4-4-系统内置函数" class="headerlink" title="4.4.系统内置函数"></a>4.4.系统内置函数</h2><p>系统内置函数小伙伴萌可以直接在 Flink 官网进行查询，博主这里就不多进行介绍。</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/dev/table/functions/systemfunctions/#hash-functions">https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/dev/table/functions/systemfunctions/#hash-functions</a></p>
<blockquote>
<p>注意：</p>
<p>在目前 1.13 版本的 Flink 体系中，内置的系统函数没有像 Hive 内置的函数那么丰富，比如 Hive 中常见的 get_json_object 之类的，Flink 都是没有的，但是 Flink 提供了插件化 Module 的能力，能扩充一些 UDF，下文会进行介绍。</p>
</blockquote>
<h2 id="4-5-SQL-自定义函数（UDF）"><a href="#4-5-SQL-自定义函数（UDF）" class="headerlink" title="4.5.SQL 自定义函数（UDF）"></a>4.5.SQL 自定义函数（UDF）</h2><p>！！！Flink 体系也提供了类似于其他大数据引擎的 UDF 体系。</p>
<p>自定义函数（UDF）是一种扩展开发机制，可以用来在查询语句里调用难以用 SQL 进行 <code>直接</code> 表达的频繁使用或自定义的逻辑。</p>
<p>目前 Flink 自定义函数可以基于 JVM 语言（例如 Java 或 Scala）或 Python 实现，实现者可以在 UDF 中使用任意第三方库，本章聚焦于使用 Java 语言开发自定义函数。</p>
<p>当前 Flink 提供了一下几种 UDF 能力：</p>
<ol>
<li>标量函数（Scalar functions 或 <code>UDAF</code>）：输入一条输出一条，将标量值转换成一个新标量值，对标 Hive 中的 UDF；</li>
<li>表值函数（Table functions 或 <code>UDTF</code>）：输入一条条输出多条，对标 Hive 中的 UDTF；</li>
<li>聚合函数（Aggregate functions 或 <code>UDAF</code>）：输入多条输出一条，对标 Hive 中的 UDAF；</li>
<li>表值聚合函数（Table aggregate functions 或 <code>UDTAF</code>）：仅仅支持 Table API，不支持 SQL API，其可以将多行转为多行；</li>
<li>异步表值函数（Async table functions）：这是一种特殊的 UDF，支持异步查询外部数据系统，用在前文介绍到的 lookup join 中作为查询外部系统的函数。</li>
</ol>
<p>先直接给一个案例看看，怎么创建并在 Flink SQL 中使用一个 UDF：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个标量函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SubstringFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">eval</span><span class="params">(String s, Integer begin, Integer end)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> s.substring(begin, end);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TableEnvironment env = TableEnvironment.create(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Table API 可以直接以引用 class 方式使用 UDF</span></span><br><span class="line">env.from(<span class="string">&quot;MyTable&quot;</span>).select(call(SubstringFunction.class, $(<span class="string">&quot;myField&quot;</span>), <span class="number">5</span>, <span class="number">12</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册 UDF</span></span><br><span class="line">env.createTemporarySystemFunction(<span class="string">&quot;SubstringFunction&quot;</span>, SubstringFunction.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API 调用 UDF</span></span><br><span class="line">env.from(<span class="string">&quot;MyTable&quot;</span>).select(call(<span class="string">&quot;SubstringFunction&quot;</span>, $(<span class="string">&quot;myField&quot;</span>), <span class="number">5</span>, <span class="number">12</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL API 调用 UDF</span></span><br><span class="line">env.sqlQuery(<span class="string">&quot;SELECT SubstringFunction(myField, 5, 12) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>注意：如果你的函数在初始化时，是有入参的，那么需要你的入参是 <code>Serializable</code> 的。即 Java 中需要继承 <code>Serializable</code> 接口。</p>
<p>案例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个带有输入参数的标量函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SubstringFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  -- <span class="keyword">boolean</span> 默认就是 Serializable 的</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">boolean</span> endInclusive;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">SubstringFunction</span><span class="params">(<span class="keyword">boolean</span> endInclusive)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.endInclusive = endInclusive;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">eval</span><span class="params">(String s, Integer begin, Integer end)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> s.substring(begin, endInclusive ? end + <span class="number">1</span> : end);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TableEnvironment env = TableEnvironment.create(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API 调用 UDF</span></span><br><span class="line">env.from(<span class="string">&quot;MyTable&quot;</span>).select(call(<span class="keyword">new</span> SubstringFunction(<span class="keyword">true</span>), $(<span class="string">&quot;myField&quot;</span>), <span class="number">5</span>, <span class="number">12</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册 UDF</span></span><br><span class="line">env.createTemporarySystemFunction(<span class="string">&quot;SubstringFunction&quot;</span>, <span class="keyword">new</span> SubstringFunction(<span class="keyword">true</span>));</span><br></pre></td></tr></table></figure>

<h2 id="4-6-开发-UDF-之前的需知事项"><a href="#4-6-开发-UDF-之前的需知事项" class="headerlink" title="4.6.开发 UDF 之前的需知事项"></a>4.6.开发 UDF 之前的需知事项</h2><p>总结这几个事项主要包含以下步骤：</p>
<ol>
<li>首先需要继承 Flink SQL UDF 体系提供的基类，每种 UDF 实现都有不同的基类</li>
<li>实现 UDF 执行逻辑函数，不同类型的 UDF 需要实现不同的执行逻辑函数</li>
<li>注意 UDF 入参、出参类型推导，Flink 在一些基础类型上的是可以直接推导出类型信息的，但是一些复杂类型就无能为力了，这里需要用户主动介入</li>
<li>明确 UDF 输出结果是否是定值，如果是定值则 Flink 会在生成计划时就执行一遍，得出结果，然后使用这个定值的结果作为后续的执行逻辑的参数，这样可以做到不用在 Flink SQL 任务运行时每次都执行一次，会有性能优化</li>
<li>巧妙运用运行时上下文，可以在任务运行前加载到一些外部资源、上下文配置信息，扩展 UDF 能力</li>
</ol>
<h3 id="4-6-1-继承-UDF-基类"><a href="#4-6-1-继承-UDF-基类" class="headerlink" title="4.6.1.继承 UDF 基类"></a>4.6.1.继承 UDF 基类</h3><p>和 Hive UDF 实现思路类似，在 Flink UDF 体系中，需要注意一下事项：</p>
<ol>
<li>⭐ Flink UDF 要继承一个基类（比如标量 UDF 要继承 <code>org.apache.flink.table.functions.ScalarFunction</code>）。</li>
<li>⭐ 类必须声明为 <code>public</code>，不能是 <code>abstract</code> 类，不能使用非静态内部类或匿名类。</li>
<li>⭐ 为了在 Catalog 中存储此类，该类必须要有默认构造函数并且在运行时可以进行实例化。</li>
</ol>
<h3 id="4-6-2-实现-UDF-执行逻辑函数"><a href="#4-6-2-实现-UDF-执行逻辑函数" class="headerlink" title="4.6.2.实现 UDF 执行逻辑函数"></a>4.6.2.实现 UDF 执行逻辑函数</h3><p>基类提供了一组可以被重写的方法，来给用户进行使用，这些可被重写的方法就是主要承担 UDF 自定义执行逻辑的地方。</p>
<p>举例在 <code>ScalarFunction</code> 中：</p>
<ol>
<li>⭐ <code>open()</code>：用于初始化资源（比如连接外部资源），程序初始化时进行调用</li>
<li>⭐ <code>close()</code>：用于关闭资源，程序结束时进行调用</li>
<li>⭐ <code>isDeterministic()</code>：用于判断返回结果是否是确定的，如果是确定的，结果会被直接执行</li>
<li>⭐ <code>eval(xxx)</code>：Flink 用于处理每一条数据的主要处理逻辑函数</li>
</ol>
<p>你可以自定义 eval 的入参，比如：</p>
<ul>
<li>eval(Integer) 和 eval(LocalDateTime)；</li>
<li>使用变长参数，例如 eval(Integer…);</li>
<li>使用对象，例如 eval(Object) 可接受 LocalDateTime、Integer 作为参数，只要是 Object 都可以；</li>
<li>也可组合使用，例如 eval(Object…) 可接受所有类型的参数。</li>
</ul>
<p>并且你可以在一个 UDF 中重载 eval 函数来实现不同的逻辑，比如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 有多个重载求和方法的函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SumFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 入参为 Integer</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Integer <span class="title">eval</span><span class="params">(Integer a, Integer b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 入参为 String</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Integer <span class="title">eval</span><span class="params">(String a, String b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Integer.valueOf(a) + Integer.valueOf(b);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 入参为多个 Double</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Integer <span class="title">eval</span><span class="params">(Double... d)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">double</span> value : d)</span><br><span class="line">      result += value;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">int</span>) result;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：<br>由于 Flink 在运行时会调用这些方法，所以这些方法必须声明为 public，并且包含明确的输入和输出参数。</p>
</blockquote>
<h3 id="4-6-3-注意-UDF-入参、出参类型推导"><a href="#4-6-3-注意-UDF-入参、出参类型推导" class="headerlink" title="4.6.3.注意 UDF 入参、出参类型推导"></a>4.6.3.注意 UDF 入参、出参类型推导</h3><p>从两个角度来说，为什么函数的入参、出参类型会对 UDF 这么重要。</p>
<ol>
<li>⭐ 从开发人员角度讲，在设计 UDF 的时候，肯定会涉及到 UDF 预期的入参、出参类型信息、也包括一些数据的精度、小数位数等信息</li>
<li>⭐ 从程序运行角度讲，Flink SQL 程序运行时，肯定也需要知道怎么将 SQL 中的类型数据与 UDF 的入参、出参类型，这样才能做数据序列化等操作</li>
</ol>
<p>而 Flink 也提供了三种方式帮助 Flink 程序获取参数类型信息。</p>
<ol>
<li><p>⭐ 自动类型推导功能：Flink 具备 UDF 自动类型推导功能，该功能可以通过反射从函数的类及其求值方法派生数据类型。比如如果你的 UDF 的方法或者类的签名中已经有了对应的入参、出参的类型，Flink 一般都可以推导并获取到这些类型信息。</p>
</li>
<li><p>⭐ 添加类型注解：当 1 中的隐式反射提取方法不成功，则可以通过使用 Flink 提供的 <code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 注解对应的参数、类或方法来显示的支持 Flink 参数类型提取。</p>
</li>
<li><p>⭐ 重写 <code>getTypeInference()</code>：你可以使用 Flink 提供的更高级的类型推导方法，你可以在 UDF 实现类中重写 <code>getTypeInference()</code> 方法去显示声明函数的参数类型信息</p>
</li>
</ol>
<p>接下来介绍几个例子。</p>
<ol>
<li>⭐ 自动类型推导案例：</li>
</ol>
<p>自动类型推导会检查函数的 <code>类</code> 签名和 <code>eval</code> 方法签名，从而推导出函数入参和出参的数据类型，<code>@DataTypeHint</code> 和 <code>@FunctionHint</code> 注解也可以辅助支持自动类型推导。</p>
<p>关于自动类型推导具体将 Java 的对象会映射成 SQL 的具体哪个数据类型，可以参考 <a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/types/#data-type-extraction">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/types/#data-type-extraction</a></p>
<p>案例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.DataTypeHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.InputGroup;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 有多个重载求值方法的函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">OverloadedFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 不需要任何声明，可以直接推导出类型信息，即入参和出参对应到 SQL 中的 bigint 类型</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Long <span class="title">eval</span><span class="params">(<span class="keyword">long</span> a, <span class="keyword">long</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用 @DataTypeHint(&quot;DECIMAL(12, 3)&quot;) 定义 decimal 的精度和小数位</span></span><br><span class="line">  <span class="keyword">public</span> <span class="meta">@DataTypeHint(&quot;DECIMAL(12, 3)&quot;)</span> <span class="function">BigDecimal <span class="title">eval</span><span class="params">(<span class="keyword">double</span> a, <span class="keyword">double</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> BigDecimal.valueOf(a + b);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用注解定义嵌套数据类型</span></span><br><span class="line">  <span class="meta">@DataTypeHint(&quot;ROW&lt;s STRING, t TIMESTAMP_LTZ(3)&gt;&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Row <span class="title">eval</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Row.of(String.valueOf(i), Instant.ofEpochSecond(i));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 允许任意类型的输入，并输出序列化定制后的值</span></span><br><span class="line">  <span class="meta">@DataTypeHint(value = &quot;RAW&quot;, bridgedTo = ByteBuffer.class)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> ByteBuffer <span class="title">eval</span><span class="params">(<span class="meta">@DataTypeHint(inputGroup = InputGroup.ANY)</span> Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> MyUtils.serializeToByteBuffer(o);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 根据 @FunctionHint 注解自动推导类型案例：</li>
</ol>
<p>使用 @DataTypeHint 注解虽好，但是有些场景下，使用起来比较复杂，比如：</p>
<ul>
<li>⭐ 我们不希望 eval 函数的入参和出参都是一个非常具体的类型，比如 long，int，double 等。我们希望它是一个通用的类型，比如 Object。这样的话就不用重载那么多的函数，可以直接使用一个 eval 函数实现不同的处理逻辑，返回不同类型的结果</li>
<li>⭐ 多个 eval 方法的返回结果类型都是相同的，我们懒得写多次 @DataTypeHint</li>
</ul>
<p>那么就可以使用 @FunctionHint 实现，@FunctionHint 是声明在类上面的，举例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.DataTypeHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.FunctionHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.TableFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 解耦类型推导与 eval 方法，类型推导根据 FunctionHint 注解中的信息来，下面的案例说明当前这个 UDF 有三种输入输出类型信息组合</span></span><br><span class="line"><span class="meta">@FunctionHint(</span></span><br><span class="line"><span class="meta">  input = &#123;@DataTypeHint(&quot;INT&quot;), @DataTypeHint(&quot;INT&quot;)&#125;,</span></span><br><span class="line"><span class="meta">  output = @DataTypeHint(&quot;INT&quot;)</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="meta">@FunctionHint(</span></span><br><span class="line"><span class="meta">  input = &#123;@DataTypeHint(&quot;BIGINT&quot;), @DataTypeHint(&quot;BIGINT&quot;)&#125;,</span></span><br><span class="line"><span class="meta">  output = @DataTypeHint(&quot;BIGINT&quot;)</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="meta">@FunctionHint(</span></span><br><span class="line"><span class="meta">  input = &#123;&#125;,</span></span><br><span class="line"><span class="meta">  output = @DataTypeHint(&quot;BOOLEAN&quot;)</span></span><br><span class="line"><span class="meta">)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">OverloadedFunction</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Object</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(Object... o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o.length == <span class="number">0</span>) &#123;</span><br><span class="line">      collect(<span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    collect(o[<span class="number">0</span>]);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 为函数类的所有 eval 方法指定同一个输出类型</span></span><br><span class="line"><span class="meta">@FunctionHint(output = @DataTypeHint(&quot;ROW&lt;s STRING, i INT&gt;&quot;))</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">OverloadedFunction</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    collect(Row.of(<span class="string">&quot;Sum&quot;</span>, a + b));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    collect(Row.of(<span class="string">&quot;Empty args&quot;</span>, -<span class="number">1</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ getTypeInference()</li>
</ol>
<p>getTypeInference() 可以做到根据小伙伴萌自定义的方式去定义类型推导过程及结果，具有高度自定义的能力。举例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.catalog.DataTypeFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.types.inference.TypeInference;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">LiteralFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> Object <span class="title">eval</span><span class="params">(String s, String type)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;INT&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> Integer.valueOf(s);</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;DOUBLE&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> Double.valueOf(s);</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;STRING&quot;</span>:</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果实现了 getTypeInference，则会禁用自动的反射式类型推导，使用如下逻辑进行类型推导</span></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> TypeInference <span class="title">getTypeInference</span><span class="params">(DataTypeFactory typeFactory)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> TypeInference.newBuilder()</span><br><span class="line">      <span class="comment">// 指定输入参数的类型，必要时参数会被隐式转换</span></span><br><span class="line">      .typedArguments(DataTypes.STRING(), DataTypes.STRING())</span><br><span class="line">      <span class="comment">// 用户高度自定义的类型推导逻辑</span></span><br><span class="line">      .outputTypeStrategy(callContext -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (!callContext.isArgumentLiteral(<span class="number">1</span>) || callContext.isArgumentNull(<span class="number">1</span>)) &#123;</span><br><span class="line">          <span class="keyword">throw</span> callContext.newValidationError(<span class="string">&quot;Literal expected for second argument.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 基于第一个入参决定具体的返回数据类型</span></span><br><span class="line">        <span class="keyword">final</span> String literal = callContext.getArgumentValue(<span class="number">1</span>, String.class).orElse(<span class="string">&quot;STRING&quot;</span>);</span><br><span class="line">        <span class="keyword">switch</span> (literal) &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="string">&quot;INT&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> Optional.of(DataTypes.INT().notNull());</span><br><span class="line">          <span class="keyword">case</span> <span class="string">&quot;DOUBLE&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> Optional.of(DataTypes.DOUBLE().notNull());</span><br><span class="line">          <span class="keyword">case</span> <span class="string">&quot;STRING&quot;</span>:</span><br><span class="line">          <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">return</span> Optional.of(DataTypes.STRING());</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">      .build();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-6-4-明确-UDF-输出结果是否是定值"><a href="#4-6-4-明确-UDF-输出结果是否是定值" class="headerlink" title="4.6.4.明确 UDF 输出结果是否是定值"></a>4.6.4.明确 UDF 输出结果是否是定值</h3><p>用户可以通过重写 <code>isDeterministic()</code> 函数来声明这个 UDF 产出的结果是否是一个定值。</p>
<p>对于纯函数（即没有入参的函数，比如 random(), date(), or now() 等）来说，默认情况下 <code>isDeterministic()</code> 返回 true，小伙伴萌可以自定义返回 false。</p>
<p>如果函数不是一个纯函数（即没有入参的函数，比如 random(), date(), or now() 等），这个方法必须返回 <code>false</code>。</p>
<p>那么 <code>isDeterministic()</code> 方法的返回值到底影响什么呢？</p>
<p>答案：影响 Flink 任务在什么时候就直接执行这个 UDF。主要在以下两个方面体现：</p>
<ol>
<li><p>⭐ Flink 在生成计划期间直接执行 UDF 获得结果：如果使用常量表达式调用函数，或者使用常量作为函数的入参，则 Flink 任务可能不会在任务正式运行时执行该函数。举个例子，<code>SELECT ABS(-1) FROM t</code>，<code>SELECT ABS(field) FROM t WHERE field = -1</code>，这两种都会被 Flink 进行优化，直接把 ABS(-1) 的结果在客户端生成执行计划时就将结果运行出来。如果不想在生成执行计划阶段直接将结果运行出来，可以实现 <code>isDeterministic()</code> 返回 false。</p>
</li>
<li><p>⭐ Flink 在程序运行期间执行 UDF 获得结果：如果 UDF 的入参不是常量表达式，或者 <code>isDeterministic()</code> 返回 false，则 Flink 会在程序运行期间执行 UDF。</p>
</li>
</ol>
<p>那么小伙伴会问到，有些场景下 Flink SQL 是做了各种优化之后然后推断出表达式是否是常量，我怎么判断能够更加方便的判断出这个 Flink 是否将这个 UDF 的优化为固定结果了呢？</p>
<p>结论：这些都是可以在 Flink SQL 生成的算子图中看到，在 Flink web ui 中，每一个算子上面都可以详细看到 Flink 最终生成的算子执行逻辑。</p>
<h3 id="4-6-5-巧妙运用运行时上下文"><a href="#4-6-5-巧妙运用运行时上下文" class="headerlink" title="4.6.5.巧妙运用运行时上下文"></a>4.6.5.巧妙运用运行时上下文</h3><p>有时候我们想在 UDF 需要获取一些 Flink 任务运行的全局信息，或者在 UDF 真正处理数据之前做一些配置（setup）/清理（clean-up）的工作。UDF 为我们提供了 open() 和 close() 方法，你可以重写这两个方法做到类似于 DataStream API 中 RichFunction 的功能。</p>
<ol>
<li>⭐ <code>open()</code> 方法：在任务初始化时被调用，常常用于加载一些外部资源；</li>
<li>⭐ <code>close()</code> 方法：在任务结束时被调用，常常用于关闭一些外部资源；</li>
</ol>
<p>其中 open() 方法提供了一个 FunctionContext，它包含了一些 UDF 被执行时的上下文信息，比如 metric group、分布式文件缓存，或者是全局的作业参数等。</p>
<p>比如可以获取到下面的信息：</p>
<ol>
<li>⭐ getMetricGroup()：执行该函数的 subtask 的 Metric Group</li>
<li>⭐ getCachedFile(name)：分布式文件缓存的本地临时文件副本</li>
<li>⭐ getJobParameter(name, defaultValue)：获取 Flink 任务的全局作业参数</li>
<li>⭐ getExternalResourceInfos(resourceName)：获取一些外部资源</li>
</ol>
<p>下面的例子展示了如何在一个标量函数中通过 FunctionContext 来获取一个全局的任务参数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.FunctionContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">HashCodeFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> factor = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(FunctionContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 4. 在 UDF 中获取全局参数 hashcode_factor</span></span><br><span class="line">        <span class="comment">// 用户可以配置全局作业参数 &quot;hashcode_factor&quot;</span></span><br><span class="line">        <span class="comment">// 获取参数 &quot;hashcode_factor&quot;</span></span><br><span class="line">        <span class="comment">// 如果不存在，则使用默认值 &quot;12&quot;</span></span><br><span class="line">        factor = Integer.parseInt(context.getJobParameter(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;12&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> s.hashCode() * factor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TableEnvironment env = TableEnvironment.create(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 设置任务参数</span></span><br><span class="line">env.getConfig().addJobParameter(<span class="string">&quot;hashcode_factor&quot;</span>, <span class="string">&quot;31&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 注册函数</span></span><br><span class="line">env.createTemporarySystemFunction(<span class="string">&quot;hashCode&quot;</span>, HashCodeFunction.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 调用函数</span></span><br><span class="line">env.sqlQuery(<span class="string">&quot;SELECT myField, hashCode(myField) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>以上就是关于开发一个 UDF 之前，你需要注意的一些事项，这些内容不但包含了一些基础必备知识，也包含了一些扩展知识，帮助我们开发更强大的 UDF。</p>
<h2 id="4-7-SQL-标量函数（Scalar-Function）"><a href="#4-7-SQL-标量函数（Scalar-Function）" class="headerlink" title="4.7.SQL 标量函数（Scalar Function）"></a>4.7.SQL 标量函数（Scalar Function）</h2><p>标量函数即 UDF，常常用于进一条数据出一条数据的场景。</p>
<p>使用 Java\Scala 开发一个 Scalar Function 必须包含以下几点：</p>
<ol>
<li>⭐ 实现 <code>org.apache.flink.table.functions.ScalarFunction</code> 接口</li>
<li>⭐ 实现一个或者多个自定义的 eval 函数，名称必须叫做 eval，eval 方法签名必须是 public 的</li>
<li>⭐ eval 方法的入参、出参都是直接体现在 eval 函数的签名中</li>
</ol>
<p>举例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.InputGroup;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.ScalarFunction;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">HashFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 接受任意类型输入，返回 INT 型输出</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eval</span><span class="params">(<span class="meta">@DataTypeHint(inputGroup = InputGroup.ANY)</span> Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> o.hashCode();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TableEnvironment env = TableEnvironment.create(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Table API 里不经注册直接调用函数</span></span><br><span class="line">env.from(<span class="string">&quot;MyTable&quot;</span>).select(call(HashFunction.class, $(<span class="string">&quot;myField&quot;</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册函数</span></span><br><span class="line">env.createTemporarySystemFunction(<span class="string">&quot;HashFunction&quot;</span>, HashFunction.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Table API 里调用注册好的函数</span></span><br><span class="line">env.from(<span class="string">&quot;MyTable&quot;</span>).select(call(<span class="string">&quot;HashFunction&quot;</span>, $(<span class="string">&quot;myField&quot;</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 SQL 里调用注册好的函数</span></span><br><span class="line">env.sqlQuery(<span class="string">&quot;SELECT HashFunction(myField) FROM MyTable&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="4-8-SQL-表值函数（Table-Function）"><a href="#4-8-SQL-表值函数（Table-Function）" class="headerlink" title="4.8.SQL 表值函数（Table Function）"></a>4.8.SQL 表值函数（Table Function）</h2><p>表值函数即 UDTF，常用于进一条数据，出多条数据的场景。</p>
<p>使用 Java\Scala 开发一个 Table Function 必须包含以下几点：</p>
<ol>
<li>⭐ 实现 <code>org.apache.flink.table.functions.TableFunction</code> 接口</li>
<li>⭐ 实现一个或者多个自定义的 eval 函数，名称必须叫做 eval，eval 方法签名必须是 public 的</li>
<li>⭐ eval 方法的入参是直接体现在 eval 函数签名中，出参是体现在 TableFunction 类的泛型参数 T 中，eval 是没有返回值的，这一点是和标量函数不同的，Flink TableFunction 接口提供了 <code>collect(T)</code> 来发送输出的数据。这一点也比较好理解，如果都体现在函数签名上，那就成了标量函数了，而使用 <code>collect(T)</code> 才能体现出 <code>进一条数据</code> <code>出多条数据</code></li>
</ol>
<p>在 SQL 中是用 SQL 中的 <code>LATERAL TABLE(&lt;TableFunction&gt;)</code> 配合 <code>JOIN</code>、<code>LEFT JOIN</code> xxx <code>ON TRUE</code> 使用。</p>
<p>举例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.DataTypeHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.annotation.FunctionHint;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.TableFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.types.Row;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FunctionHint(output = @DataTypeHint(&quot;ROW&lt;word STRING, length INT&gt;&quot;))</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitFunction</span> <span class="keyword">extends</span> <span class="title">TableFunction</span>&lt;<span class="title">Row</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eval</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (String s : str.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">      <span class="comment">// 输出结果</span></span><br><span class="line">      collect(Row.of(s, s.length()));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TableEnvironment env = TableEnvironment.create(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Table API 里可以直接调用 UDF</span></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .joinLateral(call(SplitFunction.class, $(<span class="string">&quot;myField&quot;</span>)))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), $(<span class="string">&quot;word&quot;</span>), $(<span class="string">&quot;length&quot;</span>));</span><br><span class="line"></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .leftOuterJoinLateral(call(SplitFunction.class, $(<span class="string">&quot;myField&quot;</span>)))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), $(<span class="string">&quot;word&quot;</span>), $(<span class="string">&quot;length&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Table API 里重命名 UDF 的结果字段</span></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .leftOuterJoinLateral(call(SplitFunction.class, $(<span class="string">&quot;myField&quot;</span>)).as(<span class="string">&quot;newWord&quot;</span>, <span class="string">&quot;newLength&quot;</span>))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), $(<span class="string">&quot;newWord&quot;</span>), $(<span class="string">&quot;newLength&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册函数</span></span><br><span class="line">env.createTemporarySystemFunction(<span class="string">&quot;SplitFunction&quot;</span>, SplitFunction.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 Table API 里调用注册好的 UDF</span></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .joinLateral(call(<span class="string">&quot;SplitFunction&quot;</span>, $(<span class="string">&quot;myField&quot;</span>)))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), $(<span class="string">&quot;word&quot;</span>), $(<span class="string">&quot;length&quot;</span>));</span><br><span class="line"></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .leftOuterJoinLateral(call(<span class="string">&quot;SplitFunction&quot;</span>, $(<span class="string">&quot;myField&quot;</span>)))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), $(<span class="string">&quot;word&quot;</span>), $(<span class="string">&quot;length&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 SQL 里调用注册好的 UDF</span></span><br><span class="line">env.sqlQuery(</span><br><span class="line">  <span class="string">&quot;SELECT myField, word, length &quot;</span> +</span><br><span class="line">  <span class="string">&quot;FROM MyTable, LATERAL TABLE(SplitFunction(myField))&quot;</span>);</span><br><span class="line"></span><br><span class="line">env.sqlQuery(</span><br><span class="line">  <span class="string">&quot;SELECT myField, word, length &quot;</span> +</span><br><span class="line">  <span class="string">&quot;FROM MyTable &quot;</span> +</span><br><span class="line">  <span class="string">&quot;LEFT JOIN LATERAL TABLE(SplitFunction(myField)) ON TRUE&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 SQL 里重命名 UDF 字段</span></span><br><span class="line">env.sqlQuery(</span><br><span class="line">  <span class="string">&quot;SELECT myField, newWord, newLength &quot;</span> +</span><br><span class="line">  <span class="string">&quot;FROM MyTable &quot;</span> +</span><br><span class="line">  <span class="string">&quot;LEFT JOIN LATERAL TABLE(SplitFunction(myField)) AS T(newWord, newLength) ON TRUE&quot;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<p>如果你是使用 Scala 实现函数，不要使用 Scala 中 object 实现 UDF，Scala object 是单例的，有可能会导致并发问题。</p>
</blockquote>
<h2 id="4-9-SQL-聚合函数（Aggregate-Function）"><a href="#4-9-SQL-聚合函数（Aggregate-Function）" class="headerlink" title="4.9.SQL 聚合函数（Aggregate Function）"></a>4.9.SQL 聚合函数（Aggregate Function）</h2><p>聚合函数即 UDAF，常用于进多条数据，出一条数据的场景。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/19.png" alt="UDAF"></p>
<p>上面的图片展示了一个聚合函数的例子以及聚合函数包含的几个重要方法。</p>
<p>假设你有一个关于饮料的表。表里面有三个字段，分别是 id、name、price，表里有 5 行数据。</p>
<p>假设你需要找到所有饮料里最贵的饮料的价格，即执行一个 max() 聚合就能拿到结果。那么 max() 聚合的执行旧需要遍历所有 5 行数据，最终结果就只有一个数值。</p>
<p>使用 Java\Scala 开发一个 Aggregate Function 必须包含以下几点：</p>
<ol>
<li>⭐ 实现 <code>AggregateFunction</code> 接口，其中所有的方法必须是 public 的、非 static 的</li>
<li>⭐ 必须实现以下几个方法：</li>
</ol>
<ul>
<li>⭐ <code>Acc聚合中间结果 createAccumulator()</code>：为当前 Key 初始化一个空的 accumulator，其存储了聚合的中间结果，比如在执行 max() 时会存储当前的 max 值</li>
<li>⭐ <code>accumulate(Acc accumulator, Input输入参数)</code>：对于每一行数据，都会调用 accumulate() 方法来更新 accumulator，这个方法就是用于处理每一条输入数据；这个方法必须声明为 public 和非 static 的。accumulate 方法可以重载，每个方法的参数类型可以不同，并且支持变长参数。</li>
<li>⭐ <code>Output输出参数 getValue(Acc accumulator)</code>：通过调用 getValue 方法来计算和返回最终的结果</li>
</ul>
<ol start="3">
<li>⭐ 还有几个方法是在某些场景下才必须实现的：</li>
</ol>
<ul>
<li>⭐ <code>retract(Acc accumulator, Input输入参数)</code>：在回撤流的场景下必须要实现，Flink 在计算回撤数据时需要进行调用，如果没有实现则会直接报错</li>
<li>⭐ <code>merge(Acc accumulator, Iterable&lt;Acc&gt; it)</code>：在许多批式聚合以及流式聚合中的 Session、Hop 窗口聚合场景下都是必须要实现的。除此之外，这个方法对于优化也很多帮助。例如，如果你打开了两阶段聚合优化，就需要 AggregateFunction 实现 merge 方法，从而可以做到在数据进行 shuffle 前先进行一次聚合计算。</li>
<li>⭐ <code>resetAccumulator()</code>：在批式聚合中是必须实现的。</li>
</ul>
<ol start="4">
<li>⭐ 还有几个关于入参、出参数据类型信息的方法，默认情况下，用户的 <code>Input输入参数</code>（<code>accumulate(Acc accumulator, Input输入参数)</code> 的入参 <code>Input输入参数</code>）、accumulator（<code>Acc聚合中间结果 createAccumulator()</code> 的返回结果）、<code>Output输出参数</code> 数据类型（<code>Output输出参数 getValue(Acc accumulator)</code> 的 <code>Output输出参数</code>）都会被 Flink 使用反射获取到。但是对于 <code>accumulator</code> 和 <code>Output输出参数</code> 类型来说，Flink SQL 的类型推导在遇到复杂类型的时候可能会推导出错误的结果（注意：<code>Input输入参数</code> 因为是上游算子传入的，所以类型信息是确认的，不会出现推导错误的情况），比如那些非基本类型 POJO 的复杂类型。所以跟 ScalarFunction 和 TableFunction 一样，AggregateFunction 提供了 <code>AggregateFunction#getResultType()</code> 和 <code>AggregateFunction#getAccumulatorType()</code> 来分别指定最终返回值类型和 accumulator 的类型，两个函数的返回值类型都是 TypeInformation，所以熟悉 DataStream 的小伙伴很容易上手。</li>
</ol>
<ul>
<li>⭐ <code>getResultType()</code>：即 <code>Output输出参数 getValue(Acc accumulator)</code> 的输出结果数据类型</li>
<li>⭐ <code>getAccumulatorType()</code>：即 <code>Acc聚合中间结果 createAccumulator()</code> 的返回结果数据类型</li>
</ul>
<p>这个时候，我们直接来举一个加权平均值的例子看下，总共 3 个步骤：</p>
<ul>
<li>⭐ 定义一个聚合函数来计算某一列的加权平均</li>
<li>⭐ 在 TableEnvironment 中注册函数</li>
<li>⭐ 在查询中使用函数</li>
</ul>
<p>为了计算加权平均值，accumulator 需要存储加权总和以及数据的条数。在我们的例子里，我们定义了一个类 WeightedAvgAccumulator 来作为 accumulator。</p>
<p>Flink 的 checkpoint 机制会自动保存 accumulator，在失败时进行恢复，以此来保证精确一次的语义。</p>
<p>我们的 WeightedAvg（聚合函数）的 accumulate 方法有三个输入参数。第一个是 WeightedAvgAccum accumulator，另外两个是用户自定义的输入：输入的值 ivalue 和 输入的权重 iweight。</p>
<p>尽管 retract()、merge()、resetAccumulator() 这几个方法在大多数聚合类型中都不是必须实现的，博主也在样例中提供了他们的实现。并且定义了 getResultType() 和 getAccumulatorType()。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.AggregateFunction;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.flink.table.api.Expressions.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义一个计算权重 avg 的 accmulator</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvgAccumulator</span> </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输入：Long iValue, Integer iWeight</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WeightedAvg</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Long</span>, <span class="title">WeightedAvgAccumulator</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span> </span><br><span class="line">  <span class="comment">// 创建一个 accumulator</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> WeightedAvgAccumulator <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> WeightedAvgAccumulator();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(WeightedAvgAccumulator acc, Long iValue, Integer iWeight)</span> </span>&#123;</span><br><span class="line">    acc.sum += iValue * iWeight;</span><br><span class="line">    acc.count += iWeight;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">retract</span><span class="params">(WeightedAvgAccumulator acc, Long iValue, Integer iWeight)</span> </span>&#123;</span><br><span class="line">    acc.sum -= iValue * iWeight;</span><br><span class="line">    acc.count -= iWeight;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="comment">// 获取返回结果</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Long <span class="title">getValue</span><span class="params">(WeightedAvgAccumulator acc)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (acc.count == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> acc.sum / acc.count;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Session window 可以使用这个方法将几个单独窗口的结果合并</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(WeightedAvgAccumulator acc, Iterable&lt;WeightedAvgAccumulator&gt; it)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (WeightedAvgAccumulator a : it) &#123;</span><br><span class="line">      acc.count += a.count;</span><br><span class="line">      acc.sum += a.sum;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetAccumulator</span><span class="params">(WeightedAvgAccumulator acc)</span> </span>&#123;</span><br><span class="line">    acc.count = <span class="number">0</span>;</span><br><span class="line">    acc.sum = <span class="number">0L</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TableEnvironment env = TableEnvironment.create(...);</span><br><span class="line"></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .groupBy($(<span class="string">&quot;myField&quot;</span>))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), call(WeightedAvg.class, $(<span class="string">&quot;value&quot;</span>), $(<span class="string">&quot;weight&quot;</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册函数</span></span><br><span class="line">env.createTemporarySystemFunction(<span class="string">&quot;WeightedAvg&quot;</span>, WeightedAvg.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Table API 调用函数</span></span><br><span class="line">env</span><br><span class="line">  .from(<span class="string">&quot;MyTable&quot;</span>)</span><br><span class="line">  .groupBy($(<span class="string">&quot;myField&quot;</span>))</span><br><span class="line">  .select($(<span class="string">&quot;myField&quot;</span>), call(<span class="string">&quot;WeightedAvg&quot;</span>, $(<span class="string">&quot;value&quot;</span>), $(<span class="string">&quot;weight&quot;</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL API 调用函数</span></span><br><span class="line">env.sqlQuery(</span><br><span class="line">  <span class="string">&quot;SELECT myField, WeightedAvg(`value`, weight) FROM MyTable GROUP BY myField&quot;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<h2 id="4-10-SQL-表值聚合函数（Table-Aggregate-Function）"><a href="#4-10-SQL-表值聚合函数（Table-Aggregate-Function）" class="headerlink" title="4.10.SQL 表值聚合函数（Table Aggregate Function）"></a>4.10.SQL 表值聚合函数（Table Aggregate Function）</h2><p>表值聚合函数即 UDTAF。首先说明这个函数目前只能在 Table API 中进行使用，不能在 SQL API 中使用。那么这个函数有什么作用呢，为什么被创建出来？</p>
<p>因为在 SQL 表达式中，如果我们想对数据先分组再进行聚合取值，能选择的就是 <code>select max(xxx) from source_table group by key1, key2</code>。但是上面这个 SQL 的 max 语义最后产出的结果只有一条最终结果，如果我想取聚合结果最大的 n 条数据，并且 n 条数据，每一条都要输出一次结果数据，上面的 SQL 就没有办法实现了（因为在聚合的情况下还输出多条，从上述 SQL 语义上来说就是不正确的）。</p>
<p>所以 UDTAF 就是为了处理这种场景，他可以让我们自定义 <code>怎么去</code>，<code>取多少条</code> 最终的聚合结果。所以可以看到 UDTAF 和 UDAF 是类似的。如下图所示：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/20.png" alt="UDTAF"></p>
<p>上图展示了一个表值聚合函数的例子。</p>
<p>假设你有一个饮料的表，这个表有 3 列，分别是 id、name 和 price，一共有 5 行。</p>
<p>假设你需要找到价格最高的两个饮料，类似于 top2() 表值聚合函数。你需要遍历所有 5 行数据，输出结果为 2 行数据的一个表。</p>
<p>使用 Java\Scala 开发一个 Table Aggregate Function 必须包含以下几点：</p>
<ol>
<li>⭐ 实现 <code>TableAggregateFunction</code> 接口，其中所有的方法必须是 public 的、非 static 的</li>
<li>⭐ 必须实现以下几个方法：</li>
</ol>
<ul>
<li>⭐ <code>Acc聚合中间结果 createAccumulator()</code>：为当前 Key 初始化一个空的 accumulator，其存储了聚合的中间结果，比如在执行 max() 时会存储每一条中间结果的 max 值</li>
<li>⭐ <code>accumulate(Acc accumulator, Input输入参数)</code>：对于每一行数据，都会调用 accumulate() 方法来更新 accumulator，这个方法就是对每一条输入数据进行执行，比如执行 max() 时，遍历每一条数据执行；在实现这个方法是必须声明为 public 和非 static 的。accumulate 方法可以重载，每个方法的参数类型不同，并且支持变长参数。</li>
<li>⭐ <code>emitValue(Acc accumulator, Collector&lt;OutPut&gt; collector)</code> 或者 <code>emitUpdateWithRetract(Acc accumulator, RetractableCollector&lt;OutPut&gt; collector)</code>：当遍历所有的数据，当所有的数据都处理完了之后，通过调用 emit 方法来计算和输出最终的结果，在这里你就可以自定义到底输出多条少以及怎么样去输出结果。那么对于 emitValue 以及 emitUpdateWithRetract 的区别来说，拿 TopN 实现来说，emitValue 每次都会发送所有的最大的 n 个值，而这在流式任务中可能会有一些性能问题。为了提升性能，用户可以实现 emitUpdateWithRetract 方法。这个方法在 retract 模式下会增量的输出结果，比如只在有数据更新时，可以做到撤回老的数据，然后再发送新的数据，而不需要每次都发出全量的最新数据。如果我们同时定义了 emitUpdateWithRetract、emitValue 方法，那 emitUpdateWithRetract 会优先于 emitValue 方法被使用，因为引擎会认为 emitUpdateWithRetract 会更加高效，因为它的输出是增量的。 </li>
</ul>
<ol start="3">
<li>⭐ 还有几个方法是在某些场景下才必须实现的：</li>
</ol>
<ul>
<li>⭐ <code>retract(Acc accumulator, Input输入参数)</code>：在回撤流的场景下必须要实现，Flink 在计算回撤数据时需要进行调用，如果没有实现则会直接报错</li>
<li>⭐ <code>merge(Acc accumulator, Iterable&lt;Acc&gt; it)</code>：在许多批式聚合以及流式聚合中的 Session、Hop 窗口聚合场景下都是必须要实现的。除此之外，这个方法对于优化也很多帮助。例如，如果你打开了两阶段聚合优化，就需要 AggregateFunction 实现 merge 方法，从而在第一阶段先进行数据聚合。</li>
<li>⭐ <code>resetAccumulator()</code>：在批式聚合中是必须实现的。</li>
</ul>
<ol start="4">
<li>⭐ 还有几个关于入参、出参数据类型信息的方法，默认情况下，用户的 <code>Input输入参数</code>（<code>accumulate(Acc accumulator, Input输入参数)</code> 的入参 <code>Input输入参数</code>）、accumulator（<code>Acc聚合中间结果 createAccumulator()</code> 的返回结果）、<code>Output输出参数</code> 数据类型（<code>emitValue(Acc acc, Collector&lt;Output输出参数&gt; out)</code> 的 <code>Output输出参数</code>）都会被 Flink 使用反射获取到。但是对于 <code>accumulator</code> 和 <code>Output输出参数</code> 类型来说，Flink SQL 的类型推导在遇到复杂类型的时候可能会推导出错误的结果（注意：<code>Input输入参数</code> 因为是上游算子传入的，所以类型信息是确认的，不会出现推导错误的情况），比如那些非基本类型 POJO 的复杂类型。所以跟 ScalarFunction 和 TableFunction 一样，AggregateFunction 提供了 <code>TableAggregateFunction#getResultType()</code> 和 <code>TableAggregateFunction#getAccumulatorType()</code> 来分别指定最终返回值类型和 accumulator 的类型，两个函数的返回值类型都是 TypeInformation，所以熟悉 DataStream 的小伙伴很容易上手。</li>
</ol>
<ul>
<li>⭐ <code>getResultType()</code>：即 <code>emitValue(Acc acc, Collector&lt;Output输出参数&gt; out)</code> 的输出结果数据类型</li>
<li>⭐ <code>getAccumulatorType()</code>：即 <code>Acc聚合中间结果 createAccumulator()</code> 的返回结果数据类型</li>
</ul>
<p>这个时候，我们直接来举一个 Top2 的例子看下吧：</p>
<ul>
<li>⭐ 定义一个 TableAggregateFunction 来计算给定列的最大的 2 个值</li>
<li>⭐ 在 TableEnvironment 中注册函数</li>
<li>⭐ 在 Table API 查询中使用函数（当前只在 Table API 中支持 TableAggregateFunction）</li>
</ul>
<p>为了计算最大的 2 个值，accumulator 需要保存当前看到的最大的 2 个值。</p>
<p>在我们的例子中，我们定义了类 Top2Accum 来作为 accumulator。</p>
<p>Flink 的 checkpoint 机制会自动保存 accumulator，并且在失败时进行恢复，来保证精确一次的语义。</p>
<p>我们的 Top2 表值聚合函数（TableAggregateFunction）的 accumulate() 方法有两个输入，第一个是 Top2Accum accumulator，另一个是用户定义的输入：输入的值 v。尽管 merge() 方法在大多数聚合类型中不是必须的，我们也在样例中提供了它的实现。并且定义了 getResultType() 和 getAccumulatorType() 方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accumulator for Top2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Top2Accum</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> Integer first;</span><br><span class="line">    <span class="keyword">public</span> Integer second;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Top2</span> <span class="keyword">extends</span> <span class="title">TableAggregateFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">Integer</span>, <span class="title">Integer</span>&gt;, <span class="title">Top2Accum</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Top2Accum <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Top2Accum acc = <span class="keyword">new</span> Top2Accum();</span><br><span class="line">        acc.first = Integer.MIN_VALUE;</span><br><span class="line">        acc.second = Integer.MIN_VALUE;</span><br><span class="line">        <span class="keyword">return</span> acc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(Top2Accum acc, Integer v)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (v &gt; acc.first) &#123;</span><br><span class="line">            acc.second = acc.first;</span><br><span class="line">            acc.first = v;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &gt; acc.second) &#123;</span><br><span class="line">            acc.second = v;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(Top2Accum acc, java.lang.Iterable&lt;Top2Accum&gt; iterable)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Top2Accum otherAcc : iterable) &#123;</span><br><span class="line">            accumulate(acc, otherAcc.first);</span><br><span class="line">            accumulate(acc, otherAcc.second);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">emitValue</span><span class="params">(Top2Accum acc, Collector&lt;Tuple2&lt;Integer, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// emit the value and rank</span></span><br><span class="line">        <span class="keyword">if</span> (acc.first != Integer.MIN_VALUE) &#123;</span><br><span class="line">            out.collect(Tuple2.of(acc.first, <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (acc.second != Integer.MIN_VALUE) &#123;</span><br><span class="line">            out.collect(Tuple2.of(acc.second, <span class="number">2</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册函数</span></span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;top2&quot;</span>, <span class="keyword">new</span> Top2());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化表</span></span><br><span class="line">Table tab = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用函数</span></span><br><span class="line">tab.groupBy(<span class="string">&quot;key&quot;</span>)</span><br><span class="line">    .flatAggregate(<span class="string">&quot;top2(a) as (v, rank)&quot;</span>)</span><br><span class="line">    .select(<span class="string">&quot;key, v, rank&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>下面的例子展示了如何使用 emitUpdateWithRetract 方法来只发送更新的数据。</p>
<p>为了只发送更新的结果，accumulator 保存了上一次的最大的 2 个值，也保存了当前最大的 2 个值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Accumulator for Top2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Top2Accum</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> Integer first;</span><br><span class="line">    <span class="keyword">public</span> Integer second;</span><br><span class="line">    <span class="keyword">public</span> Integer oldFirst;</span><br><span class="line">    <span class="keyword">public</span> Integer oldSecond;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Top2</span> <span class="keyword">extends</span> <span class="title">TableAggregateFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">Integer</span>, <span class="title">Integer</span>&gt;, <span class="title">Top2Accum</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Top2Accum <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Top2Accum acc = <span class="keyword">new</span> Top2Accum();</span><br><span class="line">        acc.first = Integer.MIN_VALUE;</span><br><span class="line">        acc.second = Integer.MIN_VALUE;</span><br><span class="line">        acc.oldFirst = Integer.MIN_VALUE;</span><br><span class="line">        acc.oldSecond = Integer.MIN_VALUE;</span><br><span class="line">        <span class="keyword">return</span> acc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(Top2Accum acc, Integer v)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (v &gt; acc.first) &#123;</span><br><span class="line">            acc.second = acc.first;</span><br><span class="line">            acc.first = v;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v &gt; acc.second) &#123;</span><br><span class="line">            acc.second = v;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">emitUpdateWithRetract</span><span class="params">(Top2Accum acc, RetractableCollector&lt;Tuple2&lt;Integer, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!acc.first.equals(acc.oldFirst)) &#123;</span><br><span class="line">            <span class="comment">// if there is an update, retract old value then emit new value.</span></span><br><span class="line">            <span class="keyword">if</span> (acc.oldFirst != Integer.MIN_VALUE) &#123;</span><br><span class="line">                out.retract(Tuple2.of(acc.oldFirst, <span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            out.collect(Tuple2.of(acc.first, <span class="number">1</span>));</span><br><span class="line">            acc.oldFirst = acc.first;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!acc.second.equals(acc.oldSecond)) &#123;</span><br><span class="line">            <span class="comment">// if there is an update, retract old value then emit new value.</span></span><br><span class="line">            <span class="keyword">if</span> (acc.oldSecond != Integer.MIN_VALUE) &#123;</span><br><span class="line">                out.retract(Tuple2.of(acc.oldSecond, <span class="number">2</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            out.collect(Tuple2.of(acc.second, <span class="number">2</span>));</span><br><span class="line">            acc.oldSecond = acc.second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册函数</span></span><br><span class="line">StreamTableEnvironment tEnv = ...</span><br><span class="line">tEnv.registerFunction(<span class="string">&quot;top2&quot;</span>, <span class="keyword">new</span> Top2());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化表</span></span><br><span class="line">Table tab = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用函数</span></span><br><span class="line">tab.groupBy(<span class="string">&quot;key&quot;</span>)</span><br><span class="line">    .flatAggregate(<span class="string">&quot;top2(a) as (v, rank)&quot;</span>)</span><br><span class="line">    .select(<span class="string">&quot;key, v, rank&quot;</span>);</span><br></pre></td></tr></table></figure>

<h1 id="5-SQL-能力扩展篇"><a href="#5-SQL-能力扩展篇" class="headerlink" title="5.SQL 能力扩展篇"></a>5.SQL 能力扩展篇</h1><h2 id="5-1-SQL-UDF-扩展-Module"><a href="#5-1-SQL-UDF-扩展-Module" class="headerlink" title="5.1.SQL UDF 扩展 - Module"></a>5.1.SQL UDF 扩展 - Module</h2><p>在介绍 Flink Module 具体能力之前，我们先来聊聊博主讲述的思路：</p>
<ol>
<li>⭐ 背景及应用场景介绍</li>
<li>⭐ Flink Module 功能介绍</li>
<li>⭐ 应用案例：Flink SQL 支持 Hive UDF</li>
</ol>
<h3 id="5-1-1-Flink-SQL-Module-应用场景"><a href="#5-1-1-Flink-SQL-Module-应用场景" class="headerlink" title="5.1.1.Flink SQL Module 应用场景"></a>5.1.1.Flink SQL Module 应用场景</h3><p>兄弟们，想想其实大多数公司都是从离线数仓开始建设的。相信大家必然在自己的生产环境中开发了非常多的 Hive UDF。随着需求对于时效性要求的增高，越来越多的公司也开始建设起实时数仓。很多场景下实时数仓的建设都是随着离线数仓而建设的。实时数据使用 Flink 产出，离线数据使用 Hive/Spark 产出。</p>
<p>那么回到我们的问题：为什么需要给 Flink UDF 做扩展呢？可能这个问题比较大，那么博主分析的具体一些，如果 Flink 扩展支持 Hive UDF 对我们有哪些好处呢？</p>
<p>博主分析了下，结论如下：</p>
<p>站在数据需求的角度来说，一般会有以下两种情况：</p>
<ol>
<li>⭐ 以前已经有了离线数据链路，需求方也想要实时数据。如果直接能用已经开发好的 hive udf，则不用将相同的逻辑迁移到 flink udf 中，并且后续无需费时费力维护两个 udf 的逻辑一致性。</li>
<li>⭐ 实时和离线的需求都是新的，需要新开发。如果只开发一套 UDF，则事半功倍。</li>
</ol>
<p>因此在 Flink 中支持 Hive UDF（也即扩展 Flink 的 UDF 能力）这件事对开发人员提效来说是非常有好处的。</p>
<h3 id="5-1-2-Flink-SQL-Module-功能介绍"><a href="#5-1-2-Flink-SQL-Module-功能介绍" class="headerlink" title="5.1.2.Flink SQL Module 功能介绍"></a>5.1.2.Flink SQL Module 功能介绍</h3><p>Module 允许 Flink 扩展函数能力。它是可插拔的，Flink 官方本身已经提供了一些 Module，用户也可以编写自己的 Module。</p>
<p>例如，用户可以定义自己的函数，并将其作为加载进入 Flink，以在 Flink SQL 和 Table API 中使用。</p>
<p>再举一个例子，用户可以加载官方已经提供的的 Hive Module，将 Hive 已有的内置函数作为 Flink 的内置函数。</p>
<p>目前 Flink 包含了以下三种 Module：</p>
<ol>
<li>⭐ CoreModule：CoreModule 是 Flink 内置的 Module，其包含了目前 Flink 内置的所有 UDF，Flink 默认开启的 Module 就是 CoreModule，我们可以直接使用其中的 UDF</li>
<li>⭐ HiveModule：HiveModule 可以将 Hive 内置函数作为 Flink 的系统函数提供给 SQL\Table API 用户进行使用，比如 get_json_object 这类 Hive 内置函数（Flink 默认的 CoreModule 是没有的）</li>
<li>⭐ 用户自定义 Module：用户可以实现 Module 接口实现自己的 UDF 扩展 Module</li>
</ol>
<p>在 Flink 中，Module 可以被 <code>加载</code>、<code>启用</code>、<code>禁用</code>、<code>卸载</code> Module，当 TableEnvironment 加载（见 SQL 语法篇的 Load Module） Module 之后，默认就是开启的。</p>
<p>Flink 是同时支持多个 Module 的，并且根据加载 Module 的顺序去按顺序查找和解析 UDF，先查到的先解析使用。</p>
<p>此外，Flink 只会解析已经启用了的 Module。那么当两个 Module 中出现两个同名的函数时，会有以下三种情况：</p>
<ol>
<li>⭐ 如果两个 Module 都启用的话，Flink 会根据加载 Module 的顺序进行解析，结果就是会使用顺序为第一个的 Module 的 UDF</li>
<li>⭐ 如果只有一个 Module 启用的话，Flink 就只会从启用的 Module 解析 UDF</li>
<li>⭐ 如果两个 Module 都没有启用，Flink 就无法解析这个 UDF</li>
</ol>
<p>当然如果出现第一种情况时，用户也可以改变使用 Module 的顺序。比如用户可以使用 <code>USE MODULE hive, core</code> 语句去将 Hive Module 设为第一个使用及解析的 Module。</p>
<p>另外，用户可以使用 <code>USE MODULES hive</code> 去禁用默认的 core Module，注意，禁用不是卸载 Module，用户之后还可以再次启用 Module，并且使用 <code>USE MODULES core</code> 去将 core Module 设置为启用的。如果使用未加载的 Module，则会直接抛出异常。</p>
<p>禁用和卸载 Module 的区别在于禁用依然会在 TableEnvironment 保留 Module，用户依然可以使用使用 list 命令看到禁用的 Module。</p>
<blockquote>
<p>注意：</p>
<p>由于 Module 的 UDF 是被 Flink 认为是 Flink 系统内置的，它不和任何 Catalog，数据库绑定，所以这部分 UDF 没有对应的命名空间，即没有 Catalog，数据库命名空间。</p>
</blockquote>
<ol>
<li>⭐ 使用 SQL API 加载、卸载、使用、列出 Module</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner().build();</span><br><span class="line">TableEnvironment tableEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 展示加载和启用的 Module</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// | module name | used |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// |        core | true |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 加载 hive module</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;LOAD MODULE hive WITH (&#x27;hive-version&#x27; = &#x27;...&#x27;)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 展示所有启用的 module</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 展示所有加载的 module 以及它们的启用状态</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// | module name | used |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// |        core | true |</span></span><br><span class="line"><span class="comment">// |        hive | true |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 改变 module 解析顺序</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;USE MODULES hive, core&quot;</span>);</span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// | module name | used |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// |        hive | true |</span></span><br><span class="line"><span class="comment">// |        core | true |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 禁用 core module</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;USE MODULES hive&quot;</span>);</span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// | module name |  used |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// |        hive |  true |</span></span><br><span class="line"><span class="comment">// |        core | false |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 卸载 hive module</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;UNLOAD MODULE hive&quot;</span>);</span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// Empty set</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;SHOW FULL MODULES&quot;</span>).print();</span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// | module name |  used |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// |        hive | false |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 使用 Java API 加载、卸载、使用、列出 Module</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner().build();</span><br><span class="line">TableEnvironment tableEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Show initially loaded and enabled modules</span></span><br><span class="line">tableEnv.listModules();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line">tableEnv.listFullModules();</span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// | module name | used |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// |        core | true |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Load a hive module</span></span><br><span class="line">tableEnv.loadModule(<span class="string">&quot;hive&quot;</span>, <span class="keyword">new</span> HiveModule());</span><br><span class="line"></span><br><span class="line"><span class="comment">// Show all enabled modules</span></span><br><span class="line">tableEnv.listModules();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Show all loaded modules with both name and use status</span></span><br><span class="line">tableEnv.listFullModules();</span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// | module name | used |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// |        core | true |</span></span><br><span class="line"><span class="comment">// |        hive | true |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Change resolution order</span></span><br><span class="line">tableEnv.useModules(<span class="string">&quot;hive&quot;</span>, <span class="string">&quot;core&quot;</span>);</span><br><span class="line">tableEnv.listModules();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// |        core |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line">tableEnv.listFullModules();</span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// | module name | used |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"><span class="comment">// |        hive | true |</span></span><br><span class="line"><span class="comment">// |        core | true |</span></span><br><span class="line"><span class="comment">// +-------------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Disable core module</span></span><br><span class="line">tableEnv.useModules(<span class="string">&quot;hive&quot;</span>);</span><br><span class="line">tableEnv.listModules();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// | module name |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        hive |</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line">tableEnv.listFullModules();</span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// | module name |  used |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// |        hive |  true |</span></span><br><span class="line"><span class="comment">// |        core | false |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Unload hive module</span></span><br><span class="line">tableEnv.unloadModule(<span class="string">&quot;hive&quot;</span>);</span><br><span class="line">tableEnv.listModules();</span><br><span class="line"><span class="comment">// Empty set</span></span><br><span class="line">tableEnv.listFullModules();</span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// | module name |  used |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br><span class="line"><span class="comment">// |        hive | false |</span></span><br><span class="line"><span class="comment">// +-------------+-------+</span></span><br></pre></td></tr></table></figure>

<h3 id="5-1-3-应用案例：Flink-SQL-支持-Hive-UDF"><a href="#5-1-3-应用案例：Flink-SQL-支持-Hive-UDF" class="headerlink" title="5.1.3.应用案例：Flink SQL 支持 Hive UDF"></a>5.1.3.应用案例：Flink SQL 支持 Hive UDF</h3><p>Flink 支持 hive UDF 这件事分为两个部分。</p>
<ol>
<li>⭐ Flink 扩展支持 hive 内置 UDF</li>
<li>⭐ Flink 扩展支持用户自定义 hive UDF</li>
</ol>
<p>第一部分：Flink 扩展支持 Hive 内置 UDF，比如 <code>get_json_object</code>，<code>rlike</code> 等等。</p>
<p>有同学问了，这么基本的 UDF，Flink 都没有吗？</p>
<p>确实没有。关于 Flink SQL 内置的 UDF 见如下链接，大家可以看看 Flink 支持了哪些 UDF：<br><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/functions/systemfunctions/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/functions/systemfunctions/</a></p>
<p>那么如果我如果强行使用 get_json_object 这个 UDF，会发生啥呢？结果如下图。</p>
<p>直接报错找不到 UDF。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/2.png" alt="error"></p>
<p>第二部分：Flink 扩展支持用户自定义 Hive UDF。</p>
<p>内置函数解决不了用户的复杂需求，用户就需要自己写 Hive UDF，并且这部分自定义 UDF 也想在 flink sql 中使用。</p>
<p>下面看看怎么在 Flink SQL 中进行这两种扩展。</p>
<ol>
<li>⭐ flink 扩展支持 hive 内置 udf</li>
</ol>
<p>步骤如下：</p>
<ul>
<li>⭐ 引入 hive 的 connector。其中包含了 flink 官方提供的一个 <code>HiveModule</code>。在 <code>HiveModule</code> 中包含了 hive 内置的 udf。</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-hive_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ 在 <code>StreamTableEnvironment</code> 中加载 <code>HiveModule</code>。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String name = <span class="string">&quot;default&quot;</span>;</span><br><span class="line">String version = <span class="string">&quot;3.1.2&quot;</span>;</span><br><span class="line">tEnv.loadModule(name, <span class="keyword">new</span> HiveModule(version));</span><br></pre></td></tr></table></figure>

<p>然后在控制台打印一下目前有的 module。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String[] modules = tEnv.listModules();</span><br><span class="line">Arrays.stream(modules).forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p>然后可以看到除了 <code>core</code> module，还有我们刚刚加载进去的 <code>default</code> module。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">default</span><br><span class="line">core</span><br></pre></td></tr></table></figure>

<ul>
<li>⭐ 查看所有 module 的所有 udf。在控制台打印一下。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String[] functions = tEnv.listFunctions();</span><br><span class="line">Arrays.stream(functions).forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p>就会将 default 和 core module 中的所有包含的 udf 给列举出来，当然也就包含了 hive module 中的 get_json_object。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/3.png" alt="get_json_object"></p>
<p>然后我们再去在 Flink SQL 中使用 get_json_object 这个 UDF，就没有报错，能正常输出结果了。</p>
<p>使用 Flink Hive connector 自带的 <code>HiveModule</code>，已经能够解决很大一部分常见 UDF 使用的问题了。</p>
<ol start="2">
<li>⭐ Flink 扩展支持用户自定义 Hive UDF</li>
</ol>
<p>原本博主是直接想要使用 Flink SQL 中的 <code>create temporary function</code> 去执行引入自定义 Hive UDF 的。</p>
<p>举例如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> test_hive_udf <span class="keyword">as</span> <span class="string">&#x27;flink.examples.sql._09.udf._02_stream_hive_udf.TestGenericUDF&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>发现在执行这句 SQL 时，是可以执行成功，将 UDF 注册进去的。</p>
<p>但是在后续 UDF 初始化时就报错了。具体错误如下图。直接报错 ClassCastException。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/4.png" alt="ddl hive udf error"></p>
<p>看了下源码，Flink 流任务模式下（未连接 Hive MetaStore 时）在创建 UDF 时会认为这个 UDF 是 Flink 生态体系中的 UDF。</p>
<p>所以在初始化我们引入的 <code>TestGenericUDF</code> 时，默认会按照 Flink 的 <code>UserDefinedFunction</code> 强转，因此才会报强转错误。</p>
<p>那么我们就不能使用 Hive UDF 了吗？</p>
<p>错误，小伙伴萌岂敢有这种想法。博主都把这个标题列出来了（牛逼都吹出去了），还能给不出解决方案嘛。</p>
<p>思路见下一节。</p>
<ol start="3">
<li>⭐ Flink 扩展支持用户自定义 Hive UDF 的增强 module</li>
</ol>
<p>其实思路很简单。</p>
<p>使用 Flink SQL 中的 <code>create temporary function</code> 虽然不能执行，但是 Flink 提供了插件化的自定义 module。</p>
<p>我们可以扩展一个支持用户自定义 Hive UDF 的 module，使用这个 module 来支持自定义的 Hive UDF。</p>
<p>实现的代码也非常简单。简单的把 Flink Hive connector 提供的 <code>HiveModule</code> 做一个增强即可，即下图中的 <code>HiveModuleV2</code>。使用方式如下图所示：</p>
<p>源码公众号后台回复<strong>1.13.2 sql hive udf</strong>获取。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_flinksql%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/5.png" alt="hive module enhance"></p>
<p>然后程序就正常跑起来了。</p>
<p>肥肠滴好用！</p>
<h2 id="5-2-SQL-元数据扩展-Catalog"><a href="#5-2-SQL-元数据扩展-Catalog" class="headerlink" title="5.2.SQL 元数据扩展 - Catalog"></a>5.2.SQL 元数据扩展 - Catalog</h2><h3 id="5-2-1-Flink-Catalog-功能介绍"><a href="#5-2-1-Flink-Catalog-功能介绍" class="headerlink" title="5.2.1.Flink Catalog 功能介绍"></a>5.2.1.Flink Catalog 功能介绍</h3><p>数据处理最关键的方面之一是管理元数据。元数据可以是临时的，例如临时表、UDF。 元数据也可以是持久化的，例如 Hive MetaStore 中的元数据。</p>
<p>Flink SQL 中是由 Catalog 提供了元数据信息，例如数据库、表、分区、视图以及数据库或其他外部系统中存储的函数和信息。对标 Hive 去理解就是 Hive 的 MetaStore，都是用于存储计算引擎涉及到的元数据信息。</p>
<p>Catalog 允许用户引用其数据存储系统中现有的元数据，并自动将其映射到 Flink 的相应元数据。例如，Flink 可以直接使用 Hive MetaStore 中的表的元数据，也可以将 Flink SQL 中的元数据存储到 Hive MetaStore 中。Catalog 极大地简化了用户开始使用 Flink 的步骤，提升了用户体验。</p>
<p>目前 Flink 包含了以下四种 Catalog：</p>
<ol>
<li>⭐ GenericInMemoryCatalog：GenericInMemoryCatalog 是基于内存实现的 Catalog，所有元数据只在 session 的生命周期（即一个 Flink 任务一次运行生命周期内）内可用。</li>
<li>⭐ JdbcCatalog：JdbcCatalog 使得用户可以将 Flink 通过 JDBC 协议连接到关系数据库。PostgresCatalog 是当前实现的唯一一种 JDBC Catalog，即可以将 Flink SQL 的预案数据存储在 Postgres 中。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PostgresCatalog 方法支持的方法</span></span><br><span class="line">PostgresCatalog.databaseExists(String databaseName)</span><br><span class="line">PostgresCatalog.listDatabases()</span><br><span class="line">PostgresCatalog.getDatabase(String databaseName)</span><br><span class="line">PostgresCatalog.listTables(String databaseName)</span><br><span class="line">PostgresCatalog.getTable(ObjectPath tablePath)</span><br><span class="line">PostgresCatalog.tableExists(ObjectPath tablePath)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ HiveCatalog：HiveCatalog 有两个用途，作为 Flink 元数据的持久化存储，以及作为读写现有 Hive 元数据的接口。注意：Hive MetaStore 以小写形式存储所有元数据对象名称。而 GenericInMemoryCatalog 会区分大小写。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TableEnvironment tableEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line">String name            = <span class="string">&quot;myhive&quot;</span>;</span><br><span class="line">String defaultDatabase = <span class="string">&quot;mydatabase&quot;</span>;</span><br><span class="line">String hiveConfDir     = <span class="string">&quot;/opt/hive-conf&quot;</span>;</span><br><span class="line"></span><br><span class="line">HiveCatalog hive = <span class="keyword">new</span> HiveCatalog(name, defaultDatabase, hiveConfDir);</span><br><span class="line">tableEnv.registerCatalog(<span class="string">&quot;myhive&quot;</span>, hive);</span><br><span class="line"></span><br><span class="line"><span class="comment">// set the HiveCatalog as the current catalog of the session</span></span><br><span class="line">tableEnv.useCatalog(<span class="string">&quot;myhive&quot;</span>);</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 用户自定义 Catalog：用户可以实现 Catalog 接口实现自定义 Catalog</li>
</ol>
<p>下面看看 Flink Catalog 提供了什么 API，以及对应 API 的使用案例：</p>
<ol>
<li>⭐ 使用 SQL API 将表创建注册进 Catalog</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">TableEnvironment tableEnv = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 HiveCatalog </span></span><br><span class="line">Catalog catalog = <span class="keyword">new</span> HiveCatalog(<span class="string">&quot;myhive&quot;</span>, <span class="keyword">null</span>, <span class="string">&quot;&lt;path_of_hive_conf&gt;&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册 catalog</span></span><br><span class="line">tableEnv.registerCatalog(<span class="string">&quot;myhive&quot;</span>, catalog);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 catalog 中创建 database</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;CREATE DATABASE mydb WITH (...)&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 catalog 中创建表</span></span><br><span class="line">tableEnv.executeSql(<span class="string">&quot;CREATE TABLE mytable (name STRING, age INT) WITH (...)&quot;</span>);</span><br><span class="line"></span><br><span class="line">tableEnv.listTables(); <span class="comment">// 列出当前 myhive.mydb 中的所有表</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 使用 Java API 将表创建注册进 Catalog</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.catalog.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.catalog.hive.HiveCatalog;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.descriptors.Kafka;</span><br><span class="line"></span><br><span class="line">TableEnvironment tableEnv = TableEnvironment.create(EnvironmentSettings.newInstance().build());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 HiveCatalog </span></span><br><span class="line">Catalog catalog = <span class="keyword">new</span> HiveCatalog(<span class="string">&quot;myhive&quot;</span>, <span class="keyword">null</span>, <span class="string">&quot;&lt;path_of_hive_conf&gt;&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册 catalog</span></span><br><span class="line">tableEnv.registerCatalog(<span class="string">&quot;myhive&quot;</span>, catalog);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 catalog 中创建 database</span></span><br><span class="line">catalog.createDatabase(<span class="string">&quot;mydb&quot;</span>, <span class="keyword">new</span> CatalogDatabaseImpl(...));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在 catalog 中创建表</span></span><br><span class="line">TableSchema schema = TableSchema.builder()</span><br><span class="line">    .field(<span class="string">&quot;name&quot;</span>, DataTypes.STRING())</span><br><span class="line">    .field(<span class="string">&quot;age&quot;</span>, DataTypes.INT())</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">catalog.createTable(</span><br><span class="line">        <span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), </span><br><span class="line">        <span class="keyword">new</span> CatalogTableImpl(</span><br><span class="line">            schema,</span><br><span class="line">            <span class="keyword">new</span> Kafka()</span><br><span class="line">                .version(<span class="string">&quot;0.11&quot;</span>)</span><br><span class="line">                ....</span><br><span class="line">                .startFromEarlist()</span><br><span class="line">                .toProperties(),</span><br><span class="line">            <span class="string">&quot;my comment&quot;</span></span><br><span class="line">        ),</span><br><span class="line">        <span class="keyword">false</span></span><br><span class="line">    );</span><br><span class="line">    </span><br><span class="line">List&lt;String&gt; tables = catalog.listTables(<span class="string">&quot;mydb&quot;</span>); <span class="comment">// 列出当前 myhive.mydb 中的所有表</span></span><br></pre></td></tr></table></figure>

<h3 id="5-2-2-操作-Catalog-的-API"><a href="#5-2-2-操作-Catalog-的-API" class="headerlink" title="5.2.2.操作 Catalog 的 API"></a>5.2.2.操作 Catalog 的 API</h3><p>这里只列出了 Java 的 Catalog API，用户也可以使用 SQL DDL API 实现相同的功能。关于 DDL 的详细信息请参考之前介绍到的 SQL CREATE DDL 章节。</p>
<ol>
<li>⭐ Catalog 操作</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注册 Catalog</span></span><br><span class="line">tableEnv.registerCatalog(<span class="keyword">new</span> CustomCatalog(<span class="string">&quot;myCatalog&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 切换 Catalog 和 Database</span></span><br><span class="line">tableEnv.useCatalog(<span class="string">&quot;myCatalog&quot;</span>);</span><br><span class="line">tableEnv.useDatabase(<span class="string">&quot;myDb&quot;</span>);</span><br><span class="line"><span class="comment">// 也可以通过以下方式访问对应的表</span></span><br><span class="line">tableEnv.from(<span class="string">&quot;not_the_current_catalog.not_the_current_db.my_table&quot;</span>);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 数据库操作</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create database</span></span><br><span class="line">catalog.createDatabase(<span class="string">&quot;mydb&quot;</span>, <span class="keyword">new</span> CatalogDatabaseImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// drop database</span></span><br><span class="line">catalog.dropDatabase(<span class="string">&quot;mydb&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// alter database</span></span><br><span class="line">catalog.alterDatabase(<span class="string">&quot;mydb&quot;</span>, <span class="keyword">new</span> CatalogDatabaseImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// get databse</span></span><br><span class="line">catalog.getDatabase(<span class="string">&quot;mydb&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// check if a database exist</span></span><br><span class="line">catalog.databaseExists(<span class="string">&quot;mydb&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// list databases in a catalog</span></span><br><span class="line">catalog.listDatabases(<span class="string">&quot;mycatalog&quot;</span>);</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>⭐ 表操作</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create table</span></span><br><span class="line">catalog.createTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogTableImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// drop table</span></span><br><span class="line">catalog.dropTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// alter table</span></span><br><span class="line">catalog.alterTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogTableImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// rename table</span></span><br><span class="line">catalog.renameTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="string">&quot;my_new_table&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// get table</span></span><br><span class="line">catalog.getTable(<span class="string">&quot;mytable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// check if a table exist or not</span></span><br><span class="line">catalog.tableExists(<span class="string">&quot;mytable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// list tables in a database</span></span><br><span class="line">catalog.listTables(<span class="string">&quot;mydb&quot;</span>);</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 视图操作</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create view</span></span><br><span class="line">catalog.createTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;myview&quot;</span>), <span class="keyword">new</span> CatalogViewImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// drop view</span></span><br><span class="line">catalog.dropTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;myview&quot;</span>), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// alter view</span></span><br><span class="line">catalog.alterTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogViewImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// rename view</span></span><br><span class="line">catalog.renameTable(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;myview&quot;</span>), <span class="string">&quot;my_new_view&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// get view</span></span><br><span class="line">catalog.getTable(<span class="string">&quot;myview&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// check if a view exist or not</span></span><br><span class="line">catalog.tableExists(<span class="string">&quot;mytable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// list views in a database</span></span><br><span class="line">catalog.listViews(<span class="string">&quot;mydb&quot;</span>);</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>⭐ 分区操作</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create view</span></span><br><span class="line">catalog.createPartition(</span><br><span class="line">    <span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>),</span><br><span class="line">    <span class="keyword">new</span> CatalogPartitionSpec(...),</span><br><span class="line">    <span class="keyword">new</span> CatalogPartitionImpl(...),</span><br><span class="line">    <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// drop partition</span></span><br><span class="line">catalog.dropPartition(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogPartitionSpec(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// alter partition</span></span><br><span class="line">catalog.alterPartition(</span><br><span class="line">    <span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>),</span><br><span class="line">    <span class="keyword">new</span> CatalogPartitionSpec(...),</span><br><span class="line">    <span class="keyword">new</span> CatalogPartitionImpl(...),</span><br><span class="line">    <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// get partition</span></span><br><span class="line">catalog.getPartition(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogPartitionSpec(...));</span><br><span class="line"></span><br><span class="line"><span class="comment">// check if a partition exist or not</span></span><br><span class="line">catalog.partitionExists(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogPartitionSpec(...));</span><br><span class="line"></span><br><span class="line"><span class="comment">// list partitions of a table</span></span><br><span class="line">catalog.listPartitions(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// list partitions of a table under a give partition spec</span></span><br><span class="line">catalog.listPartitions(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), <span class="keyword">new</span> CatalogPartitionSpec(...));</span><br><span class="line"></span><br><span class="line"><span class="comment">// list partitions of a table by expression filter</span></span><br><span class="line">catalog.listPartitionsByFilter(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;mytable&quot;</span>), Arrays.asList(epr1, ...));</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>⭐ 函数操作</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create function</span></span><br><span class="line">catalog.createFunction(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;myfunc&quot;</span>), <span class="keyword">new</span> CatalogFunctionImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// drop function</span></span><br><span class="line">catalog.dropFunction(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;myfunc&quot;</span>), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// alter function</span></span><br><span class="line">catalog.alterFunction(<span class="keyword">new</span> ObjectPath(<span class="string">&quot;mydb&quot;</span>, <span class="string">&quot;myfunc&quot;</span>), <span class="keyword">new</span> CatalogFunctionImpl(...), <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// get function</span></span><br><span class="line">catalog.getFunction(<span class="string">&quot;myfunc&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// check if a function exist or not</span></span><br><span class="line">catalog.functionExists(<span class="string">&quot;myfunc&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// list functions in a database</span></span><br><span class="line">catalog.listFunctions(<span class="string">&quot;mydb&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="5-3-SQL-任务参数配置"><a href="#5-3-SQL-任务参数配置" class="headerlink" title="5.3.SQL 任务参数配置"></a>5.3.SQL 任务参数配置</h2><p>关于 Flink SQL 详细的配置项及功能如下链接所示，详细内容大家可以点击链接去看，博主下面只介绍常用的性能优化参数及其功能：</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/config/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/config/</a></p>
<h3 id="5-3-1-参数设置方式"><a href="#5-3-1-参数设置方式" class="headerlink" title="5.3.1.参数设置方式"></a>5.3.1.参数设置方式</h3><p>Flink SQL 相关参数需要在 TableEnvironment 中设置。如下案例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// instantiate table environment</span></span><br><span class="line">TableEnvironment tEnv = ...</span><br><span class="line"></span><br><span class="line"><span class="comment">// access flink configuration</span></span><br><span class="line">Configuration configuration = tEnv.getConfig().getConfiguration();</span><br><span class="line"><span class="comment">// set low-level key-value options</span></span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.allow-latency&quot;</span>, <span class="string">&quot;5 s&quot;</span>);</span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.size&quot;</span>, <span class="string">&quot;5000&quot;</span>);</span><br></pre></td></tr></table></figure>


<p>具体参数分为以下 3 类：</p>
<ol>
<li>⭐ 运行时参数：优化 Flink SQL 任务在执行时的任务性能</li>
<li>⭐ 优化器参数：Flink SQL 任务在生成执行计划时，经过优化器优化生成更优的执行计划</li>
<li>⭐ 表参数：用于调整 Flink SQL table 的执行行为</li>
</ol>
<h3 id="5-3-2-运行时参数"><a href="#5-3-2-运行时参数" class="headerlink" title="5.3.2.运行时参数"></a>5.3.2.运行时参数</h3><p>用于优化 Flink SQL 任务在执行时的任务性能。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">默认值：100</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Integer</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：异步</span> <span class="string">lookup</span> <span class="string">join</span> <span class="string">中最大的异步</span> <span class="string">IO</span> <span class="string">执行数目</span></span><br><span class="line"><span class="attr">table.exec.async-lookup.buffer-capacity:</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：false</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：MiniBatch</span> <span class="string">优化是一种专门针对</span> <span class="string">unbounded</span> <span class="string">流任务的优化（即非窗口类应用），其机制是在</span> <span class="string">`允许的延迟时间间隔内`</span> <span class="string">以及</span> <span class="string">`达到最大缓冲记录数`</span> <span class="string">时触发以减少</span> <span class="string">`状态访问`</span> <span class="string">的优化，从而节约处理时间。下面两个参数一个代表</span> <span class="string">`允许的延迟时间间隔`，另一个代表</span> <span class="string">`达到最大缓冲记录数`。</span></span><br><span class="line"><span class="attr">table.exec.mini-batch.enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：0</span> <span class="string">ms</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Duration</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：此参数设置为多少就代表</span> <span class="string">MiniBatch</span> <span class="string">机制最大允许的延迟时间。注意这个参数要配合</span> <span class="string">`table.exec.mini-batch.enabled`</span> <span class="string">为</span> <span class="literal">true</span> <span class="string">时使用，而且必须大于</span> <span class="number">0</span> <span class="string">ms</span></span><br><span class="line"><span class="attr">table.exec.mini-batch.allow-latency:</span> <span class="number">0</span> <span class="string">ms</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：-1</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Long</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：此参数设置为多少就代表</span> <span class="string">MiniBatch</span> <span class="string">机制最大缓冲记录数。注意这个参数要配合</span> <span class="string">`table.exec.mini-batch.enabled`</span> <span class="string">为</span> <span class="literal">true</span> <span class="string">时使用，而且必须大于</span> <span class="number">0</span></span><br><span class="line"><span class="attr">table.exec.mini-batch.size:</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：-1</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Integer</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：可以用此参数设置</span> <span class="string">Flink</span> <span class="string">SQL</span> <span class="string">中算子的并行度，这个参数的优先级</span> <span class="string">`高于`</span> <span class="string">StreamExecutionEnvironment</span> <span class="string">中设置的并行度优先级，如果这个值设置为</span> <span class="number">-1</span><span class="string">，则代表没有设置，会默认使用</span> <span class="string">StreamExecutionEnvironment</span> <span class="string">设置的并行度</span></span><br><span class="line"><span class="attr">table.exec.resource.default-parallelism:</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：ERROR</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Enum【ERROR,</span> <span class="string">DROP】</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：表上的</span> <span class="string">NOT</span> <span class="literal">NULL</span> <span class="string">列约束强制不能将</span> <span class="literal">NULL</span> <span class="string">值插入表中。Flink</span> <span class="string">支持</span> <span class="string">`ERROR`（默认）和</span> <span class="string">`DROP`</span> <span class="string">配置。默认情况下，当</span> <span class="literal">NULL</span> <span class="string">值写入</span> <span class="string">NOT</span> <span class="literal">NULL</span> <span class="string">列时，Flink</span> <span class="string">会产生运行时异常。用户可以将行为更改为</span> <span class="string">`DROP`，直接删除此类记录，而不会引发异常。</span></span><br><span class="line"><span class="attr">table.exec.sink.not-null-enforcer:</span> <span class="string">ERROR</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：false</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：接入了</span> <span class="string">CDC</span> <span class="string">的数据源，上游</span> <span class="string">CDC</span> <span class="string">如果产生重复的数据，可以使用此参数在</span> <span class="string">Flink</span> <span class="string">数据源算子进行去重操作，去重会引入状态开销</span></span><br><span class="line"><span class="attr">table.exec.source.cdc-events-duplicate:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：0</span> <span class="string">ms</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Duration</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：如果此参数设置为</span> <span class="number">60</span> <span class="string">s，当</span> <span class="string">Source</span> <span class="string">算子在</span> <span class="number">60</span> <span class="string">s</span> <span class="string">内未收到任何元素时，这个</span> <span class="string">Source</span> <span class="string">将被标记为临时空闲，此时下游任务就不依赖此</span> <span class="string">Source</span> <span class="string">的</span> <span class="string">Watermark</span> <span class="string">来推进整体的</span> <span class="string">Watermark</span> <span class="string">了。</span></span><br><span class="line"><span class="string">//</span> <span class="string">默认值为</span> <span class="number">0</span> <span class="string">时，代表未启用检测源空闲。</span></span><br><span class="line"><span class="attr">table.exec.source.idle-timeout:</span> <span class="number">0</span> <span class="string">ms</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：0</span> <span class="string">ms</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Duration</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：指定空闲状态（即未更新的状态）将保留多长时间。尤其是在</span> <span class="string">unbounded</span> <span class="string">场景中很有用。默认</span> <span class="number">0</span> <span class="string">ms</span> <span class="string">为不清除空闲状态</span></span><br><span class="line"><span class="attr">table.exec.state.ttl:</span> <span class="number">0</span> <span class="string">ms</span></span><br></pre></td></tr></table></figure>

<p>其中上述参数中最常被用到为一下两种：</p>
<ol>
<li>⭐ MiniBatch 聚合</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">table.exec.mini-batch.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">table.exec.mini-batch.allow-latency:</span> <span class="number">60</span> <span class="string">s</span></span><br><span class="line"><span class="attr">table.exec.mini-batch.size:</span> <span class="number">1000000000</span></span><br></pre></td></tr></table></figure>

<p>具体使用场景如下链接：</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/tuning/#minibatch-aggregation">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/tuning/#minibatch-aggregation</a></p>
<ol start="2">
<li>⭐ state ttl 状态过期</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 状态清除如下流 SQL 案例场景很有用，随着实时任务的运行，前几天（即前几天的 p_date）的 state 不会被更新的情况下，就可以使用空闲状态删除机制把 state 给删除</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">  p_date</span><br><span class="line">  , <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> </span><br><span class="line">  p_date</span><br></pre></td></tr></table></figure>

<h3 id="5-3-3-优化器参数"><a href="#5-3-3-优化器参数" class="headerlink" title="5.3.3.优化器参数"></a>5.3.3.优化器参数</h3><p>Flink SQL 任务在生成执行计划时，优化生成更优的执行计划</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">默认值：AUTO</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：String</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：聚合阶段的策略。和</span> <span class="string">MapReduce</span> <span class="string">的</span> <span class="string">Combiner</span> <span class="string">功能类似，可以在数据</span> <span class="string">shuffle</span> <span class="string">前做一些提前的聚合，可以选择以下三种方式</span></span><br><span class="line"><span class="string">//</span> <span class="string">TWO_PHASE：强制使用具有</span> <span class="string">localAggregate</span> <span class="string">和</span> <span class="string">globalAggregate</span> <span class="string">的两阶段聚合。请注意，如果聚合函数不支持优化为两个阶段，Flink</span> <span class="string">仍将使用单阶段聚合。</span></span><br><span class="line"><span class="string">//</span> <span class="string">两阶段优化在计算</span> <span class="string">count，sum</span> <span class="string">时很有用，但是在计算</span> <span class="string">count</span> <span class="string">distinct</span> <span class="string">时需要注意，key</span> <span class="string">的稀疏程度，如果</span> <span class="string">key</span> <span class="string">不稀疏，那么很可能两阶段优化的效果会适得其反</span></span><br><span class="line"><span class="string">//</span> <span class="string">ONE_PHASE：强制使用只有</span> <span class="string">CompleteGlobalAggregate</span> <span class="string">的一个阶段聚合。</span></span><br><span class="line"><span class="string">//</span> <span class="string">AUTO：聚合阶段没有特殊的执行器。选择</span> <span class="string">TWO_PHASE</span> <span class="string">或者</span> <span class="string">ONE_PHASE</span> <span class="string">取决于优化器的成本。</span></span><br><span class="line"><span class="string">//</span> </span><br><span class="line"><span class="string">//</span> <span class="string">注意！！！：此优化在窗口聚合中会自动生效，但是在</span> <span class="string">unbounded</span> <span class="string">agg</span> <span class="string">中需要与</span> <span class="string">minibatch</span> <span class="string">参数相结合使用才会生效</span></span><br><span class="line"><span class="attr">table.optimizer.agg-phase-strategy:</span> <span class="string">AUTO</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：false</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：避免</span> <span class="string">group</span> <span class="string">by</span> <span class="string">计算</span> <span class="string">count</span> <span class="string">distinct\sum</span> <span class="string">distinct</span> <span class="string">数据时的</span> <span class="string">group</span> <span class="string">by</span> <span class="string">的</span> <span class="string">key</span> <span class="string">较少导致的数据倾斜，比如</span> <span class="string">group</span> <span class="string">by</span> <span class="string">中一个</span> <span class="string">key</span> <span class="string">的</span> <span class="string">distinct</span> <span class="string">要去重</span> <span class="string">500w</span> <span class="string">数据，而另一个</span> <span class="string">key</span> <span class="string">只需要去重</span> <span class="number">3</span> <span class="string">个</span> <span class="string">key，那么就需要先需要按照</span> <span class="string">distinct</span> <span class="string">的</span> <span class="string">key</span> <span class="string">进行分桶。将此参数设置为</span> <span class="literal">true</span> <span class="string">之后，下面的</span> <span class="string">table.optimizer.distinct-agg.split.bucket-num</span> <span class="string">可以用于决定分桶数是多少</span></span><br><span class="line"><span class="string">//</span> <span class="string">后文会介绍具体的案例</span></span><br><span class="line"><span class="attr">table.optimizer.distinct-agg.split.enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：1024</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Integer</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：避免</span> <span class="string">group</span> <span class="string">by</span> <span class="string">计算</span> <span class="string">count</span> <span class="string">distinct</span> <span class="string">数据时的</span> <span class="string">group</span> <span class="string">by</span> <span class="string">较少导致的数据倾斜。加了此参数之后，会先根据</span> <span class="string">group</span> <span class="string">by</span> <span class="string">key</span> <span class="string">结合</span> <span class="string">hash_code（distinct_key）进行分桶，然后再自动进行合桶。</span></span><br><span class="line"><span class="string">//</span> <span class="string">后文会介绍具体的案例</span></span><br><span class="line"><span class="attr">table.optimizer.distinct-agg.split.bucket-num:</span> <span class="number">1024</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：true</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：如果设置为</span> <span class="literal">true</span><span class="string">，Flink</span> <span class="string">优化器将会尝试找出重复的自计划并重用。默认为</span> <span class="literal">true</span> <span class="string">不需要改动</span></span><br><span class="line"><span class="attr">table.optimizer.reuse-sub-plan-enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：true</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：如果设置为</span> <span class="literal">true</span><span class="string">，Flink</span> <span class="string">优化器会找出重复使用的</span> <span class="string">table</span> <span class="string">source</span> <span class="string">并且重用。默认为</span> <span class="literal">true</span> <span class="string">不需要改动</span></span><br><span class="line"><span class="attr">table.optimizer.reuse-source-enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：true</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流任务</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：如果设置为</span> <span class="literal">true</span><span class="string">，Flink</span> <span class="string">优化器将会做谓词下推到</span> <span class="string">FilterableTableSource</span> <span class="string">中，将一些过滤条件前置，提升性能。默认为</span> <span class="literal">true</span> <span class="string">不需要改动</span></span><br><span class="line"><span class="attr">table.optimizer.source.predicate-pushdown-enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>其中上述参数中最常被用到为以下两种：</p>
<ol>
<li>⭐ 两阶段优化：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">table.optimizer.agg-phase-strategy:</span> <span class="string">AUTO</span></span><br></pre></td></tr></table></figure>

<p>在计算 count(1)，sum(col) 场景汇总提效很高，因为 count(1)，sum(col) 在经过本地 localAggregate 之后，每个 group by 的 key 就一个结果值。</p>
<p>注意！！！：此优化在窗口聚合中会自动生效，但是在 unbounded agg 中需要与 minibatch 参数相结合使用才会生效。</p>
<ol start="2">
<li>⭐ split 分桶：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">table.optimizer.distinct-agg.split.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">table.optimizer.distinct-agg.split.bucket-num:</span> <span class="number">1024</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv,</span><br><span class="line">    <span class="built_in">max</span>(<span class="built_in">cast</span>(server_timestamp <span class="keyword">as</span> <span class="type">bigint</span>)) <span class="keyword">as</span> server_timestamp</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 上述 SQL 打开了 split 分桶之后的效果等同于以下 SQL</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="built_in">sum</span>(bucket_uv) <span class="keyword">as</span> uv</span><br><span class="line">    , <span class="built_in">max</span>(server_timestamp) <span class="keyword">as</span> server_timestamp</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span></span><br><span class="line">        <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> bucket_uv,</span><br><span class="line">        <span class="built_in">max</span>(<span class="built_in">cast</span>(server_timestamp <span class="keyword">as</span> <span class="type">bigint</span>)) <span class="keyword">as</span> server_timestamp</span><br><span class="line">    <span class="keyword">FROM</span> source_table</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">        <span class="built_in">mod</span>(hash_code(user_id), <span class="number">1024</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>注意！！！：如果有多个 distinct key，则多个 distinct key 都会被作为分桶 key。</p>
<h3 id="5-3-4-表参数"><a href="#5-3-4-表参数" class="headerlink" title="5.3.4.表参数"></a>5.3.4.表参数</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">默认值：false</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Boolean</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：DML</span> <span class="string">SQL（即执行</span> <span class="string">insert</span> <span class="string">into</span> <span class="string">操作）是异步执行还是同步执行。默认为异步（false），即可以同时提交多个</span> <span class="string">DML</span> <span class="string">SQL</span> <span class="string">作业，如果设置为</span> <span class="literal">true</span><span class="string">，则为同步，第二个</span> <span class="string">DML</span> <span class="string">将会等待第一个</span> <span class="string">DML</span> <span class="string">操作执行结束之后再执行</span></span><br><span class="line"><span class="attr">table.dml-sync:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：64000</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Integer</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：Flink</span> <span class="string">SQL</span> <span class="string">会通过生产</span> <span class="string">java</span> <span class="string">代码来执行具体的</span> <span class="string">SQL</span> <span class="string">逻辑，但是</span> <span class="string">jvm</span> <span class="string">限制了一个</span> <span class="string">java</span> <span class="string">方法的最大长度不能超过</span> <span class="string">64KB，但是某些场景下</span> <span class="string">Flink</span> <span class="string">SQL</span> <span class="string">生产的</span> <span class="string">java</span> <span class="string">代码会超过</span> <span class="string">64KB，这时</span> <span class="string">jvm</span> <span class="string">就会直接报错。因此此参数可以用于限制生产的</span> <span class="string">java</span> <span class="string">代码的长度来避免超过</span> <span class="string">64KB，从而避免</span> <span class="string">jvm</span> <span class="string">报错。</span></span><br><span class="line"><span class="attr">table.generated-code.max-length:</span> <span class="number">64000</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：default</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：String</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：在使用天级别的窗口时，通常会遇到时区问题。举个例子，Flink</span> <span class="string">开一天的窗口，默认是按照</span> <span class="string">UTC</span> <span class="string">零时区进行划分，那么在北京时区划分出来的一天的窗口是第一天的早上</span> <span class="number">8</span><span class="string">:00</span> <span class="string">到第二天的早上</span> <span class="number">8</span><span class="string">:00，但是实际场景中想要的效果是第一天的早上</span> <span class="number">0</span><span class="string">:00</span> <span class="string">到第二天的早上</span> <span class="number">0</span><span class="string">:00</span> <span class="string">点。因此可以将此参数设置为</span> <span class="string">GMT+08:00</span> <span class="string">来解决这个问题。</span></span><br><span class="line"><span class="attr">table.local-time-zone:</span> <span class="string">default</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：default</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：Enum【BLINK、OLD】</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：Flink</span> <span class="string">SQL</span> <span class="string">planner，默认为</span> <span class="string">BLINK</span> <span class="string">planner，也可以选择</span> <span class="string">old</span> <span class="string">planner，但是推荐使用</span> <span class="string">BLINK</span> <span class="string">planner</span></span><br><span class="line"><span class="attr">table.planner:</span> <span class="string">BLINK</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span> <span class="string">默认值：default</span></span><br><span class="line"><span class="string">//</span> <span class="string">值类型：String</span></span><br><span class="line"><span class="string">//</span> <span class="string">流批任务：流、批任务都支持</span></span><br><span class="line"><span class="string">//</span> <span class="string">用处：Flink</span> <span class="string">解析一个</span> <span class="string">SQL</span> <span class="string">的解析器，目前有</span> <span class="string">Flink</span> <span class="string">SQL</span> <span class="string">默认的解析器和</span> <span class="string">Hive</span> <span class="string">SQL</span> <span class="string">解析器，其区别在于两种解析器支持的语法会有不同，比如</span> <span class="string">Hive</span> <span class="string">SQL</span> <span class="string">解析器支持</span> <span class="string">between</span> <span class="string">and、rlike</span> <span class="string">语法，Flink</span> <span class="string">SQL</span> <span class="string">不支持</span></span><br><span class="line"><span class="attr">table.sql-dialect:</span> <span class="string">default</span></span><br></pre></td></tr></table></figure>

<h2 id="5-4-SQL-性能调优"><a href="#5-4-SQL-性能调优" class="headerlink" title="5.4.SQL 性能调优"></a>5.4.SQL 性能调优</h2><p>本小节主要介绍 Flink SQL 中的聚合算子的优化，在某些场景下应用这些优化后，性能提升会非常大。本小节主要包含以下四种优化：</p>
<ol>
<li>⭐ <code>（常用）</code>MiniBatch 聚合：unbounded group agg 中，可以使用 minibatch 聚合来做到微批计算、访问状态、输出结果，避免每来一条数据就计算、访问状态、输出一次结果，从而减少访问 state 的时长（尤其是 Rocksdb）提升性能。</li>
<li>⭐ <code>（常用）</code>两阶段聚合：类似 MapReduce 中的 Combiner 的效果，可以先在 shuffle 数据之前先进行一次聚合，减少 shuffle 数据量</li>
<li>⭐ <code>（不常用）</code>split 分桶：在 count distinct、sum distinct 的去重的场景中，如果出现数据倾斜，任务性能会非常差，所以如果先按照 distinct key 进行分桶，将数据打散到各个 TM 进行计算，然后将分桶的结果再进行聚合，性能就会提升很大</li>
<li>⭐ <code>（常用）</code>去重 filter 子句：在 count distinct 中使用 filter 子句于 Hive SQL 中的 count(distinct if(xxx, user_id, null)) 子句，但是 state 中同一个 key 会按照 bit 位会进行复用，这对状态大小优化非常有用</li>
</ol>
<p>上面简单介绍了聚合场景的四种优化，下面详细介绍一下其最终效果以及实现原理。</p>
<h3 id="5-4-1-MiniBatch-聚合"><a href="#5-4-1-MiniBatch-聚合" class="headerlink" title="5.4.1.MiniBatch 聚合"></a>5.4.1.MiniBatch 聚合</h3><ol>
<li>⭐ 问题场景：默认情况下，unbounded agg 算子是逐条处理输入的记录，其处理流程如下：</li>
</ol>
<ul>
<li>⭐ 从状态中读取 accumulator；</li>
<li>⭐ 累加/撤回的数据记录至 accumulator；</li>
<li>⭐ 将 accumulator 写回状态；</li>
<li>⭐ 下一条记录将再次从流程 1 开始处理。</li>
</ul>
<p>但是上述处理流程的问题在于会增加 StateBackend 的访问性能开销（尤其是对于 RocksDB StateBackend）。</p>
<ol start="2">
<li>⭐ MiniBatch 聚合如何解决上述问题：其核心思想是将一组输入的数据缓存在聚合算子内部的缓冲区中。当输入的数据被触发处理时，每个 key 只需要访问一次状态后端，这样可以大大减少访问状态的时间开销从而获得更好的吞吐量。但是，其会增加一些数据产出的延迟，因为它会缓冲一些数据再去处理。因此如果你要做这个优化，需要提前做一下吞吐量和延迟之间的权衡，但是大多数情况下，buffer 数据的延迟都是可以被接受的。所以非常建议在 unbounded agg 场景下使用这项优化。</li>
</ol>
<p>下图说明了 MiniBatch 聚合如何减少状态访问的。</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/21.png" alt="MiniBatch"></p>
<p>上图展示了加 MiniBatch 和没加 MiniBatch 之前的执行区别。</p>
<ol start="3">
<li>⭐ 启用 MiniBatch 聚合的参数：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TableEnvironment tEnv = ...</span><br><span class="line"></span><br><span class="line">Configuration configuration = tEnv.getConfig().getConfiguration();</span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>); <span class="comment">// 启用 MiniBatch 聚合</span></span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.allow-latency&quot;</span>, <span class="string">&quot;5 s&quot;</span>); <span class="comment">// buffer 最多 5s 的输入数据记录</span></span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.size&quot;</span>, <span class="string">&quot;5000&quot;</span>); <span class="comment">// buffer 最多的输入数据记录数目</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意！！！</p>
<ol>
<li>⭐ <code>table.exec.mini-batch.allow-latency</code> 和 <code>table.exec.mini-batch.size</code> 两者只要其中一项满足条件就会执行 batch 访问状态操作。</li>
<li>⭐ 上述 MiniBatch 配置不会对 Window TVF 生效，因为！！！Window TVF 默认就会启用小批量优化，Window TVF 会将 buffer 的输入记录记录在托管内存中，而不是 JVM 堆中，因此 Window TVF 不会有 GC 过高或者 OOM 的问题。</li>
</ol>
</blockquote>
<h3 id="5-4-2-两阶段聚合"><a href="#5-4-2-两阶段聚合" class="headerlink" title="5.4.2.两阶段聚合"></a>5.4.2.两阶段聚合</h3><ol>
<li>⭐ 问题场景：在聚合数据处理场景中，很可能会由于热点数据导致数据倾斜，如下 SQL 所示，当 color = RED 为 50000w 条，而 color = BLUE 为 5 条，就产生了数据倾斜，而器数据处理的算子产生性能瓶颈。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> color, <span class="built_in">sum</span>(id)</span><br><span class="line"><span class="keyword">FROM</span> T</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> color</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ 两阶段聚合如何解决上述问题：其核心思想类似于 MapReduce 中的 Combiner + Reduce，先将聚合操作在本地做一次 local 聚合，这样 shuffle 到下游的数据就会变少。</li>
</ol>
<p>还是上面的 SQL 案例，如果在 50000w 条的 color = RED 的数据 shuffle 之前，在本地将 color = RED 的数据聚合成为 1 条结果，那么 shuffle 给下游的数据量就被极大地减少了。</p>
<p>下图说明了两阶段聚合是如何处理热点数据的：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/22.png" alt="两阶段聚合"></p>
<ol start="3">
<li>⭐ 启用两阶段聚合的参数：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TableEnvironment tEnv = ...</span><br><span class="line"></span><br><span class="line">Configuration configuration = tEnv.getConfig().getConfiguration();</span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>); <span class="comment">// 打开 minibatch</span></span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.allow-latency&quot;</span>, <span class="string">&quot;5 s&quot;</span>);</span><br><span class="line">configuration.setString(<span class="string">&quot;table.exec.mini-batch.size&quot;</span>, <span class="string">&quot;5000&quot;</span>);</span><br><span class="line">configuration.setString(<span class="string">&quot;table.optimizer.agg-phase-strategy&quot;</span>, <span class="string">&quot;TWO_PHASE&quot;</span>); <span class="comment">// 打开两阶段聚合</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意！！！</p>
<ol>
<li>⭐ 此优化在窗口聚合中会自动生效，大家在使用 Window TVF 时可以看到 localagg + globalagg 两部分</li>
<li>⭐ 但是在 unbounded agg 中需要与 MiniBatch 参数相结合使用才会生效。</li>
</ol>
</blockquote>
<h3 id="5-4-3-split-分桶"><a href="#5-4-3-split-分桶" class="headerlink" title="5.4.3.split 分桶"></a>5.4.3.split 分桶</h3><ol>
<li>⭐ 问题场景：使用两阶段聚合虽然能够很好的处理 count，sum 等常规聚合算子，但是在 count distinct，sum distinct 等算子的两阶段聚合效果在大多数场景下都不太满足预期。</li>
</ol>
<p>因为 100w 条数据的 count 聚合能够在 local 算子聚合为 1 条数据，但是 count distinct 聚合 100w 条在 local 聚合之后的结果和可能是 90w 条，那么依然会有数据倾斜，如下 SQL 案例所示：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> color, <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_id)</span><br><span class="line"><span class="keyword">FROM</span> T</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> color</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>⭐ split 分桶如何解决上述问题：其核心思想在于按照 distinct 的 key，即 user_id，先做数据的分桶，将数据打散，分散到 Flink 的多个 TM 上进行计算，然后再将数据合桶计算。打开 split 分桶之后的效果就等同于以下 SQL：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> color, <span class="built_in">SUM</span>(cnt)</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> color, <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_id) <span class="keyword">as</span> cnt</span><br><span class="line">    <span class="keyword">FROM</span> T</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> color, <span class="built_in">MOD</span>(HASH_CODE(user_id), <span class="number">1024</span>)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> color</span><br></pre></td></tr></table></figure>

<p>下图说明了 split 分桶的处理流程：</p>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/23.png" alt="split 聚合"></p>
<ol start="3">
<li>⭐ 启用 split 分桶的参数：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TableEnvironment tEnv = ...</span><br><span class="line"></span><br><span class="line">tEnv.getConfig()</span><br><span class="line">  .getConfiguration()</span><br><span class="line">  .setString(<span class="string">&quot;table.optimizer.distinct-agg.split.enabled&quot;</span>, <span class="string">&quot;true&quot;</span>);  <span class="comment">// 打开 split 分桶</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意！！！</p>
<ol>
<li>⭐ 如果有多个 distinct key，则多个 distinct key 都会被作为分桶 key。比如 count(distinct a)，sum(distinct b) 这种多个 distinct key 也支持。</li>
<li>⭐ 小伙伴萌自己写的 UDAF 不支持！</li>
<li>⭐ 其实此种优化很少使用，因为大家直接自己按照分桶的写法自己就可以写了，而且最后生成的算子图和自己写的 SQL 的语法也能对应的上</li>
</ol>
</blockquote>
<h3 id="5-4-4-去重-filter-子句"><a href="#5-4-4-去重-filter-子句" class="headerlink" title="5.4.4.去重 filter 子句"></a>5.4.4.去重 filter 子句</h3><ol>
<li>⭐ 问题场景：在一些场景下，用户可能需要从不同维度计算 UV，例如 Android 的 UV、iPhone 的 UV、Web 的 UV 和总 UV。许多用户会选择 CASE WHEN 支持此功能，如下 SQL 所示：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"> <span class="keyword">day</span>,</span><br><span class="line"> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_id) <span class="keyword">AS</span> total_uv,</span><br><span class="line"> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> flag <span class="keyword">IN</span> (<span class="string">&#x27;android&#x27;</span>, <span class="string">&#x27;iphone&#x27;</span>) <span class="keyword">THEN</span> user_id <span class="keyword">ELSE</span> <span class="keyword">NULL</span> <span class="keyword">END</span>) <span class="keyword">AS</span> app_uv,</span><br><span class="line"> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> flag <span class="keyword">IN</span> (<span class="string">&#x27;wap&#x27;</span>, <span class="string">&#x27;other&#x27;</span>) <span class="keyword">THEN</span> user_id <span class="keyword">ELSE</span> <span class="keyword">NULL</span> <span class="keyword">END</span>) <span class="keyword">AS</span> web_uv</span><br><span class="line"><span class="keyword">FROM</span> T</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span></span><br></pre></td></tr></table></figure>

<p>但是如果你想实现类似的效果，Flink SQL 提供了更好性能的写法，就是本小节的 filter 子句。</p>
<ol start="2">
<li>⭐ Filter 子句重写上述场景：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line"> <span class="keyword">day</span>,</span><br><span class="line"> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_id) <span class="keyword">AS</span> total_uv,</span><br><span class="line"> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_id) <span class="keyword">FILTER</span> (<span class="keyword">WHERE</span> flag <span class="keyword">IN</span> (<span class="string">&#x27;android&#x27;</span>, <span class="string">&#x27;iphone&#x27;</span>)) <span class="keyword">AS</span> app_uv,</span><br><span class="line"> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> user_id) <span class="keyword">FILTER</span> (<span class="keyword">WHERE</span> flag <span class="keyword">IN</span> (<span class="string">&#x27;web&#x27;</span>, <span class="string">&#x27;other&#x27;</span>)) <span class="keyword">AS</span> web_uv</span><br><span class="line"><span class="keyword">FROM</span> T</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span></span><br></pre></td></tr></table></figure>

<p>Filter 子句的优化点在于，Flink 会识别出三个去重的 key 都是 user_id，因此会把三个去重的 key 存在一个共享的状态中。而不是上文 case when 中的三个状态中。其具体实现区别在于：</p>
<ul>
<li>⭐ case when：total_uv、app_uv、web_uv 在去重时，state 是存在三个 MapState 中的，MapState key 为 user_id，value 为默认值，判断是否重复直接按照 key 是在 MapState 中的出现过进行判断。如果总 uv 为 1 亿，’android’, ‘iphone’ uv 为 5kw，’wap’, ‘other’ uv 为 5kw，则 3 个 state 要存储总共 2 亿条数据</li>
<li>⭐ filter：total_uv、app_uv、web_uv 在去重时，state 是存在一个 MapState 中的，MapState key 为 user_id，value 为 long，其中 long 的第一个 bit 位标识在计算总 uv 时此 user_id 是否来光顾哦，第二个标识 ‘android’, ‘iphone’，第三个标识 ‘wap’, ‘other’，因此在上述 case when 相同的数据量的情况下，总共只需要存储 1 亿条数据，state 容量减小了几乎 50%</li>
</ul>
<p>或者下面的场景也可以使用 filter 子句进行替换。</p>
<ol>
<li>⭐ 优化前：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="keyword">day</span></span><br><span class="line">    , app_typp</span><br><span class="line">    , <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    <span class="keyword">day</span></span><br><span class="line">    , app_type</span><br></pre></td></tr></table></figure>

<p>如果能够确定 app_type 是可以枚举的，比如为 android、iphone、web 三种，则可以使用 filter 子句做性能优化：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="keyword">day</span></span><br><span class="line">    , <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">filter</span> (<span class="keyword">where</span> app_type <span class="operator">=</span> <span class="string">&#x27;android&#x27;</span>) <span class="keyword">as</span> android_uv</span><br><span class="line">    , <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">filter</span> (<span class="keyword">where</span> app_type <span class="operator">=</span> <span class="string">&#x27;iphone&#x27;</span>) <span class="keyword">as</span> iphone_uv</span><br><span class="line">    , <span class="built_in">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">filter</span> (<span class="keyword">where</span> app_type <span class="operator">=</span> <span class="string">&#x27;web&#x27;</span>) <span class="keyword">as</span> web_uv</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    <span class="keyword">day</span></span><br></pre></td></tr></table></figure>

<p>经过上述优化之后，state 大小的优化效果也会是成倍提升的。</p>
<h2 id="5-5-SQL-Connector-扩展-自定义-Source-Sink"><a href="#5-5-SQL-Connector-扩展-自定义-Source-Sink" class="headerlink" title="5.5.SQL Connector 扩展 - 自定义 Source\Sink"></a>5.5.SQL Connector 扩展 - 自定义 Source\Sink</h2><h3 id="5-5-1-自定义-Source-Sink"><a href="#5-5-1-自定义-Source-Sink" class="headerlink" title="5.5.1.自定义 Source\Sink"></a>5.5.1.自定义 Source\Sink</h3><p>详细内容可见：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/xIXh8B_suAlKSp56aO5aEg">https://mp.weixin.qq.com/s/xIXh8B_suAlKSp56aO5aEg</a></p>
<h3 id="5-5-2-自定义-Source-Sink-的扩展接口"><a href="#5-5-2-自定义-Source-Sink-的扩展接口" class="headerlink" title="5.5.2.自定义 Source\Sink 的扩展接口"></a>5.5.2.自定义 Source\Sink 的扩展接口</h3><p>Flink SQL 中除了自定义的 Source 的基础接口之外，还提供了一部分扩展接口用于性能的优化、能力扩展，接下来详细进行介绍。在 Source\Sink 中主要包含了以下接口：</p>
<ol>
<li>⭐ Source 算子的接口：</li>
</ol>
<ul>
<li>⭐ <code>SupportsFilterPushDown</code>：将过滤条件下推到 Source 中提前过滤，减少下游处理的数据量。案例可见 <code>org.apache.flink.table.filesystem.FileSystemTableSource</code></li>
<li>⭐ <code>SupportsLimitPushDown</code>：将 limit 条目数下推到 Source 中提前限制处理的条目数。案例可见 <code>org.apache.flink.table.filesystem.FileSystemTableSource</code></li>
<li>⭐ <code>SupportsPartitionPushDown</code>：（常用于批处理场景）将带有 Partition 属性的 Source，将所有的 Partition 数据获取到之后，然后在 Source 决定哪个 Source 读取哪些 Partition 的数据，而不必在 Source 后过滤。比如 Hive 表的 Partition，将所有 Partition 获取到之后，然后决定某个 Source 应该读取哪些 Partition，详细可见 <code>org.apache.flink.table.filesystem.FileSystemTableSource</code>。</li>
<li>⭐ <code>SupportsProjectionPushDown</code>：将下游用到的字段下推到 Source 中，然后 Source 中只取这些字段，不使用的字段就不往下游发。案例可见 <code>org.apache.flink.connector.jdbc.table.JdbcDynamicTableSource</code></li>
<li>⭐ <code>SupportsReadingMetadata</code>：支持读取 Source 的 metadata，比如在 Kafka Source 中读取 Kafka 的 offset，写入时间戳等数据。案例可见 <code>org.apache.flink.streaming.connectors.kafka.table.KafkaDynamicSource</code></li>
<li>⭐ <code>SupportsWatermarkPushDown</code>：支持将 Watermark 的分配方式下推到 Source 中，比如 Kafka Source 中一个 Source Task 可以读取多个 Partition，然后为每个 Partition 单独分配 Watermark Generator，这样 Watermark 的生成粒度就是单 Partition，在事件时间下数据计算会更加准确。案例可见 <code>org.apache.flink.streaming.connectors.kafka.table.KafkaDynamicSource</code></li>
<li>⭐ <code>SupportsSourceWatermark</code>：支持自定义的 Source Watermark 分配方式，比如目前已有的 Watermark 分配方式不满足需求，需要自定义 Source 的 Watermark 生成方式，则可以实现此接口 + <code>在 DDL 中声明 SOURCE_WATERMARK()</code> 来声明使用自定义 Source 的 Watermark 生成方式。案例可见 <code>org.apache.flink.table.planner.connectors.ExternalDynamicSource</code></li>
</ul>
<ol start="2">
<li>⭐ Sink 算子的接口：</li>
</ol>
<ul>
<li>⭐ <code>SupportsOverwrite</code>：（常用于批处理场景）支持类似于 Hive SQL 的 insert overwrite table xxx 的能力，将已有分区内的数据进行覆盖。案例可见 <code>org.apache.flink.connectors.hive.HiveTableSink</code></li>
<li>⭐ <code>SupportsPartitioning</code>：（常用于批处理场景）支持类似于 Hive SQL 的 insert INTO xxx partition(key = ‘A’) xxx 的能力，支持将结果数据写入某个静态分区。案例可见 <code>org.apache.flink.connectors.hive.HiveTableSink</code></li>
<li>⭐ <code>SupportsWritingMetadata</code>：支持将 metadata 写入到 Sink 中，比如可以往 Kafka Sink 中写入 Kafka 的 timestamp、header 等。案例可见 <code>org.apache.flink.streaming.connectors.kafka.table.KafkaDynamicSink</code></li>
</ul>
<h3 id="5-5-3-Source：SupportsFilterPushDown"><a href="#5-5-3-Source：SupportsFilterPushDown" class="headerlink" title="5.5.3.Source：SupportsFilterPushDown"></a>5.5.3.Source：SupportsFilterPushDown</h3><ol>
<li><p>⭐ 应用场景：将 where 中的一些过滤条件下推到 Source 中进行处理，这样不需要的数据就可以不往下游发送了，性能会有提升。</p>
</li>
<li><p>⭐ 优化前：如下图 web ui 算子图，过滤条件都在 Source 节点之后有单独的 filter 算子进行承接</p>
</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/24.png" alt="filter 前"></p>
<ol start="3">
<li>⭐ 优化方案及实现：在 DynamicTableSource 中实现 SupportsFilterPushDown 接口的方法，具体实现方案如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Abilities_TableSource</span> <span class="keyword">implements</span> <span class="title">ScanTableSource</span></span></span><br><span class="line"><span class="class">        , <span class="title">SupportsFilterPushDown</span> // 过滤条件下推 </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;ResolvedExpression&gt; filters;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方法输入参数：List&lt;ResolvedExpression&gt; filters：引擎下推过来的过滤条件，然后在此方法中来决定哪些条件需要被下推</span></span><br><span class="line">    <span class="comment">// 方法输出参数：Result：Result 记录哪些过滤条件在 Source 中应用，哪些条件不能在 Source 中应用</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Result <span class="title">applyFilters</span><span class="params">(List&lt;ResolvedExpression&gt; filters)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.filters = <span class="keyword">new</span> LinkedList&lt;&gt;(filters);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.不上推任何过滤条件</span></span><br><span class="line">        <span class="comment">// Result.of(上推的 filter, 没有做上推的 filter)</span></span><br><span class="line"><span class="comment">//        return Result.of(Lists.newLinkedList(), filters);</span></span><br><span class="line">        <span class="comment">// 2.将所有的过滤条件都上推到 source</span></span><br><span class="line">        <span class="keyword">return</span> Result.of(filters, Lists.newLinkedList());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 优化效果：如下图 web ui 算子图，过滤条件在 Source 节点执行</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/25.png" alt="filter 后"></p>
<h3 id="5-5-4-Source：SupportsLimitPushDown"><a href="#5-5-4-Source：SupportsLimitPushDown" class="headerlink" title="5.5.4.Source：SupportsLimitPushDown"></a>5.5.4.Source：SupportsLimitPushDown</h3><ol>
<li><p>⭐ 应用场景：将 limit 子句下推到 Source 中，在批场景中可以过滤大部分不需要的数据</p>
</li>
<li><p>⭐ 优化前：如下图 web ui 算子图，limit 条件都在 Source 节点之后有单独的 Limit 算子进行承接</p>
</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/27.png" alt="limit 前"></p>
<ol start="3">
<li>⭐ 优化方案及实现：在 DynamicTableSource 中实现 SupportsLimitPushDown 接口的方法，具体实现方案如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Abilities_TableSource</span> <span class="keyword">implements</span> <span class="title">ScanTableSource</span></span></span><br><span class="line"><span class="class">        , <span class="title">SupportsLimitPushDown</span> // <span class="title">limit</span> 条件下推 </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> limit = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// 方法输入参数：long limit：引擎下推过来的 limit 条目数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyLimit</span><span class="params">(<span class="keyword">long</span> limit)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 将 limit 数接收到之后，然后在 SourceFunction 中可以进行过滤</span></span><br><span class="line">        <span class="keyword">this</span>.limit = limit;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 优化效果：如下图 web ui 算子图，limit 条件在 Source 节点执行</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/26.png" alt="limit 后"></p>
<h3 id="5-5-5-Source：SupportsProjectionPushDown"><a href="#5-5-5-Source：SupportsProjectionPushDown" class="headerlink" title="5.5.5.Source：SupportsProjectionPushDown"></a>5.5.5.Source：SupportsProjectionPushDown</h3><ol>
<li><p>⭐ 应用场景：将下游用到的字段下推到 Source 中，然后 Source 中可以做到只取这些字段，不使用的字段就不往下游发</p>
</li>
<li><p>⭐ 优化前：如下图 web ui 算子图，limit 条件都在 Source 节点之后有单独的 Limit 算子进行承接</p>
</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/28.png" alt="project 前"></p>
<ol start="3">
<li>⭐ 优化方案及实现：在 DynamicTableSource 中实现 SupportsProjectionPushDown 接口的方法，具体实现方案如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Abilities_TableSource</span> <span class="keyword">implements</span> <span class="title">ScanTableSource</span></span></span><br><span class="line"><span class="class">        , <span class="title">SupportsProjectionPushDown</span> // <span class="title">select</span> 字段下推 </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TableSchema tableSchema;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@SneakyThrows</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ScanRuntimeProvider <span class="title">getScanRuntimeProvider</span><span class="params">(ScanContext runtimeProviderContext)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create runtime classes that are shipped to the cluster</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> DeserializationSchema&lt;RowData&gt; deserializer = decodingFormat.createRuntimeDecoder(</span><br><span class="line">                runtimeProviderContext,</span><br><span class="line">                getSchemaWithMetadata(<span class="keyword">this</span>.tableSchema).toRowDataType());</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// 方法输入参数：</span></span><br><span class="line">    <span class="comment">// int[][] projectedFields：下游算子 `使用到的那些字段` 的下标，可以通过 projectSchemaWithMetadata 方法结合 table schema 信息生成 Source 新的需要写出 schema 信息</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyProjection</span><span class="params">(<span class="keyword">int</span>[][] projectedFields)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.tableSchema = projectSchemaWithMetadata(<span class="keyword">this</span>.tableSchema, projectedFields);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 优化效果：如下图 web ui 算子图，下游没有用到的字段直接在 Source 节点过滤掉，不输出</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/29.png" alt="project 后"></p>
<h3 id="5-5-6-Source：SupportsReadingMetadata"><a href="#5-5-6-Source：SupportsReadingMetadata" class="headerlink" title="5.5.6.Source：SupportsReadingMetadata"></a>5.5.6.Source：SupportsReadingMetadata</h3><ol>
<li><p>⭐ 应用场景：支持读取 Source 的 metadata，比如在 Kafka Source 中读取 Kafka 的 offset，写入时间戳等数据</p>
</li>
<li><p>⭐ 支持之前：比如想获取 Kafka 中的 offset 字段，在之前是不支持的</p>
</li>
<li><p>⭐ 支持方案及实现：在 DynamicTableSource 中实现 SupportsReadingMetadata 接口的方法，我们来看看 Flink Kafka Consumer 的具体实现方案：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注意！！！先执行 listReadableMetadata()，然后执行 applyReadableMetadata(xxx, xxx) 方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法输出参数：列出 Kafka Source 可以从 Kafka 中读取的 metadata 数据</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Map&lt;String, DataType&gt; <span class="title">listReadableMetadata</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Map&lt;String, DataType&gt; metadataMap = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// add value format metadata with prefix</span></span><br><span class="line">    valueDecodingFormat</span><br><span class="line">            .listReadableMetadata()</span><br><span class="line">            .forEach((key, value) -&gt; metadataMap.put(VALUE_METADATA_PREFIX + key, value));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// add connector metadata</span></span><br><span class="line">    Stream.of(ReadableMetadata.values())</span><br><span class="line">            .forEachOrdered(m -&gt; metadataMap.putIfAbsent(m.key, m.dataType));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> metadataMap;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法输入参数：</span></span><br><span class="line"><span class="comment">// List&lt;String&gt; metadataKeys：用户 SQL 中写入到 Sink 表的的 metadata 字段名称（metadataKeys）</span></span><br><span class="line"><span class="comment">// DataType producedDataType：将用户 SQL 写入到 Sink 表的所有字段的类型信息传进来，包括了 metadata 字段的类型信息</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyReadableMetadata</span><span class="params">(List&lt;String&gt; metadataKeys, DataType producedDataType)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> List&lt;String&gt; formatMetadataKeys =</span><br><span class="line">            metadataKeys.stream()</span><br><span class="line">                    .filter(k -&gt; k.startsWith(VALUE_METADATA_PREFIX))</span><br><span class="line">                    .collect(Collectors.toList());</span><br><span class="line">    <span class="keyword">final</span> List&lt;String&gt; connectorMetadataKeys = <span class="keyword">new</span> ArrayList&lt;&gt;(metadataKeys);</span><br><span class="line">    connectorMetadataKeys.removeAll(formatMetadataKeys);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Map&lt;String, DataType&gt; formatMetadata = valueDecodingFormat.listReadableMetadata();</span><br><span class="line">    <span class="keyword">if</span> (formatMetadata.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">final</span> List&lt;String&gt; requestedFormatMetadataKeys =</span><br><span class="line">                formatMetadataKeys.stream()</span><br><span class="line">                        .map(k -&gt; k.substring(VALUE_METADATA_PREFIX.length()))</span><br><span class="line">                        .collect(Collectors.toList());</span><br><span class="line">        valueDecodingFormat.applyReadableMetadata(requestedFormatMetadataKeys);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.metadataKeys = connectorMetadataKeys;</span><br><span class="line">    <span class="keyword">this</span>.producedDataType = producedDataType;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 支持之后的效果：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> KafkaTable (</span><br><span class="line">   <span class="operator">/</span><span class="operator">/</span> METADATA 字段用于声明可以从 Source 读取的 metadata</span><br><span class="line">   <span class="operator">/</span><span class="operator">/</span> 关于 Flink Kafka Source 可以读取的 metadata 见以下链接</span><br><span class="line">   <span class="operator">/</span><span class="operator">/</span> https:<span class="operator">/</span><span class="operator">/</span>nightlies.apache.org<span class="operator">/</span>flink<span class="operator">/</span>flink<span class="operator">-</span>docs<span class="operator">-</span><span class="keyword">release</span><span class="number">-1.13</span><span class="operator">/</span>docs<span class="operator">/</span>connectors<span class="operator">/</span><span class="keyword">table</span><span class="operator">/</span>kafka<span class="operator">/</span>#available<span class="operator">-</span>metadata</span><br><span class="line">  `event_time` <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> <span class="string">&#x27;timestamp&#x27;</span>,</span><br><span class="line">  `<span class="keyword">partition</span>` <span class="type">BIGINT</span> METADATA VIRTUAL,</span><br><span class="line">  `<span class="keyword">offset</span>` <span class="type">BIGINT</span> METADATA VIRTUAL,</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `item_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `behavior` STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;user_behavior&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;localhost:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>在后续的 DML SQL 语句中就可以正常使用这些 metadata 字段的数据了。</p>
<h3 id="5-5-7-Source：SupportsWatermarkPushDown"><a href="#5-5-7-Source：SupportsWatermarkPushDown" class="headerlink" title="5.5.7.Source：SupportsWatermarkPushDown"></a>5.5.7.Source：SupportsWatermarkPushDown</h3><ol>
<li><p>⭐ 应用场景：支持将 Watermark 的分配方式下推到 Source 中，比如 Kafka Source 中一个 Source Task 可以读取多个 Partition，Watermark 分配器下推到 Source 算子中后，就可以为每个 Partition 单独分配 Watermark Generator，这样 Watermark 的生成粒度就是 Kafka 的单 Partition，在事件时间下数据乱序会更小。</p>
</li>
<li><p>⭐ 支持之前：可以看到下图，Watermark 的分配是在 Source 节点之后的。</p>
</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/32.png" alt="watermark 前"></p>
<ol start="3">
<li>⭐ 支持方案及实现：在 DynamicTableSource 中实现 SupportsWatermarkPushDown 接口的方法，我们来看看 Flink Kafka Consumer 的具体实现方案：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 方法输入参数：</span></span><br><span class="line"><span class="comment">// WatermarkStrategy&lt;RowData&gt; watermarkStrategy：将用户 DDL 中的 watermark 生成方式传入</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyWatermark</span><span class="params">(WatermarkStrategy&lt;RowData&gt; watermarkStrategy)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.watermarkStrategy = watermarkStrategy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 支持之后的效果：</li>
</ol>
<p><img src="/blog-img/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/21_flinksql%E7%89%9B%E9%80%BC%E8%BD%B0%E8%BD%B0/31.png" alt="watermark 前"></p>
<h3 id="5-5-8-Sink：SupportsOverwrite"><a href="#5-5-8-Sink：SupportsOverwrite" class="headerlink" title="5.5.8.Sink：SupportsOverwrite"></a>5.5.8.Sink：SupportsOverwrite</h3><ol>
<li><p>⭐ 应用场景：（常用于批处理场景）支持类似于 Hive SQL 的 insert overwrite table xxx 的能力，将已有分区内的数据进行覆盖。</p>
</li>
<li><p>⭐ 支持方案及实现：在 DynamicTableSink 中实现 SupportsOverwrite 接口的方法，我们来看看 <code>HiveTableSink</code> 的具体实现方案：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DataStreamSink&lt;Row&gt; <span class="title">createBatchSink</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    DataStream&lt;RowData&gt; dataStream,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataStructureConverter converter,</span></span></span><br><span class="line"><span class="function"><span class="params">    StorageDescriptor sd,</span></span></span><br><span class="line"><span class="function"><span class="params">    HiveWriterFactory recordWriterFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">    OutputFileConfig fileNaming,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">int</span> parallelism)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">FileSystemOutputFormat.Builder&lt;Row&gt; builder = <span class="keyword">new</span> FileSystemOutputFormat.Builder&lt;&gt;();</span><br><span class="line">...</span><br><span class="line">--- <span class="number">2.</span> 将 overwrite 字段设置到 FileSystemOutputFormat 中，在后续写入数据到 Hive 表时，如果 overwrite = <span class="keyword">true</span>，则会覆盖直接覆盖已有数据</span><br><span class="line">builder.setOverwrite(overwrite);</span><br><span class="line">builder.setStaticPartitions(staticPartitionSpec);</span><br><span class="line">...</span><br><span class="line"><span class="keyword">return</span> dataStream</span><br><span class="line">        .map((MapFunction&lt;RowData, Row&gt;) value -&gt; (Row) converter.toExternal(value))</span><br><span class="line">        .writeUsingOutputFormat(builder.build())</span><br><span class="line">        .setParallelism(parallelism);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 方法输入参数：</span></span><br><span class="line"><span class="comment">// boolean overwrite：用户写的 SQL 中如果包含了 overwrite 关键字，则方法入参 overwrite = true</span></span><br><span class="line"><span class="comment">// 如果不包含 overwrite 关键字，则方法入参 overwrite = false</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyOverwrite</span><span class="params">(<span class="keyword">boolean</span> overwrite)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.overwrite = overwrite;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 支持之后的效果：</li>
</ol>
<p>支持在批任务中 insert overwrite xxx。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite hive_sink_table</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id</span><br><span class="line">    , order_amount</span><br><span class="line">    , server_timestamp_bigint</span><br><span class="line">    , server_timestamp </span><br><span class="line"><span class="keyword">from</span> hive_source_table</span><br></pre></td></tr></table></figure>

<h3 id="5-5-9-Sink：SupportsPartitioning"><a href="#5-5-9-Sink：SupportsPartitioning" class="headerlink" title="5.5.9.Sink：SupportsPartitioning"></a>5.5.9.Sink：SupportsPartitioning</h3><ol>
<li><p>⭐ 应用场景：（常用于批处理场景）支持类似于 Hive SQL 的 insert INTO xxx partition(key = ‘A’) 的能力，支持将结果数据写入某个静态分区。</p>
</li>
<li><p>⭐ 支持方案及实现：在 DynamicTableSink 中实现 SupportsPartitioning 接口的方法，我们来看看 <code>HiveTableSink</code> 的具体实现方案：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DataStreamSink&lt;Row&gt; <span class="title">createBatchSink</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    DataStream&lt;RowData&gt; dataStream,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataStructureConverter converter,</span></span></span><br><span class="line"><span class="function"><span class="params">    StorageDescriptor sd,</span></span></span><br><span class="line"><span class="function"><span class="params">    HiveWriterFactory recordWriterFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">    OutputFileConfig fileNaming,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">int</span> parallelism)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">FileSystemOutputFormat.Builder&lt;Row&gt; builder = <span class="keyword">new</span> FileSystemOutputFormat.Builder&lt;&gt;();</span><br><span class="line">...</span><br><span class="line">builder.setMetaStoreFactory(msFactory());</span><br><span class="line">builder.setOverwrite(overwrite);</span><br><span class="line">--- <span class="number">2.</span> 将 staticPartitionSpec 字段设置到 FileSystemOutputFormat 中，在后续写入数据到 Hive 表时，如果有静态分区，则会将数据写入到对应的静态分区中</span><br><span class="line">builder.setStaticPartitions(staticPartitionSpec);</span><br><span class="line">...</span><br><span class="line"><span class="keyword">return</span> dataStream</span><br><span class="line">        .map((MapFunction&lt;RowData, Row&gt;) value -&gt; (Row) converter.toExternal(value))</span><br><span class="line">        .writeUsingOutputFormat(builder.build())</span><br><span class="line">        .setParallelism(parallelism);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 方法输入参数：</span></span><br><span class="line"><span class="comment">// Map&lt;String, String&gt; partitionMap：用户写的 SQL 中如果包含了 partition(partition_key = &#x27;A&#x27;) 关键字</span></span><br><span class="line"><span class="comment">// 则方法入参 Map&lt;String, String&gt; partitionMap 的输入值转为 JSON 后为：&#123;&quot;partition_key&quot;: &quot;A&quot;&#125;</span></span><br><span class="line"><span class="comment">// 用户可以自己将方法入参的 partitionMap 保存到自定义变量中，后续写出到 Hive 表时进行使用</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyStaticPartition</span><span class="params">(Map&lt;String, String&gt; partitionMap)</span> </span>&#123;</span><br><span class="line">    staticPartitionSpec = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (String partitionCol : getPartitionKeys()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (partitionMap.containsKey(partitionCol)) &#123;</span><br><span class="line">            staticPartitionSpec.put(partitionCol, partitionMap.get(partitionCol));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 支持之后的效果：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite hive_sink_table <span class="keyword">partition</span>(<span class="type">date</span> <span class="operator">=</span> <span class="string">&#x27;2022-01-01&#x27;</span>)</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    user_id</span><br><span class="line">    , order_amount</span><br><span class="line">    , server_timestamp_bigint</span><br><span class="line">    , server_timestamp </span><br><span class="line"><span class="keyword">from</span> hive_source_table</span><br></pre></td></tr></table></figure>

<h3 id="5-5-9-Sink：SupportsWritingMetadata"><a href="#5-5-9-Sink：SupportsWritingMetadata" class="headerlink" title="5.5.9.Sink：SupportsWritingMetadata"></a>5.5.9.Sink：SupportsWritingMetadata</h3><ol>
<li><p>⭐ 应用场景：支持将 metadata 写入到 Sink 中。举例：可以往 Kafka Sink 中写入 Kafka 的 timestamp、header 等。案例可见 <code>org.apache.flink.streaming.connectors.kafka.table.KafkaDynamicSink</code></p>
</li>
<li><p>⭐ 支持方案及实现：在 DynamicTableSink 中实现 SupportsWritingMetadata 接口的方法，我们来看看 <code>KafkaDynamicSink</code> 的具体实现方案：</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注意！！！先执行 listWritableMetadata()，然后执行 applyWritableMetadata(xxx, xxx) 方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 方法返回参数 Map&lt;String, DataType&gt;：Flink 会获取到可以写入到 Kafka Sink 中的 metadata 都有哪些</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Map&lt;String, DataType&gt; <span class="title">listWritableMetadata</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Map&lt;String, DataType&gt; metadataMap = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</span><br><span class="line">    Stream.of(WritableMetadata.values())</span><br><span class="line">            .forEachOrdered(m -&gt; metadataMap.put(m.key, m.dataType));</span><br><span class="line">    <span class="keyword">return</span> metadataMap;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 方法输入参数：</span></span><br><span class="line"><span class="comment">// List&lt;String&gt; metadataKeys：通过解析用户的 SQL 语句，得出用户写出到 Sink 的 metadata 列信息，是 listWritableMetadata() 返回结果的子集</span></span><br><span class="line"><span class="comment">// DataType consumedDataType：写出到 Sink 字段的 DataType 类型信息，包括了写出的 metadata 列的类型信息（注意！！！metadata 列会被添加到最后一列）。</span></span><br><span class="line"><span class="comment">// 用户可以将这两个信息获取到，然后传入构造的 SinkFunction 中实现将对应字段写入 metadata 流程。</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyWritableMetadata</span><span class="params">(List&lt;String&gt; metadataKeys, DataType consumedDataType)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.metadataKeys = metadataKeys;</span><br><span class="line">    <span class="keyword">this</span>.consumedDataType = consumedDataType;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>⭐ 支持之后的效果：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> KafkaSourceTable (</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `item_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `behavior` STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;source_topic&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;localhost:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> KafkaSinkTable (</span><br><span class="line">  <span class="comment">-- 1. 定义 kafka 中 metadata 的 timestamp 列</span></span><br><span class="line">  `<span class="type">timestamp</span>` TIMESTAMP_LTZ(<span class="number">3</span>) METADATA,</span><br><span class="line">  `user_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `item_id` <span class="type">BIGINT</span>,</span><br><span class="line">  `behavior` STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;sink_topic&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;localhost:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> KafkaSinkTable</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="comment">-- 2. 写入到 kafka 的 metadata 中的 timestamp</span></span><br><span class="line">    <span class="built_in">cast</span>(<span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> TIMESTAMP_LTZ(<span class="number">3</span>)) <span class="keyword">as</span> `<span class="type">timestamp</span>`</span><br><span class="line">    , user_id</span><br><span class="line">    , item_id</span><br><span class="line">    , behavior</span><br><span class="line"><span class="keyword">from</span> KafkaSourceTable</span><br></pre></td></tr></table></figure>

<h2 id="5-6-SQL-Format-扩展"><a href="#5-6-SQL-Format-扩展" class="headerlink" title="5.6.SQL Format 扩展"></a>5.6.SQL Format 扩展</h2><p>关于怎么实现一个自定义的 Format 可以参考文章：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/STUC4trW-HA3cnrsqT-N6g">https://mp.weixin.qq.com/s/STUC4trW-HA3cnrsqT-N6g</a></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat.png" alt=" 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.png" alt=" 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Apache-Flink/" rel="tag"># Apache Flink</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/16_flink%20sql%20%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9Aflink-sql-batch-lookup-join/" rel="next" title="flink sql 知其所以然（十五）：改了改源码，实现了个 batch lookup join">
                <i class="fa fa-chevron-left"></i> flink sql 知其所以然（十五）：改了改源码，实现了个 batch lookup join
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/19_flink%20sql%20%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9Aflinksqludf/" rel="prev" title="flink sql 知其所以然（十八）：在 flink 中怎么使用 hive udf？">
                flink sql 知其所以然（十八）：在 flink 中怎么使用 hive udf？ <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/blog-img/avatar.jpeg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives%7C%7C%20archive">
              
                  <span class="site-state-item-count">115</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yangyichao-mango" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:1048262223@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">1.前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E7%AF%87"><span class="nav-number">2.</span> <span class="nav-text">2.基础概念篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-SQL-amp-Table-%E7%AE%80%E4%BB%8B%E5%8F%8A%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="nav-number">2.1.</span> <span class="nav-text">2.1.SQL &amp; Table 简介及运行环境</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-%E7%AE%80%E4%BB%8B"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1.简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2-SQL-%E5%92%8C-Table-API-%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E4%BE%9D%E8%B5%96"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2.SQL 和 Table API 运行环境依赖</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-SQL-amp-Table-%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%B8%B8%E7%94%A8-API"><span class="nav-number">2.2.</span> <span class="nav-text">2.2.SQL &amp; Table 的基本概念及常用 API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-%E4%B8%80%E4%B8%AA-SQL-Table-API-%E4%BB%BB%E5%8A%A1%E7%9A%84%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1.一个 SQL\Table API 任务的代码结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-SQL-%E4%B8%8A%E4%B8%8B%E6%96%87%EF%BC%9ATableEnvironment"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2.SQL 上下文：TableEnvironment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-3-SQL-%E4%B8%AD%E8%A1%A8%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.2.3.SQL 中表的概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-4-SQL-%E4%B8%B4%E6%97%B6%E8%A1%A8%E3%80%81%E6%B0%B8%E4%B9%85%E8%A1%A8"><span class="nav-number">2.2.4.</span> <span class="nav-text">2.2.4.SQL 临时表、永久表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-5-SQL-%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E8%A1%A8"><span class="nav-number">2.2.5.</span> <span class="nav-text">2.2.5.SQL 外部数据表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-6-SQL-%E8%A7%86%E5%9B%BE-VIEW"><span class="nav-number">2.2.6.</span> <span class="nav-text">2.2.6.SQL 视图 VIEW</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-7-%E4%B8%80%E4%B8%AA-SQL-%E6%9F%A5%E8%AF%A2%E6%A1%88%E4%BE%8B"><span class="nav-number">2.2.7.</span> <span class="nav-text">2.2.7.一个 SQL 查询案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-8-SQL-%E4%B8%8E-DataStream-API-%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="nav-number">2.2.8.</span> <span class="nav-text">2.2.8.SQL 与 DataStream API 的转换</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-SQL-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">2.3.SQL 数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-%E5%8E%9F%E5%AD%90%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.3.1.</span> <span class="nav-text">2.3.1.原子数据类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.3.2.</span> <span class="nav-text">2.3.2.复合数据类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-3-%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.3.3.</span> <span class="nav-text">2.3.3.用户自定义数据类型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-SQL-%E5%8A%A8%E6%80%81%E8%A1%A8-amp-%E8%BF%9E%E7%BB%AD%E6%9F%A5%E8%AF%A2"><span class="nav-number">2.4.</span> <span class="nav-text">2.4.SQL 动态表 &amp; 连续查询</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-1-SQL-%E5%BA%94%E7%94%A8%E4%BA%8E%E6%B5%81%E5%A4%84%E7%90%86%E7%9A%84%E6%80%9D%E8%B7%AF"><span class="nav-number">2.4.1.</span> <span class="nav-text">2.4.1.SQL 应用于流处理的思路</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-2-%E6%B5%81%E6%89%B9%E5%A4%84%E7%90%86%E7%9A%84%E5%BC%82%E5%90%8C%E7%82%B9%E5%8F%8A%E5%B0%86-SQL-%E5%BA%94%E7%94%A8%E4%BA%8E%E6%B5%81%E5%A4%84%E7%90%86%E6%A0%B8%E5%BF%83%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.4.2.</span> <span class="nav-text">2.4.2.流批处理的异同点及将 SQL 应用于流处理核心解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-3-SQL-%E6%B5%81%E5%A4%84%E7%90%86%E7%9A%84%E8%BE%93%E5%85%A5%EF%BC%9A%E8%BE%93%E5%85%A5%E6%B5%81%E6%98%A0%E5%B0%84%E4%B8%BA-SQL-%E5%8A%A8%E6%80%81%E8%BE%93%E5%85%A5%E8%A1%A8"><span class="nav-number">2.4.3.</span> <span class="nav-text">2.4.3.SQL 流处理的输入：输入流映射为 SQL 动态输入表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-4-SQL-%E6%B5%81%E5%A4%84%E7%90%86%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%9A%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF-SQL-%E8%BF%9E%E7%BB%AD%E6%9F%A5%E8%AF%A2"><span class="nav-number">2.4.4.</span> <span class="nav-text">2.4.4.SQL 流处理的计算：实时处理底层技术 - SQL 连续查询</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-5-SQL-%E6%B5%81%E5%A4%84%E7%90%86%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%EF%BC%9A%E5%8A%A8%E6%80%81%E8%A1%A8-amp-%E8%BF%9E%E7%BB%AD%E6%9F%A5%E8%AF%A2%E6%8A%80%E6%9C%AF%E7%9A%84%E4%B8%A4%E4%B8%AA%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B"><span class="nav-number">2.4.5.</span> <span class="nav-text">2.4.5.SQL 流处理实际应用：动态表 &amp; 连续查询技术的两个实战案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-6-SQL-%E8%BF%9E%E7%BB%AD%E6%9F%A5%E8%AF%A2%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%B1%BB%E5%9E%8B%EF%BC%9A%E6%9B%B4%E6%96%B0%EF%BC%88Update%EF%BC%89%E6%9F%A5%E8%AF%A2-amp-%E8%BF%BD%E5%8A%A0%EF%BC%88Append%EF%BC%89%E6%9F%A5%E8%AF%A2"><span class="nav-number">2.4.6.</span> <span class="nav-text">2.4.6.SQL 连续查询的两种类型：更新（Update）查询 &amp; 追加（Append）查询</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-7-SQL-%E6%B5%81%E5%A4%84%E7%90%86%E7%9A%84%E8%BE%93%E5%87%BA%EF%BC%9A%E5%8A%A8%E6%80%81%E8%BE%93%E5%87%BA%E8%A1%A8%E8%BD%AC%E5%8C%96%E4%B8%BA%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="nav-number">2.4.7.</span> <span class="nav-text">2.4.7.SQL 流处理的输出：动态输出表转化为输出数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-8-%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86%EF%BC%9ASQL-%E4%B8%8E%E5%85%B3%E7%B3%BB%E4%BB%A3%E6%95%B0"><span class="nav-number">2.4.8.</span> <span class="nav-text">2.4.8.补充知识：SQL 与关系代数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-SQL-%E7%9A%84%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7"><span class="nav-number">2.5.</span> <span class="nav-text">2.5.SQL 的时间属性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-1-Flink-%E4%B8%89%E7%A7%8D%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7%E7%AE%80%E4%BB%8B"><span class="nav-number">2.5.1.</span> <span class="nav-text">2.5.1.Flink 三种时间属性简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-2-Flink-%E4%B8%89%E7%A7%8D%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">2.5.2.</span> <span class="nav-text">2.5.2.Flink 三种时间属性的应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-3-SQL-%E6%8C%87%E5%AE%9A%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F"><span class="nav-number">2.5.3.</span> <span class="nav-text">2.5.3.SQL 指定时间属性的两种方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-4-SQL-%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4%E6%A1%88%E4%BE%8B"><span class="nav-number">2.5.4.</span> <span class="nav-text">2.5.4.SQL 事件时间案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-5-SQL-%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4%E6%A1%88%E4%BE%8B"><span class="nav-number">2.5.5.</span> <span class="nav-text">2.5.5.SQL 处理时间案例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-SQL-%E6%97%B6%E5%8C%BA%E9%97%AE%E9%A2%98"><span class="nav-number">2.6.</span> <span class="nav-text">2.6.SQL 时区问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-1-SQL-%E6%97%B6%E5%8C%BA%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.6.1.</span> <span class="nav-text">2.6.1.SQL 时区解决的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-1-SQL-%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.6.2.</span> <span class="nav-text">2.6.1.SQL 时间类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-2-%E6%97%B6%E5%8C%BA%E5%8F%82%E6%95%B0%E7%94%9F%E6%95%88%E7%9A%84-SQL-%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0"><span class="nav-number">2.6.3.</span> <span class="nav-text">2.6.2.时区参数生效的 SQL 时间函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-3-%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4%E5%92%8C%E6%97%B6%E5%8C%BA%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="nav-number">2.6.4.</span> <span class="nav-text">2.6.3.事件时间和时区应用案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-4-%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4%E5%92%8C%E6%97%B6%E5%8C%BA%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="nav-number">2.6.5.</span> <span class="nav-text">2.6.4.处理时间和时区应用案例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-5-SQL-%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E5%9C%A8%E6%B5%81%E6%89%B9%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BC%82%E5%90%8C"><span class="nav-number">2.6.6.</span> <span class="nav-text">2.6.5.SQL 时间函数返回在流批任务中的异同</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-SQL-%E8%AF%AD%E6%B3%95%E7%AF%87"><span class="nav-number">3.</span> <span class="nav-text">3.SQL 语法篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-DDL%EF%BC%9ACreate-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.1.</span> <span class="nav-text">3.1.DDL：Create 子句</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-%E5%BB%BA%E8%A1%A8%E8%AF%AD%E5%8F%A5"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1.建表语句</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-2-%E8%A1%A8%E4%B8%AD%E7%9A%84%E5%88%97"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.2.表中的列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-3-%E5%AE%9A%E4%B9%89-Watermark"><span class="nav-number">3.1.3.</span> <span class="nav-text">3.1.3.定义 Watermark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-4-Create-Table-With-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.1.4.</span> <span class="nav-text">3.1.4.Create Table With 子句</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-4-Create-Table-Like-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.1.5.</span> <span class="nav-text">3.1.4.Create Table Like 子句</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-DML%EF%BC%9AWith-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.2.</span> <span class="nav-text">3.2.DML：With 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-DML%EF%BC%9ASELECT-amp-WHERE-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.3.</span> <span class="nav-text">3.3.DML：SELECT &amp; WHERE 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-DML%EF%BC%9ASELECT-DISTINCT-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.4.</span> <span class="nav-text">3.4.DML：SELECT DISTINCT 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-5-DML%EF%BC%9A%E7%AA%97%E5%8F%A3%E8%81%9A%E5%90%88"><span class="nav-number">3.5.</span> <span class="nav-text">3.5.DML：窗口聚合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-1-%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3%EF%BC%88TUMBLE%EF%BC%89"><span class="nav-number">3.5.1.</span> <span class="nav-text">3.5.1.滚动窗口（TUMBLE）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-2-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%EF%BC%88HOP%EF%BC%89"><span class="nav-number">3.5.2.</span> <span class="nav-text">3.5.2.滑动窗口（HOP）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-3-Session-%E7%AA%97%E5%8F%A3%EF%BC%88SESSION%EF%BC%89"><span class="nav-number">3.5.3.</span> <span class="nav-text">3.5.3.Session 窗口（SESSION）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-4-%E6%B8%90%E8%BF%9B%E5%BC%8F%E7%AA%97%E5%8F%A3%EF%BC%88CUMULATE%EF%BC%89"><span class="nav-number">3.5.4.</span> <span class="nav-text">3.5.4.渐进式窗口（CUMULATE）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-5-Window-TVF-%E6%94%AF%E6%8C%81-Grouping-Sets%E3%80%81Rollup%E3%80%81Cube"><span class="nav-number">3.5.5.</span> <span class="nav-text">3.5.5.Window TVF 支持 Grouping Sets、Rollup、Cube</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-6-DML%EF%BC%9AGroup-%E8%81%9A%E5%90%88"><span class="nav-number">3.6.</span> <span class="nav-text">3.6.DML：Group 聚合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-6-1-Group-%E8%81%9A%E5%90%88%E6%94%AF%E6%8C%81-Grouping-sets%E3%80%81Rollup%E3%80%81Cube"><span class="nav-number">3.6.1.</span> <span class="nav-text">3.6.1.Group 聚合支持 Grouping sets、Rollup、Cube</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-7-DML%EF%BC%9AOver-%E8%81%9A%E5%90%88"><span class="nav-number">3.7.</span> <span class="nav-text">3.7.DML：Over 聚合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-8-DML%EF%BC%9AJoins"><span class="nav-number">3.8.</span> <span class="nav-text">3.8.DML：Joins</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-8-1-Regular-Join"><span class="nav-number">3.8.1.</span> <span class="nav-text">3.8.1.Regular Join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-8-2-Interval-Join%EF%BC%88%E6%97%B6%E9%97%B4%E5%8C%BA%E9%97%B4-Join%EF%BC%89"><span class="nav-number">3.8.2.</span> <span class="nav-text">3.8.2.Interval Join（时间区间 Join）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-8-3-Temporal-Join%EF%BC%88%E5%BF%AB%E7%85%A7-Join%EF%BC%89"><span class="nav-number">3.8.3.</span> <span class="nav-text">3.8.3.Temporal Join（快照 Join）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-8-4-Lookup-Join%EF%BC%88%E7%BB%B4%E8%A1%A8-Join%EF%BC%89"><span class="nav-number">3.8.4.</span> <span class="nav-text">3.8.4.Lookup Join（维表 Join）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-8-5-Array-Expansion%EF%BC%88%E6%95%B0%E7%BB%84%E5%88%97%E8%BD%AC%E8%A1%8C%EF%BC%89"><span class="nav-number">3.8.5.</span> <span class="nav-text">3.8.5.Array Expansion（数组列转行）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-8-6-Table-Function%EF%BC%88%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%97%E8%BD%AC%E8%A1%8C%EF%BC%89"><span class="nav-number">3.8.6.</span> <span class="nav-text">3.8.6.Table Function（自定义列转行）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-9-DML%EF%BC%9A%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C"><span class="nav-number">3.9.</span> <span class="nav-text">3.9 DML：集合操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-10-DML%EF%BC%9AOrder-By%E3%80%81Limit-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.10.</span> <span class="nav-text">3.10.DML：Order By、Limit 子句</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-10-1-Order-By-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.10.1.</span> <span class="nav-text">3.10.1.Order By 子句</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-10-2-Limit-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.10.2.</span> <span class="nav-text">3.10.2.Limit 子句</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-11-DML%EF%BC%9ATopN-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.11.</span> <span class="nav-text">3.11.DML：TopN 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-12-DML%EF%BC%9AWindow-TopN"><span class="nav-number">3.12.</span> <span class="nav-text">3.12.DML：Window TopN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-13-DML%EF%BC%9ADeduplication"><span class="nav-number">3.13.</span> <span class="nav-text">3.13.DML：Deduplication</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-14-EXPLAIN-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.14.</span> <span class="nav-text">3.14.EXPLAIN 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-15-USE-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.15.</span> <span class="nav-text">3.15.USE 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-16-SHOW-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.16.</span> <span class="nav-text">3.16.SHOW 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-17-LOAD%E3%80%81UNLOAD-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.17.</span> <span class="nav-text">3.17.LOAD、UNLOAD 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-18-SET%E3%80%81RESET-%E5%AD%90%E5%8F%A5"><span class="nav-number">3.18.</span> <span class="nav-text">3.18.SET、RESET 子句</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-19-SQL-Hints"><span class="nav-number">3.19.</span> <span class="nav-text">3.19.SQL Hints</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-SQL-UDF-%E7%AF%87"><span class="nav-number">4.</span> <span class="nav-text">4.SQL UDF 篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-SQL-%E5%87%BD%E6%95%B0%E7%9A%84%E5%BD%92%E7%B1%BB"><span class="nav-number">4.1.</span> <span class="nav-text">4.1.SQL 函数的归类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-SQL-%E5%87%BD%E6%95%B0%E7%9A%84%E5%BC%95%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="nav-number">4.2.</span> <span class="nav-text">4.2.SQL 函数的引用方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-%E7%B2%BE%E7%A1%AE%E5%87%BD%E6%95%B0"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1.精确函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-%E6%A8%A1%E7%B3%8A%E5%87%BD%E6%95%B0"><span class="nav-number">4.2.2.</span> <span class="nav-text">4.2.2.模糊函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-SQL-%E5%87%BD%E6%95%B0%E7%9A%84%E8%A7%A3%E6%9E%90%E9%A1%BA%E5%BA%8F"><span class="nav-number">4.3.</span> <span class="nav-text">4.3.SQL 函数的解析顺序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-1-%E7%B2%BE%E7%A1%AE%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.1.</span> <span class="nav-text">4.3.1.精确函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-%E6%A8%A1%E7%B3%8A%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.2.</span> <span class="nav-text">4.3.2.模糊函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-%E7%B3%BB%E7%BB%9F%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0"><span class="nav-number">4.4.</span> <span class="nav-text">4.4.系统内置函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-5-SQL-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%EF%BC%88UDF%EF%BC%89"><span class="nav-number">4.5.</span> <span class="nav-text">4.5.SQL 自定义函数（UDF）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-6-%E5%BC%80%E5%8F%91-UDF-%E4%B9%8B%E5%89%8D%E7%9A%84%E9%9C%80%E7%9F%A5%E4%BA%8B%E9%A1%B9"><span class="nav-number">4.6.</span> <span class="nav-text">4.6.开发 UDF 之前的需知事项</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-1-%E7%BB%A7%E6%89%BF-UDF-%E5%9F%BA%E7%B1%BB"><span class="nav-number">4.6.1.</span> <span class="nav-text">4.6.1.继承 UDF 基类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-2-%E5%AE%9E%E7%8E%B0-UDF-%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0"><span class="nav-number">4.6.2.</span> <span class="nav-text">4.6.2.实现 UDF 执行逻辑函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-3-%E6%B3%A8%E6%84%8F-UDF-%E5%85%A5%E5%8F%82%E3%80%81%E5%87%BA%E5%8F%82%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC"><span class="nav-number">4.6.3.</span> <span class="nav-text">4.6.3.注意 UDF 入参、出参类型推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-4-%E6%98%8E%E7%A1%AE-UDF-%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E6%98%AF%E5%AE%9A%E5%80%BC"><span class="nav-number">4.6.4.</span> <span class="nav-text">4.6.4.明确 UDF 输出结果是否是定值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-5-%E5%B7%A7%E5%A6%99%E8%BF%90%E7%94%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="nav-number">4.6.5.</span> <span class="nav-text">4.6.5.巧妙运用运行时上下文</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-7-SQL-%E6%A0%87%E9%87%8F%E5%87%BD%E6%95%B0%EF%BC%88Scalar-Function%EF%BC%89"><span class="nav-number">4.7.</span> <span class="nav-text">4.7.SQL 标量函数（Scalar Function）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-8-SQL-%E8%A1%A8%E5%80%BC%E5%87%BD%E6%95%B0%EF%BC%88Table-Function%EF%BC%89"><span class="nav-number">4.8.</span> <span class="nav-text">4.8.SQL 表值函数（Table Function）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-9-SQL-%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%EF%BC%88Aggregate-Function%EF%BC%89"><span class="nav-number">4.9.</span> <span class="nav-text">4.9.SQL 聚合函数（Aggregate Function）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-10-SQL-%E8%A1%A8%E5%80%BC%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%EF%BC%88Table-Aggregate-Function%EF%BC%89"><span class="nav-number">4.10.</span> <span class="nav-text">4.10.SQL 表值聚合函数（Table Aggregate Function）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-SQL-%E8%83%BD%E5%8A%9B%E6%89%A9%E5%B1%95%E7%AF%87"><span class="nav-number">5.</span> <span class="nav-text">5.SQL 能力扩展篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-SQL-UDF-%E6%89%A9%E5%B1%95-Module"><span class="nav-number">5.1.</span> <span class="nav-text">5.1.SQL UDF 扩展 - Module</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-1-Flink-SQL-Module-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">5.1.1.</span> <span class="nav-text">5.1.1.Flink SQL Module 应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-2-Flink-SQL-Module-%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D"><span class="nav-number">5.1.2.</span> <span class="nav-text">5.1.2.Flink SQL Module 功能介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-3-%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B%EF%BC%9AFlink-SQL-%E6%94%AF%E6%8C%81-Hive-UDF"><span class="nav-number">5.1.3.</span> <span class="nav-text">5.1.3.应用案例：Flink SQL 支持 Hive UDF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-SQL-%E5%85%83%E6%95%B0%E6%8D%AE%E6%89%A9%E5%B1%95-Catalog"><span class="nav-number">5.2.</span> <span class="nav-text">5.2.SQL 元数据扩展 - Catalog</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-1-Flink-Catalog-%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D"><span class="nav-number">5.2.1.</span> <span class="nav-text">5.2.1.Flink Catalog 功能介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-2-%E6%93%8D%E4%BD%9C-Catalog-%E7%9A%84-API"><span class="nav-number">5.2.2.</span> <span class="nav-text">5.2.2.操作 Catalog 的 API</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-SQL-%E4%BB%BB%E5%8A%A1%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="nav-number">5.3.</span> <span class="nav-text">5.3.SQL 任务参数配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-1-%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E6%96%B9%E5%BC%8F"><span class="nav-number">5.3.1.</span> <span class="nav-text">5.3.1.参数设置方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-2-%E8%BF%90%E8%A1%8C%E6%97%B6%E5%8F%82%E6%95%B0"><span class="nav-number">5.3.2.</span> <span class="nav-text">5.3.2.运行时参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-3-%E4%BC%98%E5%8C%96%E5%99%A8%E5%8F%82%E6%95%B0"><span class="nav-number">5.3.3.</span> <span class="nav-text">5.3.3.优化器参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-4-%E8%A1%A8%E5%8F%82%E6%95%B0"><span class="nav-number">5.3.4.</span> <span class="nav-text">5.3.4.表参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-SQL-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98"><span class="nav-number">5.4.</span> <span class="nav-text">5.4.SQL 性能调优</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-1-MiniBatch-%E8%81%9A%E5%90%88"><span class="nav-number">5.4.1.</span> <span class="nav-text">5.4.1.MiniBatch 聚合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-2-%E4%B8%A4%E9%98%B6%E6%AE%B5%E8%81%9A%E5%90%88"><span class="nav-number">5.4.2.</span> <span class="nav-text">5.4.2.两阶段聚合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-3-split-%E5%88%86%E6%A1%B6"><span class="nav-number">5.4.3.</span> <span class="nav-text">5.4.3.split 分桶</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-4-%E5%8E%BB%E9%87%8D-filter-%E5%AD%90%E5%8F%A5"><span class="nav-number">5.4.4.</span> <span class="nav-text">5.4.4.去重 filter 子句</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-SQL-Connector-%E6%89%A9%E5%B1%95-%E8%87%AA%E5%AE%9A%E4%B9%89-Source-Sink"><span class="nav-number">5.5.</span> <span class="nav-text">5.5.SQL Connector 扩展 - 自定义 Source\Sink</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-1-%E8%87%AA%E5%AE%9A%E4%B9%89-Source-Sink"><span class="nav-number">5.5.1.</span> <span class="nav-text">5.5.1.自定义 Source\Sink</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-2-%E8%87%AA%E5%AE%9A%E4%B9%89-Source-Sink-%E7%9A%84%E6%89%A9%E5%B1%95%E6%8E%A5%E5%8F%A3"><span class="nav-number">5.5.2.</span> <span class="nav-text">5.5.2.自定义 Source\Sink 的扩展接口</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-3-Source%EF%BC%9ASupportsFilterPushDown"><span class="nav-number">5.5.3.</span> <span class="nav-text">5.5.3.Source：SupportsFilterPushDown</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-4-Source%EF%BC%9ASupportsLimitPushDown"><span class="nav-number">5.5.4.</span> <span class="nav-text">5.5.4.Source：SupportsLimitPushDown</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-5-Source%EF%BC%9ASupportsProjectionPushDown"><span class="nav-number">5.5.5.</span> <span class="nav-text">5.5.5.Source：SupportsProjectionPushDown</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-6-Source%EF%BC%9ASupportsReadingMetadata"><span class="nav-number">5.5.6.</span> <span class="nav-text">5.5.6.Source：SupportsReadingMetadata</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-7-Source%EF%BC%9ASupportsWatermarkPushDown"><span class="nav-number">5.5.7.</span> <span class="nav-text">5.5.7.Source：SupportsWatermarkPushDown</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-8-Sink%EF%BC%9ASupportsOverwrite"><span class="nav-number">5.5.8.</span> <span class="nav-text">5.5.8.Sink：SupportsOverwrite</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-9-Sink%EF%BC%9ASupportsPartitioning"><span class="nav-number">5.5.9.</span> <span class="nav-text">5.5.9.Sink：SupportsPartitioning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-9-Sink%EF%BC%9ASupportsWritingMetadata"><span class="nav-number">5.5.10.</span> <span class="nav-text">5.5.9.Sink：SupportsWritingMetadata</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-6-SQL-Format-%E6%89%A9%E5%B1%95"><span class="nav-number">5.6.</span> <span class="nav-text">5.6.SQL Format 扩展</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yangyichao-mango</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">244.8k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://true.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://yangyichao-mango.github.io/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%B9%B2%E8%B4%A7%EF%BC%81FlinkSQL%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%85%A8%E6%96%876%E4%B8%87%E5%AD%97%E3%80%81110%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9%E3%80%81160%E5%BC%A0%E5%9B%BE%EF%BC%89/';
          this.page.identifier = '2021/11/15/wechat-blog/01_大数据/01_数据仓库/01_实时数仓/02_数据内容建设/03_one-engine/01_计算引擎/01_flink/01_flink-sql/20_史上最全干货！FlinkSQL成神之路（全文6万字、110个知识点、160张图）/';
          this.page.title = '史上最全干货！Flink SQL 成神之路（全文 18 万字、138 个案例、42 张图）';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://true.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
